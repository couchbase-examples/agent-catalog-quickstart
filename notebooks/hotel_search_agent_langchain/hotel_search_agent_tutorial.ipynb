{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Hotel Support Agent Tutorial\n",
        "\n",
        "This notebook demonstrates the Agent Catalog hotel support agent using LangChain with Couchbase vector store and Arize Phoenix evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary modules for the hotel support agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import getpass\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "import agentc\n",
        "import agentc_langchain\n",
        "import dotenv\n",
        "import requests\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.management.buckets import CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress verbose logging\n",
        "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"agentc_core\").setLevel(logging.WARNING)\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv(override=True)\n",
        "\n",
        "# Set default values for travel-sample bucket configuration\n",
        "DEFAULT_BUCKET = \"travel-sample\"\n",
        "DEFAULT_SCOPE = \"agentc_data\"\n",
        "DEFAULT_COLLECTION = \"hotel_data\"\n",
        "DEFAULT_INDEX = \"hotel_data_index\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Setup environment variables and configuration for the hotel support agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:40:11,568 - __main__ - INFO - Setting up environment variables...\n",
            "2025-07-28 14:40:11,569 - __main__ - INFO - Added /v1 suffix to endpoint: https://6u2le4tknje7yzkg.ai.cloud.couchbase.com/v1\n",
            "2025-07-28 14:40:11,570 - __main__ - INFO - Testing Capella AI connectivity...\n",
            "2025-07-28 14:40:12,767 - __main__ - INFO - ✅ Capella AI embedding test successful\n"
          ]
        }
      ],
      "source": [
        "def setup_capella_ai_config():\n",
        "    \"\"\"Setup Capella AI configuration - requires environment variables to be set.\"\"\"\n",
        "    required_capella_vars = [\n",
        "        \"CB_USERNAME\",\n",
        "        \"CB_PASSWORD\", \n",
        "        \"CAPELLA_API_ENDPOINT\",\n",
        "        \"CAPELLA_API_EMBEDDING_MODEL\",\n",
        "        \"CAPELLA_API_LLM_MODEL\",\n",
        "    ]\n",
        "    missing_vars = [var for var in required_capella_vars if not os.getenv(var)]\n",
        "    if missing_vars:\n",
        "        raise ValueError(f\"Missing required Capella AI environment variables: {missing_vars}\")\n",
        "\n",
        "    return {\n",
        "        \"endpoint\": os.getenv(\"CAPELLA_API_ENDPOINT\"),\n",
        "        \"embedding_model\": os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\"),\n",
        "        \"llm_model\": os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
        "    }\n",
        "\n",
        "\n",
        "def test_capella_connectivity():\n",
        "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
        "    try:\n",
        "        endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        if not endpoint:\n",
        "            logger.warning(\"CAPELLA_API_ENDPOINT not configured\")\n",
        "            return False\n",
        "\n",
        "        # Test embedding model (requires API key)\n",
        "        if os.getenv(\"CB_USERNAME\") and os.getenv(\"CB_PASSWORD\"):\n",
        "            api_key = base64.b64encode(\n",
        "                f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
        "            ).decode()\n",
        "\n",
        "            headers = {\n",
        "                \"Authorization\": f\"Basic {api_key}\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "            }\n",
        "\n",
        "            # Test embedding\n",
        "            logger.info(\"Testing Capella AI connectivity...\")\n",
        "            embedding_data = {\n",
        "                \"model\": os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\", \"intfloat/e5-mistral-7b-instruct\"),\n",
        "                \"input\": \"test connectivity\",\n",
        "            }\n",
        "\n",
        "            response = requests.post(\n",
        "                f\"{endpoint}/embeddings\", json=embedding_data, headers=headers\n",
        "            )\n",
        "            if response.status_code == 200:\n",
        "                logger.info(\"✅ Capella AI embedding test successful\")\n",
        "                return True\n",
        "            else:\n",
        "                logger.warning(f\"❌ Capella AI embedding test failed: {response.text}\")\n",
        "                return False\n",
        "        else:\n",
        "            logger.warning(\"Capella AI credentials not available\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"❌ Capella AI connectivity test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def _set_if_undefined(env_var: str, default_value: str = None):\n",
        "    \"\"\"Set environment variable if not already defined.\"\"\"\n",
        "    if not os.getenv(env_var):\n",
        "        if default_value is None:\n",
        "            value = getpass.getpass(f\"Enter {env_var}: \")\n",
        "        else:\n",
        "            value = default_value\n",
        "        os.environ[env_var] = value\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup required environment variables with defaults for travel-sample configuration.\"\"\"\n",
        "    logger.info(\"Setting up environment variables...\")\n",
        "\n",
        "    # Set default bucket configuration\n",
        "    _set_if_undefined(\"CB_BUCKET\", DEFAULT_BUCKET)\n",
        "    _set_if_undefined(\"CB_SCOPE\", DEFAULT_SCOPE)\n",
        "    _set_if_undefined(\"CB_COLLECTION\", DEFAULT_COLLECTION)\n",
        "    _set_if_undefined(\"CB_INDEX\", DEFAULT_INDEX)\n",
        "\n",
        "    # Required Couchbase connection variables\n",
        "    _set_if_undefined(\"CB_CONN_STRING\")\n",
        "    _set_if_undefined(\"CB_USERNAME\")\n",
        "    _set_if_undefined(\"CB_PASSWORD\")\n",
        "\n",
        "    # Optional Capella AI configuration\n",
        "    endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "    if endpoint:\n",
        "        # Ensure endpoint has /v1 suffix for OpenAI compatibility\n",
        "        if not endpoint.endswith(\"/v1\"):\n",
        "            endpoint = endpoint.rstrip(\"/\") + \"/v1\"\n",
        "            os.environ[\"CAPELLA_API_ENDPOINT\"] = endpoint\n",
        "            logger.info(f\"Added /v1 suffix to endpoint: {endpoint}\")\n",
        "\n",
        "    # Test Capella AI connectivity\n",
        "    test_capella_connectivity()\n",
        "\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CouchbaseClient Class\n",
        "\n",
        "Define the CouchbaseClient for all database operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
        "\n",
        "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
        "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "\n",
        "            # Use WAN profile for better timeout handling with remote clusters\n",
        "            options.apply_profile(\"wan_development\")\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=10))\n",
        "            logger.info(\"Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Setup collection - create scope and collection if they don't exist, but don't clear scope.\"\"\"\n",
        "        try:\n",
        "            # Ensure cluster connection\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            # For travel-sample bucket, assume it exists\n",
        "            if not self.bucket:\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"Connected to bucket '{self.bucket_name}'\")\n",
        "\n",
        "            # Setup scope\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
        "\n",
        "            # Setup collection - clear if exists, create if doesn't\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name\n",
        "                and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists:\n",
        "                logger.info(f\"Collection '{collection_name}' exists, clearing data...\")\n",
        "                # Clear existing data\n",
        "                self.clear_collection_data(scope_name, collection_name)\n",
        "            else:\n",
        "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
        "\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Create primary index\n",
        "            try:\n",
        "                self.cluster.query(\n",
        "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                ).execute()\n",
        "                logger.info(\"Primary index created successfully\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error creating primary index: {e}\")\n",
        "\n",
        "            logger.info(\"Collection setup complete\")\n",
        "            return self.bucket.scope(scope_name).collection(collection_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Clear all data from a collection.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "            \n",
        "            # Use N1QL to delete all documents with explicit execution\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "            \n",
        "            # Execute the query and get the results\n",
        "            rows = list(result)\n",
        "            \n",
        "            # Wait a moment for the deletion to propagate\n",
        "            time.sleep(2)\n",
        "            \n",
        "            # Verify collection is empty\n",
        "            count_query = f\"SELECT COUNT(*) as count FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            count_result = self.cluster.query(count_query)\n",
        "            count_row = list(count_result)[0]\n",
        "            remaining_count = count_row['count']\n",
        "            \n",
        "            if remaining_count == 0:\n",
        "                logger.info(f\"Collection cleared successfully, {remaining_count} documents remaining\")\n",
        "            else:\n",
        "                logger.warning(f\"Collection clear incomplete, {remaining_count} documents remaining\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error clearing collection data: {e}\")\n",
        "            # If N1QL fails, try to continue anyway\n",
        "            pass\n",
        "\n",
        "    def get_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Get a collection object.\"\"\"\n",
        "        key = f\"{scope_name}.{collection_name}\"\n",
        "        if key not in self._collections:\n",
        "            self._collections[key] = self.bucket.scope(scope_name).collection(collection_name)\n",
        "        return self._collections[key]\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        \"\"\"Setup vector search index.\"\"\"\n",
        "        try:\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
        "            else:\n",
        "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector search index: {e!s}\")\n",
        "\n",
        "    def load_hotel_data(self, scope_name, collection_name, index_name, embeddings):\n",
        "        \"\"\"Load hotel data into Couchbase.\"\"\"\n",
        "        try:\n",
        "            # Import hotel data loading function\n",
        "            sys.path.append(os.path.join(os.getcwd(), \"data\"))\n",
        "            from hotel_data import load_hotel_data_to_couchbase\n",
        "\n",
        "            # Load hotel data using the data loading script\n",
        "            load_hotel_data_to_couchbase(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embeddings=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "            logger.info(\"Hotel data loaded into vector store successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading hotel data: {e!s}\")\n",
        "\n",
        "    def setup_vector_store(\n",
        "        self, scope_name: str, collection_name: str, index_name: str, embeddings\n",
        "    ):\n",
        "        \"\"\"Setup vector store with hotel data.\"\"\"\n",
        "        try:\n",
        "            # Load hotel data\n",
        "            self.load_hotel_data(scope_name, collection_name, index_name, embeddings)\n",
        "\n",
        "            # Create vector store instance\n",
        "            vector_store = CouchbaseVectorStore(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embedding=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "\n",
        "            logger.info(\"Vector store setup complete\")\n",
        "            return vector_store\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector store: {e!s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Hotel Support Agent Setup\n",
        "\n",
        "Setup the hotel support agent with Agent Catalog integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:40:14,979 - __main__ - INFO - Successfully connected to Couchbase\n",
            "2025-07-28 14:40:16,092 - __main__ - INFO - Connected to bucket 'travel-sample'\n",
            "2025-07-28 14:40:17,920 - __main__ - INFO - Collection 'hotel_data' exists, clearing data...\n",
            "2025-07-28 14:40:17,921 - __main__ - INFO - Clearing data from travel-sample.agentc_data.hotel_data...\n",
            "2025-07-28 14:40:22,477 - __main__ - INFO - Collection cleared successfully, 0 documents remaining\n",
            "2025-07-28 14:40:26,476 - __main__ - INFO - Primary index created successfully\n",
            "2025-07-28 14:40:26,477 - __main__ - INFO - Collection setup complete\n",
            "2025-07-28 14:40:26,488 - __main__ - INFO - Loaded vector search index definition from agentcatalog_index.json\n",
            "2025-07-28 14:40:27,391 - __main__ - INFO - Vector search index 'hotel_data_index' already exists\n",
            "2025-07-28 14:40:27,721 - __main__ - INFO - ✅ Using Capella AI for embeddings\n",
            "2025-07-28 14:40:30,544 - hotel_data - INFO - Loading hotel data from travel-sample.inventory.hotel...\n",
            "2025-07-28 14:40:34,100 - hotel_data - INFO - Loaded 917 hotels from travel-sample.inventory.hotel\n",
            "2025-07-28 14:40:36,034 - hotel_data - INFO - Loading hotel data from travel-sample.inventory.hotel...\n",
            "2025-07-28 14:40:38,433 - hotel_data - INFO - Loaded 917 hotels from travel-sample.inventory.hotel\n",
            "Processing hotels: 100%|██████████| 917/917 [00:00<00:00, 118661.55it/s]\n",
            "2025-07-28 14:40:38,465 - hotel_data - INFO - Generated 917 hotel text embeddings\n",
            "2025-07-28 14:40:41,621 - hotel_data - INFO - Loading 917 hotel embeddings to travel-sample.agentc_data.hotel_data\n",
            "Loading hotel embeddings: 100%|██████████| 917/917 [00:37<00:00, 24.51it/s]\n",
            "2025-07-28 14:41:19,043 - hotel_data - INFO - Successfully loaded 917 hotel embeddings to vector store\n",
            "2025-07-28 14:41:19,046 - __main__ - INFO - Hotel data loaded into vector store successfully\n",
            "2025-07-28 14:41:22,156 - __main__ - INFO - Vector store setup complete\n",
            "2025-07-28 14:41:24,741 - __main__ - INFO - ✅ Using Capella AI LLM\n"
          ]
        }
      ],
      "source": [
        "def setup_hotel_support_agent():\n",
        "    \"\"\"Setup the hotel support agent with Agent Catalog integration.\"\"\"\n",
        "    try:\n",
        "        # Initialize Agent Catalog with single application span\n",
        "        catalog = agentc.catalog.Catalog()\n",
        "        application_span = catalog.Span(name=\"Hotel Support Agent\")\n",
        "\n",
        "        # Setup Couchbase connection and collections\n",
        "        couchbase_client = CouchbaseClient(\n",
        "            conn_string=os.getenv(\"CB_CONN_STRING\"),\n",
        "            username=os.getenv(\"CB_USERNAME\"),\n",
        "            password=os.getenv(\"CB_PASSWORD\"),\n",
        "            bucket_name=os.getenv(\"CB_BUCKET\", DEFAULT_BUCKET),\n",
        "        )\n",
        "        couchbase_client.connect()\n",
        "        couchbase_client.setup_collection(\n",
        "            os.getenv(\"CB_SCOPE\", DEFAULT_SCOPE),\n",
        "            os.getenv(\"CB_COLLECTION\", DEFAULT_COLLECTION)\n",
        "        )\n",
        "\n",
        "        # Setup vector index\n",
        "        try:\n",
        "            with open(\"agentcatalog_index.json\", \"r\") as file:\n",
        "                index_definition = json.load(file)\n",
        "            logger.info(\"Loaded vector search index definition from agentcatalog_index.json\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error loading index definition: {e!s}\")\n",
        "        \n",
        "        couchbase_client.setup_vector_search_index(\n",
        "            index_definition, os.getenv(\"CB_SCOPE\", DEFAULT_SCOPE)\n",
        "        )\n",
        "\n",
        "        # Setup embeddings using Capella AI\n",
        "        try:\n",
        "            if (\n",
        "                os.getenv(\"CB_USERNAME\")\n",
        "                and os.getenv(\"CB_PASSWORD\")\n",
        "                and os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "                and os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\")\n",
        "            ):\n",
        "                api_key = base64.b64encode(\n",
        "                    f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
        "                ).decode()\n",
        "                embeddings = OpenAIEmbeddings(\n",
        "                    model=os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\"),\n",
        "                    api_key=api_key,\n",
        "                    base_url=os.getenv(\"CAPELLA_API_ENDPOINT\"),\n",
        "                )\n",
        "                logger.info(\"✅ Using Capella AI for embeddings\")\n",
        "            else:\n",
        "                raise ValueError(\"Capella AI credentials not available\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Capella AI embeddings failed: {e}\")\n",
        "            raise RuntimeError(\"Capella AI embeddings required for this configuration\")\n",
        "\n",
        "        couchbase_client.setup_vector_store(\n",
        "            os.getenv(\"CB_SCOPE\", DEFAULT_SCOPE),\n",
        "            os.getenv(\"CB_COLLECTION\", DEFAULT_COLLECTION),\n",
        "            os.getenv(\"CB_INDEX\", DEFAULT_INDEX),\n",
        "            embeddings,\n",
        "        )\n",
        "\n",
        "        # Setup LLM with Agent Catalog callback - try Capella AI first, fallback to OpenAI\n",
        "        try:\n",
        "            # Create API key for Capella AI\n",
        "            api_key = base64.b64encode(\n",
        "                f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
        "            ).decode()\n",
        "\n",
        "            llm = ChatOpenAI(\n",
        "                api_key=api_key,\n",
        "                base_url=os.getenv(\"CAPELLA_API_ENDPOINT\"),\n",
        "                model=os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
        "                temperature=0,\n",
        "                callbacks=[agentc_langchain.chat.Callback(span=application_span)],\n",
        "            )\n",
        "            # Test the LLM works\n",
        "            llm.invoke(\"Hello\")\n",
        "            logger.info(\"✅ Using Capella AI LLM\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Capella AI LLM failed: {e}\")\n",
        "            logger.info(\"🔄 Falling back to OpenAI LLM...\")\n",
        "            _set_if_undefined(\"OPENAI_API_KEY\")\n",
        "            llm = ChatOpenAI(\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                model=\"gpt-4o\",\n",
        "                temperature=0,\n",
        "                callbacks=[agentc_langchain.chat.Callback(span=application_span)],\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI LLM as fallback\")\n",
        "\n",
        "        # Load tools and create agent\n",
        "        tool_search = catalog.find(\"tool\", name=\"search_vector_database\")\n",
        "        if not tool_search:\n",
        "            raise ValueError(\n",
        "                \"Could not find search_vector_database tool. Make sure it's indexed with 'agentc index tools/'\"\n",
        "            )\n",
        "\n",
        "        tools = [\n",
        "            Tool(\n",
        "                name=tool_search.meta.name,\n",
        "                description=tool_search.meta.description,\n",
        "                func=tool_search.func,\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        hotel_prompt = catalog.find(\"prompt\", name=\"hotel_search_assistant\")\n",
        "        if not hotel_prompt:\n",
        "            raise ValueError(\n",
        "                \"Could not find hotel_search_assistant prompt in catalog. Make sure it's indexed with 'agentc index prompts/'\"\n",
        "            )\n",
        "\n",
        "        custom_prompt = PromptTemplate(\n",
        "            template=hotel_prompt.content.strip(),\n",
        "            input_variables=[\"input\", \"agent_scratchpad\"],\n",
        "            partial_variables={\n",
        "                \"tools\": \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools]),\n",
        "                \"tool_names\": \", \".join([tool.name for tool in tools]),\n",
        "            },\n",
        "        )\n",
        "\n",
        "        def handle_parsing_error(error) -> str:\n",
        "            \"\"\"Custom error handler for parsing errors that guides agent back to ReAct format.\"\"\"\n",
        "            logger.warning(f\"Parsing error occurred: {error}\")\n",
        "            return \"\"\"I need to use the correct format. Let me start over:\n",
        "\n",
        "Thought: I need to search for hotels using the search_vector_database tool\n",
        "Action: search_vector_database\n",
        "Action Input: \"\"\"\n",
        "\n",
        "        agent = create_react_agent(llm, tools, custom_prompt)\n",
        "\n",
        "        agent_executor = AgentExecutor(\n",
        "            agent=agent,\n",
        "            tools=tools,\n",
        "            verbose=True,\n",
        "            handle_parsing_errors=handle_parsing_error,\n",
        "            max_iterations=8,\n",
        "            max_execution_time=120,\n",
        "            early_stopping_method=\"force\",\n",
        "            return_intermediate_steps=True,\n",
        "        )\n",
        "\n",
        "        return agent_executor, application_span\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error setting up hotel support agent: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Setup the hotel support agent\n",
        "agent_executor, application_span = setup_hotel_support_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test Functions\n",
        "\n",
        "Define test functions to demonstrate the hotel support agent functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:41:24,863 - __main__ - INFO - Testing Hotel Data Loading from travel-sample\n",
            "2025-07-28 14:41:24,864 - __main__ - INFO - ==================================================\n",
            "2025-07-28 14:41:27,089 - __main__ - INFO - ✅ Hotel count in travel-sample.inventory.hotel: 917\n",
            "2025-07-28 14:41:29,131 - hotel_data - INFO - Loading hotel data from travel-sample.inventory.hotel...\n",
            "2025-07-28 14:41:31,519 - hotel_data - INFO - Loaded 917 hotels from travel-sample.inventory.hotel\n",
            "Processing hotels: 100%|██████████| 917/917 [00:00<00:00, 138755.97it/s]\n",
            "2025-07-28 14:41:31,528 - hotel_data - INFO - Generated 917 hotel text embeddings\n",
            "2025-07-28 14:41:31,530 - __main__ - INFO - ✅ Generated 917 hotel texts for embeddings\n",
            "2025-07-28 14:41:31,531 - __main__ - INFO - ✅ First hotel text sample: 'La Mirande Hotel in Avignon, France. Title: Avignon. Description: 5 star hotel housed in a 700 year old converted townhouse. Address: 4 place de la Mirande,F- AVIGNON. Price: €400 and up. State: Prov...\n",
            "2025-07-28 14:41:31,531 - __main__ - INFO - ✅ Data loading test completed successfully\n"
          ]
        }
      ],
      "source": [
        "def run_hotel_query(query: str, agent_executor, application_span):\n",
        "    \"\"\"Run a single hotel query with error handling.\"\"\"\n",
        "    logger.info(f\"🔍 Hotel Query: {query}\")\n",
        "    \n",
        "    try:\n",
        "        with application_span.new(f\"Hotel Query: {query}\") as query_span:\n",
        "            query_span[\"query\"] = query\n",
        "            \n",
        "            # Run the agent\n",
        "            response = agent_executor.invoke({\"input\": query})\n",
        "            result = response.get(\"output\", \"No response generated\")\n",
        "            \n",
        "            query_span[\"result\"] = result\n",
        "            logger.info(f\"🤖 AI Response: {result}\")\n",
        "            logger.info(\"✅ Query completed successfully\")\n",
        "            \n",
        "            return result\n",
        "            \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Query failed: {e}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def test_hotel_data_loading():\n",
        "    \"\"\"Test hotel data loading from travel-sample independently.\"\"\"\n",
        "    logger.info(\"Testing Hotel Data Loading from travel-sample\")\n",
        "    logger.info(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Import hotel data functions\n",
        "        sys.path.append(os.path.join(os.getcwd(), \"data\"))\n",
        "        from hotel_data import get_hotel_count, get_hotel_texts\n",
        "        \n",
        "        # Test hotel count\n",
        "        count = get_hotel_count()\n",
        "        logger.info(f\"✅ Hotel count in travel-sample.inventory.hotel: {count}\")\n",
        "        \n",
        "        # Test hotel text generation\n",
        "        texts = get_hotel_texts()\n",
        "        logger.info(f\"✅ Generated {len(texts)} hotel texts for embeddings\")\n",
        "        \n",
        "        if texts:\n",
        "            logger.info(f\"✅ First hotel text sample: {texts[0][:200]}...\")\n",
        "        \n",
        "        logger.info(\"✅ Data loading test completed successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Data loading test failed: {e}\")\n",
        "\n",
        "\n",
        "# Import queries for consistent testing\n",
        "sys.path.append(os.path.join(os.getcwd(), \"data\"))\n",
        "from queries import get_evaluation_queries\n",
        "\n",
        "# Test hotel data loading\n",
        "test_hotel_data_loading()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 1: Hotel Search in Giverny\n",
        "\n",
        "Search for hotels in Giverny with free breakfast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:41:31,535 - __main__ - INFO - 🔍 Hotel Query: Find hotels in Giverny with free breakfast\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find hotels in Giverny with free breakfast. First, I should figure out the best way to search for this. I remember that the tool available is search_vector_database, which uses semantic similarity. That means I should phrase my query in a way that matches what people might search for when looking for hotels.\n",
            "\n",
            "I think starting with \"Giverny hotels with free breakfast\" makes sense. It's straightforward and covers both the location and the specific amenity they're looking for. I should make sure to include all the important keywords so the tool can find the most relevant results.\n",
            "\n",
            "I wonder if there are any other ways to phrase it, but I think this is clear enough. Maybe adding \"near Eiffel Tower\" could help, but Giverny is already a specific location, so maybe it's better to keep it simple. I don't want to overcomplicate the query.\n",
            "\n",
            "Once I run the search, the tool will return the results. I should look for hotels that are in Giverny and offer free breakfast. I need to make sure the results are accurate and up-to-date. If there are multiple options, I should present them clearly in the final answer.\n",
            "\n",
            "I should also check if there are any errors or if the tool returns an error message. If it does, I might need to adjust the query or try again. But I think \"Giverny hotels with free breakfast\" is a solid starting point.\n",
            "\n",
            "Alright, time to use the tool with this query and see what comes up.\n",
            "</think>\n",
            "\n",
            "Thought: I need to search for hotels using the search_vector_database tool.  \n",
            "Action: search_vector_database  \n",
            "Action Input: Giverny hotels with free breakfast  \u001b[0m\u001b[36;1m\u001b[1;3mFOUND_6_HOTELS:\n",
            "HOTEL_1: Rosewood Chancery Court London in London, United Kingdom. Title: London/Holborn-Clerkenwell. Description: Try this hotel for a very upscale experience.  It is in an older building that has been beautifully renovated (formerly HQ of Pearl Assurance).  There is high-speed internet, but the charge is £15 per day.  The hotel is air-conditioned.  The staff is very helpful.  A great experience, if you can pay the rates.. Address: 252 High Holborn, WC1V 7EN. Directions: tube: Holborn. Phone: +44 20 7781-8888. Email: london@rosewoodhotels.com. Website: http://www.rosewoodhotels.com/en/london. Price: From £204. Type: hotel. Vacancy: Yes. Pets allowed: Yes. Free breakfast: Yes. Free internet: No. Free parking: Yes. Coordinates: 51.5175, -0.1179 (Score: 0.043)\n",
            "\n",
            "HOTEL_2: Carlsbad Seapointe Resort in Carlsbad, United States. Title: Carlsbad (California). Description: A seaside resort located adjacent to Carlsbad State Beach. Each condo has full kitchens, fireplaces and balconies with views. Two ocean view pools, lighted tennis and basketball courts, a putting green and fitness center.. Address: 6400 Surfside Lane. Toll-free: +1-877-477-7368. Website: http://www.carlsbadseapointe.com/. Check-in: 4PM. Check-out: 11AM. Price: $98-399. State: California. Type: hotel. Vacancy: No. Pets allowed: Yes. Free breakfast: Yes. Free internet: Yes. Free parking: Yes. Coordinates: 33.113201, -117.322228. Public likes: 6 likes (Score: 0.041)\n",
            "\n",
            "HOTEL_3: Carbieston Lodge in South Ayrshire, United Kingdom. Title: Prestwick. Description: Small detached cottage set in stunning country, ideal for birdwatching. Address: Ayr. Phone: +44 845 268 1553. Website: http://www.bookcottages.com/cottages/100-SDDE-carbieston-lodge.htm. Price: £332.00. Type: hotel. Vacancy: No. Also known as: Carbieston Lodge. Pets allowed: Yes. Free breakfast: Yes. Free internet: Yes. Free parking: No. Coordinates: 55.45, -4.55. Reviews: 6 customer reviews available. Review 1: The Encore property is beautiful. The strip-view room I had was quite spacious. There were no noise issues as some have mentioned from outside. The downfall came in service. The front desk was general.... Review 2: We've been in may resorts. This one is the best. I will come back again.. Public likes: 8 likes (Score: 0.040)\n",
            "\n",
            "HOTEL_4: Radisson Blu Hotel Birmingham in Birmingham, United Kingdom. Title: Birmingham (England). Description: The Radisson is located in a blue glass tower, with views over Birmingham's city centre, and is one of the few truly modern high-end hotels in the city.. Address: 12 Holloway Circus. Phone: +44 121 654-6000. Website: http://www.radissonblu.co.uk/hotel-birmingham. Type: hotel. Vacancy: No. Pets allowed: No. Free breakfast: Yes. Free internet: No. Free parking: No. Coordinates: 52.47537, -1.90022. Reviews: 3 customer reviews available. Review 1: Our experience at the Palmer House was outstanding. The customer service and amenities made our trip extra special. We truly enjoyed the best musical ever, Billy Elliott in the threatre district along.... Review 2: This is a much nicer building than most Hilton Hotels with beautiful architecture. It's situated in the heart of downtown in the Chicago loop. We didn't eat in the restaurant or drink in the bar, ther... (Score: 0.038)\n",
            "\n",
            "HOTEL_5: Lou Cigaloun in Orange, France. Title: Orange (France). Description: Three-star hotel.. Address: 4 rue Caristie. Price: From 45 to 144€.. State: Provence-Alpes-Côte d'Azur. Type: hotel. Vacancy: Yes. Pets allowed: No. Free breakfast: Yes. Free internet: Yes. Free parking: Yes. Coordinates: 44.1381253, 4.808372100000042. Public likes: 2 likes (Score: 0.029)\n",
            "\n",
            "HOTEL_6: Hallmark Hotel Derby in Derby, United Kingdom. Title: Derby. Description: Part of the Best Western chain of hotels. Sits opposite the Derby Mainline station.. Address: Midland Road. Phone: +44 1332 345894. Website: http://www.hallmarkhotels.co.uk/our_hotels/derby/. Type: hotel. Vacancy: Yes. Also known as: Midland Hotel. Pets allowed: No. Free breakfast: Yes. Free internet: No. Free parking: No. Coordinates: 52.915715, -1.464273. Reviews: 6 customer reviews available. Review 1: My partner and myself stayed in Chancellor Hotel for a week during our summer holiday in the States recently and I've only good things to say about this boutique hotel. I picked this hotel from the fa.... Review 2: With just a few hiccups (room request not fufilled right away and initially unfriendly front desk worker - but we think she was new b/c she didn't know much ...) everything turned out great. The rooms.... Public likes: 5 likes (Score: 0.028)\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:41:49,280 - __main__ - INFO - 🤖 AI Response: Based on the search results, here are hotels in Giverny with free breakfast: [list from search results]\n",
            "2025-07-28 14:41:49,281 - __main__ - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mFinal Answer: Based on the search results, here are hotels in Giverny with free breakfast: [list from search results]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Get evaluation queries for consistent testing\n",
        "eval_queries = get_evaluation_queries()\n",
        "\n",
        "result1 = run_hotel_query(\n",
        "    eval_queries[0],  # Giverny with free breakfast\n",
        "    agent_executor,\n",
        "    application_span\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 2: Hotel Search in Glossop\n",
        "\n",
        "Search for hotels in Glossop with free internet access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:41:49,288 - __main__ - INFO - 🔍 Hotel Query: I need a hotel in Glossop with free internet access\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find a hotel in Glossop with free internet access. First, I should figure out the best way to search for this. I remember that the tool available is search_vector_database, which uses semantic similarity to find hotels based on the query. \n",
            "\n",
            "I should start by constructing the query. The location is Glossop, and the key amenity is free internet access. Maybe I can phrase it as \"Glossop hotels with free internet\". That should cover both the location and the specific amenity they're looking for.\n",
            "\n",
            "I need to make sure I follow the format exactly. So, the first thought is to use the search tool. Then, the action is to call search_vector_database with the query. After that, I wait for the observation from the tool. Finally, I'll present the results based on that observation.\n",
            "\n",
            "I should double-check that I'm not adding any extra text or explanations, just the required format. Also, ensure that the search query is precise to get accurate results. Maybe I can also consider if there are any other amenities they might be interested in, but since the query is specific to free internet, I'll stick with that.\n",
            "\n",
            "Alright, putting it all together, the query is \"Glossop hotels with free internet\". I'll run this through the search tool and then present the results as the final answer.\n",
            "</think>\n",
            "\n",
            "Thought: I need to search for hotels using the search_vector_database tool  \n",
            "Action: search_vector_database  \n",
            "Action Input: Glossop hotels with free internet  \u001b[0m\u001b[36;1m\u001b[1;3mNO_RESULTS: No hotels found for 'Glossop hotels with free internet'\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:42:10,956 - __main__ - INFO - 🤖 AI Response: Based on the search results, there are no hotels found for 'Glossop hotels with free internet'.\n",
            "2025-07-28 14:42:10,956 - __main__ - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find a hotel in Glossop with free internet access. First, I should figure out the best way to search for this. I remember that the tool available is search_vector_database, which uses semantic similarity to find hotels based on the query.\n",
            "\n",
            "I should start by constructing the query. The location is Glossop, and the key amenity is free internet access. Maybe I can phrase it as \"Glossop hotels with free internet\". That should cover both the location and the specific amenity they're looking for.\n",
            "\n",
            "I need to make sure I follow the format exactly. So, the first thought is to use the search tool. Then, the action is to call search_vector_database with the query. After that, I wait for the observation from the tool. Finally, I'll present the results based on that observation.\n",
            "\n",
            "I should double-check that I'm not adding any extra text or explanations, just the required format. Also, ensure that the search query is precise to get accurate results. Maybe I can also consider if there are any other amenities they might be interested in, but since the query is specific to free internet, I'll stick with that.\n",
            "\n",
            "Alright, putting it all together, the query is \"Glossop hotels with free internet\". I'll run this through the search tool and then present the results as the final answer.\n",
            "\n",
            "Final Answer: Based on the search results, there are no hotels found for 'Glossop hotels with free internet'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result2 = run_hotel_query(\n",
        "    eval_queries[1],  # Glossop with free internet access\n",
        "    agent_executor,\n",
        "    application_span\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 3: Hotel Search in Helensburgh\n",
        "\n",
        "Search for hotels in Helensburgh with free breakfast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:42:10,972 - __main__ - INFO - 🔍 Hotel Query: Show me hotels in Helensburgh with free breakfast\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find hotels in Helensburgh that offer free breakfast. First, I should figure out the best way to search for this. I remember that the tool available is search_vector_database, which uses semantic similarity to find relevant hotels based on the query. \n",
            "\n",
            "I should start by crafting a query that accurately reflects what I'm looking for. The location is Helensburgh, and the key amenity is free breakfast. So, I'll phrase the query as \"Helensburgh hotels with free breakfast.\" This should help the tool understand the exact requirements.\n",
            "\n",
            "Next, I'll use the search_vector_database tool with this query. The tool will return the results, which I'll need to process. Once I have the results, I can present them to the user as the final answer.\n",
            "\n",
            "I should make sure to follow the format strictly, starting with the thought, then the action, followed by the observation, and ending with the final answer. No extra information or explanations should be added.\n",
            "</think>\n",
            "\n",
            "Thought: I need to search for hotels using the search_vector_database tool.  \n",
            "Action: search_vector_database  \n",
            "Action Input: Helensburgh hotels with free breakfast  \u001b[0m\u001b[36;1m\u001b[1;3mNO_RESULTS: No hotels found for 'Helensburgh hotels with free breakfast'\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:42:29,317 - __main__ - INFO - 🤖 AI Response: Based on the search results, there are no hotels found for 'Helensburgh hotels with free breakfast'.\n",
            "2025-07-28 14:42:29,317 - __main__ - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find hotels in Helensburgh that offer free breakfast. First, I should figure out the best way to search for this. I remember that the tool available is search_vector_database, which uses semantic similarity to find relevant hotels based on the query.\n",
            "\n",
            "I should start by crafting a query that accurately reflects what I'm looking for. The location is Helensburgh, and the key amenity is free breakfast. So, I'll phrase the query as \"Helensburgh hotels with free breakfast.\" This should help the tool understand the exact requirements.\n",
            "\n",
            "Next, I'll use the search_vector_database tool with this query. The tool will return the results, which I'll need to process. Once I have the results, I can present them to the user as the final answer.\n",
            "\n",
            "I should make sure to follow the format strictly, starting with the thought, then the action, followed by the observation, and ending with the final answer. No extra information or explanations should be added.\n",
            "\n",
            "Final Answer: Based on the search results, there are no hotels found for 'Helensburgh hotels with free breakfast'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result3 = run_hotel_query(\n",
        "    eval_queries[2],  # Helensburgh with free breakfast\n",
        "    agent_executor,\n",
        "    application_span\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Arize Phoenix Evaluation\n",
        "\n",
        "This section demonstrates how to evaluate the hotel support agent using Arize Phoenix observability platform. The evaluation includes:\n",
        "\n",
        "- **Relevance Scoring**: Using Phoenix RelevanceEvaluator to score how relevant responses are to queries\n",
        "- **QA Scoring**: Using Phoenix QAEvaluator to score answer quality\n",
        "- **Hallucination Detection**: Using Phoenix HallucinationEvaluator to detect fabricated information  \n",
        "- **Toxicity Detection**: Using Phoenix ToxicityEvaluator to detect harmful content\n",
        "- **Phoenix UI**: Real-time observability dashboard at `http://localhost:6006/`\n",
        "\n",
        "We'll run hotel search queries and evaluate the responses for quality and safety.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kaustavghosh/Desktop/agent-catalog-quickstart/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-07-28 14:42:30,494 - phoenix.config - INFO - 📋 Ensuring phoenix working directory: /Users/kaustavghosh/.phoenix\n",
            "2025-07-28 14:42:30,511 - phoenix.inferences.inferences - INFO - Dataset: phoenix_inferences_720b9b00-97ee-434b-b8fc-93bfb017792e initialized\n",
            "2025-07-28 14:42:35,352 - __main__ - INFO - ✅ Arize Phoenix evaluation components available\n",
            "2025-07-28 14:42:35,353 - phoenix.config - INFO - 📋 Ensuring phoenix working directory: /Users/kaustavghosh/.phoenix\n",
            "2025-07-28 14:42:35,503 - alembic.runtime.migration - INFO - Context impl SQLiteImpl.\n",
            "2025-07-28 14:42:35,504 - alembic.runtime.migration - INFO - Will assume transactional DDL.\n",
            "2025-07-28 14:42:35,533 - alembic.runtime.migration - INFO - Running upgrade  -> cf03bd6bae1d, init\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗️ The launch_app `port` parameter is deprecated and will be removed in a future release. Use the `PHOENIX_PORT` environment variable instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:42:35,683 - alembic.runtime.migration - INFO - Running upgrade cf03bd6bae1d -> 10460e46d750, datasets\n",
            "2025-07-28 14:42:35,689 - alembic.runtime.migration - INFO - Running upgrade 10460e46d750 -> 3be8647b87d8, add token columns to spans table\n",
            "2025-07-28 14:42:35,692 - alembic.runtime.migration - INFO - Running upgrade 3be8647b87d8 -> cd164e83824f, users and tokens\n",
            "2025-07-28 14:42:35,697 - alembic.runtime.migration - INFO - Running upgrade cd164e83824f -> 4ded9e43755f, create project_session table\n",
            "2025-07-28 14:42:35,706 - alembic.runtime.migration - INFO - Running upgrade 4ded9e43755f -> bc8fea3c2bc8, Add prompt tables\n",
            "2025-07-28 14:42:35,711 - alembic.runtime.migration - INFO - Running upgrade bc8fea3c2bc8 -> 2f9d1a65945f, Annotation config migrations\n",
            "/Users/kaustavghosh/.pyenv/versions/3.12.8/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "/Users/kaustavghosh/.pyenv/versions/3.12.8/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n",
            "2025-07-28 14:42:35,782 - alembic.runtime.migration - INFO - Running upgrade 2f9d1a65945f -> bb8139330879, create project trace retention policies table\n",
            "2025-07-28 14:42:35,788 - alembic.runtime.migration - INFO - Running upgrade bb8139330879 -> 8a3764fe7f1a, change jsonb to json for prompts\n",
            "2025-07-28 14:42:35,798 - alembic.runtime.migration - INFO - Running upgrade 8a3764fe7f1a -> 6a88424799fe, Add auth_method column to users table and migrate existing authentication data.\n",
            "2025-07-28 14:42:35,805 - alembic.runtime.migration - INFO - Running upgrade 6a88424799fe -> a20694b15f82, Cost-related tables\n",
            "2025-07-28 14:42:35,813 - phoenix.server.app - INFO - Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n",
            "2025-07-28 14:42:36,122 - __main__ - INFO - 🚀 Phoenix UI available at http://localhost:6006/\n",
            "2025-07-28 14:42:36,122 - __main__ - INFO - 🔍 Running evaluation query 1: Find hotels in Giverny with free breakfast\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find hotels in Giverny with free breakfast. First, I should figure out the best way to search for this. I remember that the tool available is search_vector_database, which uses semantic similarity. That means I should phrase my query in a way that matches what people might search for when looking for hotels.\n",
            "\n",
            "I think starting with \"Giverny hotels with free breakfast\" makes sense. It's straightforward and covers both the location and the specific amenity they're looking for. I should make sure to include all the important keywords so the tool can find the most relevant results.\n",
            "\n",
            "I wonder if there are any other ways to phrase it, but I think this is clear enough. Maybe adding \"near Eiffel Tower\" could help, but Giverny is already a specific location, so maybe it's better to keep it simple. I don't want to overcomplicate the query.\n",
            "\n",
            "Once I run the search, the tool will return the results. I should look for hotels that are in Giverny and offer free breakfast. I need to make sure the results are accurate and up-to-date. If there are multiple options, I should present them clearly in the final answer.\n",
            "\n",
            "I should also check if there are any errors or if the tool returns an error message. If it does, I might need to adjust the query or try again. But I think \"Giverny hotels with free breakfast\" is a solid starting point.\n",
            "\n",
            "Alright, time to use the tool with this query and see what comes up.\n",
            "</think>\n",
            "\n",
            "Thought: I need to search for hotels using the search_vector_database tool.  \n",
            "Action: search_vector_database  \n",
            "Action Input: Giverny hotels with free breakfast  \u001b[0m\u001b[36;1m\u001b[1;3mNO_RESULTS: No hotels found for 'Giverny hotels with free breakfast'\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:42:55,026 - __main__ - INFO - ✅ Query 1 completed successfully\n",
            "2025-07-28 14:42:55,027 - __main__ - INFO - 📊 Collected 1 responses for evaluation\n",
            "2025-07-28 14:42:55,028 - __main__ - INFO - Query: Find hotels in Giverny with free breakfast\n",
            "2025-07-28 14:42:55,029 - __main__ - INFO - Response: Based on the search results, there are no hotels found for 'Giverny hotels with free breakfast'....\n",
            "2025-07-28 14:42:55,029 - __main__ - INFO - Success: True\n",
            "2025-07-28 14:42:55,029 - __main__ - INFO - --------------------------------------------------\n",
            "2025-07-28 14:42:55,029 - __main__ - INFO - 💡 Visit Phoenix UI at http://localhost:6006/ to see detailed traces and evaluations\n",
            "2025-07-28 14:42:55,030 - __main__ - INFO - 💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mOkay, so I need to find hotels in Giverny with free breakfast. I'll start by using the search_vector_database tool with the query \"Giverny hotels with free breakfast\". If the tool returns results, I'll list them. If not, I'll let the user know there are no available hotels. \n",
            "\n",
            "Final Answer: Based on the search results, there are no hotels found for 'Giverny hotels with free breakfast'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_classify |          | 0/1 (0.0%) | ⏳ 00:04<? | ?it/s\n"
          ]
        }
      ],
      "source": [
        "# Import Phoenix evaluation components and queries system\n",
        "try:\n",
        "    import phoenix as px\n",
        "    from phoenix.evals import (\n",
        "        HALLUCINATION_PROMPT_RAILS_MAP,\n",
        "        HALLUCINATION_PROMPT_TEMPLATE,\n",
        "        QA_PROMPT_RAILS_MAP,\n",
        "        QA_PROMPT_TEMPLATE,\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        OpenAIModel,\n",
        "        llm_classify,\n",
        "    )\n",
        "    import pandas as pd\n",
        "    \n",
        "    # Import queries system\n",
        "    sys.path.append(os.path.join(os.getcwd(), \"data\"))\n",
        "    from queries import get_evaluation_queries, get_reference_answer\n",
        "    \n",
        "    ARIZE_AVAILABLE = True\n",
        "    logger.info(\"✅ Arize Phoenix evaluation components available\")\n",
        "\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Arize dependencies not available: {e}\")\n",
        "    logger.warning(\"Skipping evaluation section...\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "if ARIZE_AVAILABLE:\n",
        "    # Start Phoenix session for observability\n",
        "    try:\n",
        "        px.launch_app(port=6006)\n",
        "        logger.info(\"🚀 Phoenix UI available at http://localhost:6006/\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not start Phoenix UI: {e}\")\n",
        "\n",
        "    # Get evaluation queries - use first working query for demo\n",
        "    all_eval_queries = get_evaluation_queries()\n",
        "    hotel_demo_queries = [all_eval_queries[0]]  # Use first query: Giverny with free breakfast\n",
        "    \n",
        "    # Run demo queries and collect responses for evaluation\n",
        "    hotel_demo_results = []\n",
        "    \n",
        "    for i, query in enumerate(hotel_demo_queries, 1):\n",
        "        try:\n",
        "            logger.info(f\"🔍 Running evaluation query {i}: {query}\")\n",
        "            \n",
        "            # Run the agent\n",
        "            response = agent_executor.invoke({\"input\": query})\n",
        "            output = response.get(\"output\", \"No response generated\")\n",
        "    \n",
        "            hotel_demo_results.append({\n",
        "                \"query\": query,\n",
        "                \"response\": output,\n",
        "                \"query_type\": f\"hotel_demo_{i}\",\n",
        "                \"success\": True\n",
        "            })\n",
        "            \n",
        "            logger.info(f\"✅ Query {i} completed successfully\")\n",
        "    \n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query {i} failed: {e}\")\n",
        "            hotel_demo_results.append({\n",
        "                \"query\": query,\n",
        "                \"response\": f\"Error: {e!s}\",\n",
        "                \"query_type\": f\"hotel_demo_{i}\",\n",
        "                \"success\": False\n",
        "            })\n",
        "    \n",
        "    # Convert to DataFrame for evaluation\n",
        "    hotel_results_df = pd.DataFrame(hotel_demo_results)\n",
        "    logger.info(f\"📊 Collected {len(hotel_results_df)} responses for evaluation\")\n",
        "    \n",
        "    # Display results summary\n",
        "    for _, row in hotel_results_df.iterrows():\n",
        "        logger.info(f\"Query: {row['query']}\")\n",
        "        logger.info(f\"Response: {row['response'][:200]}...\")\n",
        "        logger.info(f\"Success: {row['success']}\")\n",
        "        logger.info(\"-\" * 50)\n",
        "    \n",
        "    logger.info(\"💡 Visit Phoenix UI at http://localhost:6006/ to see detailed traces and evaluations\")\n",
        "    logger.info(\"💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\")\n",
        "\n",
        "else:\n",
        "    logger.info(\"Arize evaluation not available - install phoenix-evals to enable evaluation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 14:42:55,051 - __main__ - INFO - 🔍 Running comprehensive Phoenix evaluations...\n",
            "2025-07-28 14:42:55,066 - __main__ - INFO - 🔍 Running Relevance Evaluation...\n",
            "2025-07-28 14:42:55,082 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
            "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:02<00:00 |  2.90s/it\n",
            "2025-07-28 14:42:57,980 - __main__ - INFO - ✅ Relevance Evaluation Results:\n",
            "2025-07-28 14:42:57,981 - __main__ - INFO -    Query: Find hotels in Giverny with free breakfast\n",
            "2025-07-28 14:42:57,981 - __main__ - INFO -    Relevance: relevant\n",
            "2025-07-28 14:42:57,981 - __main__ - INFO -    ------------------------------\n",
            "2025-07-28 14:42:57,981 - __main__ - INFO - 🔍 Running QA Evaluation...\n",
            "2025-07-28 14:42:57,994 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
            "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:05<00:00 |  5.64s/it\n",
            "2025-07-28 14:43:03,640 - __main__ - INFO - ✅ QA Evaluation Results:\n",
            "2025-07-28 14:43:03,640 - __main__ - INFO -    Query: Find hotels in Giverny with free breakfast\n",
            "2025-07-28 14:43:03,640 - __main__ - INFO -    QA Score: incorrect\n",
            "2025-07-28 14:43:03,640 - __main__ - INFO -    ------------------------------\n",
            "2025-07-28 14:43:03,641 - __main__ - INFO - 🔍 Running Hallucination Evaluation...\n",
            "2025-07-28 14:43:03,654 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
            "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:02<00:00 |  2.81s/it\n",
            "2025-07-28 14:43:06,469 - __main__ - INFO - ✅ Hallucination Evaluation Results:\n",
            "2025-07-28 14:43:06,469 - __main__ - INFO -    Query: Find hotels in Giverny with free breakfast\n",
            "2025-07-28 14:43:06,469 - __main__ - INFO -    Hallucination: hallucinated\n",
            "2025-07-28 14:43:06,470 - __main__ - INFO -    ------------------------------\n",
            "2025-07-28 14:43:06,470 - __main__ - INFO - 🔍 Running Toxicity Evaluation...\n",
            "2025-07-28 14:43:06,484 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
            "llm_classify |          | 0/1 (0.0%) | ⏳ 00:00<? | ?it/s 2025-07-28 14:43:06,491 - __main__ - INFO - ✅ Toxicity Evaluation Results:\n",
            "2025-07-28 14:43:06,492 - __main__ - INFO -    Query: Find hotels in Giverny with free breakfast\n",
            "2025-07-28 14:43:06,492 - __main__ - INFO -    Toxicity: None\n",
            "2025-07-28 14:43:06,492 - __main__ - INFO -    ------------------------------\n",
            "2025-07-28 14:43:06,493 - __main__ - INFO - 📊 EVALUATION SUMMARY\n",
            "2025-07-28 14:43:06,493 - __main__ - INFO - ==================================================\n",
            "2025-07-28 14:43:06,493 - __main__ - INFO - Query 1: Find hotels in Giverny with free breakfast\n",
            "2025-07-28 14:43:06,493 - __main__ - INFO -   Relevance: relevant\n",
            "2025-07-28 14:43:06,494 - __main__ - INFO -   QA Score: incorrect\n",
            "2025-07-28 14:43:06,494 - __main__ - INFO -   Hallucination: hallucinated\n",
            "2025-07-28 14:43:06,494 - __main__ - INFO -   Toxicity: None\n",
            "2025-07-28 14:43:06,494 - __main__ - INFO -   ----------------------------------------\n",
            "2025-07-28 14:43:06,495 - __main__ - INFO - ✅ All Phoenix evaluations completed successfully!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retries exhausted after 1 attempts: Missing template variable: 'input'\n"
          ]
        }
      ],
      "source": [
        "if ARIZE_AVAILABLE and len(hotel_demo_results) > 0:\n",
        "    logger.info(\"🔍 Running comprehensive Phoenix evaluations...\")\n",
        "    \n",
        "    # Setup evaluator LLM (using OpenAI for consistency)\n",
        "    evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.0)\n",
        "    \n",
        "    # Prepare evaluation data with proper column names for Phoenix evaluators\n",
        "    hotel_eval_data = []\n",
        "    for _, row in hotel_results_df.iterrows():\n",
        "        query = row[\"query\"]\n",
        "        reference = get_reference_answer(query)\n",
        "        hotel_eval_data.append({\n",
        "            \"input\": query,\n",
        "            \"output\": row[\"response\"],\n",
        "            \"reference\": reference,\n",
        "            \"text\": row[\"response\"]  # For toxicity evaluation\n",
        "        })\n",
        "    \n",
        "    hotel_eval_df = pd.DataFrame(hotel_eval_data)\n",
        "    \n",
        "    try:\n",
        "        # 1. Relevance Evaluation\n",
        "        logger.info(\"🔍 Running Relevance Evaluation...\")\n",
        "        hotel_relevance_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\", \"reference\"]],  # Fixed: use 'data' instead of 'dataframe'\n",
        "            model=evaluator_llm,\n",
        "            template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "            rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True  # Added for explanations\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Relevance Evaluation Results:\")\n",
        "        # Fixed: Handle DataFrame results correctly\n",
        "        if hasattr(hotel_relevance_results, \"columns\"):\n",
        "            relevance_labels = hotel_relevance_results[\"label\"].tolist() if \"label\" in hotel_relevance_results.columns else [\"unknown\"] * len(hotel_eval_data)\n",
        "            relevance_explanations = hotel_relevance_results[\"explanation\"].tolist() if \"explanation\" in hotel_relevance_results.columns else [\"No explanation\"] * len(hotel_eval_data)\n",
        "            \n",
        "            for i, label in enumerate(relevance_labels):\n",
        "                query = hotel_eval_data[i][\"input\"]\n",
        "                logger.info(f\"   Query: {query}\")\n",
        "                logger.info(f\"   Relevance: {label}\")\n",
        "                logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 2. QA Evaluation\n",
        "        logger.info(\"🔍 Running QA Evaluation...\")\n",
        "        hotel_qa_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\", \"output\", \"reference\"]],  # Fixed: use 'data'\n",
        "            model=evaluator_llm,\n",
        "            template=QA_PROMPT_TEMPLATE,\n",
        "            rails=list(QA_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ QA Evaluation Results:\")\n",
        "        if hasattr(hotel_qa_results, \"columns\"):\n",
        "            qa_labels = hotel_qa_results[\"label\"].tolist() if \"label\" in hotel_qa_results.columns else [\"unknown\"] * len(hotel_eval_data)\n",
        "            qa_explanations = hotel_qa_results[\"explanation\"].tolist() if \"explanation\" in hotel_qa_results.columns else [\"No explanation\"] * len(hotel_eval_data)\n",
        "            \n",
        "            for i, label in enumerate(qa_labels):\n",
        "                query = hotel_eval_data[i][\"input\"]\n",
        "                logger.info(f\"   Query: {query}\")\n",
        "                logger.info(f\"   QA Score: {label}\")\n",
        "                logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 3. Hallucination Evaluation\n",
        "        logger.info(\"🔍 Running Hallucination Evaluation...\")\n",
        "        hotel_hallucination_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\", \"reference\", \"output\"]],  # Fixed: use 'data'\n",
        "            model=evaluator_llm,\n",
        "            template=HALLUCINATION_PROMPT_TEMPLATE,\n",
        "            rails=list(HALLUCINATION_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Hallucination Evaluation Results:\")\n",
        "        if hasattr(hotel_hallucination_results, \"columns\"):\n",
        "            hallucination_labels = hotel_hallucination_results[\"label\"].tolist() if \"label\" in hotel_hallucination_results.columns else [\"unknown\"] * len(hotel_eval_data)\n",
        "            hallucination_explanations = hotel_hallucination_results[\"explanation\"].tolist() if \"explanation\" in hotel_hallucination_results.columns else [\"No explanation\"] * len(hotel_eval_data)\n",
        "            \n",
        "            for i, label in enumerate(hallucination_labels):\n",
        "                query = hotel_eval_data[i][\"input\"]\n",
        "                logger.info(f\"   Query: {query}\")\n",
        "                logger.info(f\"   Hallucination: {label}\")\n",
        "                logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 4. Toxicity Evaluation\n",
        "        logger.info(\"🔍 Running Toxicity Evaluation...\")\n",
        "        hotel_toxicity_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"text\"]],  # Fixed: use 'data'\n",
        "            model=evaluator_llm,\n",
        "            template=TOXICITY_PROMPT_TEMPLATE,\n",
        "            rails=list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Toxicity Evaluation Results:\")\n",
        "        if hasattr(hotel_toxicity_results, \"columns\"):\n",
        "            toxicity_labels = hotel_toxicity_results[\"label\"].tolist() if \"label\" in hotel_toxicity_results.columns else [\"unknown\"] * len(hotel_eval_data)\n",
        "            toxicity_explanations = hotel_toxicity_results[\"explanation\"].tolist() if \"explanation\" in hotel_toxicity_results.columns else [\"No explanation\"] * len(hotel_eval_data)\n",
        "            \n",
        "            for i, label in enumerate(toxicity_labels):\n",
        "                query = hotel_eval_data[i][\"input\"]\n",
        "                logger.info(f\"   Query: {query}\")\n",
        "                logger.info(f\"   Toxicity: {label}\")\n",
        "                logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # Summary of all evaluations\n",
        "        logger.info(\"📊 EVALUATION SUMMARY\")\n",
        "        logger.info(\"=\" * 50)\n",
        "        \n",
        "        for i, query in enumerate([item[\"input\"] for item in hotel_eval_data]):\n",
        "            logger.info(f\"Query {i+1}: {query}\")\n",
        "            logger.info(f\"  Relevance: {relevance_labels[i] if 'relevance_labels' in locals() else 'N/A'}\")\n",
        "            logger.info(f\"  QA Score: {qa_labels[i] if 'qa_labels' in locals() else 'N/A'}\")\n",
        "            logger.info(f\"  Hallucination: {hallucination_labels[i] if 'hallucination_labels' in locals() else 'N/A'}\")\n",
        "            logger.info(f\"  Toxicity: {toxicity_labels[i] if 'toxicity_labels' in locals() else 'N/A'}\")\n",
        "            logger.info(\"  \" + \"-\"*40)\n",
        "        \n",
        "        logger.info(\"✅ All Phoenix evaluations completed successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Phoenix evaluation failed: {e}\")\n",
        "        logger.info(\"💡 This might be due to API rate limits or model availability\")\n",
        "        \n",
        "else:\n",
        "    if not ARIZE_AVAILABLE:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - Arize dependencies not available\")\n",
        "    else:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - No demo results to evaluate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete hotel support agent implementation using:\n",
        "\n",
        "1. **Agent Catalog Integration**: Using agentc to find tools and prompts\n",
        "2. **LangChain Framework**: ReAct agent pattern with Agent Catalog callbacks\n",
        "3. **Couchbase Vector Store**: Storing and searching hotel data from travel-sample bucket\n",
        "4. **Single Tool Architecture**: Focused on `search_vector_database` for hotel search\n",
        "5. **Comprehensive Evaluation**: Phoenix-based evaluation with multiple metrics\n",
        "\n",
        "The agent can handle various hotel-related queries including:\n",
        "- Hotel search by location and amenities\n",
        "- Finding hotels with specific features (parking, internet, spa, etc.)\n",
        "- Luxury hotel searches with premium amenities\n",
        "- Location-based hotel recommendations\n",
        "\n",
        "## Phoenix Evaluation Metrics\n",
        "\n",
        "The notebook demonstrates all four key Phoenix evaluation types:\n",
        "\n",
        "1. **Relevance Evaluation**: Measures how relevant responses are to user queries\n",
        "2. **QA Evaluation**: Assesses the quality and accuracy of answers\n",
        "3. **Hallucination Detection**: Identifies fabricated or incorrect information\n",
        "4. **Toxicity Detection**: Screens for harmful or inappropriate content\n",
        "\n",
        "Each evaluation provides:\n",
        "- Binary or categorical labels (e.g., \"relevant\"/\"irrelevant\", \"correct\"/\"incorrect\")\n",
        "- Detailed explanations of the evaluation reasoning\n",
        "- Confidence scores for the assessments\n",
        "\n",
        "## Key Features\n",
        "\n",
        "This hotel support agent implementation:\n",
        "- **Uses travel-sample bucket**: Leverages existing Couchbase sample data\n",
        "- **Capella AI integration**: Supports both embeddings and LLM through Capella AI\n",
        "- **Fallback to OpenAI**: Graceful fallback when Capella AI is unavailable\n",
        "- **Single focused tool**: Simplified architecture with one search tool\n",
        "- **Comprehensive evaluation**: Full Phoenix evaluation pipeline\n",
        "- **Agent Catalog callbacks**: Integrated observability and tracing\n",
        "\n",
        "## Data Source\n",
        "\n",
        "The agent uses hotel data from the `travel-sample.inventory.hotel` collection, which contains:\n",
        "- Real hotel information with names, locations, and amenities\n",
        "- Structured data with address, city, country, and facilities\n",
        "- Rich text descriptions suitable for vector embedding\n",
        "- Comprehensive coverage of global hotel properties\n",
        "\n",
        "For production use, consider:\n",
        "- Setting up proper monitoring with Arize Phoenix\n",
        "- Implementing comprehensive evaluation pipelines\n",
        "- Adding error handling and retry logic\n",
        "- Scaling the vector store for larger datasets\n",
        "- Adding more sophisticated query understanding\n",
        "\n",
        "## Usage Instructions\n",
        "\n",
        "To run this notebook:\n",
        "1. Set up the required environment variables (Couchbase connection, API keys)\n",
        "2. Install dependencies: `pip install -r requirements.txt`\n",
        "3. Ensure travel-sample bucket is available in your Couchbase cluster\n",
        "4. Publish your agent catalog: `agentc index . && agentc publish`\n",
        "5. Run the notebook cells sequentially\n",
        "\n",
        "The agent will automatically load hotel data from travel-sample and create embeddings for semantic search capabilities.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
