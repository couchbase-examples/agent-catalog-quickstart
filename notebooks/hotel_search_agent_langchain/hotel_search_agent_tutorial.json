{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Hotel Search Agent Tutorial - Priority 1 Implementation\n",
        "\n",
        "This notebook demonstrates the Agent Catalog hotel search agent using LangChain with Couchbase vector store and Arize Phoenix evaluation. Uses Priority 1 AI services with standard OpenAI wrappers and Capella (simple & fast).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download required resources for the hotel search agent\n",
        "!mkdir -p prompts\n",
        "!wget -O prompts/hotel_search_assistant.yaml https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/hotel_search_agent_langchain/prompts/hotel_search_assistant.yaml\n",
        "!mkdir -p tools\n",
        "!wget -O tools/search_vector_database.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/hotel_search_agent_langchain/tools/search_vector_database.py\n",
        "!wget -O agentcatalog_index.json https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/hotel_search_agent_langchain/agentcatalog_index.json\n",
        "!wget -O .agentcignore https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/hotel_search_agent_langchain/.agentcignore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q \\\n",
        "    \"pydantic>=2.0.0,<3.0.0\" \\\n",
        "    \"python-dotenv>=1.0.0,<2.0.0\" \\\n",
        "    \"pandas>=2.0.0,<3.0.0\" \\\n",
        "    \"nest-asyncio>=1.6.0,<2.0.0\" \\\n",
        "    \"uvicorn>=0.29.0,<0.30.0\" \\\n",
        "    \"httpx>=0.24.0,<1.0.0\" \\\n",
        "    \"langchain-couchbase>=0.2.4,<0.5.0\" \\\n",
        "    \"langchain-openai>=0.3.11,<0.4.0\" \\\n",
        "    \"langchain-nvidia-ai-endpoints>=0.3.13,<0.4.0\" \\\n",
        "    \"arize>=7.51.0,<8.0.0\" \\\n",
        "    \"arize-phoenix>=11.37.0,<12.0.0\" \\\n",
        "    \"arize-phoenix-evals>=2.2.0,<3.0.0\" \\\n",
        "    \"openinference-instrumentation-langchain>=0.1.29,<0.2.0\" \\\n",
        "    \"openinference-instrumentation-openai>=0.1.18,<0.2.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_core-0.2.5a3-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_cli-0.2.5a3-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc-0.2.5a3-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_langchain-0.2.5a3-py3-none-any.whl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the couchbase-infrastructure package\n",
        "%pip install -q couchbase-infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Educational Infrastructure Setup\n",
        "\n",
        "**This cell uses the `couchbase-infrastructure` package to provision your Couchbase Capella infrastructure step-by-step.**\n",
        "\n",
        "### What It Does (Educational Approach):\n",
        "1. **Interactive Credentials** - Securely collects your API key using `getpass` (Google Colab compatible)\n",
        "2. **Creates Capella Project** - Sets up your cloud database project\n",
        "3. **Provisions Free Tier Cluster** - Deploys a Couchbase cluster on AWS\n",
        "4. **Configures Network Access** - Sets up allowlists for connectivity\n",
        "5. **Loads travel-sample Data** - Imports the sample hotel dataset\n",
        "6. **Creates Database User** - Generates credentials with appropriate permissions\n",
        "7. **Deploys AI Models** - Provisions embedding and LLM models for the agent\n",
        "8. **Creates API Keys** - Generates keys for AI model access\n",
        "9. **Sets Environment Variables** - Configures all required variables for subsequent cells\n",
        "\n",
        "### Prerequisites:\n",
        "- Get your `MANAGEMENT_API_KEY` from [Capella Console](https://cloud.couchbase.com) → Settings → API Keys\n",
        "- **No `.env` file needed** - This notebook uses interactive prompts (Google Colab compatible)\n",
        "\n",
        "### After Running:\n",
        "All environment variables will be set and ready for the hotel search agent cells below.\n",
        "\n",
        "**Package Documentation**: https://pypi.org/project/couchbase-infrastructure/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"🚀 Couchbase Capella Infrastructure Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis educational setup shows you how to provision Capella infrastructure\")\n",
        "print(\"step-by-step using the couchbase-infrastructure package.\\n\")\n",
        "\n",
        "# Import the infrastructure package\n",
        "from couchbase_infrastructure import CapellaConfig, CapellaClient\n",
        "from couchbase_infrastructure.resources import (\n",
        "    create_project,\n",
        "    create_cluster,\n",
        "    add_allowed_cidr,\n",
        "    load_sample_data,\n",
        "    create_database_user,\n",
        "    deploy_ai_model,\n",
        "    create_ai_api_key,\n",
        ")\n",
        "\n",
        "# Step 1: Load from .env file if available, then collect any missing credentials\n",
        "print(\"\\n📋 Step 1: Collecting Credentials\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Try to load .env file\n",
        "env_file = Path('.env')\n",
        "if env_file.exists():\n",
        "    print(\"✅ Found .env file. Loading configuration...\\n\")\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv('.env')\n",
        "else:\n",
        "    print(\"ℹ️  No .env file found. Will prompt for credentials.\\n\")\n",
        "\n",
        "print(\"Get your credentials from: https://cloud.couchbase.com → Settings → API Keys\\n\")\n",
        "\n",
        "# Required: MANAGEMENT_API_KEY\n",
        "management_api_key = os.getenv('MANAGEMENT_API_KEY')\n",
        "if management_api_key:\n",
        "    print(\"✅ Using MANAGEMENT_API_KEY from environment\")\n",
        "else:\n",
        "    management_api_key = getpass(\"Enter your MANAGEMENT_API_KEY (hidden): \")\n",
        "    if not management_api_key:\n",
        "        raise ValueError(\"MANAGEMENT_API_KEY is required!\")\n",
        "\n",
        "# Required: ORGANIZATION_ID\n",
        "organization_id = os.getenv('ORGANIZATION_ID')\n",
        "if organization_id:\n",
        "    print(f\"✅ Using ORGANIZATION_ID from environment: {organization_id}\")\n",
        "else:\n",
        "    organization_id = input(\"Enter your ORGANIZATION_ID (required): \").strip()\n",
        "    if not organization_id:\n",
        "        raise ValueError(\"ORGANIZATION_ID is required! Find it in Capella Console under Settings.\")\n",
        "\n",
        "# Optional configuration (use env vars if available, otherwise prompt with defaults)\n",
        "api_base_url = os.getenv('API_BASE_URL') or input(\"Enter API_BASE_URL (default: 'cloudapi.cloud.couchbase.com'): \").strip() or \"cloudapi.cloud.couchbase.com\"\n",
        "project_name = os.getenv('PROJECT_NAME') or input(\"Enter PROJECT_NAME (default: 'agent-app'): \").strip() or \"agent-app\"\n",
        "cluster_name = os.getenv('CLUSTER_NAME') or input(\"Enter CLUSTER_NAME (default: 'agent-app-cluster'): \").strip() or \"agent-app-cluster\"\n",
        "db_username = os.getenv('DB_USERNAME') or input(\"Enter DB_USERNAME (default: 'agent_app_user'): \").strip() or \"agent_app_user\"\n",
        "sample_bucket = os.getenv('SAMPLE_BUCKET') or input(\"Enter BUCKET_NAME (default: 'travel-sample'): \").strip() or \"travel-sample\"\n",
        "embedding_model = os.getenv('EMBEDDING_MODEL_NAME') or input(\"Enter EMBEDDING_MODEL (default: 'nvidia/llama-3.2-nv-embedqa-1b-v2'): \").strip() or \"nvidia/llama-3.2-nv-embedqa-1b-v2\"\n",
        "llm_model = os.getenv('LLM_MODEL_NAME') or input(\"Enter LLM_MODEL (default: 'meta/llama3-8b-instruct'): \").strip() or \"meta/llama3-8b-instruct\"\n",
        "\n",
        "print(\"\\n✅ Configuration collected successfully!\\n\")\n",
        "\n",
        "# Step 2: Initialize configuration\n",
        "print(\"\\n🔧 Step 2: Initializing Configuration\")\n",
        "print(\"-\"*70)\n",
        "config = CapellaConfig(\n",
        "    management_api_key=management_api_key,\n",
        "    organization_id=organization_id,\n",
        "    api_base_url=api_base_url,\n",
        "    project_name=project_name,\n",
        "    cluster_name=cluster_name,\n",
        "    db_username=db_username,\n",
        "    sample_bucket=sample_bucket,\n",
        "    embedding_model_name=embedding_model,\n",
        "    llm_model_name=llm_model,\n",
        ")\n",
        "print(\"✅ Configuration initialized\\n\")\n",
        "\n",
        "# Step 3: Initialize client and get organization ID\n",
        "print(\"\\n🔌 Step 3: Initializing Client\")\n",
        "print(\"-\"*70)\n",
        "client = CapellaClient(config)\n",
        "org_id = client.get_organization_id()\n",
        "print(f\"✅ Using Organization ID: {org_id}\\n\")\n",
        "\n",
        "# Step 4: Test API connection\n",
        "print(\"\\n🔍 Step 4: Testing API Connection\")\n",
        "print(\"-\"*70)\n",
        "if not client.test_connection(org_id):\n",
        "    raise ConnectionError(\"Failed to connect to Capella API\")\n",
        "print(\"✅ API connection successful\\n\")\n",
        "\n",
        "# Step 5: Create Capella Project\n",
        "print(\"\\n📁 Step 5: Creating Capella Project\")\n",
        "print(\"-\"*70)\n",
        "project_id = create_project(client, org_id, config.project_name)\n",
        "print(f\"✅ Project ready: {config.project_name} (ID: {project_id})\\n\")\n",
        "\n",
        "# Step 6: Create free-tier cluster\n",
        "print(\"\\n☁️ Step 6: Creating Free Tier Cluster\")\n",
        "print(\"-\"*70)\n",
        "print(\"⏳ This will take 10-15 minutes for cluster deployment...\\n\")\n",
        "cluster_id = create_cluster(client, org_id, project_id, config.cluster_name, config)\n",
        "# Wait for cluster to be ready\n",
        "cluster_check_url = f\"/v4/organizations/{org_id}/projects/{project_id}/clusters/{cluster_id}\"\n",
        "cluster_details = client.wait_for_resource(cluster_check_url, \"Cluster\", None)\n",
        "cluster_conn_string = cluster_details.get(\"connectionString\")\n",
        "\n",
        "# Ensure connection string has proper protocol\n",
        "if not cluster_conn_string.startswith(\"couchbase://\") and not cluster_conn_string.startswith(\"couchbases://\"):\n",
        "    cluster_conn_string = f\"couchbases://{cluster_conn_string}\"\n",
        "    print(f\"⚠️  Added protocol to connection string: {cluster_conn_string}\")\n",
        "\n",
        "print(f\"✅ Cluster ready: {config.cluster_name} (ID: {cluster_id})\\n\")\n",
        "\n",
        "# Step 7: Configure network access\n",
        "print(\"\\n🌐 Step 7: Configuring Network Access\")\n",
        "print(\"-\"*70)\n",
        "add_allowed_cidr(client, org_id, project_id, cluster_id, config.allowed_cidr)\n",
        "print(\"✅ Network access configured (0.0.0.0/0 allowed)\\n\")\n",
        "\n",
        "# Step 8: Load travel-sample bucket\n",
        "print(\"\\n📦 Step 8: Loading travel-sample Bucket\")\n",
        "print(\"-\"*70)\n",
        "load_sample_data(client, org_id, project_id, cluster_id, config.sample_bucket)\n",
        "print(f\"✅ Sample data loaded: {config.sample_bucket}\\n\")\n",
        "\n",
        "# Step 9: Create database user (password auto-generated)\n",
        "print(\"\\n👤 Step 9: Creating Database User\")\n",
        "print(\"-\"*70)\n",
        "db_password = create_database_user(\n",
        "    client,\n",
        "    org_id,\n",
        "    project_id,\n",
        "    cluster_id,\n",
        "    config.db_username,\n",
        "    config.sample_bucket,\n",
        ")\n",
        "print(f\"✅ Database user created: {config.db_username}\\n\")\n",
        "if db_password and db_password != \"existing_user_password_not_retrievable\":\n",
        "    print(f\"   Auto-generated password: {db_password[:4]}...{db_password[-4:]}\\n\")\n",
        "\n",
        "# Step 10: Deploy AI models\n",
        "print(\"\\n🤖 Step 10: Deploying AI Models\")\n",
        "print(\"-\"*70)\n",
        "print(\"⏳ Deploying embedding and LLM models (5-10 minutes)...\\n\")\n",
        "\n",
        "# Deploy Embedding Model\n",
        "print(\"   Deploying embedding model...\")\n",
        "embedding_model_id = deploy_ai_model(\n",
        "    client,\n",
        "    org_id,\n",
        "    config.embedding_model_name,\n",
        "    \"agent-hub-embedding-model\",\n",
        "    \"embedding\",\n",
        "    config,\n",
        ")\n",
        "embedding_check_url = f\"/v4/organizations/{org_id}/aiServices/models/{embedding_model_id}\"\n",
        "embedding_details = client.wait_for_resource(embedding_check_url, \"Embedding Model\", None)\n",
        "embedding_endpoint = embedding_details.get(\"connectionString\", \"\")\n",
        "print(f\"✅ Embedding model deployed: {config.embedding_model_name}\\n\")\n",
        "\n",
        "# Deploy LLM Model\n",
        "print(\"   Deploying LLM model...\")\n",
        "llm_model_id = deploy_ai_model(\n",
        "    client,\n",
        "    org_id,\n",
        "    config.llm_model_name,\n",
        "    \"agent-hub-llm-model\",\n",
        "    \"llm\",\n",
        "    config,\n",
        ")\n",
        "llm_check_url = f\"/v4/organizations/{org_id}/aiServices/models/{llm_model_id}\"\n",
        "llm_details = client.wait_for_resource(llm_check_url, \"LLM Model\", None)\n",
        "llm_endpoint = llm_details.get(\"connectionString\", \"\")\n",
        "print(f\"✅ LLM model deployed: {config.llm_model_name}\\n\")\n",
        "\n",
        "# Step 11: Create API Key for AI models\n",
        "print(\"\\n🔑 Step 11: Creating API Key for AI Models\")\n",
        "print(\"-\"*70)\n",
        "api_key = create_ai_api_key(client, org_id, config.ai_model_region)\n",
        "print(f\"✅ AI API key created\\n\")\n",
        "\n",
        "# Step 12: Set environment variables\n",
        "print(\"\\n⚙️ Step 12: Setting Environment Variables\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Set all environment variables for subsequent cells\n",
        "os.environ[\"CB_CONN_STRING\"] = cluster_conn_string + \"?tls_verify=none\"\n",
        "os.environ[\"CB_USERNAME\"] = config.db_username\n",
        "os.environ[\"CB_PASSWORD\"] = db_password\n",
        "os.environ[\"CB_BUCKET\"] = config.sample_bucket\n",
        "os.environ[\"CAPELLA_API_ENDPOINT\"] = embedding_endpoint  # Use as base endpoint\n",
        "os.environ[\"CAPELLA_API_EMBEDDING_ENDPOINT\"] = embedding_endpoint\n",
        "os.environ[\"CAPELLA_API_LLM_ENDPOINT\"] = llm_endpoint\n",
        "os.environ[\"CAPELLA_API_EMBEDDINGS_KEY\"] = api_key\n",
        "os.environ[\"CAPELLA_API_LLM_KEY\"] = api_key\n",
        "os.environ[\"CAPELLA_API_EMBEDDING_MODEL\"] = config.embedding_model_name\n",
        "os.environ[\"CAPELLA_API_LLM_MODEL\"] = config.llm_model_name\n",
        "\n",
        "print(\"✅ Environment variables configured:\\n\")\n",
        "print(f\"   CB_CONN_STRING: {cluster_conn_string}\")\n",
        "print(f\"   CB_USERNAME: {config.db_username}\")\n",
        "print(f\"   CB_BUCKET: {config.sample_bucket}\")\n",
        "print(f\"   CAPELLA_API_EMBEDDING_ENDPOINT: {embedding_endpoint}\")\n",
        "print(f\"   CAPELLA_API_LLM_ENDPOINT: {llm_endpoint}\")\n",
        "print(f\"   CAPELLA_API_EMBEDDING_MODEL: {config.embedding_model_name}\")\n",
        "print(f\"   CAPELLA_API_LLM_MODEL: {config.llm_model_name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Infrastructure Setup Complete!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou can now run the hotel search agent cells below.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set Agent Catalog environment variables (required for agentc commands)\n",
        "# These use the same Couchbase connection created above\n",
        "import os\n",
        "\n",
        "os.environ[\"AGENT_CATALOG_CONN_STRING\"] = os.environ[\"CB_CONN_STRING\"]\n",
        "os.environ[\"AGENT_CATALOG_USERNAME\"] = os.environ[\"CB_USERNAME\"]\n",
        "os.environ[\"AGENT_CATALOG_PASSWORD\"] = os.environ[\"CB_PASSWORD\"]\n",
        "os.environ[\"AGENT_CATALOG_BUCKET\"] = os.environ[\"CB_BUCKET\"]\n",
        "\n",
        "print(\"✅ Agent Catalog environment variables set:\")\n",
        "print(f\"   AGENT_CATALOG_CONN_STRING: {os.environ['AGENT_CATALOG_CONN_STRING']}\")\n",
        "print(f\"   AGENT_CATALOG_USERNAME: {os.environ['AGENT_CATALOG_USERNAME']}\")\n",
        "print(f\"   AGENT_CATALOG_BUCKET: {os.environ['AGENT_CATALOG_BUCKET']}\")\n",
        "\n",
        "# Handle root certificate (required for secure connections)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📜 Root Certificate Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n⚠️  IMPORTANT: You need to download the root certificate from Capella UI\")\n",
        "print(\"\\nSteps:\")\n",
        "print(\"1. Go to Capella Console: https://cloud.couchbase.com\")\n",
        "print(\"2. Navigate to your cluster → Connect tab\")\n",
        "print(\"3. Download the 'Root Certificate' file\")\n",
        "print(\"4. Upload it using the file upload below\\n\")\n",
        "\n",
        "# Try to use Google Colab's file upload, fallback to manual input\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"📤 Please upload your root certificate file:\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    if uploaded:\n",
        "        cert_filename = list(uploaded.keys())[0]\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = cert_filename\n",
        "        print(f\"\\n✅ Root certificate uploaded: {cert_filename}\")\n",
        "        print(f\"   AGENT_CATALOG_CONN_ROOT_CERTIFICATE: {cert_filename}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️  No file uploaded. You can set it manually later if needed.\")\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "except ImportError:\n",
        "    # Not in Colab - ask user to place file and provide filename\n",
        "    print(\"📝 Not running in Google Colab.\")\n",
        "    print(\"   Please place the root certificate file in the current directory.\\n\")\n",
        "    cert_filename = input(\"Enter the certificate filename (or press Enter to skip): \").strip()\n",
        "    \n",
        "    if cert_filename:\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = cert_filename\n",
        "        print(f\"\\n✅ Root certificate set: {cert_filename}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️  Root certificate not set. You can add it manually later if needed.\")\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Agent Catalog Configuration Complete\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Write environment variables to .env file for agentc commands\n",
        "# agentc CLI will load from .env file automatically\n",
        "import os.path\n",
        "with open('.env', 'w') as f:\n",
        "    # CB variables (needed for database operations - prevents wiping by dotenv.load_dotenv)\n",
        "    f.write(f\"CB_CONN_STRING={os.environ['CB_CONN_STRING']}\\n\")\n",
        "    f.write(f\"CB_USERNAME={os.environ['CB_USERNAME']}\\n\")\n",
        "    f.write(f\"CB_PASSWORD={os.environ['CB_PASSWORD']}\\n\")\n",
        "    f.write(f\"CB_BUCKET={os.environ['CB_BUCKET']}\\n\")\n",
        "    \n",
        "    # CAPELLA_API variables (needed for AI services - prevents wiping by dotenv.load_dotenv)\n",
        "    f.write(f\"CAPELLA_API_ENDPOINT={os.environ['CAPELLA_API_ENDPOINT']}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDING_ENDPOINT={os.environ['CAPELLA_API_EMBEDDING_ENDPOINT']}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_ENDPOINT={os.environ['CAPELLA_API_LLM_ENDPOINT']}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDINGS_KEY={os.environ['CAPELLA_API_EMBEDDINGS_KEY']}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_KEY={os.environ['CAPELLA_API_LLM_KEY']}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDING_MODEL={os.environ['CAPELLA_API_EMBEDDING_MODEL']}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_MODEL={os.environ['CAPELLA_API_LLM_MODEL']}\\n\")\n",
        "    \n",
        "    # AGENT_CATALOG variables (for agentc CLI)\n",
        "    f.write(f\"AGENT_CATALOG_CONN_STRING={os.environ['AGENT_CATALOG_CONN_STRING']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_USERNAME={os.environ['AGENT_CATALOG_USERNAME']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_PASSWORD={os.environ['AGENT_CATALOG_PASSWORD']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_BUCKET={os.environ['AGENT_CATALOG_BUCKET']}\\n\")\n",
        "    \n",
        "    # Only write certificate if it exists and is a valid file\n",
        "    cert = os.environ.get('AGENT_CATALOG_CONN_ROOT_CERTIFICATE', '').strip()\n",
        "    if cert and os.path.isfile(cert):\n",
        "        f.write(f\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE={cert}\\n\")\n",
        "    elif cert:\n",
        "        print(f\"⚠️  Warning: Certificate file '{cert}' not found, skipping from .env\")\n",
        "\n",
        "print(\"\\n✅ Environment variables written to .env file for agentc commands\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: Configure OpenAI and Arize (Observability)\n",
        "\n",
        "Provide optional API keys for:\n",
        "- **OpenAI**: Fallback LLM/embeddings if Capella AI is unavailable\n",
        "- **Arize Phoenix**: Observability and evaluation platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"🔧 Optional API Keys Configuration\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# OpenAI Configuration (optional - for fallback)\n",
        "print(\"\\n📝 OpenAI API (Optional - for fallback LLM/embeddings)\")\n",
        "print(\"-\"*70)\n",
        "openai_api_key = input(\"Enter OpenAI API Key (or press Enter to skip): \").strip()\n",
        "\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gpt-4o\"  # Default model\n",
        "    print(\"✅ OpenAI API key configured\")\n",
        "    print(f\"   Model: gpt-4o\")\n",
        "else:\n",
        "    print(\"⏭️  Skipped OpenAI configuration\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gpt-4o\"\n",
        "\n",
        "# Arize Phoenix Configuration (optional - for observability)\n",
        "print(\"\\n📊 Arize Phoenix (Optional - for observability and evaluation)\")\n",
        "print(\"-\"*70)\n",
        "arize_space_id = input(\"Enter Arize Space ID (or press Enter to skip): \").strip()\n",
        "arize_api_key = input(\"Enter Arize API Key (or press Enter to skip): \").strip()\n",
        "\n",
        "if arize_space_id and arize_api_key:\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = arize_space_id\n",
        "    os.environ[\"ARIZE_API_KEY\"] = arize_api_key\n",
        "    print(\"✅ Arize Phoenix configured\")\n",
        "else:\n",
        "    print(\"⏭️  Skipped Arize configuration\")\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = \"\"\n",
        "    os.environ[\"ARIZE_API_KEY\"] = \"\"\n",
        "\n",
        "# Append optional variables to .env file\n",
        "with open('.env', 'a') as f:\n",
        "    f.write(\"\\n# Optional: OpenAI Configuration (fallback LLM/embeddings)\\n\")\n",
        "    f.write(f\"OPENAI_API_KEY={os.environ['OPENAI_API_KEY']}\\n\")\n",
        "    f.write(f\"OPENAI_MODEL={os.environ['OPENAI_MODEL']}\\n\")\n",
        "    \n",
        "    f.write(\"\\n# Optional: Arize Phoenix (observability and evaluation)\\n\")\n",
        "    f.write(f\"ARIZE_SPACE_ID={os.environ['ARIZE_SPACE_ID']}\\n\")\n",
        "    f.write(f\"ARIZE_API_KEY={os.environ['ARIZE_API_KEY']}\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Optional Configuration Complete\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add .\n",
        "!git config --global user.email \"your.email@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "!git commit -m \"initial commit\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!agentc init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!agentc index .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!agentc publish\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary modules for the hotel search agent using self-contained setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import getpass\n",
        "import httpx\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import agentc\n",
        "import dotenv\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.management.buckets import BucketType, CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup logging to output to stdout for Colab environments\n",
        "root_logger = logging.getLogger()\n",
        "if not root_logger.handlers:\n",
        "    handler = logging.StreamHandler(sys.stdout)\n",
        "    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
        "    handler.setFormatter(formatter)\n",
        "    root_logger.addHandler(handler)\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Setup logging for this module\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Reduce noise from various libraries during embedding/vector operations\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv(override=True)\n",
        "\n",
        "# Set default values for travel-sample bucket configuration\n",
        "DEFAULT_BUCKET = \"travel-sample\"\n",
        "DEFAULT_SCOPE = \"agentc_data\"\n",
        "DEFAULT_COLLECTION = \"hotel_data\"\n",
        "DEFAULT_INDEX = \"hotel_data_index\"\n",
        "DEFAULT_CAPELLA_API_EMBEDDING_MODEL = \"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
        "DEFAULT_CAPELLA_API_LLM_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Self-Contained Setup Functions\n",
        "\n",
        "Define all necessary setup functions inline for a self-contained notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_environment():\n",
        "    \"\"\"Setup default environment variables for agent operations.\"\"\"\n",
        "    defaults = {\n",
        "        \"CB_BUCKET\": \"travel-sample\",\n",
        "        \"CB_SCOPE\": \"agentc_data\",\n",
        "        \"CB_COLLECTION\": \"hotel_data\",\n",
        "        \"CB_INDEX\": \"hotel_data_index\",\n",
        "        \"CAPELLA_API_EMBEDDING_MODEL\": \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
        "        \"CAPELLA_API_LLM_MODEL\": \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
        "    }\n",
        "    \n",
        "    for key, value in defaults.items():\n",
        "        if not os.getenv(key):\n",
        "            os.environ[key] = value\n",
        "    \n",
        "    logger.info(\"✅ Environment variables configured\")\n",
        "\n",
        "\n",
        "def test_capella_connectivity(api_key: str = None, endpoint: str = None) -> bool:\n",
        "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
        "    try:\n",
        "        test_key = api_key or os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\") or os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "        test_endpoint = endpoint or os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        \n",
        "        if not test_key or not test_endpoint:\n",
        "            return False\n",
        "        \n",
        "        # Simple connectivity test\n",
        "        headers = {\"Authorization\": f\"Bearer {test_key}\"}\n",
        "        \n",
        "        with httpx.Client(timeout=10.0) as client:\n",
        "            response = client.get(f\"{test_endpoint.rstrip('/')}/v1/models\", headers=headers)\n",
        "            return response.status_code < 500\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"⚠️ Capella connectivity test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def setup_ai_services(framework: str = \"langchain\", temperature: float = 0.0, application_span=None):\n",
        "    \"\"\"Priority 1: Capella AI with OpenAI wrappers (simple & fast) for LangChain.\"\"\"\n",
        "    embeddings = None\n",
        "    llm = None\n",
        "    \n",
        "    logger.info(f\"🔧 Setting up Priority 1 AI services for {framework} framework...\")\n",
        "    \n",
        "    # Priority 1: Capella AI with direct API keys and OpenAI wrappers\n",
        "    if not embeddings and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            api_key = os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "            model = os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\")\n",
        "            \n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                api_base = endpoint\n",
        "            else:\n",
        "                api_base = f\"{endpoint}/v1\"\n",
        "            \n",
        "            # Debug logging - same pattern as working test\n",
        "            logger.info(f\"🔧 Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 Model: {model}\")\n",
        "            logger.info(f\"🔧 API Base: {api_base}\")\n",
        "            \n",
        "            embeddings = OpenAIEmbeddings(\n",
        "                model=model,\n",
        "                api_key=api_key,\n",
        "                base_url=api_base,\n",
        "                check_embedding_ctx_length=False,  # Fix for asymmetric models\n",
        "            )\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI embeddings failed: {type(e).__name__}: {e}\")\n",
        "    \n",
        "    if not llm and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_LLM_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            llm_key = os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "            llm_model = os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
        "            \n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                api_base = endpoint\n",
        "            else:\n",
        "                api_base = f\"{endpoint}/v1\"\n",
        "            \n",
        "            # Debug logging\n",
        "            logger.info(f\"🔧 LLM Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 LLM Model: {llm_model}\")\n",
        "            logger.info(f\"🔧 LLM API Base: {api_base}\")\n",
        "            \n",
        "            llm = ChatOpenAI(\n",
        "                model=llm_model,\n",
        "                base_url=api_base,\n",
        "                api_key=llm_key,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            # Test the LLM works\n",
        "            test_response = llm.invoke(\"Hello\")\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI LLM failed: {type(e).__name__}: {e}\")\n",
        "            llm = None\n",
        "    \n",
        "    # Fallback: OpenAI\n",
        "    if not embeddings and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            embeddings = OpenAIEmbeddings(\n",
        "                model=\"text-embedding-3-small\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI embeddings fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI embeddings failed: {e}\")\n",
        "    \n",
        "    if not llm and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            llm = ChatOpenAI(\n",
        "                model=\"gpt-4o\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI LLM fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI LLM failed: {e}\")\n",
        "    \n",
        "    if not embeddings:\n",
        "        raise ValueError(\"❌ No embeddings service could be initialized\")\n",
        "    if not llm:\n",
        "        raise ValueError(\"❌ No LLM service could be initialized\")\n",
        "    \n",
        "    logger.info(f\"✅ Priority 1 AI services setup completed for {framework}\")\n",
        "    return embeddings, llm\n",
        "\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()\n",
        "\n",
        "# Test Capella AI connectivity if configured\n",
        "if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "    if not test_capella_connectivity():\n",
        "        logger.warning(\"❌ Capella AI connectivity test failed. Will use fallback models.\")\n",
        "else:\n",
        "    logger.info(\"ℹ️ Capella API not configured - will use fallback models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CouchbaseClient Class\n",
        "\n",
        "Define the CouchbaseClient for all database operations and LangChain agent creation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
        "\n",
        "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
        "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "\n",
        "            # Use WAN profile for better timeout handling with remote clusters\n",
        "            options.apply_profile(\"wan_development\")\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=20))\n",
        "            logger.info(\"Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str, clear_existing_data: bool = False):\n",
        "        \"\"\"Setup collection - create scope and collection if they don't exist.\"\"\"\n",
        "        try:\n",
        "            # Ensure cluster connection\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            # For travel-sample bucket, assume it exists\n",
        "            if not self.bucket:\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"Connected to bucket '{self.bucket_name}'\")\n",
        "\n",
        "            # Setup scope\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
        "\n",
        "            # Setup collection - clear if exists, create if doesn't\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name\n",
        "                and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists:\n",
        "                if clear_existing_data:\n",
        "                    logger.info(f\"Collection '{collection_name}' exists, clearing data...\")\n",
        "                    self.clear_collection_data(scope_name, collection_name)\n",
        "                else:\n",
        "                    logger.info(f\"Collection '{collection_name}' exists, keeping existing data...\")\n",
        "            else:\n",
        "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
        "\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Create primary index\n",
        "            try:\n",
        "                self.cluster.query(\n",
        "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                ).execute()\n",
        "                logger.info(\"Primary index created successfully\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error creating primary index: {e}\")\n",
        "\n",
        "            logger.info(\"Collection setup complete\")\n",
        "            return self.bucket.scope(scope_name).collection(collection_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Clear all data from a collection.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "\n",
        "            # Use N1QL to delete all documents with explicit execution\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "\n",
        "            # Execute the query and get the results\n",
        "            rows = list(result)\n",
        "\n",
        "            # Wait a moment for the deletion to propagate\n",
        "            time.sleep(2)\n",
        "\n",
        "            # Verify collection is empty\n",
        "            count_query = f\"SELECT COUNT(*) as count FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            count_result = self.cluster.query(count_query)\n",
        "            count_row = list(count_result)[0]\n",
        "            remaining_count = count_row[\"count\"]\n",
        "\n",
        "            if remaining_count == 0:\n",
        "                logger.info(f\"Collection cleared successfully, {remaining_count} documents remaining\")\n",
        "            else:\n",
        "                logger.warning(f\"Collection clear incomplete, {remaining_count} documents remaining\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error clearing collection data: {e}\")\n",
        "            # If N1QL fails, try to continue anyway\n",
        "            pass\n",
        "\n",
        "    def get_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Get a collection object.\"\"\"\n",
        "        key = f\"{scope_name}.{collection_name}\"\n",
        "        if key not in self._collections:\n",
        "            self._collections[key] = self.bucket.scope(scope_name).collection(collection_name)\n",
        "        return self._collections[key]\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                raise RuntimeError(\"Bucket not initialized. Call setup_collection first.\")\n",
        "\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
        "            else:\n",
        "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector search index: {e!s}\")\n",
        "\n",
        "    def setup_vector_store_langchain(self, scope_name, collection_name, index_name, embeddings, data_loader_func):\n",
        "        \"\"\"Setup vector store with hotel data using LangChain.\"\"\"\n",
        "        try:\n",
        "            # Load hotel data using the data loading function\n",
        "            data_loader_func(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embeddings=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "            logger.info(\"Hotel data loaded into vector store successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector store: {e!s}\")\n",
        "\n",
        "    def create_langchain_agent(self, catalog, span):\n",
        "        \"\"\"Create LangChain ReAct agent with hotel search tool from Agent Catalog.\"\"\"\n",
        "        try:\n",
        "            # Setup AI services using Priority 1: Capella AI + OpenAI wrappers\n",
        "            embeddings, llm = setup_ai_services(framework=\"langchain\", temperature=0.1, application_span=span)\n",
        "            \n",
        "            # Setup collection\n",
        "            self.setup_collection(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"], clear_existing_data=False)\n",
        "            \n",
        "            # Setup vector search index - MUST have agentcatalog_index.json\n",
        "            with open(\"agentcatalog_index.json\") as file:\n",
        "                index_definition = json.load(file)\n",
        "            logger.info(\"Loaded vector search index definition from agentcatalog_index.json\")\n",
        "            self.setup_vector_search_index(index_definition, os.environ[\"CB_SCOPE\"])\n",
        "            \n",
        "            # Setup vector store with hotel data\n",
        "            self.setup_vector_store_langchain(\n",
        "                os.environ[\"CB_SCOPE\"],\n",
        "                os.environ[\"CB_COLLECTION\"],\n",
        "                os.environ[\"CB_INDEX\"],\n",
        "                embeddings,\n",
        "                load_hotel_data_to_couchbase,\n",
        "            )\n",
        "            \n",
        "            # Load tools and create agent\n",
        "            tool_search = catalog.find(\"tool\", name=\"search_vector_database\")\n",
        "            if not tool_search:\n",
        "                raise ValueError(\n",
        "                    \"Could not find search_vector_database tool. Make sure it's indexed with 'agentc index tools/'\"\n",
        "                )\n",
        "\n",
        "            tools = [\n",
        "                Tool(\n",
        "                    name=tool_search.meta.name,\n",
        "                    description=tool_search.meta.description,\n",
        "                    func=tool_search.func,\n",
        "                ),\n",
        "            ]\n",
        "\n",
        "            hotel_prompt = catalog.find(\"prompt\", name=\"hotel_search_assistant\")\n",
        "            if not hotel_prompt:\n",
        "                raise ValueError(\n",
        "                    \"Could not find hotel_search_assistant prompt in catalog. Make sure it's indexed with 'agentc index prompts/'\"\n",
        "                )\n",
        "\n",
        "            custom_prompt = PromptTemplate(\n",
        "                template=hotel_prompt.content.strip(),\n",
        "                input_variables=[\"input\", \"agent_scratchpad\"],\n",
        "                partial_variables={\n",
        "                    \"tools\": \"\\n\".join(\n",
        "                        [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
        "                    ),\n",
        "                    \"tool_names\": \", \".join([tool.name for tool in tools]),\n",
        "                },\n",
        "            )\n",
        "\n",
        "            def handle_parsing_error(error) -> str:\n",
        "                \"\"\"Custom error handler for parsing errors that guides agent back to ReAct format.\"\"\"\n",
        "                logger.warning(f\"Parsing error occurred: {error}\")\n",
        "                return \"\"\"I need to use the correct format. Let me start over:\n",
        "\n",
        "Thought: I need to search for hotels using the search_vector_database tool\n",
        "Action: search_vector_database\n",
        "Action Input: \"\"\"\n",
        "\n",
        "            agent = create_react_agent(llm, tools, custom_prompt)\n",
        "            agent_executor = AgentExecutor(\n",
        "                agent=agent,\n",
        "                tools=tools,\n",
        "                verbose=True,\n",
        "                handle_parsing_errors=handle_parsing_error,  # Use custom error handler\n",
        "                max_iterations=2,  # STRICT: 1 tool call + 1 Final Answer only\n",
        "                max_execution_time=120,  # Force stop when max iterations reached\n",
        "                early_stopping_method=\"force\",  # Force stop when max iterations reached\n",
        "                return_intermediate_steps=True,  # For better debugging\n",
        "            )\n",
        "\n",
        "            logger.info(\"LangChain ReAct agent created successfully\")\n",
        "            return agent_executor\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error creating LangChain agent: {e!s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Loading Module\n",
        "\n",
        "Complete hotel data loading functions from data/hotel_data.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading functions from data/hotel_data.py\n",
        "import couchbase.auth\n",
        "import couchbase.cluster\n",
        "import couchbase.exceptions\n",
        "import couchbase.options\n",
        "\n",
        "\n",
        "def retry_with_backoff(func, retries=3):\n",
        "    \"\"\"Simple retry with exponential backoff.\"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            return func()\n",
        "        except Exception:\n",
        "            if attempt == retries - 1:\n",
        "                raise\n",
        "            delay = 2 ** attempt\n",
        "            logger.warning(f\"Attempt {attempt + 1} failed, retrying in {delay}s...\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "\n",
        "def get_cluster_connection():\n",
        "    \"\"\"Get a fresh cluster connection for each request.\"\"\"\n",
        "    try:\n",
        "        auth = couchbase.auth.PasswordAuthenticator(\n",
        "            username=os.getenv(\"CB_USERNAME\", \"Administrator\"),\n",
        "            password=os.getenv(\"CB_PASSWORD\", \"password\"),\n",
        "        )\n",
        "        options = couchbase.options.ClusterOptions(authenticator=auth)\n",
        "        # Use WAN profile for better timeout handling with remote clusters\n",
        "        options.apply_profile(\"wan_development\")\n",
        "\n",
        "        cluster = couchbase.cluster.Cluster(\n",
        "            os.getenv(\"CB_CONN_STRING\", \"couchbase://localhost\"), options\n",
        "        )\n",
        "        cluster.wait_until_ready(timedelta(seconds=15))\n",
        "        return cluster\n",
        "    except couchbase.exceptions.CouchbaseException as e:\n",
        "        logger.error(f\"Could not connect to Couchbase cluster: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_hotel_data_from_travel_sample():\n",
        "    \"\"\"Load hotel data from travel-sample.inventory.hotel collection.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        # Query to get all hotel documents from travel-sample.inventory.hotel\n",
        "        query = \"\"\"\n",
        "            SELECT h.*, META(h).id as doc_id\n",
        "            FROM `travel-sample`.inventory.hotel h\n",
        "            ORDER BY h.name\n",
        "        \"\"\"\n",
        "\n",
        "        logger.info(\"Loading hotel data from travel-sample.inventory.hotel...\")\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        hotels = []\n",
        "        for row in result:\n",
        "            hotel = row\n",
        "            hotels.append(hotel)\n",
        "\n",
        "        logger.info(f\"Loaded {len(hotels)} hotels from travel-sample.inventory.hotel\")\n",
        "        return hotels\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading hotel data: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_hotel_texts():\n",
        "    \"\"\"Returns formatted hotel texts for vector store embedding from travel-sample data.\"\"\"\n",
        "    hotels = load_hotel_data_from_travel_sample()\n",
        "    hotel_texts = []\n",
        "\n",
        "    for hotel in tqdm(hotels, desc=\"Processing hotels\"):\n",
        "        # Start with basic info\n",
        "        name = hotel.get(\"name\", \"Unknown Hotel\")\n",
        "        city = hotel.get(\"city\", \"Unknown City\")\n",
        "        country = hotel.get(\"country\", \"Unknown Country\")\n",
        "\n",
        "        # Build text with PRIORITIZED information for search\n",
        "        text_parts = [f\"{name} in {city}, {country}\"]\n",
        "\n",
        "        # PRIORITY 1: Location details (critical for search)\n",
        "        location_fields = [\"address\", \"state\", \"directions\"]\n",
        "        for field in location_fields:\n",
        "            value = hotel.get(field)\n",
        "            if value and value != \"None\":\n",
        "                text_parts.append(f\"{field.title()}: {value}\")\n",
        "\n",
        "        # PRIORITY 2: Key amenities (most searched features)\n",
        "        amenity_fields = [\n",
        "            (\"free_breakfast\", \"Free breakfast\"),\n",
        "            (\"free_internet\", \"Free internet\"), \n",
        "            (\"free_parking\", \"Free parking\"),\n",
        "            (\"pets_ok\", \"Pets allowed\")\n",
        "        ]\n",
        "        for field, label in amenity_fields:\n",
        "            value = hotel.get(field)\n",
        "            if value is not None:\n",
        "                text_parts.append(f\"{label}: {'Yes' if value else 'No'}\")\n",
        "\n",
        "        # PRIORITY 3: Hotel description and type\n",
        "        description_fields = [\n",
        "            (\"description\", \"Description\"),\n",
        "            (\"type\", \"Type\"),\n",
        "            (\"title\", \"Title\")\n",
        "        ]\n",
        "        for field, label in description_fields:\n",
        "            value = hotel.get(field)\n",
        "            if value and value != \"None\":\n",
        "                text_parts.append(f\"{label}: {value}\")\n",
        "\n",
        "        # PRIORITY 4: Other details (less critical for search)\n",
        "        other_fields = [\n",
        "            (\"price\", \"Price\"),\n",
        "            (\"checkin\", \"Check-in\"),\n",
        "            (\"checkout\", \"Check-out\"),\n",
        "            (\"phone\", \"Phone\"),\n",
        "            (\"email\", \"Email\"),\n",
        "            (\"vacancy\", \"Vacancy\"),\n",
        "            (\"alias\", \"Also known as\")\n",
        "        ]\n",
        "        for field, label in other_fields:\n",
        "            value = hotel.get(field)\n",
        "            if value and value != \"None\":\n",
        "                if isinstance(value, bool):\n",
        "                    text_parts.append(f\"{label}: {'Yes' if value else 'No'}\")\n",
        "                else:\n",
        "                    text_parts.append(f\"{label}: {value}\")\n",
        "\n",
        "        # Add geographic coordinates if available\n",
        "        if hotel.get(\"geo\"):\n",
        "            geo = hotel[\"geo\"]\n",
        "            if geo.get(\"lat\") and geo.get(\"lon\"):\n",
        "                text_parts.append(f\"Coordinates: {geo['lat']}, {geo['lon']}\")\n",
        "\n",
        "        # Add review summary if available\n",
        "        if hotel.get(\"reviews\") and isinstance(hotel[\"reviews\"], list):\n",
        "            review_count = len(hotel[\"reviews\"])\n",
        "            if review_count > 0:\n",
        "                text_parts.append(f\"Reviews: {review_count} customer reviews available\")\n",
        "\n",
        "                # Include a sample of review content for better search matching\n",
        "                sample_reviews = hotel[\"reviews\"][:2]  # First 2 reviews\n",
        "                for i, review in enumerate(sample_reviews):\n",
        "                    if review.get(\"content\"):\n",
        "                        # Truncate long reviews for embedding efficiency\n",
        "                        content = (\n",
        "                            review[\"content\"][:200] + \"...\"\n",
        "                            if len(review[\"content\"]) > 200\n",
        "                            else review[\"content\"]\n",
        "                        )\n",
        "                        text_parts.append(f\"Review {i + 1}: {content}\")\n",
        "\n",
        "        # Add public likes if available\n",
        "        if hotel.get(\"public_likes\") and isinstance(hotel[\"public_likes\"], list):\n",
        "            likes_count = len(hotel[\"public_likes\"])\n",
        "            if likes_count > 0:\n",
        "                text_parts.append(f\"Public likes: {likes_count} likes\")\n",
        "\n",
        "        # Join all parts with \". \"\n",
        "        text = \". \".join(text_parts)\n",
        "        hotel_texts.append(text)\n",
        "\n",
        "    logger.info(f\"Generated {len(hotel_texts)} hotel text embeddings\")\n",
        "    return hotel_texts\n",
        "\n",
        "\n",
        "def load_hotel_data_to_couchbase(\n",
        "    cluster,\n",
        "    bucket_name: str,\n",
        "    scope_name: str,\n",
        "    collection_name: str,\n",
        "    embeddings,\n",
        "    index_name: str,\n",
        "):\n",
        "    \"\"\"Load hotel data from travel-sample into the target collection with embeddings.\"\"\"\n",
        "    try:\n",
        "        # Check if data already exists\n",
        "        count_query = f\"SELECT COUNT(*) as count FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "        count_result = cluster.query(count_query)\n",
        "        count_row = list(count_result)[0]\n",
        "        existing_count = count_row[\"count\"]\n",
        "\n",
        "        if existing_count > 0:\n",
        "            logger.info(\n",
        "                f\"Found {existing_count} existing documents in collection, skipping data load\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Get hotel texts for embeddings\n",
        "        hotel_texts = get_hotel_texts()\n",
        "\n",
        "        # Setup vector store for the target collection\n",
        "        vector_store = CouchbaseVectorStore(\n",
        "            cluster=cluster,\n",
        "            bucket_name=bucket_name,\n",
        "            scope_name=scope_name,\n",
        "            collection_name=collection_name,\n",
        "            embedding=embeddings,\n",
        "            index_name=index_name,\n",
        "        )\n",
        "\n",
        "        # Add hotel texts to vector store with batch processing\n",
        "        logger.info(\n",
        "            f\"Loading {len(hotel_texts)} hotel embeddings to {bucket_name}.{scope_name}.{collection_name}\"\n",
        "        )\n",
        "\n",
        "        # Process in batches with simple retry\n",
        "        batch_size = 10\n",
        "\n",
        "        with tqdm(total=len(hotel_texts), desc=\"Loading hotel embeddings\") as pbar:\n",
        "            for i in range(0, len(hotel_texts), batch_size):\n",
        "                batch = hotel_texts[i : i + batch_size]\n",
        "                \n",
        "                def add_batch():\n",
        "                    return vector_store.add_texts(texts=batch, batch_size=batch_size)\n",
        "                \n",
        "                retry_with_backoff(add_batch, retries=3)\n",
        "                pbar.update(len(batch))\n",
        "\n",
        "        logger.info(\n",
        "            f\"Successfully loaded {len(hotel_texts)} hotel embeddings to vector store\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading hotel data to Couchbase: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_hotel_count():\n",
        "    \"\"\"Get the count of hotels in travel-sample.inventory.hotel.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        query = \"SELECT COUNT(*) as count FROM `travel-sample`.inventory.hotel\"\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        for row in result:\n",
        "            return row[\"count\"]\n",
        "\n",
        "        return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting hotel count: {str(e)}\")\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Query Module\n",
        "\n",
        "Complete query collections and functions from data/queries.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query functions and data from data/queries.py\n",
        "\n",
        "# Hotel search queries (based on travel-sample data)\n",
        "HOTEL_SEARCH_QUERIES = [\n",
        "    \"Find hotels in Giverny with free breakfast\",\n",
        "    \"I need a hotel in Glossop with free internet access\",\n",
        "    \"Show me hotels in Helensburgh with free breakfast\",\n",
        "]\n",
        "\n",
        "# Comprehensive reference answers matching actual database content\n",
        "HOTEL_REFERENCE_ANSWERS = [\n",
        "    # Query 1: Giverny with free breakfast\n",
        "    \"\"\"I found one hotel in Giverny that offers free breakfast:\n",
        "\n",
        "**Le Clos Fleuri**\n",
        "- **Location:** Giverny, France  \n",
        "- **Address:** 5 rue de la Dîme, 27620 Giverny\n",
        "- **Phone:** +33 2 32 21 36 51\n",
        "- **Website:** http://www.giverny-leclosfleuri.fr/\n",
        "- **Amenities:** Free breakfast ✅, Free internet ✅, Free parking ✅, No pets allowed\n",
        "- **Vacancy:** Yes\n",
        "- **Coordinates:** 49.0763077, 1.5234464\n",
        "- **Reviews:** 3 customer reviews available with mixed ratings\n",
        "- **Public Likes:** 7 likes\n",
        "- **Description:** Situated near the church and just a few minutes walking distance from Monet's gardens and the Museum of Impressionisms, you will find Danielle and Claude's home, surrounded by a large magnificent garden, where you will find a haven of peace and tranquillity. Danielle speaks fluent English having spent many years in Australia.\n",
        "\n",
        "This hotel is perfect for your stay in Giverny with the requested free breakfast amenity. It's ideally located for visiting Monet's gardens and offers a peaceful garden setting.\"\"\",\n",
        "    # Query 2: Glossop with free internet\n",
        "    \"\"\"Here are hotels in Glossop that offer free internet access:\n",
        "\n",
        "1. **The George Hotel**\n",
        "   - **Address:** Norfolk Street, Glossop, United Kingdom\n",
        "   - **Phone:** +44 1457 855449\n",
        "   - **Price:** From £35.00 (single) or £60.00 (double)\n",
        "   - **Amenities:** Free internet ✅, Free breakfast ✅, Pets allowed ✅\n",
        "   - **Vacancy:** Yes\n",
        "   - **Reviews:** 6 customer reviews available\n",
        "   - **Coordinates:** 53.444331, -1.948299\n",
        "   - **Description:** Set in the centre of town, this hotel makes an ideal base for a visit to the area.\n",
        "\n",
        "2. **Avondale Guest House**\n",
        "   - **Address:** 28 Woodhead Road, Glossop, United Kingdom\n",
        "   - **Phone:** +44 1457 853132, Mobile: +44 7784 764969\n",
        "   - **Website:** http://www.avondale-guesthouse.co.uk/\n",
        "   - **Amenities:** Free internet ✅, Free breakfast ✅, Pets allowed ✅\n",
        "   - **Vacancy:** Yes\n",
        "   - **Reviews:** 7 customer reviews available\n",
        "   - **Coordinates:** 53.449979, -1.945284\n",
        "\n",
        "These hotels are located in Glossop and offer the free internet access you're looking for.\"\"\",\n",
        "    # Query 3: Helensburgh with free breakfast\n",
        "    \"\"\"Here are the hotels in Helensburgh that offer free breakfast:\n",
        "\n",
        "1. **County Lodge Hotel**\n",
        "   - **Location:** Helensburgh, United Kingdom\n",
        "   - **Address:** Old Luss Road, Helensburgh, G84 7BH\n",
        "   - **Phone:** +44 1436 672034\n",
        "   - **Website:** http://www.countylodgehotel.co.uk/\n",
        "   - **Amenities:** Free breakfast ✅, Free internet ✅, Free parking ✅, No pets allowed\n",
        "   - **Price:** Rooms £40-£55\n",
        "   - **Vacancy:** No\n",
        "   - **Coordinates:** 55.99884, -4.71354\n",
        "   - **Description:** Nearly 1 mile east of the town centre, near Colgrain Station.\n",
        "\n",
        "2. **Commodore Hotel**\n",
        "   - **Location:** Helensburgh, United Kingdom\n",
        "   - **Address:** 112-117 West Clyde Street, Helensburgh, G84 8ES\n",
        "   - **Phone:** +44 1436 676924\n",
        "   - **Website:** http://www.innkeeperslodge.com/lodgedetail.asp?lid=91\n",
        "   - **Amenities:** Free breakfast ✅, Free internet ✅, Pets allowed ✅, No free parking\n",
        "   - **Price:** Rooms from £55\n",
        "   - **Vacancy:** No\n",
        "   - **Reviews:** 2 customer reviews available\n",
        "   - **Coordinates:** 56.00481, -4.74472\n",
        "   - **Description:** The biggest hotel in town with rooms from £55. Refurbished in about 2004. On the sea front about 1/2 mile from the town centre.\n",
        "\n",
        "Both hotels offer the requested free breakfast along with additional amenities.\"\"\",\n",
        "]\n",
        "\n",
        "# Create dictionary for backward compatibility\n",
        "QUERY_REFERENCE_ANSWERS = {\n",
        "    query: answer\n",
        "    for query, answer in zip(HOTEL_SEARCH_QUERIES, HOTEL_REFERENCE_ANSWERS)\n",
        "}\n",
        "\n",
        "\n",
        "def get_evaluation_queries():\n",
        "    \"\"\"Get queries for evaluation\"\"\"\n",
        "    return HOTEL_SEARCH_QUERIES\n",
        "\n",
        "\n",
        "def get_reference_answer(query: str) -> str:\n",
        "    \"\"\"Get the correct reference answer for a given query\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS.get(\n",
        "        query, f\"No reference answer available for: {query}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Hotel Search Agent Setup\n",
        "\n",
        "Setup the complete hotel search agent infrastructure using LangChain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_hotel_support_agent():\n",
        "    \"\"\"Setup the hotel support agent with Agent Catalog integration.\"\"\"\n",
        "    try:\n",
        "        # Initialize Agent Catalog with single application span\n",
        "        catalog = agentc.catalog.Catalog()\n",
        "        application_span = catalog.Span(name=\"Hotel Support Agent\", blacklist=set())\n",
        "\n",
        "        # Setup environment\n",
        "        setup_environment()\n",
        "\n",
        "        # Test Capella AI connectivity if configured\n",
        "        if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "            if not test_capella_connectivity():\n",
        "                logger.warning(\n",
        "                    \"❌ Capella AI connectivity test failed. Will use OpenAI fallback.\"\n",
        "                )\n",
        "        else:\n",
        "            logger.info(\"ℹ️ Capella API not configured - will use OpenAI models\")\n",
        "\n",
        "        # Setup Couchbase connection and collections using CouchbaseClient\n",
        "        couchbase_client = CouchbaseClient(\n",
        "            conn_string=os.getenv(\"CB_CONN_STRING\", \"couchbase://localhost\"),\n",
        "            username=os.getenv(\"CB_USERNAME\", \"Administrator\"),\n",
        "            password=os.getenv(\"CB_PASSWORD\", \"password\"),\n",
        "            bucket_name=os.getenv(\"CB_BUCKET\", DEFAULT_BUCKET),\n",
        "        )\n",
        "        couchbase_client.connect()\n",
        "\n",
        "        # Create agent using the CouchbaseClient\n",
        "        agent_executor = couchbase_client.create_langchain_agent(catalog, application_span)\n",
        "\n",
        "        return agent_executor, application_span\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error setting up hotel support agent: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Setup the hotel search agent\n",
        "agent, span = setup_hotel_support_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test Functions\n",
        "Define test functions to demonstrate the hotel search agent functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_hotel_query(query: str, agent):\n",
        "    \"\"\"Run a single hotel query with error handling.\"\"\"\n",
        "    logger.info(f\"🏨 Hotel Query: {query}\")\n",
        "    \n",
        "    try:\n",
        "        # Run the agent with LangChain invoke interface\n",
        "        response = agent.invoke({\"input\": query})\n",
        "        result = response[\"output\"]\n",
        "        \n",
        "        logger.info(f\"🤖 AI Response: {result}\")\n",
        "        logger.info(\"✅ Query completed successfully\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Query failed: {e}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def test_hotel_data_loading():\n",
        "    \"\"\"Test hotel data loading from travel-sample independently.\"\"\"\n",
        "    logger.info(\"Testing Hotel Data Loading from travel-sample\")\n",
        "    logger.info(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Test hotel count\n",
        "        count = get_hotel_count()\n",
        "        logger.info(f\"✅ Hotel count in travel-sample.inventory.hotel: {count}\")\n",
        "        \n",
        "        # Test hotel text generation\n",
        "        texts = get_hotel_texts()\n",
        "        logger.info(f\"✅ Generated {len(texts)} hotel texts for embeddings\")\n",
        "        \n",
        "        if texts:\n",
        "            logger.info(f\"✅ First hotel text sample: {texts[0][:200]}...\")\n",
        "        \n",
        "        logger.info(\"✅ Data loading test completed successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Data loading test failed: {e}\")\n",
        "\n",
        "\n",
        "# Test hotel data loading\n",
        "test_hotel_data_loading()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 1: Hotels in Giverny with Free Breakfast\n",
        "\n",
        "Search for hotels in Giverny, France that offer free breakfast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result1 = run_hotel_query(\"Find hotels in Giverny with free breakfast\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 2: Hotels in Glossop with Free Internet\n",
        "\n",
        "Search for hotels in Glossop, UK that offer free internet access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result2 = run_hotel_query(\"I need a hotel in Glossop with free internet access\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 3: Hotels in Helensburgh with Free Breakfast\n",
        "\n",
        "Search for hotels in Helensburgh, Scotland that offer free breakfast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result3 = run_hotel_query(\"Show me hotels in Helensburgh with free breakfast\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Phoenix Evaluation System\n",
        "\n",
        "Complete Phoenix evaluation system from evals/eval_arize.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phoenix evaluation dependencies and configuration\n",
        "import json\n",
        "import socket\n",
        "import subprocess\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from dataclasses import dataclass\n",
        "import pandas as pd\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to handle nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sqlalchemy\")\n",
        "warnings.filterwarnings(\"ignore\", message=\".*expression-based index.*\")\n",
        "\n",
        "# Try to import Phoenix dependencies\n",
        "try:\n",
        "    import phoenix as px\n",
        "    from openinference.instrumentation.langchain import LangChainInstrumentor\n",
        "    from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "    from phoenix.evals import (\n",
        "        HALLUCINATION_PROMPT_RAILS_MAP,\n",
        "        HALLUCINATION_PROMPT_TEMPLATE,\n",
        "        QA_PROMPT_RAILS_MAP,\n",
        "        QA_PROMPT_TEMPLATE,\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        HallucinationEvaluator,\n",
        "        OpenAIModel,\n",
        "        QAEvaluator,\n",
        "        RelevanceEvaluator,\n",
        "        ToxicityEvaluator,\n",
        "        llm_classify,\n",
        "        run_evals,\n",
        "    )\n",
        "    from phoenix.otel import register\n",
        "    ARIZE_AVAILABLE = True\n",
        "    logger.info(\"✅ Phoenix dependencies available\")\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Phoenix dependencies not available: {e}\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "@dataclass\n",
        "class EvaluationConfig:\n",
        "    \"\"\"Configuration for the evaluation system.\"\"\"\n",
        "    project_name: str = \"hotel-search-agent-evaluation\"\n",
        "    phoenix_base_port: int = 6007\n",
        "    evaluator_model: str = \"gpt-4o\"\n",
        "    max_queries: int = 10\n",
        "\n",
        "class PhoenixManager:\n",
        "    \"\"\"Manages Phoenix server lifecycle.\"\"\"\n",
        "    \n",
        "    def __init__(self, config: EvaluationConfig):\n",
        "        self.config = config\n",
        "        self.session = None\n",
        "        self.active_port = None\n",
        "        self.tracer_provider = None\n",
        "\n",
        "    def _kill_existing_phoenix_processes(self) -> None:\n",
        "        \"\"\"Kill any existing Phoenix processes.\"\"\"\n",
        "        try:\n",
        "            subprocess.run([\"pkill\", \"-f\", \"phoenix\"], check=False, capture_output=True)\n",
        "            time.sleep(2)  # Wait for processes to terminate\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"Error killing Phoenix processes: {e}\")\n",
        "\n",
        "    def start_phoenix(self) -> bool:\n",
        "        if not ARIZE_AVAILABLE:\n",
        "            logger.warning(\"⚠️ Phoenix dependencies not available\")\n",
        "            return False\n",
        "        try:\n",
        "            # Kill existing Phoenix processes first\n",
        "            self._kill_existing_phoenix_processes()\n",
        "            logger.info(\"🔧 Setting up Phoenix observability...\")\n",
        "            self.session = px.launch_app(port=self.config.phoenix_base_port)\n",
        "            self.active_port = self.config.phoenix_base_port\n",
        "            if self.session:\n",
        "                logger.info(f\"🌐 Phoenix UI: {self.session.url}\")\n",
        "            self.tracer_provider = register(\n",
        "                project_name=self.config.project_name,\n",
        "                endpoint=f\"http://localhost:{self.config.phoenix_base_port}/v1/traces\",\n",
        "            )\n",
        "            logger.info(\"✅ Phoenix setup completed successfully\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Phoenix setup failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def setup_instrumentation(self) -> bool:\n",
        "        if not self.tracer_provider or not ARIZE_AVAILABLE:\n",
        "            return False\n",
        "        try:\n",
        "            instrumentors = [(\"LangChain\", LangChainInstrumentor), (\"OpenAI\", OpenAIInstrumentor)]\n",
        "            for name, instrumentor_class in instrumentors:\n",
        "                try:\n",
        "                    instrumentor = instrumentor_class()\n",
        "                    instrumentor.instrument(tracer_provider=self.tracer_provider)\n",
        "                    logger.info(f\"✅ {name} instrumentation enabled\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"⚠️ {name} instrumentation failed: {e}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Instrumentation setup failed: {e}\")\n",
        "            return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Arize Phoenix Evaluation\n",
        "\n",
        "This section demonstrates how to evaluate the hotel search agent using Arize Phoenix observability platform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phoenix evaluation demo\n",
        "if ARIZE_AVAILABLE:\n",
        "    try:\n",
        "        # Start Phoenix\n",
        "        config = EvaluationConfig(phoenix_base_port=6007)\n",
        "        phoenix_manager = PhoenixManager(config)\n",
        "        \n",
        "        if phoenix_manager.start_phoenix():\n",
        "            phoenix_manager.setup_instrumentation()\n",
        "            \n",
        "            # Run demo queries\n",
        "            demo_queries = get_evaluation_queries()\n",
        "            demo_results = []\n",
        "            \n",
        "            for i, query in enumerate(demo_queries, 1):\n",
        "                try:\n",
        "                    logger.info(f\"🔍 Query {i}: {query}\")\n",
        "                    response = agent.invoke({\"input\": query})\n",
        "                    output = response[\"output\"]\n",
        "                    demo_results.append({\n",
        "                        \"query\": query,\n",
        "                        \"response\": output,\n",
        "                        \"success\": True\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    demo_results.append({\n",
        "                        \"query\": query,\n",
        "                        \"response\": f\"Error: {e}\",\n",
        "                        \"success\": False\n",
        "                    })\n",
        "            \n",
        "            # Convert to DataFrame for evaluation\n",
        "            hotel_results_df = pd.DataFrame(demo_results)\n",
        "            logger.info(f\"📊 Collected {len(hotel_results_df)} responses for evaluation\")\n",
        "            \n",
        "            logger.info(f\"🚀 Phoenix UI: http://localhost:{config.phoenix_base_port}/\")\n",
        "            logger.info(\"💡 Visit Phoenix UI for detailed traces\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Phoenix evaluation failed: {e}\")\n",
        "        \n",
        "else:\n",
        "    logger.info(\"Phoenix not available - install phoenix-evals\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run comprehensive Phoenix evaluations with lenient templates\n",
        "if ARIZE_AVAILABLE and len(demo_results) > 0:\n",
        "    logger.info(\"🔍 Running comprehensive Phoenix evaluations...\")\n",
        "\n",
        "    # Setup evaluator LLM\n",
        "    evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.1)\n",
        "\n",
        "    # Prepare evaluation data\n",
        "    hotel_eval_data = []\n",
        "    for _, row in hotel_results_df.iterrows():\n",
        "        hotel_eval_data.append({\n",
        "            \"input\": row[\"query\"],\n",
        "            \"output\": row[\"response\"],\n",
        "            \"reference\": get_reference_answer(row[\"query\"]),\n",
        "            \"text\": row[\"response\"],  # For toxicity evaluation\n",
        "        })\n",
        "\n",
        "    hotel_eval_df = pd.DataFrame(hotel_eval_data)\n",
        "    logger.info(f\"📊 Prepared {len(hotel_eval_df)} queries for Phoenix evaluation\")\n",
        "\n",
        "    try:\n",
        "        # 1. Relevance Evaluation\n",
        "        logger.info(\"🔍 Running Relevance Evaluation...\")\n",
        "        hotel_relevance_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "            rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Relevance Evaluation Results:\")\n",
        "        relevance_labels = hotel_relevance_results['label'].tolist() if 'label' in hotel_relevance_results.columns else []\n",
        "        for i, (query, label) in enumerate(zip(hotel_eval_df['input'], relevance_labels)):\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Relevance: {label}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 2. QA Evaluation\n",
        "        logger.info(\"🔍 Running QA Evaluation...\")\n",
        "        hotel_qa_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\", \"output\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=QA_PROMPT_TEMPLATE,\n",
        "            rails=list(QA_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ QA Evaluation Results:\")\n",
        "        qa_labels = hotel_qa_results['label'].tolist() if 'label' in hotel_qa_results.columns else []\n",
        "        for i, (query, label) in enumerate(zip(hotel_eval_df['input'], qa_labels)):\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   QA Score: {label}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 3. Hallucination Evaluation\n",
        "        logger.info(\"🔍 Running Hallucination Evaluation...\")\n",
        "        hotel_hallucination_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\", \"reference\", \"output\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=HALLUCINATION_PROMPT_TEMPLATE,\n",
        "            rails=list(HALLUCINATION_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Hallucination Evaluation Results:\")\n",
        "        hallucination_labels = hotel_hallucination_results['label'].tolist() if 'label' in hotel_hallucination_results.columns else []\n",
        "        for i, (query, label) in enumerate(zip(hotel_eval_df['input'], hallucination_labels)):\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Hallucination: {label}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 4. Toxicity Evaluation\n",
        "        logger.info(\"🔍 Running Toxicity Evaluation...\")\n",
        "        hotel_toxicity_results = llm_classify(\n",
        "            data=hotel_eval_df[[\"input\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=TOXICITY_PROMPT_TEMPLATE,\n",
        "            rails=list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Toxicity Evaluation Results:\")\n",
        "        toxicity_labels = hotel_toxicity_results['label'].tolist() if 'label' in hotel_toxicity_results.columns else []\n",
        "        for i, (query, label) in enumerate(zip(hotel_eval_df['input'], toxicity_labels)):\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Toxicity: {label}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # Summary\n",
        "        logger.info(\"\\n📊 Phoenix Evaluation Summary:\")\n",
        "        logger.info(f\"  Relevance: {dict(pd.Series(relevance_labels).value_counts())}\")\n",
        "        logger.info(f\"  QA Correctness: {dict(pd.Series(qa_labels).value_counts())}\")\n",
        "        logger.info(f\"  Hallucination: {dict(pd.Series(hallucination_labels).value_counts())}\")\n",
        "        logger.info(f\"  Toxicity: {dict(pd.Series(toxicity_labels).value_counts())}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Phoenix evaluation failed: {e}\")\n",
        "\n",
        "else:\n",
        "    logger.info(\"⚠️ Skipping Phoenix evaluations - no demo results available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete hotel search agent using LangChain, Couchbase vector store, and Capella AI. The agent handles hotel search queries with amenity filtering and location-based recommendations using real travel-sample data.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "1. **LangChain ReAct Agent**: Uses LangChain's ReAct pattern for reasoning and action\n",
        "2. **Couchbase Vector Store**: Real travel-sample hotel data with vector search\n",
        "3. **Capella AI Integration**: Priority 1 AI services with OpenAI fallback\n",
        "4. **Agent Catalog**: Tool and prompt discovery and integration\n",
        "5. **Phoenix Evaluation**: Comprehensive evaluation with relevance, QA, hallucination, and toxicity metrics\n",
        "\n",
        "## Phoenix Evaluation Metrics\n",
        "\n",
        "The notebook demonstrates all four key Phoenix evaluation types:\n",
        "\n",
        "1. **Relevance Evaluation**: Measures how relevant responses are to hotel queries\n",
        "2. **QA Evaluation**: Assesses the quality and accuracy of hotel information\n",
        "3. **Hallucination Detection**: Identifies fabricated or incorrect hotel information\n",
        "4. **Toxicity Detection**: Screens for harmful or inappropriate content\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
