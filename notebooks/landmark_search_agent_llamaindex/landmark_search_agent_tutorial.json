{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Landmark Search Agent Tutorial - Priority 1 Implementation\n",
        "\n",
        "This notebook demonstrates the Agent Catalog landmark search agent using LlamaIndex with Couchbase vector store and Arize Phoenix evaluation. Uses Priority 1 AI services with standard OpenAI wrappers and Capella (simple & fast).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary modules for the landmark search agent using self-contained setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import getpass\n",
        "import httpx\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "import agentc\n",
        "import dotenv\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.management.buckets import BucketType, CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.nvidia import NVIDIA\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore\n",
        "from pydantic import SecretStr\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Reduce noise from various libraries during embedding/vector operations\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv(override=True)\n",
        "\n",
        "# Set default values for travel-sample bucket configuration\n",
        "DEFAULT_BUCKET = \"travel-sample\"\n",
        "DEFAULT_SCOPE = \"agentc_data\"\n",
        "DEFAULT_COLLECTION = \"landmark_data\"\n",
        "DEFAULT_INDEX = \"landmark_data_index\"\n",
        "DEFAULT_CAPELLA_API_EMBEDDING_MODEL = \"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
        "DEFAULT_CAPELLA_API_LLM_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "DEFAULT_NVIDIA_API_LLM_MODEL = \"meta/llama-3.1-70b-instruct\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Self-Contained Setup Functions\n",
        "\n",
        "Define all necessary setup functions inline for a self-contained notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:22:26,620 - INFO - ✅ Environment variables configured\n"
          ]
        }
      ],
      "source": [
        "def setup_environment():\n",
        "    \"\"\"Setup default environment variables for agent operations.\"\"\"\n",
        "    defaults = {\n",
        "        \"CB_BUCKET\": \"travel-sample\",\n",
        "        \"CB_SCOPE\": \"agentc_data\",\n",
        "        \"CB_COLLECTION\": \"landmark_data\",\n",
        "        \"CB_INDEX\": \"landmark_data_index\",\n",
        "        \"NVIDIA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"NVIDIA_API_LLM_MODEL\": \"meta/llama-3.1-70b-instruct\",\n",
        "        \"CAPELLA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"CAPELLA_API_LLM_MODEL\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "    }\n",
        "    \n",
        "    for key, value in defaults.items():\n",
        "        if not os.getenv(key):\n",
        "            os.environ[key] = value\n",
        "    \n",
        "    logger.info(\"✅ Environment variables configured\")\n",
        "\n",
        "\n",
        "def test_capella_connectivity(api_key: str = None, endpoint: str = None) -> bool:\n",
        "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
        "    try:\n",
        "        test_key = api_key or os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\") or os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "        test_endpoint = endpoint or os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        \n",
        "        if not test_key or not test_endpoint:\n",
        "            return False\n",
        "        \n",
        "        # Simple connectivity test\n",
        "        headers = {\"Authorization\": f\"Bearer {test_key}\"}\n",
        "        \n",
        "        with httpx.Client(timeout=10.0) as client:\n",
        "            response = client.get(f\"{test_endpoint.rstrip('/')}/v1/models\", headers=headers)\n",
        "            return response.status_code < 500\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"⚠️ Capella connectivity test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def setup_ai_services(framework: str = \"llamaindex\", temperature: float = 0.0, application_span=None):\n",
        "    \"\"\"Priority 1: Capella AI with OpenAI wrappers (simple & fast) for LlamaIndex.\"\"\"\n",
        "    embeddings = None\n",
        "    llm = None\n",
        "    \n",
        "    logger.info(f\"🔧 Setting up Priority 1 AI services for {framework} framework...\")\n",
        "    \n",
        "    # Priority 1: Capella AI with direct API keys and OpenAI wrappers\n",
        "    if not embeddings and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            api_key = os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "            model = os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\")\n",
        "            \n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                api_base = endpoint\n",
        "            else:\n",
        "                api_base = f\"{endpoint}/v1\"\n",
        "            \n",
        "            # Debug logging - same pattern as working test\n",
        "            logger.info(f\"🔧 Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 Model: {model}\")\n",
        "            logger.info(f\"🔧 API Base: {api_base}\")\n",
        "            \n",
        "            embeddings = OpenAIEmbedding(\n",
        "                api_key=api_key,\n",
        "                api_base=api_base,\n",
        "                model_name=model,\n",
        "                embed_batch_size=30,\n",
        "                # Note: LlamaIndex doesn't need check_embedding_ctx_length=False\n",
        "            )\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI embeddings failed: {type(e).__name__}: {e}\")\n",
        "    \n",
        "    if not llm and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_LLM_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            llm_key = os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "            llm_model = os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
        "            \n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                api_base = endpoint\n",
        "            else:\n",
        "                api_base = f\"{endpoint}/v1\"\n",
        "            \n",
        "            # Debug logging\n",
        "            logger.info(f\"🔧 LLM Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 LLM Model: {llm_model}\")\n",
        "            logger.info(f\"🔧 LLM API Base: {api_base}\")\n",
        "            \n",
        "            llm = OpenAILike(\n",
        "                model=llm_model,\n",
        "                api_base=api_base,\n",
        "                api_key=llm_key,\n",
        "                is_chat_model=True,\n",
        "                is_function_calling_model=False,  # KEY FIX - prevents 500 errors\n",
        "                context_window=128000,  # Add context window for compatibility\n",
        "                temperature=temperature,\n",
        "                max_retries=1,  # Faster debugging\n",
        "            )\n",
        "            # Test the LLM works\n",
        "            test_response = llm.complete(\"Hello\")\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI LLM failed: {type(e).__name__}: {e}\")\n",
        "            llm = None\n",
        "    \n",
        "    # Fallback: OpenAI\n",
        "    if not embeddings and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            embeddings = OpenAIEmbedding(\n",
        "                model_name=\"text-embedding-3-small\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI embeddings fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI embeddings failed: {e}\")\n",
        "    \n",
        "    if not llm and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            llm = OpenAILike(\n",
        "                model=\"gpt-4o\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                is_chat_model=True,\n",
        "                is_function_calling_model=False,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI LLM fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI LLM failed: {e}\")\n",
        "    \n",
        "    if not embeddings:\n",
        "        raise ValueError(\"❌ No embeddings service could be initialized\")\n",
        "    if not llm:\n",
        "        raise ValueError(\"❌ No LLM service could be initialized\")\n",
        "    \n",
        "    logger.info(f\"✅ Priority 1 AI services setup completed for {framework}\")\n",
        "    return embeddings, llm\n",
        "\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()\n",
        "\n",
        "# Test Capella AI connectivity if configured\n",
        "if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "    if not test_capella_connectivity():\n",
        "        logger.warning(\"❌ Capella AI connectivity test failed. Will use fallback models.\")\n",
        "else:\n",
        "    logger.info(\"ℹ️ Capella API not configured - will use fallback models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CouchbaseClient Class\n",
        "\n",
        "Define the CouchbaseClient for all database operations and LlamaIndex agent creation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
        "\n",
        "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
        "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "\n",
        "            # Use WAN profile for better timeout handling with remote clusters\n",
        "            options.apply_profile(\"wan_development\")\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=20))\n",
        "            logger.info(\"Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Setup collection - create scope and collection if they don't exist.\"\"\"\n",
        "        try:\n",
        "            # Ensure cluster connection\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            # For travel-sample bucket, assume it exists\n",
        "            if not self.bucket:\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"Connected to bucket '{self.bucket_name}'\")\n",
        "\n",
        "            # Setup scope\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
        "\n",
        "            # Setup collection - clear if exists, create if doesn't\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name\n",
        "                and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists:\n",
        "                logger.info(f\"Collection '{collection_name}' exists, clearing data...\")\n",
        "                # Clear existing data\n",
        "                self.clear_collection_data(scope_name, collection_name)\n",
        "            else:\n",
        "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
        "\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Create primary index\n",
        "            try:\n",
        "                self.cluster.query(\n",
        "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                ).execute()\n",
        "                logger.info(\"Primary index created successfully\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error creating primary index: {e}\")\n",
        "\n",
        "            logger.info(\"Collection setup complete\")\n",
        "            return self.bucket.scope(scope_name).collection(collection_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Clear all data from a collection.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "\n",
        "            # Use N1QL to delete all documents with explicit execution\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "\n",
        "            # Execute the query and get the results\n",
        "            rows = list(result)\n",
        "\n",
        "            # Wait a moment for the deletion to propagate\n",
        "            time.sleep(2)\n",
        "\n",
        "            # Verify collection is empty\n",
        "            count_query = f\"SELECT COUNT(*) as count FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            count_result = self.cluster.query(count_query)\n",
        "            count_row = list(count_result)[0]\n",
        "            remaining_count = count_row[\"count\"]\n",
        "\n",
        "            if remaining_count == 0:\n",
        "                logger.info(f\"Collection cleared successfully, {remaining_count} documents remaining\")\n",
        "            else:\n",
        "                logger.warning(f\"Collection clear incomplete, {remaining_count} documents remaining\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error clearing collection data: {e}\")\n",
        "            # If N1QL fails, try to continue anyway\n",
        "            pass\n",
        "\n",
        "    def get_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Get a collection object.\"\"\"\n",
        "        key = f\"{scope_name}.{collection_name}\"\n",
        "        if key not in self._collections:\n",
        "            self._collections[key] = self.bucket.scope(scope_name).collection(collection_name)\n",
        "        return self._collections[key]\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                raise RuntimeError(\"Bucket not initialized. Call setup_collection first.\")\n",
        "\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
        "            else:\n",
        "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector search index: {e!s}\")\n",
        "\n",
        "    def load_landmark_data(self, scope_name, collection_name, index_name, embeddings):\n",
        "        \"\"\"Load landmark data into Couchbase.\"\"\"\n",
        "        try:\n",
        "            # Import landmark data loading function\n",
        "            # Use inline landmark data loading function (already defined in this notebook)\n",
        "            # The function load_landmark_data_to_couchbase is defined inline above in this notebook\n",
        "\n",
        "            # Load landmark data using the data loading script\n",
        "            load_landmark_data_to_couchbase(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embeddings=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "            logger.info(\"Landmark data loaded into vector store successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading landmark data: {e!s}\")\n",
        "\n",
        "    def setup_vector_store_and_agent(self, catalog, span):\n",
        "        \"\"\"Setup vector store with landmark data and create agent.\"\"\"\n",
        "        # Setup AI services using Priority 1: Capella AI + OpenAI wrappers\n",
        "        embeddings, llm = setup_ai_services(framework=\"llamaindex\", temperature=0.1, application_span=span)\n",
        "        \n",
        "        # Set global LlamaIndex settings\n",
        "        Settings.llm = llm\n",
        "        Settings.embed_model = embeddings\n",
        "        \n",
        "        # Setup collection\n",
        "        self.setup_collection(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"])\n",
        "        \n",
        "        # Setup vector search index - MUST have agentcatalog_index.json\n",
        "        with open(\"agentcatalog_index.json\") as file:\n",
        "            index_definition = json.load(file)\n",
        "        logger.info(\"Loaded vector search index definition from agentcatalog_index.json\")\n",
        "        self.setup_vector_search_index(index_definition, os.environ[\"CB_SCOPE\"])\n",
        "        \n",
        "        # Load landmark data\n",
        "        self.load_landmark_data(\n",
        "            os.environ[\"CB_SCOPE\"],\n",
        "            os.environ[\"CB_COLLECTION\"],\n",
        "            os.environ[\"CB_INDEX\"],\n",
        "            embeddings,\n",
        "        )\n",
        "        \n",
        "        # Create LlamaIndex ReAct agent\n",
        "        agent = self.create_llamaindex_agent(catalog, span)\n",
        "        \n",
        "        return agent\n",
        "\n",
        "    def create_llamaindex_agent(self, catalog, span):\n",
        "        \"\"\"Create LlamaIndex ReAct agent with landmark search tool from Agent Catalog.\"\"\"\n",
        "        try:\n",
        "            # Get tools from Agent Catalog\n",
        "            tools = []\n",
        "\n",
        "            # Search landmarks tool\n",
        "            search_tool_result = catalog.find(\"tool\", name=\"search_landmarks\")\n",
        "            if search_tool_result:\n",
        "                tools.append(\n",
        "                    FunctionTool.from_defaults(\n",
        "                        fn=search_tool_result.func,\n",
        "                        name=\"search_landmarks\",\n",
        "                        description=getattr(search_tool_result.meta, \"description\", None)\n",
        "                        or \"Search for landmark information using semantic vector search. Use for finding attractions, monuments, museums, parks, and other points of interest.\",\n",
        "                    )\n",
        "                )\n",
        "                logger.info(\"Loaded search_landmarks tool from AgentC\")\n",
        "\n",
        "            if not tools:\n",
        "                logger.warning(\"No tools found in Agent Catalog\")\n",
        "            else:\n",
        "                logger.info(f\"Loaded {len(tools)} tools from Agent Catalog\")\n",
        "\n",
        "            # Get prompt from Agent Catalog - REQUIRED, no fallbacks\n",
        "            prompt_result = catalog.find(\"prompt\", name=\"landmark_search_assistant\")\n",
        "            if not prompt_result:\n",
        "                raise RuntimeError(\"Prompt 'landmark_search_assistant' not found in Agent Catalog\")\n",
        "\n",
        "            # Try different possible attributes for the prompt content\n",
        "            system_prompt = (\n",
        "                getattr(prompt_result, \"content\", None)\n",
        "                or getattr(prompt_result, \"template\", None)\n",
        "                or getattr(prompt_result, \"text\", None)\n",
        "            )\n",
        "            if not system_prompt:\n",
        "                raise RuntimeError(\n",
        "                    \"Could not access prompt content from AgentC - prompt content is None or empty\"\n",
        "                )\n",
        "\n",
        "            logger.info(\"Loaded system prompt from Agent Catalog\")\n",
        "\n",
        "            # Create ReAct agent with limits to prevent excessive iterations\n",
        "            agent = ReActAgent.from_tools(\n",
        "                tools=tools,\n",
        "                llm=Settings.llm,\n",
        "                verbose=True,\n",
        "                system_prompt=system_prompt,\n",
        "                max_iterations=12,\n",
        "            )\n",
        "\n",
        "            logger.info(\"LlamaIndex ReAct agent created successfully\")\n",
        "            return agent\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error creating LlamaIndex agent: {e!s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Standalone Agent Creation Function\n",
        "\n",
        "Standalone version of the agent creation function for compatibility with main.py structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_llamaindex_agent(catalog, span):\n",
        "    \"\"\"Create LlamaIndex ReAct agent with landmark search tool from Agent Catalog.\"\"\"\n",
        "    try:\n",
        "        from llama_index.core.agent import ReActAgent\n",
        "        from llama_index.core.tools import FunctionTool\n",
        "\n",
        "        # Get tools from Agent Catalog\n",
        "        tools = []\n",
        "\n",
        "        # Search landmarks tool\n",
        "        search_tool_result = catalog.find(\"tool\", name=\"search_landmarks\")\n",
        "        if search_tool_result:\n",
        "            tools.append(\n",
        "                FunctionTool.from_defaults(\n",
        "                    fn=search_tool_result.func,\n",
        "                    name=\"search_landmarks\",\n",
        "                    description=getattr(search_tool_result.meta, \"description\", None)\n",
        "                    or \"Search for landmark information using semantic vector search. Use for finding attractions, monuments, museums, parks, and other points of interest.\",\n",
        "                )\n",
        "            )\n",
        "            logger.info(\"Loaded search_landmarks tool from AgentC\")\n",
        "\n",
        "        if not tools:\n",
        "            logger.warning(\"No tools found in Agent Catalog\")\n",
        "        else:\n",
        "            logger.info(f\"Loaded {len(tools)} tools from Agent Catalog\")\n",
        "\n",
        "        # Get prompt from Agent Catalog - REQUIRED, no fallbacks\n",
        "        prompt_result = catalog.find(\"prompt\", name=\"landmark_search_assistant\")\n",
        "        if not prompt_result:\n",
        "            raise RuntimeError(\"Prompt 'landmark_search_assistant' not found in Agent Catalog\")\n",
        "\n",
        "        # Try different possible attributes for the prompt content\n",
        "        system_prompt = (\n",
        "            getattr(prompt_result, \"content\", None)\n",
        "            or getattr(prompt_result, \"template\", None)\n",
        "            or getattr(prompt_result, \"text\", None)\n",
        "        )\n",
        "        if not system_prompt:\n",
        "            raise RuntimeError(\n",
        "                \"Could not access prompt content from AgentC - prompt content is None or empty\"\n",
        "            )\n",
        "\n",
        "        logger.info(\"Loaded system prompt from Agent Catalog\")\n",
        "\n",
        "        # Create ReAct agent with reasonable iteration limit\n",
        "        agent = ReActAgent.from_tools(\n",
        "            tools=tools,\n",
        "            llm=Settings.llm,\n",
        "            verbose=True,  # Keep on for debugging\n",
        "            system_prompt=system_prompt,\n",
        "            max_iterations=10,  # Allow sufficient reasoning steps for complex landmark queries\n",
        "        )\n",
        "\n",
        "        logger.info(\"LlamaIndex ReAct agent created successfully\")\n",
        "        return agent\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error creating LlamaIndex agent: {e!s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Loading Module\n",
        "\n",
        "Complete landmark data loading functions from data/landmark_data.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading functions from data/landmark_data.py\n",
        "import couchbase.auth\n",
        "import couchbase.cluster\n",
        "import couchbase.exceptions\n",
        "import couchbase.options\n",
        "from llama_index.core import Document\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def get_cluster_connection():\n",
        "    \"\"\"Get a fresh cluster connection for each request.\"\"\"\n",
        "    try:\n",
        "        auth = couchbase.auth.PasswordAuthenticator(\n",
        "            username=os.environ[\"CB_USERNAME\"],\n",
        "            password=os.environ[\"CB_PASSWORD\"],\n",
        "        )\n",
        "        options = couchbase.options.ClusterOptions(authenticator=auth)\n",
        "        # Use WAN profile for better timeout handling with remote clusters\n",
        "        options.apply_profile(\"wan_development\")\n",
        "\n",
        "        cluster = couchbase.cluster.Cluster(\n",
        "            os.environ[\"CB_CONN_STRING\"], options\n",
        "        )\n",
        "        cluster.wait_until_ready(timedelta(seconds=15))\n",
        "        return cluster\n",
        "    except couchbase.exceptions.CouchbaseException as e:\n",
        "        logger.error(f\"Could not connect to Couchbase cluster: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_landmark_data_from_travel_sample():\n",
        "    \"\"\"Load landmark data from travel-sample.inventory.landmark collection.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        # Query to get all landmark documents from travel-sample.inventory.landmark\n",
        "        query = \"\"\"\n",
        "        SELECT l.*, META(l).id as doc_id\n",
        "        FROM `travel-sample`.inventory.landmark l\n",
        "        ORDER BY l.name\n",
        "        \"\"\"\n",
        "\n",
        "        logger.info(\"Loading landmark data from travel-sample.inventory.landmark...\")\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        landmarks = []\n",
        "        logger.info(\"Processing landmark documents...\")\n",
        "\n",
        "        # Convert to list to get total count for progress bar\n",
        "        landmark_rows = list(result)\n",
        "\n",
        "        # Use tqdm for progress bar\n",
        "        for row in tqdm(landmark_rows, desc=\"Loading landmarks\", unit=\"landmarks\"):\n",
        "            landmark = row\n",
        "            landmarks.append(landmark)\n",
        "\n",
        "        logger.info(f\"Loaded {len(landmarks)} landmarks from travel-sample.inventory.landmark\")\n",
        "        return landmarks\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading landmark data: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_landmark_texts():\n",
        "    \"\"\"Returns formatted landmark texts for vector store embedding from travel-sample data.\"\"\"\n",
        "    landmarks = load_landmark_data_from_travel_sample()\n",
        "    landmark_texts = []\n",
        "\n",
        "    logger.info(\"Generating landmark text embeddings...\")\n",
        "\n",
        "    # Use tqdm for progress bar while processing landmarks\n",
        "    for landmark in tqdm(landmarks, desc=\"Processing landmarks\", unit=\"landmarks\"):\n",
        "        # Start with basic info\n",
        "        name = landmark.get(\"name\", \"Unknown Landmark\")\n",
        "        title = landmark.get(\"title\", name)\n",
        "        city = landmark.get(\"city\", \"Unknown City\")\n",
        "        country = landmark.get(\"country\", \"Unknown Country\")\n",
        "\n",
        "        # Build comprehensive text with all available fields\n",
        "        text_parts = [f\"{title} ({name}) in {city}, {country}\"]\n",
        "\n",
        "        # Add all fields dynamically instead of manual selection\n",
        "        field_mappings = {\n",
        "            \"content\": \"Description\",\n",
        "            \"address\": \"Address\",\n",
        "            \"directions\": \"Directions\",\n",
        "            \"phone\": \"Phone\",\n",
        "            \"tollfree\": \"Toll-free\",\n",
        "            \"email\": \"Email\",\n",
        "            \"url\": \"Website\",\n",
        "            \"hours\": \"Hours\",\n",
        "            \"price\": \"Price\",\n",
        "            \"activity\": \"Activity type\",\n",
        "            \"type\": \"Type\",\n",
        "            \"state\": \"State\",\n",
        "            \"alt\": \"Alternative name\",\n",
        "            \"image\": \"Image\",\n",
        "        }\n",
        "\n",
        "        # Add all available fields\n",
        "        for field, label in field_mappings.items():\n",
        "            value = landmark.get(field)\n",
        "            if value is not None and value != \"\" and value != \"None\":\n",
        "                if isinstance(value, bool):\n",
        "                    text_parts.append(f\"{label}: {'Yes' if value else 'No'}\")\n",
        "                else:\n",
        "                    text_parts.append(f\"{label}: {value}\")\n",
        "\n",
        "        # Add geographic coordinates if available\n",
        "        if landmark.get(\"geo\"):\n",
        "            geo = landmark[\"geo\"]\n",
        "            if geo.get(\"lat\") and geo.get(\"lon\"):\n",
        "                accuracy = geo.get(\"accuracy\", \"Unknown\")\n",
        "                text_parts.append(f\"Coordinates: {geo['lat']}, {geo['lon']} (accuracy: {accuracy})\")\n",
        "\n",
        "        # Add ID for reference\n",
        "        if landmark.get(\"id\"):\n",
        "            text_parts.append(f\"ID: {landmark['id']}\")\n",
        "\n",
        "        # Join all parts with \". \"\n",
        "        text = \". \".join(text_parts)\n",
        "        landmark_texts.append(text)\n",
        "\n",
        "    logger.info(f\"Generated {len(landmark_texts)} landmark text embeddings\")\n",
        "    return landmark_texts\n",
        "\n",
        "\n",
        "def load_landmark_data_to_couchbase(\n",
        "    cluster, bucket_name: str, scope_name: str, collection_name: str, embeddings, index_name: str\n",
        "):\n",
        "    \"\"\"Load landmark data from travel-sample into the target collection with embeddings.\"\"\"\n",
        "    try:\n",
        "        # Check if data already exists\n",
        "        count_query = (\n",
        "            f\"SELECT COUNT(*) as count FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "        )\n",
        "        count_result = cluster.query(count_query)\n",
        "        count_row = list(count_result)[0]\n",
        "        existing_count = count_row[\"count\"]\n",
        "\n",
        "        if existing_count > 0:\n",
        "            logger.info(\n",
        "                f\"Found {existing_count} existing documents in collection, skipping data load\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Get the source landmarks from travel-sample\n",
        "        landmarks = load_landmark_data_from_travel_sample()\n",
        "        landmark_texts = get_landmark_texts()\n",
        "\n",
        "        # Setup vector store for the target collection\n",
        "        vector_store = CouchbaseSearchVectorStore(\n",
        "            cluster=cluster,\n",
        "            bucket_name=bucket_name,\n",
        "            scope_name=scope_name,\n",
        "            collection_name=collection_name,\n",
        "            index_name=index_name,\n",
        "        )\n",
        "\n",
        "        # Create LlamaIndex Documents\n",
        "        logger.info(f\"Creating {len(landmark_texts)} LlamaIndex Documents...\")\n",
        "        documents = []\n",
        "        \n",
        "        for i, (landmark, text) in enumerate(zip(landmarks, landmark_texts)):\n",
        "            document = Document(\n",
        "                text=text,\n",
        "                metadata={\n",
        "                    \"landmark_id\": landmark.get(\"id\", f\"landmark_{i}\"),\n",
        "                    \"name\": landmark.get(\"name\", \"Unknown\"),\n",
        "                    \"city\": landmark.get(\"city\", \"Unknown\"),\n",
        "                    \"country\": landmark.get(\"country\", \"Unknown\"),\n",
        "                    \"activity\": landmark.get(\"activity\", \"\"),\n",
        "                    \"type\": landmark.get(\"type\", \"\"),\n",
        "                    # Add the missing fields that search tool expects\n",
        "                    \"address\": landmark.get(\"address\", \"\"),\n",
        "                    \"phone\": landmark.get(\"phone\", \"\"),\n",
        "                    \"url\": landmark.get(\"url\", \"\"),\n",
        "                    \"hours\": landmark.get(\"hours\", \"\"),\n",
        "                    \"price\": landmark.get(\"price\", \"\"),\n",
        "                    \"state\": landmark.get(\"state\", \"\"),\n",
        "                }\n",
        "            )\n",
        "            documents.append(document)\n",
        "\n",
        "        # Use IngestionPipeline to process documents with embeddings\n",
        "        logger.info(f\"Processing documents with ingestion pipeline...\")\n",
        "        pipeline = IngestionPipeline(\n",
        "            transformations=[SentenceSplitter(chunk_size=800, chunk_overlap=100), embeddings],\n",
        "            vector_store=vector_store,\n",
        "        )\n",
        "\n",
        "        # Process documents in batches to avoid memory issues\n",
        "        batch_size = 25  # Well below Capella AI embedding model limit\n",
        "        total_batches = (len(documents) + batch_size - 1) // batch_size\n",
        "\n",
        "        logger.info(f\"Processing {len(documents)} documents in {total_batches} batches...\")\n",
        "        \n",
        "        # Process in batches\n",
        "        for i in tqdm(\n",
        "            range(0, len(documents), batch_size),\n",
        "            desc=\"Loading batches\",\n",
        "            unit=\"batch\",\n",
        "            total=total_batches,\n",
        "        ):\n",
        "            batch = documents[i : i + batch_size]\n",
        "            pipeline.run(documents=batch)\n",
        "\n",
        "        logger.info(\n",
        "            f\"Successfully loaded {len(documents)} landmark documents to vector store\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading landmark data to Couchbase: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_landmark_count():\n",
        "    \"\"\"Get the count of landmarks in travel-sample.inventory.landmark.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        query = \"SELECT COUNT(*) as count FROM `travel-sample`.inventory.landmark\"\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        for row in result:\n",
        "            return row[\"count\"]\n",
        "\n",
        "        return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting landmark count: {str(e)}\")\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Query Module\n",
        "\n",
        "Complete query collections and functions from data/queries.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query functions and data from data/queries.py\n",
        "from typing import Dict, List\n",
        "\n",
        "# Landmark search queries (based on travel-sample data)\n",
        "LANDMARK_SEARCH_QUERIES = [\n",
        "    \"Find museums and galleries in Glasgow\",  # Art & Culture, Scotland\n",
        "    \"Show me restaurants serving Asian cuisine\",  # Food & Dining, Real Asian restaurants\n",
        "    \"What attractions can I see in Glasgow?\",  # General sightseeing, Scotland\n",
        "    \"Tell me about Monet's House\",  # Specific landmark, France\n",
        "    \"Find places to eat in Gillingham\",  # Food, Real UK town\n",
        "]\n",
        "\n",
        "# Comprehensive reference answers based on ACTUAL agent responses from travel-sample.inventory.landmark data\n",
        "LANDMARK_REFERENCE_ANSWERS = [\n",
        "    # Query 1: Glasgow museums and galleries\n",
        "    \"\"\"Glasgow has several museums and galleries including the Gallery of Modern Art (Glasgow) located at Royal Exchange Square with a terrific collection of recent paintings and sculptures, the Kelvingrove Art Gallery and Museum on Argyle Street with one of the finest civic collections in Europe including works by Van Gogh, Monet and Rembrandt, the Hunterian Museum and Art Gallery at University of Glasgow with a world famous Whistler collection, and the Riverside Museum at 100 Pointhouse Place with an excellent collection of vehicles and transport history. All offer free admission except for special exhibitions.\"\"\",\n",
        "\n",
        "    # Query 2: Asian cuisine restaurants\n",
        "    \"\"\"There are several Asian restaurants available including Shangri-la Chinese Restaurant in Birmingham at 51 Station Street offering good quality Chinese food with spring rolls and sizzling steak, Taiwan Restaurant in San Francisco famous for their dumplings, Hong Kong Seafood Restaurant in San Francisco for sit-down dim sum, Cheung Hing Chinese Restaurant in San Francisco for Cantonese BBQ and roast duck, Vietnam Restaurant in San Francisco for Vietnamese dishes including crab soup and pork sandwich, and various other Chinese and Asian establishments across different locations.\"\"\",\n",
        "\n",
        "    # Query 3: Glasgow attractions\n",
        "    \"\"\"Glasgow attractions include Glasgow Green (founded by Royal grant in 1450) with Nelson's Memorial and the Doulton Fountain, Glasgow University (founded 1451) with neo-Gothic architecture and commanding views, Glasgow Cathedral with fine Gothic architecture from medieval times, the City Chambers in George Square built in 1888 in Italian Renaissance style with guided tours available, Glasgow Central Station with its grand interior, and Kelvingrove Park which is popular with students and contains the Art Gallery and Museum.\"\"\",\n",
        "\n",
        "    # Query 4: Monet's House\n",
        "    \"\"\"Monet's House is located in Giverny, France at 84 rue Claude Monet. The house is quietly eccentric and highly interesting in an Orient-influenced style, featuring Monet's collection of Japanese prints. The main attraction is the gardens around the house, including the water garden with the Japanese bridge, weeping willows and waterlilies which are now iconic. It's open April-October, Monday-Sunday 9:30-18:00, with admission €9 for adults, €5 for students, €4 for disabled visitors, and free for under-7s. E-tickets can be purchased online and wheelchair access is available.\"\"\",\n",
        "\n",
        "    # Query 5: Gillingham restaurants\n",
        "    \"\"\"Gillingham has various dining options including Beijing Inn (Chinese restaurant at 3 King Street), Spice Court (Indian restaurant at 56-58 Balmoral Road opposite the railway station, award-winning with Sunday Buffet for £8.50), Hollywood Bowl (American-style restaurant at 4 High Street with burgers and ribs in a Hollywood-themed setting), Ossie's Fish and Chips (at 75 Richmond Road, known for the best fish and chips in the area), and Thai Won Mien (oriental restaurant at 59-61 High Street with noodles, duck and other oriental dishes).\"\"\",\n",
        "]\n",
        "\n",
        "# Create dictionary for backward compatibility\n",
        "QUERY_REFERENCE_ANSWERS = {\n",
        "    query: answer for query, answer in zip(LANDMARK_SEARCH_QUERIES, LANDMARK_REFERENCE_ANSWERS)\n",
        "}\n",
        "\n",
        "# Category-based queries for testing specific search capabilities (based on real data)\n",
        "CATEGORY_QUERIES = {\n",
        "    \"cultural\": [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"Show me historic buildings and architecture\",\n",
        "        \"What art collections can I visit?\",\n",
        "    ],\n",
        "    \"culinary\": [\n",
        "        \"Show me restaurants serving Asian cuisine\",\n",
        "        \"Find places to eat in Gillingham\",\n",
        "        \"What dining options are available?\",\n",
        "    ],\n",
        "    \"sightseeing\": [\n",
        "        \"What attractions can I see in Glasgow?\",\n",
        "        \"Show me historic landmarks and buildings\",\n",
        "        \"Find interesting places to visit\",\n",
        "    ],\n",
        "    \"specific\": [\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"Show me the Glasgow Cathedral\",\n",
        "        \"What can you tell me about the Burrell Collection?\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Location-based queries for geographic diversity testing (based on real data)\n",
        "LOCATION_QUERIES = {\n",
        "    \"Scotland\": [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"What attractions can I see in Glasgow?\",\n",
        "        \"Show me historic buildings in Glasgow\",\n",
        "    ],\n",
        "    \"England\": [\n",
        "        \"Find places to eat in Gillingham\",\n",
        "        \"Show me restaurants serving Asian cuisine\",\n",
        "        \"What landmarks are in Gillingham?\",\n",
        "    ],\n",
        "    \"France\": [\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"Show me attractions in Giverny\",\n",
        "        \"What can I visit in France?\",\n",
        "    ],\n",
        "    \"UK_General\": [\n",
        "        \"Find attractions in the United Kingdom\",\n",
        "        \"Show me places to visit in the UK\",\n",
        "        \"What can I see in Britain?\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Activity-based queries for testing different search patterns\n",
        "ACTIVITY_QUERIES = [\n",
        "    \"What can I see in Glasgow?\",  # 'see' activity queries\n",
        "    \"Where can I eat in Gillingham?\",  # 'eat' activity queries\n",
        "    \"Show me places to dine\",  # Generic eating queries\n",
        "    \"Find things to visit and see\",  # Generic sightseeing queries\n",
        "    \"What museums can I visit?\",  # Specific venue type queries\n",
        "]\n",
        "\n",
        "\n",
        "def get_all_queries() -> List[str]:\n",
        "    \"\"\"Get all queries for comprehensive testing.\"\"\"\n",
        "    all_queries = LANDMARK_SEARCH_QUERIES.copy()\n",
        "\n",
        "    # Add category queries\n",
        "    for category_list in CATEGORY_QUERIES.values():\n",
        "        all_queries.extend(category_list)\n",
        "\n",
        "    # Add location queries\n",
        "    for location_list in LOCATION_QUERIES.values():\n",
        "        all_queries.extend(location_list)\n",
        "\n",
        "    # Add activity queries\n",
        "    all_queries.extend(ACTIVITY_QUERIES)\n",
        "\n",
        "    return all_queries\n",
        "\n",
        "\n",
        "def get_reference_answer(query: str) -> str:\n",
        "    \"\"\"Get reference answer for a specific query.\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS.get(query, \"No reference answer available for this query.\")\n",
        "\n",
        "\n",
        "def get_queries_by_category(category: str) -> List[str]:\n",
        "    \"\"\"Get queries filtered by category.\"\"\"\n",
        "    if category == \"basic\":\n",
        "        return LANDMARK_SEARCH_QUERIES\n",
        "    elif category == \"category\":\n",
        "        return [q for queries in CATEGORY_QUERIES.values() for q in queries]\n",
        "    elif category == \"location\":\n",
        "        return [q for queries in LOCATION_QUERIES.values() for q in queries]\n",
        "    elif category == \"activity\":\n",
        "        return ACTIVITY_QUERIES\n",
        "    else:\n",
        "        return get_all_queries()\n",
        "\n",
        "\n",
        "def get_queries_for_evaluation(limit: int = 5) -> List[str]:\n",
        "    \"\"\"Get a subset of queries for evaluation purposes.\"\"\"\n",
        "    return LANDMARK_SEARCH_QUERIES[:limit]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Landmark Search Agent Setup\n",
        "\n",
        "Setup the complete landmark search agent infrastructure using LlamaIndex.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:22:28,098 - INFO - ✅ Environment variables configured\n",
            "2025-09-03 10:22:28,142 - INFO - A local catalog and a remote catalog have been found. Building a chained tool catalog.\n",
            "2025-09-03 10:22:28,142 - INFO - A local catalog and a remote catalog have been found. Building a chained prompt catalog.\n",
            "2025-09-03 10:22:28,188 - INFO - Using both a local auditor and a remote auditor.\n",
            "2025-09-03 10:22:28,189 - INFO - 🔧 Setting up Priority 1 AI services for llamaindex framework...\n",
            "2025-09-03 10:22:28,189 - INFO - 🔧 Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-03 10:22:28,190 - INFO - 🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "2025-09-03 10:22:28,190 - INFO - 🔧 API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-03 10:22:28,190 - INFO - ✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "2025-09-03 10:22:28,191 - INFO - 🔧 LLM Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-03 10:22:28,191 - INFO - 🔧 LLM Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "2025-09-03 10:22:28,191 - INFO - 🔧 LLM API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-03 10:22:29,678 - INFO - ✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "2025-09-03 10:22:29,679 - INFO - ✅ Priority 1 AI services setup completed for llamaindex\n",
            "2025-09-03 10:22:32,008 - INFO - Successfully connected to Couchbase\n",
            "2025-09-03 10:22:32,009 - INFO - 🔧 Setting up Priority 1 AI services for llamaindex framework...\n",
            "2025-09-03 10:22:32,009 - INFO - 🔧 Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-03 10:22:32,009 - INFO - 🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "2025-09-03 10:22:32,010 - INFO - 🔧 API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-03 10:22:32,010 - INFO - ✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "2025-09-03 10:22:32,011 - INFO - 🔧 LLM Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-03 10:22:32,012 - INFO - 🔧 LLM Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "2025-09-03 10:22:32,012 - INFO - 🔧 LLM API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-03 10:22:33,293 - INFO - ✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "2025-09-03 10:22:33,294 - INFO - ✅ Priority 1 AI services setup completed for llamaindex\n",
            "2025-09-03 10:22:34,790 - INFO - Connected to bucket 'travel-sample'\n",
            "2025-09-03 10:22:37,198 - INFO - Collection 'landmark_data' exists, clearing data...\n",
            "2025-09-03 10:22:37,198 - INFO - Clearing data from travel-sample.agentc_data.landmark_data...\n",
            "2025-09-03 10:22:42,522 - INFO - Collection cleared successfully, 0 documents remaining\n",
            "2025-09-03 10:22:46,626 - INFO - Primary index created successfully\n",
            "2025-09-03 10:22:46,627 - INFO - Collection setup complete\n",
            "2025-09-03 10:22:46,627 - INFO - Loaded vector search index definition from agentcatalog_index.json\n",
            "2025-09-03 10:22:47,788 - INFO - Vector search index 'landmark_data_index' already exists\n",
            "2025-09-03 10:22:51,227 - INFO - Loading landmark data from travel-sample.inventory.landmark...\n",
            "2025-09-03 10:22:51,228 - INFO - Processing landmark documents...\n",
            "Loading landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 5319807.13landmarks/s]\n",
            "2025-09-03 10:22:59,306 - INFO - Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "2025-09-03 10:23:01,467 - INFO - Loading landmark data from travel-sample.inventory.landmark...\n",
            "2025-09-03 10:23:01,467 - INFO - Processing landmark documents...\n",
            "Loading landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 5354557.36landmarks/s]\n",
            "2025-09-03 10:23:06,976 - INFO - Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "2025-09-03 10:23:06,978 - INFO - Generating landmark text embeddings...\n",
            "Processing landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 261881.83landmarks/s]\n",
            "2025-09-03 10:23:06,997 - INFO - Generated 4495 landmark text embeddings\n",
            "2025-09-03 10:23:10,479 - INFO - Creating 4495 LlamaIndex Documents...\n",
            "2025-09-03 10:23:10,513 - INFO - Processing documents with ingestion pipeline...\n",
            "2025-09-03 10:23:10,595 - INFO - Processing 4495 documents in 180 batches...\n",
            "Loading batches: 100%|██████████| 180/180 [04:45<00:00,  1.59s/batch]\n",
            "2025-09-03 10:27:56,078 - INFO - Successfully loaded 4495 landmark documents to vector store\n",
            "2025-09-03 10:27:56,079 - INFO - Landmark data loaded into vector store successfully\n",
            "2025-09-03 10:27:56,091 - INFO - Loaded search_landmarks tool from AgentC\n",
            "2025-09-03 10:27:56,091 - INFO - Loaded 1 tools from Agent Catalog\n",
            "2025-09-03 10:27:56,103 - INFO - Loaded system prompt from Agent Catalog\n",
            "/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n",
            "2025-09-03 10:27:56,113 - INFO - LlamaIndex ReAct agent created successfully\n"
          ]
        }
      ],
      "source": [
        "def setup_landmark_agent():\n",
        "    \"\"\"Setup the complete landmark search agent infrastructure and return the agent.\"\"\"\n",
        "    setup_environment()\n",
        "\n",
        "    # Initialize Agent Catalog with credentials\n",
        "    catalog = agentc.Catalog()\n",
        "    span = catalog.Span(name=\"Landmark Search Agent Setup\", blacklist=set())\n",
        "\n",
        "    # Setup LLM and embeddings\n",
        "    embeddings, llm = setup_ai_services(framework=\"llamaindex\", temperature=0.1, application_span=span)\n",
        "\n",
        "    # Set global LlamaIndex settings\n",
        "    Settings.llm = llm\n",
        "    Settings.embed_model = embeddings\n",
        "\n",
        "\n",
        "    # Setup database client\n",
        "    client = CouchbaseClient(\n",
        "        conn_string=os.environ[\"CB_CONN_STRING\"],\n",
        "        username=os.environ[\"CB_USERNAME\"],\n",
        "        password=os.environ[\"CB_PASSWORD\"],\n",
        "        bucket_name=os.environ[\"CB_BUCKET\"],\n",
        "    )\n",
        "\n",
        "    client.connect()\n",
        "\n",
        "    # Setup vector store and agent\n",
        "    agent = client.setup_vector_store_and_agent(catalog, span)\n",
        "\n",
        "    return agent, client\n",
        "\n",
        "\n",
        "# Inline evaluation templates for lenient evaluation\n",
        "LENIENT_QA_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert evaluator assessing if an AI assistant's response correctly answers the user's question about landmarks and attractions.\n",
        "\n",
        "FOCUS ON FUNCTIONAL SUCCESS, NOT EXACT MATCHING:\n",
        "1. Did the agent provide the requested landmark information?\n",
        "2. Is the core information accurate and helpful to the user?\n",
        "3. Would the user be satisfied with what they received?\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND CORRECT:\n",
        "- Landmark search results vary based on current database state\n",
        "- Different search queries may return different but valid landmarks\n",
        "- Order of results may vary (this is normal for search results)\n",
        "- Formatting differences are acceptable\n",
        "\n",
        "IGNORE THESE DIFFERENCES:\n",
        "- Format differences, duplicate searches, system messages\n",
        "- Different result ordering or landmark selection\n",
        "- Reference mismatches due to dynamic search results\n",
        "\n",
        "MARK AS CORRECT IF:\n",
        "- Agent successfully found landmarks matching the request\n",
        "- User received useful, accurate landmark information\n",
        "- Core functionality worked as expected (search worked, results filtered properly)\n",
        "\n",
        "MARK AS INCORRECT ONLY IF:\n",
        "- Agent completely failed to provide landmark information\n",
        "- Response is totally irrelevant to the landmark search request\n",
        "- Agent provided clearly wrong or nonsensical information\n",
        "\n",
        "**Question:** {input}\n",
        "\n",
        "**Reference Answer:** {reference}\n",
        "\n",
        "**AI Response:** {output}\n",
        "\n",
        "Based on the criteria above, is the AI response correct?\n",
        "\n",
        "Answer: [correct/incorrect]\n",
        "\n",
        "Explanation: [Provide a brief explanation focusing on functional success]\n",
        "\"\"\"\n",
        "\n",
        "# Lenient hallucination evaluation template  \n",
        "LENIENT_HALLUCINATION_PROMPT_TEMPLATE = \"\"\"\n",
        "You are evaluating whether an AI assistant's response about landmarks contains hallucinated (fabricated) information.\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND FACTUAL:\n",
        "- Landmark search results are pulled from a real database\n",
        "- Different searches return different valid landmarks (this is correct behavior)\n",
        "- Landmark details like addresses, descriptions, and activities come from actual data\n",
        "- Search result variations are normal and factual\n",
        "\n",
        "MARK AS FACTUAL IF:\n",
        "- Response contains \"iteration limit\" or \"time limit\" (system issue, not hallucination)\n",
        "- Agent provides plausible landmark data from search results\n",
        "- Information is consistent with typical landmark search functionality\n",
        "- Results differ from reference due to dynamic search (this is expected!)\n",
        "\n",
        "ONLY MARK AS HALLUCINATED IF:\n",
        "- Response contains clearly impossible landmark information\n",
        "- Agent makes up fake landmark names, addresses, or details\n",
        "- Response contradicts fundamental facts about landmark search\n",
        "- Agent claims to have data it cannot access\n",
        "\n",
        "REMEMBER: Different search results are EXPECTED dynamic behavior, not hallucinations!\n",
        "\n",
        "**Question:** {input}\n",
        "\n",
        "**Reference Answer:** {reference}\n",
        "\n",
        "**AI Response:** {output}\n",
        "\n",
        "Based on the criteria above, does the response contain hallucinated information?\n",
        "\n",
        "Answer: [factual/hallucinated]\n",
        "\n",
        "Explanation: [Focus on whether information is plausible vs clearly fabricated]\n",
        "\"\"\"\n",
        "\n",
        "# Setup the landmark search agent\n",
        "agent, client = setup_landmark_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test Functions\n",
        "Define test functions to demonstrate the landmark search agent functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:27:56,133 - INFO - Testing Landmark Data Loading from travel-sample\n",
            "2025-09-03 10:27:56,135 - INFO - ==================================================\n",
            "2025-09-03 10:27:58,740 - INFO - ✅ Landmark count in travel-sample.inventory.landmark: 4495\n",
            "2025-09-03 10:28:00,936 - INFO - Loading landmark data from travel-sample.inventory.landmark...\n",
            "2025-09-03 10:28:00,937 - INFO - Processing landmark documents...\n",
            "Loading landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 5316806.68landmarks/s]\n",
            "2025-09-03 10:28:07,006 - INFO - Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "2025-09-03 10:28:07,007 - INFO - Generating landmark text embeddings...\n",
            "Processing landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 165884.14landmarks/s]\n",
            "2025-09-03 10:28:07,037 - INFO - Generated 4495 landmark text embeddings\n",
            "2025-09-03 10:28:07,040 - INFO - ✅ Generated 4495 landmark texts for embeddings\n",
            "2025-09-03 10:28:07,041 - INFO - ✅ First landmark text sample: San Francisco/Haight (&quot;Hippie Temptation&quot; house) in San Francisco, United States. Description: Site of the CBS documentary.. Address: 1550 Page St. Activity type: see. Type: landmark. State:...\n",
            "2025-09-03 10:28:07,042 - INFO - ✅ Data loading test completed successfully\n"
          ]
        }
      ],
      "source": [
        "def run_landmark_query(query: str, agent):\n",
        "    \"\"\"Run a single landmark query with error handling.\"\"\"\n",
        "    logger.info(f\"🏛️ Landmark Query: {query}\")\n",
        "    \n",
        "    try:\n",
        "        # Run the agent with LlamaIndex chat interface\n",
        "        response = agent.chat(query, chat_history=[])\n",
        "        result = response.response\n",
        "        \n",
        "        logger.info(f\"🤖 AI Response: {result}\")\n",
        "        logger.info(\"✅ Query completed successfully\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Query failed: {e}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def test_landmark_data_loading():\n",
        "    \"\"\"Test landmark data loading from travel-sample independently.\"\"\"\n",
        "    logger.info(\"Testing Landmark Data Loading from travel-sample\")\n",
        "    logger.info(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Import landmark data functions\n",
        "        # Use inline landmark data functions (already defined in this notebook)\n",
        "        # The functions get_landmark_count and get_landmark_texts are defined inline above\n",
        "        \n",
        "        # Test landmark count\n",
        "        count = get_landmark_count()\n",
        "        logger.info(f\"✅ Landmark count in travel-sample.inventory.landmark: {count}\")\n",
        "        \n",
        "        # Test landmark text generation\n",
        "        texts = get_landmark_texts()\n",
        "        logger.info(f\"✅ Generated {len(texts)} landmark texts for embeddings\")\n",
        "        \n",
        "        if texts:\n",
        "            logger.info(f\"✅ First landmark text sample: {texts[0][:200]}...\")\n",
        "        \n",
        "        logger.info(\"✅ Data loading test completed successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Data loading test failed: {e}\")\n",
        "\n",
        "\n",
        "# Test landmark data loading\n",
        "test_landmark_data_loading()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 1: Landmarks in Tokyo\n",
        "\n",
        "Search for landmarks and attractions in Tokyo, Japan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:28:07,076 - INFO - 🏛️ Landmark Query: Find me landmarks in Tokyo\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 24917a16-be47-4c11-973b-6d39e2644315. Step input: Find me landmarks in Tokyo\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo landmarks', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:28:17,172 - INFO - Search query: 'Tokyo landmarks' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo landmarks':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo**\n",
            "   📍 Location: Liverpool, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 134 Duke Street, East Village.\n",
            "   📞 Phone: +44 151 709-4002.\n",
            "   🌐 Website: http://www.sapporo.co.uk/restaurant-liverpool/.\n",
            "   📝 Description: Japanese cuisine.\n",
            "\n",
            "3. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\u001b[0m> Running step dae92e2d-cf3a-47a7-9ea4-9be9ee8d8e39. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results seem to be about Japanese restaurants in various cities, not landmarks in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo landmarks', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:28:27,309 - INFO - Search query: 'Tokyo landmarks' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo landmarks':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo**\n",
            "   📍 Location: Liverpool, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 134 Duke Street, East Village.\n",
            "   📞 Phone: +44 151 709-4002.\n",
            "   🌐 Website: http://www.sapporo.co.uk/restaurant-liverpool/.\n",
            "   📝 Description: Japanese cuisine.\n",
            "\n",
            "3. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\u001b[0m> Running step 0627e629-e254-48f3-ab6d-48a5772709ac. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not showing landmarks in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous landmarks', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:28:37,857 - INFO - Search query: 'Tokyo famous landmarks' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous landmarks':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo**\n",
            "   📍 Location: Liverpool, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 134 Duke Street, East Village.\n",
            "   📞 Phone: +44 151 709-4002.\n",
            "   🌐 Website: http://www.sapporo.co.uk/restaurant-liverpool/.\n",
            "   📝 Description: Japanese cuisine.\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "5. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\u001b[0m> Running step 4381925a-fa14-487c-babb-c34d2c3dacfc. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not showing famous landmarks in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous buildings', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:28:48,404 - INFO - Search query: 'Tokyo famous buildings' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous buildings':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mikawaya**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 118 Japanese Village Plaza Mall.\n",
            "   📞 Phone: +1 213 624-1681.\n",
            "   🌐 Website: http://www.mikawayausa.com.\n",
            "   🕒 Hours: M,Sa 10AM-7PM, Tu-Th 10AM-10PM, F 9AM-11PM, Su closed.\n",
            "   📝 Description: Their motto says it best: &quot;The finest name in Japanese pastries since 1910.&quot;.\n",
            "\u001b[0m> Running step cfc2affa-14c1-49d1-8702-e79e31489e95. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not showing famous buildings in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous buildings Tokyo Japan', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:28:58,851 - INFO - Search query: 'Tokyo famous buildings Tokyo Japan' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous buildings Tokyo Japan':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Webster Bridge**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: on Webster Street over Geary Boulevard.\n",
            "   📝 Description: The bridge's design was inspired by traditional Japanese pedestrian walkways. In addition to providing a safe passage over the traffic on Geary Boulevard, the arched bridge has views of Japan Center and Western Addition..\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Maison de la culture du Japon**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 101Bis Quai Branly.\n",
            "   📞 Phone: +33 1 44 37 95 01.\n",
            "   🌐 Website: http://www.mcjp.fr/.\n",
            "   📝 Description: The location hosts several expositions, a library and a concert hall..\n",
            "\n",
            "5. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\u001b[0m> Running step 35a957f7-cee1-4b77-811d-5b16d07093b4. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not showing famous buildings in Tokyo, Japan. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous buildings Tokyo Japan famous', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:09,836 - INFO - Search query: 'Tokyo famous buildings Tokyo Japan famous' found 5 results\n",
            "2025-09-03 10:29:09,838 - ERROR - ❌ Query failed: Reached max iterations.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_63525/2404050830.py\", line 7, in run_landmark_query\n",
            "    response = agent.chat(query, chat_history=[])\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py\", line 317, in wrapper\n",
            "    result = func(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/callbacks/utils.py\", line 42, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/runner/base.py\", line 708, in chat\n",
            "    chat_response = self._chat(\n",
            "                    ^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py\", line 317, in wrapper\n",
            "    result = func(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/runner/base.py\", line 640, in _chat\n",
            "    cur_step_output = self._run_step(\n",
            "                      ^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py\", line 317, in wrapper\n",
            "    result = func(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/runner/base.py\", line 436, in _run_step\n",
            "    cur_step_output = self.agent_worker.run_step(step, task, **kwargs)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py\", line 317, in wrapper\n",
            "    result = func(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/callbacks/utils.py\", line 42, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/react/step.py\", line 828, in run_step\n",
            "    return self._run_step(step, task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/react/step.py\", line 586, in _run_step\n",
            "    agent_response = self._get_response(\n",
            "                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/react/step.py\", line 439, in _get_response\n",
            "    raise ValueError(\"Reached max iterations.\")\n",
            "ValueError: Reached max iterations.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous buildings Tokyo Japan famous':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Maison de la culture du Japon**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 101Bis Quai Branly.\n",
            "   📞 Phone: +33 1 44 37 95 01.\n",
            "   🌐 Website: http://www.mcjp.fr/.\n",
            "   📝 Description: The location hosts several expositions, a library and a concert hall..\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Webster Bridge**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: on Webster Street over Geary Boulevard.\n",
            "   📝 Description: The bridge's design was inspired by traditional Japanese pedestrian walkways. In addition to providing a safe passage over the traffic on Geary Boulevard, the arched bridge has views of Japan Center and Western Addition..\n",
            "\n",
            "5. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "result1 = run_landmark_query(\"Find me landmarks in Tokyo\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 2: Museums in London\n",
        "\n",
        "Search for museums and cultural attractions in London, UK.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:09,867 - INFO - 🏛️ Landmark Query: Show me museums in London\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step c8b795ca-0b7a-4474-bbd8-031dc6cef844. Step input: Show me museums in London\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums in London', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:19,231 - INFO - Search query: 'museums in London' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 4 landmarks matching 'museums in London':\n",
            "\n",
            "1. **London Transport Museum**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🌐 Website: http://www.ltmuseum.co.uk.\n",
            "   📝 Description: [[London]] (in [[London/Covent Garden|Covent Garden]]).\n",
            "\n",
            "2. **Clockmaker's Museum**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: Guildhall Library, Aldermanbury EC2P 2EJ.\n",
            "   📞 Phone: +44 20 7332-1868. Email: printedbooks.guildhall@corpoflondon.gov.uk.\n",
            "   🌐 Website: http://www.clockmakers.org/.\n",
            "   🕒 Hours: M–Sa 09:30–17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: Charts the history of clockmaking and houses a priceless collection of old timepieces..\n",
            "\n",
            "4. **575 Wandsworth Road**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 575 Wandsworth Road, Lambeth, London, London, SW8 3JD.\n",
            "   📞 Phone: +44 20 7720-9459. Email: 575wandsworthroad@nationaltrust.org.uk.\n",
            "   🌐 Website: http://www.nationaltrust.org.uk/575-wandsworth-road/.\n",
            "   📝 Description: Need to book in advance..\n",
            "\n",
            "5. **Tottenham Marsh**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   📝 Description: Part of the Lea Valley Park, a natural habitat for many resident plants and animals..\n",
            "\u001b[0m> Running step 210870cc-01ac-4874-9de7-57e46441b38e. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:21,482 - INFO - 🤖 AI Response: There are several museums in London that you might be interested in visiting. Some of the options include the London Transport Museum, the Clockmaker's Museum, 575 Wandsworth Road, and Tottenham Marsh. The London Transport Museum is located in Covent Garden and features a collection of old timepieces. The Clockmaker's Museum is located in the Guildhall Library and offers free admission. 575 Wandsworth Road is a historic house that requires booking in advance, and Tottenham Marsh is a natural habitat for plants and animals.\n",
            "2025-09-03 10:29:21,483 - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are several museums in London that you might be interested in visiting. Some of the options include the London Transport Museum, the Clockmaker's Museum, 575 Wandsworth Road, and Tottenham Marsh. The London Transport Museum is located in Covent Garden and features a collection of old timepieces. The Clockmaker's Museum is located in the Guildhall Library and offers free admission. 575 Wandsworth Road is a historic house that requires booking in advance, and Tottenham Marsh is a natural habitat for plants and animals.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "result2 = run_landmark_query(\"Show me museums in London\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "xml"
        }
      },
      "source": [
        "## Test 3: Parks in Paris\n",
        "\n",
        "Search for parks and outdoor spaces in Paris, France.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:21,496 - INFO - 🏛️ Landmark Query: What parks can I visit in Paris?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 5bfd5a6b-db47-45c4-b4d4-124fcb01a1e3. Step input: What parks can I visit in Paris?\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'parks in Paris', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:30,340 - INFO - Search query: 'parks in Paris' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'parks in Paris':\n",
            "\n",
            "1. **Parc André Malraux**\n",
            "   📍 Location: Nanterre, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: See.\n",
            "   📝 Description: The expansive, calm park around a lake extends westwards behind the Tours Aillaud, and is to La Defense quite what Central Park is to downtown Manhattan. You can take spectaular pictures of the La Defense skyline juxtaposted against the park's greenery from there..\n",
            "\n",
            "2. **Madeleine**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Listing.\n",
            "   📝 Description: (lines 8, 12 and 14).\n",
            "\n",
            "3. **Parc André Citroën**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France. Image: https://en.wikivoyage.org/wiki/File:Jardin André Citroën (PARIS,FR75) (3830986538).jpg.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 2, rue Cauchy.\n",
            "   🌐 Website: http://equipement.paris.fr/parc-andre-citroen-1791.\n",
            "   🕒 Hours: 08:00-17:45.\n",
            "   📝 Description: The large park occupies the 14 ha formerly occupied by a Citroën factory. Several gardens have specific themes, including water games. On sunny weekends or vacation days many people chill out or jog there..\n",
            "\n",
            "4. **Concorde**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Listing.\n",
            "   📝 Description: (lines 1, 8 and 12).\n",
            "\n",
            "5. **Musée en Herbe**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 21, rue Hérold.\n",
            "   📞 Phone: +33 1 40 67 97 66.\n",
            "   🌐 Website: http://www.musee-en-herbe.com.\n",
            "   🕒 Hours: Daily 10:00-19:00.\n",
            "   💰 Price: €4 for the exhibitions, €8 for the workshops.\n",
            "   📝 Description: The little brother of the original Musée en Herbe in the Bois de Boulogne, this museum is also geared to '''children'''. They have games and hands-on exhibits so won't have to supervise quite as closely as in other museums. Arts workshops are available as well, but you'll need to reserve a space in advance..\n",
            "\u001b[0m> Running step a41ad6f0-9c05-4114-bb21-f8de6f5247d5. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:31,899 - INFO - 🤖 AI Response: You can visit the following parks in Paris: Parc André Malraux, Parc André Citroën, and Musée en Herbe.\n",
            "2025-09-03 10:29:31,899 - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: You can visit the following parks in Paris: Parc André Malraux, Parc André Citroën, and Musée en Herbe.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "result3 = run_landmark_query(\"What parks can I visit in Paris?\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Comprehensive Phoenix Evaluation System\n",
        "\n",
        "Complete Phoenix evaluation system from evals/eval_arize.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Phoenix evaluation system from evals/eval_arize.py\n",
        "import nest_asyncio\n",
        "import socket\n",
        "import subprocess\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Apply nest_asyncio to handle nested event loops in Jupyter/LlamaIndex\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "@dataclass\n",
        "class EvaluationConfig:\n",
        "    \"\"\"Configuration for the evaluation system.\"\"\"\n",
        "\n",
        "    # Arize Configuration\n",
        "    arize_space_id: str = os.getenv(\"ARIZE_SPACE_ID\", \"default-space\")\n",
        "    arize_api_key: str = os.getenv(\"ARIZE_API_KEY\", \"\")\n",
        "    project_name: str = \"landmark-search-agent-evaluation\"\n",
        "\n",
        "    # Phoenix Configuration\n",
        "    phoenix_base_port: int = 6006\n",
        "    phoenix_grpc_base_port: int = 4317\n",
        "    phoenix_max_port_attempts: int = 5\n",
        "\n",
        "    # Evaluation Configuration\n",
        "    evaluator_model: str = \"gpt-4o\"\n",
        "    max_queries: int = 10\n",
        "    evaluation_timeout: int = 300\n",
        "\n",
        "\n",
        "class PhoenixManager:\n",
        "    \"\"\"Manages Phoenix server lifecycle.\"\"\"\n",
        "\n",
        "    def __init__(self, config: EvaluationConfig):\n",
        "        self.config = config\n",
        "        self.session = None\n",
        "        self.active_port = None\n",
        "\n",
        "    def _is_port_in_use(self, port: int) -> bool:\n",
        "        \"\"\"Check if a port is in use.\"\"\"\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "            return s.connect_ex((\"localhost\", port)) == 0\n",
        "\n",
        "    def _kill_existing_phoenix_processes(self) -> None:\n",
        "        \"\"\"Kill any existing Phoenix processes.\"\"\"\n",
        "        try:\n",
        "            subprocess.run([\"pkill\", \"-f\", \"phoenix\"], check=False, capture_output=True)\n",
        "            time.sleep(2)  # Wait for processes to terminate\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"Error killing Phoenix processes: {e}\")\n",
        "\n",
        "    def _find_available_port(self) -> tuple[int, int]:\n",
        "        \"\"\"Find available ports for Phoenix.\"\"\"\n",
        "        phoenix_port = self.config.phoenix_base_port\n",
        "        grpc_port = self.config.phoenix_grpc_base_port\n",
        "\n",
        "        for _ in range(self.config.phoenix_max_port_attempts):\n",
        "            if not self._is_port_in_use(phoenix_port):\n",
        "                return phoenix_port, grpc_port\n",
        "            phoenix_port += 1\n",
        "            grpc_port += 1\n",
        "\n",
        "        raise RuntimeError(\n",
        "            f\"Could not find available ports after {self.config.phoenix_max_port_attempts} attempts\"\n",
        "        )\n",
        "\n",
        "    def start_phoenix(self) -> bool:\n",
        "        \"\"\"Start Phoenix server and return success status.\"\"\"\n",
        "        try:\n",
        "            import phoenix as px\n",
        "            from phoenix.otel import register\n",
        "            from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "            \n",
        "            logger.info(\"🔧 Setting up Phoenix observability...\")\n",
        "\n",
        "            # Clean up existing processes\n",
        "            self._kill_existing_phoenix_processes()\n",
        "\n",
        "            # Find available ports\n",
        "            phoenix_port, grpc_port = self._find_available_port()\n",
        "\n",
        "            # Set environment variables\n",
        "            os.environ[\"PHOENIX_PORT\"] = str(phoenix_port)\n",
        "            os.environ[\"PHOENIX_GRPC_PORT\"] = str(grpc_port)\n",
        "\n",
        "            # Start Phoenix session\n",
        "            self.session = px.launch_app()\n",
        "            self.active_port = phoenix_port\n",
        "\n",
        "            if self.session:\n",
        "                logger.info(f\"🌐 Phoenix UI: {self.session.url}\")\n",
        "\n",
        "            # Register Phoenix OTEL for LlamaIndex\n",
        "            register(\n",
        "                project_name=self.config.project_name,\n",
        "                endpoint=f\"http://localhost:{self.active_port}/v1/traces\",\n",
        "            )\n",
        "\n",
        "            # Instrument LlamaIndex specifically\n",
        "            LlamaIndexInstrumentor().instrument()\n",
        "\n",
        "            logger.info(\"✅ Phoenix setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Phoenix setup failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"Clean up Phoenix resources.\"\"\"\n",
        "        try:\n",
        "            if self.session:\n",
        "                # Phoenix session cleanup happens automatically\n",
        "                pass\n",
        "            logger.info(\"🔒 Phoenix cleanup completed\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error during Phoenix cleanup: {e}\")\n",
        "\n",
        "\n",
        "class LandmarkSearchEvaluator:\n",
        "    \"\"\"LlamaIndex-specific evaluator for the landmark search agent.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Optional[EvaluationConfig] = None):\n",
        "        \"\"\"Initialize the evaluator with configuration.\"\"\"\n",
        "        self.config = config or EvaluationConfig()\n",
        "        self.phoenix_manager = PhoenixManager(self.config)\n",
        "\n",
        "        # Agent components\n",
        "        self.agent = None\n",
        "        self.client = None\n",
        "\n",
        "        # Phoenix evaluators\n",
        "        self.evaluator_llm = None\n",
        "\n",
        "        # Add option to bypass Phoenix for debugging\n",
        "        try:\n",
        "            import phoenix as px\n",
        "            if not os.getenv(\"SKIP_PHOENIX\", \"false\").lower() == \"true\":\n",
        "                self._setup_phoenix_evaluators()\n",
        "            elif os.getenv(\"SKIP_PHOENIX\", \"false\").lower() == \"true\":\n",
        "                logger.info(\"🔧 Phoenix setup skipped due to SKIP_PHOENIX=true\")\n",
        "        except ImportError:\n",
        "            logger.warning(\"Phoenix not available - skipping Phoenix setup\")\n",
        "\n",
        "    def _setup_phoenix_evaluators(self) -> None:\n",
        "        \"\"\"Setup Phoenix evaluators for LLM-based evaluation.\"\"\"\n",
        "        try:\n",
        "            from phoenix.evals import OpenAIModel\n",
        "            \n",
        "            self.evaluator_llm = OpenAIModel(model=self.config.evaluator_model)\n",
        "            logger.info(\"✅ Phoenix evaluators initialized\")\n",
        "\n",
        "            # Start Phoenix\n",
        "            if self.phoenix_manager.start_phoenix():\n",
        "                logger.info(\"✅ Phoenix instrumentation enabled for LlamaIndex\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Phoenix evaluators setup failed: {e}\")\n",
        "            self.evaluator_llm = None\n",
        "\n",
        "    def setup_agent(self) -> bool:\n",
        "        \"\"\"Setup landmark search agent using the setup function.\"\"\"\n",
        "        try:\n",
        "            logger.info(\"🔧 Setting up landmark search agent...\")\n",
        "\n",
        "            self.agent, self.client = setup_landmark_agent()\n",
        "\n",
        "            logger.info(\"✅ Landmark search agent setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Error setting up landmark search agent: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _extract_response_content(self, result: Any) -> str:\n",
        "        \"\"\"Extract clean response content from LlamaIndex agent result.\"\"\"\n",
        "        try:\n",
        "            # Prefer explicit response field\n",
        "            if hasattr(result, \"response\"):\n",
        "                response_content = str(result.response).strip()\n",
        "                if response_content and not response_content.lower().startswith(\"error:\"):\n",
        "                    return response_content\n",
        "\n",
        "            # Some LlamaIndex results may carry a .message or .output\n",
        "            for attr in (\"message\", \"output\", \"final_response\"):\n",
        "                if hasattr(result, attr):\n",
        "                    text = str(getattr(result, attr)).strip()\n",
        "                    if text:\n",
        "                        return text\n",
        "\n",
        "            # Last resort fallback\n",
        "            text = str(result).strip()\n",
        "            return text if text else \"\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error extracting response content: {e}\")\n",
        "            return f\"Error extracting response: {e}\"\n",
        "\n",
        "    def run_single_evaluation(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"Run evaluation for a single query using LlamaIndex agent.\"\"\"\n",
        "        if not self.agent:\n",
        "            raise RuntimeError(\"Agent not initialized. Call setup_agent() first.\")\n",
        "\n",
        "        logger.info(f\"🔍 Evaluating query: {query}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Use LlamaIndex .chat() method\n",
        "            result = self.agent.chat(query, chat_history=[])\n",
        "\n",
        "            # Extract response content\n",
        "            response = self._extract_response_content(result)\n",
        "\n",
        "            # Create evaluation result\n",
        "            evaluation_result = {\n",
        "                \"query\": query,\n",
        "                \"response\": response,\n",
        "                \"execution_time\": time.time() - start_time,\n",
        "                \"success\": True,\n",
        "                \"sources\": [],\n",
        "                \"num_sources\": 0,\n",
        "            }\n",
        "\n",
        "            logger.info(f\"✅ Query completed in {evaluation_result['execution_time']:.2f}s\")\n",
        "\n",
        "            return evaluation_result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query failed: {e}\")\n",
        "            return {\n",
        "                \"query\": query,\n",
        "                \"response\": f\"Error: {str(e)}\",\n",
        "                \"execution_time\": time.time() - start_time,\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"sources\": [],\n",
        "                \"num_sources\": 0,\n",
        "            }\n",
        "\n",
        "    def run_phoenix_evaluations(self, results_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Run Phoenix evaluations on the results.\"\"\"\n",
        "        if not self.evaluator_llm:\n",
        "            logger.warning(\"⚠️ Phoenix evaluators not available - skipping LLM evaluations\")\n",
        "            return results_df\n",
        "\n",
        "        logger.info(f\"🧠 Running Phoenix evaluations on {len(results_df)} responses...\")\n",
        "\n",
        "        try:\n",
        "            from phoenix.evals import (\n",
        "                RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "                RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "                TOXICITY_PROMPT_TEMPLATE,\n",
        "                TOXICITY_PROMPT_RAILS_MAP,\n",
        "                llm_classify,\n",
        "            )\n",
        "            \n",
        "            # Prepare evaluation data\n",
        "            evaluation_data = []\n",
        "            for _, row in results_df.iterrows():\n",
        "                query = row[\"query\"]\n",
        "                response = row[\"response\"]\n",
        "\n",
        "                # Get reference answer for this query\n",
        "                reference = self._get_reference_answer(str(query))\n",
        "\n",
        "                evaluation_data.append(\n",
        "                    {\n",
        "                        \"input\": query,\n",
        "                        \"output\": response,\n",
        "                        \"reference\": reference,\n",
        "                        \"context\": \"Landmark search results\",\n",
        "                        \"text\": response,  # For toxicity evaluation\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            eval_df = pd.DataFrame(evaluation_data)\n",
        "\n",
        "            # Run individual Phoenix evaluations\n",
        "            evaluations = {\n",
        "                \"relevance\": {\n",
        "                    \"template\": RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "                    \"rails\": list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "                    \"data_cols\": [\"input\", \"reference\"],\n",
        "                },\n",
        "                \"qa_correctness\": {\n",
        "                    \"template\": LENIENT_QA_PROMPT_TEMPLATE,\n",
        "                    \"rails\": [\"correct\", \"incorrect\"],\n",
        "                    \"data_cols\": [\"input\", \"output\", \"reference\"],\n",
        "                },\n",
        "                \"hallucination\": {\n",
        "                    \"template\": LENIENT_HALLUCINATION_PROMPT_TEMPLATE,\n",
        "                    \"rails\": [\"factual\", \"hallucinated\"],\n",
        "                    \"data_cols\": [\"input\", \"reference\", \"output\"],\n",
        "                },\n",
        "                \"toxicity\": {\n",
        "                    \"template\": TOXICITY_PROMPT_TEMPLATE,\n",
        "                    \"rails\": list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "                    \"data_cols\": [\"text\"],\n",
        "                },\n",
        "            }\n",
        "\n",
        "            for eval_name, eval_config in evaluations.items():\n",
        "                try:\n",
        "                    logger.info(f\"   📊 Running {eval_name} evaluation...\")\n",
        "\n",
        "                    # Prepare data for this evaluator\n",
        "                    data = eval_df[eval_config[\"data_cols\"]].copy()\n",
        "\n",
        "                    # Run evaluation\n",
        "                    eval_results = llm_classify(\n",
        "                        dataframe=data,\n",
        "                        model=self.evaluator_llm,\n",
        "                        template=eval_config[\"template\"],\n",
        "                        rails=eval_config[\"rails\"],\n",
        "                    )\n",
        "\n",
        "                    # Process results\n",
        "                    if hasattr(eval_results, \"label\"):\n",
        "                        results_df[eval_name] = eval_results.label.tolist()\n",
        "                    else:\n",
        "                        results_df[eval_name] = \"unknown\"\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"⚠️ {eval_name} evaluation failed: {e}\")\n",
        "                    results_df[eval_name] = \"error\"\n",
        "\n",
        "            logger.info(\"✅ Phoenix evaluations completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Error running Phoenix evaluations: {e}\")\n",
        "            # Add error indicators\n",
        "            for eval_type in [\"relevance\", \"qa_correctness\", \"hallucination\", \"toxicity\"]:\n",
        "                results_df[eval_type] = \"error\"\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _get_reference_answer(self, query: str) -> str:\n",
        "        \"\"\"Get reference answer for evaluation.\"\"\"\n",
        "        try:\n",
        "            reference_answer = get_reference_answer(query)\n",
        "\n",
        "            if reference_answer.startswith(\"No reference answer available\"):\n",
        "                # Create a basic reference based on query\n",
        "                if \"museum\" in query.lower() or \"gallery\" in query.lower():\n",
        "                    return \"Should provide information about museums and galleries with accurate names, addresses, and descriptions.\"\n",
        "                elif \"restaurant\" in query.lower() or \"food\" in query.lower():\n",
        "                    return \"Should provide information about restaurants and food establishments.\"\n",
        "                else:\n",
        "                    return \"Should provide relevant and accurate landmark information.\"\n",
        "\n",
        "            return reference_answer\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not get reference answer for '{query}': {e}\")\n",
        "            return \"Should provide relevant and accurate landmark information.\"\n",
        "\n",
        "    def run_evaluation(self, queries: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Run complete evaluation pipeline.\"\"\"\n",
        "        if not self.setup_agent():\n",
        "            raise RuntimeError(\"Failed to setup agent\")\n",
        "\n",
        "        # Limit queries if specified\n",
        "        if len(queries) > self.config.max_queries:\n",
        "            queries = queries[: self.config.max_queries]\n",
        "            logger.info(f\"Limited to {self.config.max_queries} queries for evaluation\")\n",
        "\n",
        "        logger.info(\n",
        "            f\"🚀 Starting LlamaIndex landmark search evaluation with {len(queries)} queries\"\n",
        "        )\n",
        "\n",
        "        # Run queries\n",
        "        results = []\n",
        "        for i, query in enumerate(queries, 1):\n",
        "            logger.info(f\"\\n📋 Query {i}/{len(queries)}\")\n",
        "            result = self.run_single_evaluation(query)\n",
        "            results.append(result)\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Run Phoenix evaluations\n",
        "        results_df = self.run_phoenix_evaluations(results_df)\n",
        "\n",
        "        # Log summary\n",
        "        self._log_evaluation_summary(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _log_evaluation_summary(self, results_df: pd.DataFrame) -> None:\n",
        "        \"\"\"Log evaluation summary.\"\"\"\n",
        "        logger.info(\"\\n📊 Evaluation Summary:\")\n",
        "        logger.info(f\"  Total queries: {len(results_df)}\")\n",
        "        logger.info(f\"  Successful executions: {results_df['success'].sum()}\")\n",
        "        logger.info(f\"  Failed executions: {(~results_df['success']).sum()}\")\n",
        "        logger.info(f\"  Average execution time: {results_df['execution_time'].mean():.2f}s\")\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"Clean up all resources.\"\"\"\n",
        "        self.phoenix_manager.cleanup()\n",
        "\n",
        "\n",
        "def get_default_queries() -> List[str]:\n",
        "    \"\"\"Get default test queries for evaluation.\"\"\"\n",
        "    return get_queries_for_evaluation(limit=10)\n",
        "\n",
        "\n",
        "def run_comprehensive_evaluation() -> pd.DataFrame:\n",
        "    \"\"\"Run comprehensive evaluation with all Phoenix evaluators.\"\"\"\n",
        "    evaluator = LandmarkSearchEvaluator()\n",
        "    try:\n",
        "        queries = get_default_queries()\n",
        "        results = evaluator.run_evaluation(queries)\n",
        "        logger.info(\"\\n✅ Comprehensive landmark search evaluation complete!\")\n",
        "        return results\n",
        "    finally:\n",
        "        evaluator.cleanup()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Demo and Test Functions\n",
        "\n",
        "Interactive demo and test functions from main.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo and test functions from main.py\n",
        "\n",
        "def run_interactive_demo():\n",
        "    \"\"\"Run an interactive landmark search demo.\"\"\"\n",
        "    logger.info(\"Landmark Search Agent - Interactive Demo\")\n",
        "    logger.info(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        agent, client = setup_landmark_agent()\n",
        "\n",
        "        # Interactive landmark search loop\n",
        "        logger.info(\"Available commands:\")\n",
        "        logger.info(\"- Enter landmark search queries (e.g., 'Find landmarks in Paris')\")\n",
        "        logger.info(\"- 'quit' - Exit the demo\")\n",
        "        logger.info(\"Try asking: 'Find me landmarks in Tokyo' or 'Show me museums in London'\")\n",
        "        logger.info(\"─\" * 40)\n",
        "\n",
        "        while True:\n",
        "            query = input(\"🔍 Enter landmark search query (or 'quit' to exit): \").strip()\n",
        "\n",
        "            if query.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                logger.info(\"Thanks for using Landmark Search Agent!\")\n",
        "                break\n",
        "\n",
        "            if not query:\n",
        "                logger.warning(\"Please enter a search query\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                response = agent.chat(query, chat_history=[])\n",
        "                result = response.response\n",
        "\n",
        "                logger.info(f\"\\n🏛️ Agent Response:\\n{result}\\n\")\n",
        "                logger.info(\"─\" * 40)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing query: {e}\")\n",
        "                logger.error(f\"❌ Error: {e}\")\n",
        "                logger.info(\"─\" * 40)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Demo interrupted by user\")\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Demo error: {e}\")\n",
        "    finally:\n",
        "        logger.info(\"Demo completed\")\n",
        "\n",
        "\n",
        "def run_test():\n",
        "    \"\"\"Run comprehensive test of landmark search agent with queries from queries.py.\"\"\"\n",
        "    logger.info(\"Landmark Search Agent - Comprehensive Test Suite\")\n",
        "    logger.info(\"=\" * 55)\n",
        "\n",
        "    try:\n",
        "        agent, client = setup_landmark_agent()\n",
        "\n",
        "        # Test scenarios covering different types of landmark searches\n",
        "        test_queries = get_queries_for_evaluation()\n",
        "\n",
        "        logger.info(f\"Running {len(test_queries)} test queries...\")\n",
        "\n",
        "        for i, query in enumerate(test_queries, 1):\n",
        "            logger.info(f\"\\n🔍 Test {i}: {query}\")\n",
        "            try:\n",
        "                response = agent.chat(query, chat_history=[])\n",
        "                result = response.response\n",
        "\n",
        "                # Display the response\n",
        "                logger.info(f\"🤖 AI Response: {result}\")\n",
        "                logger.info(f\"✅ Test {i} completed successfully\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(f\"❌ Test {i} failed: {e}\")\n",
        "\n",
        "            logger.info(\"-\" * 50)\n",
        "\n",
        "        logger.info(\"All tests completed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Test error: {e}\")\n",
        "\n",
        "\n",
        "def run_landmark_data_test():\n",
        "    \"\"\"Test landmark data loading and querying functions.\"\"\"\n",
        "    logger.info(\"Landmark Data Test Suite\")\n",
        "    logger.info(\"=\" * 30)\n",
        "    \n",
        "    try:\n",
        "        # Test landmark count\n",
        "        count = get_landmark_count()\n",
        "        logger.info(f\"✅ Landmark count in travel-sample.inventory.landmark: {count}\")\n",
        "        \n",
        "        # Test data availability - basic validation\n",
        "        logger.info(\"\\n✅ Basic landmark data validation completed successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Landmark data test error: {e}\")\n",
        "\n",
        "\n",
        "# Quick demo functions for notebook use\n",
        "def run_demo_queries():\n",
        "    \"\"\"Run a few demo queries for quick testing.\"\"\"\n",
        "    demo_queries = [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"What attractions can I see in Glasgow?\"\n",
        "    ]\n",
        "    \n",
        "    agent, client = setup_landmark_agent()\n",
        "    \n",
        "    for i, query in enumerate(demo_queries, 1):\n",
        "        logger.info(f\"\\n🔍 Demo Query {i}: {query}\")\n",
        "        try:\n",
        "            response = agent.chat(query, chat_history=[])\n",
        "            logger.info(f\"🏛️ Response: {response.response}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Error: {e}\")\n",
        "        logger.info(\"-\" * 50)\n",
        "\n",
        "\n",
        "# Run comprehensive evaluation (uses the Phoenix evaluator above)\n",
        "def run_evaluation():\n",
        "    \"\"\"Run the comprehensive Phoenix evaluation.\"\"\"\n",
        "    return run_comprehensive_evaluation()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Arize Phoenix Evaluation\n",
        "\n",
        "This section demonstrates how to evaluate the landmark search agent using Arize Phoenix observability platform. The evaluation includes:\n",
        "\n",
        "- **Relevance Scoring**: Using Phoenix RelevanceEvaluator to score how relevant responses are to queries\n",
        "- **QA Scoring**: Using Phoenix QAEvaluator to score answer quality\n",
        "- **Hallucination Detection**: Using Phoenix HallucinationEvaluator to detect fabricated information  \n",
        "- **Toxicity Detection**: Using Phoenix ToxicityEvaluator to detect harmful content\n",
        "- **Phoenix UI**: Real-time observability dashboard at `http://localhost:6006/`\n",
        "\n",
        "We'll run landmark search queries and evaluate the responses for quality and safety using LlamaIndex instrumentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:32,019 - INFO - 📋 Ensuring phoenix working directory: /home/kaustav/.phoenix\n",
            "2025-09-03 10:29:32,032 - INFO - Dataset: phoenix_inferences_6069ae2c-b207-4025-8e45-3679fe207b51 initialized\n",
            "2025-09-03 10:29:33,057 - INFO - ✅ Arize Phoenix evaluation components available\n",
            "2025-09-03 10:29:33,058 - INFO - 📋 Ensuring phoenix working directory: /home/kaustav/.phoenix\n",
            "2025-09-03 10:29:33,107 - INFO - Context impl SQLiteImpl.\n",
            "2025-09-03 10:29:33,108 - INFO - Will assume transactional DDL.\n",
            "2025-09-03 10:29:33,145 - INFO - Running upgrade  -> cf03bd6bae1d, init\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗️ The launch_app `port` parameter is deprecated and will be removed in a future release. Use the `PHOENIX_PORT` environment variable instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:33,722 - INFO - Running upgrade cf03bd6bae1d -> 10460e46d750, datasets\n",
            "2025-09-03 10:29:33,731 - INFO - Running upgrade 10460e46d750 -> 3be8647b87d8, add token columns to spans table\n",
            "2025-09-03 10:29:33,734 - INFO - Running upgrade 3be8647b87d8 -> cd164e83824f, users and tokens\n",
            "2025-09-03 10:29:33,742 - INFO - Running upgrade cd164e83824f -> 4ded9e43755f, create project_session table\n",
            "2025-09-03 10:29:33,752 - INFO - Running upgrade 4ded9e43755f -> bc8fea3c2bc8, Add prompt tables\n",
            "2025-09-03 10:29:34,085 - INFO - Running upgrade bc8fea3c2bc8 -> 2f9d1a65945f, Annotation config migrations\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n",
            "2025-09-03 10:29:34,175 - INFO - Running upgrade 2f9d1a65945f -> bb8139330879, create project trace retention policies table\n",
            "2025-09-03 10:29:34,182 - INFO - Running upgrade bb8139330879 -> 8a3764fe7f1a, change jsonb to json for prompts\n",
            "2025-09-03 10:29:34,193 - INFO - Running upgrade 8a3764fe7f1a -> 6a88424799fe, Add auth_method column to users table and migrate existing authentication data.\n",
            "2025-09-03 10:29:34,203 - INFO - Running upgrade 6a88424799fe -> a20694b15f82, Cost-related tables\n",
            "2025-09-03 10:29:34,247 - INFO - Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n",
            "2025-09-03 10:29:34,546 - INFO - 🚀 Phoenix UI available at http://localhost:6006/\n",
            "2025-09-03 10:29:34,584 - INFO - ✅ LlamaIndex instrumentation enabled\n",
            "2025-09-03 10:29:34,584 - INFO - 🔍 Running evaluation query 1: Find me landmarks in Tokyo\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "🔭 OpenTelemetry Tracing Details 🔭\n",
            "|  Phoenix Project: landmark-search-agent-evaluation\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ⚠️ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n",
            "> Running step 8200cda7-3616-4824-95d5-21731a94f86d. Step input: Find me landmarks in Tokyo\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo landmarks', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:44,282 - INFO - Search query: 'Tokyo landmarks' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo landmarks':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo**\n",
            "   📍 Location: Liverpool, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 134 Duke Street, East Village.\n",
            "   📞 Phone: +44 151 709-4002.\n",
            "   🌐 Website: http://www.sapporo.co.uk/restaurant-liverpool/.\n",
            "   📝 Description: Japanese cuisine.\n",
            "\n",
            "3. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\u001b[0m> Running step 59672c3c-5442-4248-acdf-1738b2bf8afa. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results seem to be about Japanese restaurants in various cities, not landmarks in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo landmarks', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:29:54,120 - INFO - Search query: 'Tokyo landmarks' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo landmarks':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo**\n",
            "   📍 Location: Liverpool, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 134 Duke Street, East Village.\n",
            "   📞 Phone: +44 151 709-4002.\n",
            "   🌐 Website: http://www.sapporo.co.uk/restaurant-liverpool/.\n",
            "   📝 Description: Japanese cuisine.\n",
            "\n",
            "3. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\u001b[0m> Running step 40c924cb-1f2e-4ad5-9e3e-2ae6e87ee042. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not about landmarks in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous landmarks', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:04,089 - INFO - Search query: 'Tokyo famous landmarks' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous landmarks':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo**\n",
            "   📍 Location: Liverpool, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 134 Duke Street, East Village.\n",
            "   📞 Phone: +44 151 709-4002.\n",
            "   🌐 Website: http://www.sapporo.co.uk/restaurant-liverpool/.\n",
            "   📝 Description: Japanese cuisine.\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "5. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\u001b[0m> Running step c298c10b-49ee-4dab-8d41-da32150ce52b. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not about famous landmarks in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous buildings', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:14,740 - INFO - Search query: 'Tokyo famous buildings' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous buildings':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mikawaya**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 118 Japanese Village Plaza Mall.\n",
            "   📞 Phone: +1 213 624-1681.\n",
            "   🌐 Website: http://www.mikawayausa.com.\n",
            "   🕒 Hours: M,Sa 10AM-7PM, Tu-Th 10AM-10PM, F 9AM-11PM, Su closed.\n",
            "   📝 Description: Their motto says it best: &quot;The finest name in Japanese pastries since 1910.&quot;.\n",
            "\u001b[0m> Running step 36aedfda-e756-4237-8777-8a6edba05517. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The search results are still not about famous buildings in Tokyo. I need to use the tool to search again with a more specific query.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Tokyo famous buildings', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:24,878 - INFO - Search query: 'Tokyo famous buildings' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Tokyo famous buildings':\n",
            "\n",
            "1. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "2. **Sapporo-Ya Japanese Restaurant**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1581 Webster Street.\n",
            "   📞 Phone: +1 415 563-7400.\n",
            "   🕒 Hours: M-Sa 11AM-11PM, Su 11AM-10:30PM.\n",
            "   📝 Description: Excellent Japanese noodles served dozens of ways. Open very late, and a good place to warm up on a cold foggy day..\n",
            "\n",
            "3. **Mitsuwa Marketplace**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Buy.\n",
            "   🏠 Address: 3760 S. Centinela Ave.\n",
            "   📝 Description: A Japanese supermarket with several locations in the US, boasting a collection of Japanese food shops in its food court such as '''Santouka Ramen''', '''Tendon Hannosuke''' tempura, '''Sanuki Sandou Udon''', '''Misasa''', and '''Daikichi Sushi'''..\n",
            "\n",
            "4. **Kyoto Sushi**\n",
            "   📍 Location: San Francisco, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1233 Van Ness Ave.\n",
            "   📞 Phone: +1 415 351-1234.\n",
            "   🌐 Website: http://www.kyotosushi-sf.com/.\n",
            "   🕒 Hours: M-Th 11AM-10:30PM, F 11AM-11PM, Sa 11:30AM-11PM, Su 4:30PM-10:30PM.\n",
            "   💰 Price: $11-$23.\n",
            "   📝 Description: With the multitude of sushi places it is hard to say which is best, but this one rates at the top for taste, freshness, and authenticity..\n",
            "\n",
            "5. **Mikawaya**\n",
            "   📍 Location: Los Angeles, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 118 Japanese Village Plaza Mall.\n",
            "   📞 Phone: +1 213 624-1681.\n",
            "   🌐 Website: http://www.mikawayausa.com.\n",
            "   🕒 Hours: M,Sa 10AM-7PM, Tu-Th 10AM-10PM, F 9AM-11PM, Su closed.\n",
            "   📝 Description: Their motto says it best: &quot;The finest name in Japanese pastries since 1910.&quot;.\n",
            "\u001b[0m> Running step bf6f9dd1-be04-4040-b71d-cdc07faf3635. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:27,589 - INFO - ✅ Query 1 completed successfully\n",
            "2025-09-03 10:30:27,590 - INFO - 🔍 Running evaluation query 2: Show me museums in London\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: The search results are still not about famous buildings in Tokyo. I need to try a different approach to find the information.\n",
            "\n",
            "Thought: I will try to search for famous buildings in Tokyo using a different tool or approach.\n",
            "\n",
            "Thought: I will try to search for famous buildings in Tokyo using a general search engine.\n",
            "Answer: Unfortunately, I was unable to find the information about famous buildings in Tokyo using the provided tools. However, I can suggest some famous buildings in Tokyo such as Tokyo Tower, Tokyo Skytree, and the Imperial Palace.\n",
            "\u001b[0m> Running step a63a0082-e946-4f64-8fd3-ebb73381318f. Step input: Show me museums in London\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums in London', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:37,166 - INFO - Search query: 'museums in London' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 4 landmarks matching 'museums in London':\n",
            "\n",
            "1. **London Transport Museum**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🌐 Website: http://www.ltmuseum.co.uk.\n",
            "   📝 Description: [[London]] (in [[London/Covent Garden|Covent Garden]]).\n",
            "\n",
            "2. **Clockmaker's Museum**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: Guildhall Library, Aldermanbury EC2P 2EJ.\n",
            "   📞 Phone: +44 20 7332-1868. Email: printedbooks.guildhall@corpoflondon.gov.uk.\n",
            "   🌐 Website: http://www.clockmakers.org/.\n",
            "   🕒 Hours: M–Sa 09:30–17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: Charts the history of clockmaking and houses a priceless collection of old timepieces..\n",
            "\n",
            "4. **575 Wandsworth Road**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 575 Wandsworth Road, Lambeth, London, London, SW8 3JD.\n",
            "   📞 Phone: +44 20 7720-9459. Email: 575wandsworthroad@nationaltrust.org.uk.\n",
            "   🌐 Website: http://www.nationaltrust.org.uk/575-wandsworth-road/.\n",
            "   📝 Description: Need to book in advance..\n",
            "\n",
            "5. **Tottenham Marsh**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   📝 Description: Part of the Lea Valley Park, a natural habitat for many resident plants and animals..\n",
            "\u001b[0m> Running step c6c563b4-a175-4bce-98dd-5d7ff3d4d822. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:39,256 - INFO - ✅ Query 2 completed successfully\n",
            "2025-09-03 10:30:39,258 - INFO - 📊 Collected 2 responses for evaluation\n",
            "2025-09-03 10:30:39,260 - INFO - Query: Find me landmarks in Tokyo\n",
            "2025-09-03 10:30:39,260 - INFO - Response: Unfortunately, I was unable to find the information about famous buildings in Tokyo using the provided tools. However, I can suggest some famous buildings in Tokyo such as Tokyo Tower, Tokyo Skytree, ...\n",
            "2025-09-03 10:30:39,261 - INFO - Success: True\n",
            "2025-09-03 10:30:39,262 - INFO - --------------------------------------------------\n",
            "2025-09-03 10:30:39,263 - INFO - Query: Show me museums in London\n",
            "2025-09-03 10:30:39,264 - INFO - Response: There are several museums in London that you might be interested in visiting. These include the London Transport Museum, the Clockmaker's Museum, and the National Trust's 575 Wandsworth Road. Each of ...\n",
            "2025-09-03 10:30:39,265 - INFO - Success: True\n",
            "2025-09-03 10:30:39,267 - INFO - --------------------------------------------------\n",
            "2025-09-03 10:30:39,268 - INFO - 💡 Visit Phoenix UI at http://localhost:6006/ to see detailed traces and evaluations\n",
            "2025-09-03 10:30:39,269 - INFO - 💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are several museums in London that you might be interested in visiting. These include the London Transport Museum, the Clockmaker's Museum, and the National Trust's 575 Wandsworth Road. Each of these museums offers a unique perspective on history and culture, and they are all located in different parts of the city.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Import Phoenix evaluation components\n",
        "try:\n",
        "    import phoenix as px\n",
        "    from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "    from phoenix.evals import (\n",
        "        HALLUCINATION_PROMPT_RAILS_MAP,\n",
        "        HALLUCINATION_PROMPT_TEMPLATE,\n",
        "        QA_PROMPT_RAILS_MAP,\n",
        "        QA_PROMPT_TEMPLATE,\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        OpenAIModel,\n",
        "        llm_classify,\n",
        "    )\n",
        "    from phoenix.otel import register\n",
        "    import pandas as pd\n",
        "    \n",
        "    ARIZE_AVAILABLE = True\n",
        "    logger.info(\"✅ Arize Phoenix evaluation components available\")\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Arize dependencies not available: {e}\")\n",
        "    logger.warning(\"Skipping evaluation section...\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "if ARIZE_AVAILABLE:\n",
        "    # Start Phoenix session for observability\n",
        "    try:\n",
        "        px.launch_app(port=6006)\n",
        "        logger.info(\"🚀 Phoenix UI available at http://localhost:6006/\")\n",
        "        \n",
        "        # Register LlamaIndex instrumentation\n",
        "        tracer_provider = register(\n",
        "            project_name=\"landmark-search-agent-evaluation\",\n",
        "            endpoint=\"http://localhost:6006/v1/traces\"\n",
        "        )\n",
        "        \n",
        "        # Instrument LlamaIndex\n",
        "        LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "        logger.info(\"✅ LlamaIndex instrumentation enabled\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not start Phoenix UI: {e}\")\n",
        "\n",
        "    # Demo queries for evaluation\n",
        "    landmark_demo_queries = [\n",
        "        \"Find me landmarks in Tokyo\",\n",
        "        \"Show me museums in London\"\n",
        "    ]\n",
        "    \n",
        "    # Run demo queries and collect responses for evaluation\n",
        "    landmark_demo_results = []\n",
        "    \n",
        "    for i, query in enumerate(landmark_demo_queries, 1):\n",
        "        try:\n",
        "            logger.info(f\"🔍 Running evaluation query {i}: {query}\")\n",
        "            \n",
        "            # Run the agent with LlamaIndex\n",
        "            response = agent.chat(query, chat_history=[])\n",
        "            output = response.response\n",
        "    \n",
        "            landmark_demo_results.append({\n",
        "                \"query\": query,\n",
        "                \"response\": output,\n",
        "                \"query_type\": f\"landmark_demo_{i}\",\n",
        "                \"success\": True\n",
        "            })\n",
        "            \n",
        "            logger.info(f\"✅ Query {i} completed successfully\")\n",
        "    \n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query {i} failed: {e}\")\n",
        "            landmark_demo_results.append({\n",
        "                \"query\": query,\n",
        "                \"response\": f\"Error: {e!s}\",\n",
        "                \"query_type\": f\"landmark_demo_{i}\",\n",
        "                \"success\": False\n",
        "            })\n",
        "    \n",
        "    # Convert to DataFrame for evaluation\n",
        "    landmark_results_df = pd.DataFrame(landmark_demo_results)\n",
        "    logger.info(f\"📊 Collected {len(landmark_results_df)} responses for evaluation\")\n",
        "    \n",
        "    # Display results summary\n",
        "    for _, row in landmark_results_df.iterrows():\n",
        "        logger.info(f\"Query: {row['query']}\")\n",
        "        logger.info(f\"Response: {row['response'][:200]}...\")\n",
        "        logger.info(f\"Success: {row['success']}\")\n",
        "        logger.info(\"-\" * 50)\n",
        "    \n",
        "    logger.info(\"💡 Visit Phoenix UI at http://localhost:6006/ to see detailed traces and evaluations\")\n",
        "    logger.info(\"💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\")\n",
        "\n",
        "else:\n",
        "    logger.info(\"Arize evaluation not available - install phoenix-evals to enable evaluation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:39,302 - INFO - 🔍 Running comprehensive Phoenix evaluations...\n",
            "2025-09-03 10:30:39,345 - INFO - 🔍 Running Relevance Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81410a3a258d4b6496fd066ea3cdec0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ⏳ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-03 10:30:41,641 - INFO - ✅ Relevance Evaluation Results:\n",
            "2025-09-03 10:30:41,641 - INFO -    Query: Find me landmarks in Tokyo\n",
            "2025-09-03 10:30:41,642 - INFO -    Relevance: label\n",
            "2025-09-03 10:30:41,642 - INFO -    ------------------------------\n",
            "2025-09-03 10:30:41,642 - INFO -    Query: Show me museums in London\n",
            "2025-09-03 10:30:41,642 - INFO -    Relevance: exceptions\n",
            "2025-09-03 10:30:41,642 - INFO -    ------------------------------\n",
            "2025-09-03 10:30:41,642 - ERROR - ❌ Phoenix evaluation failed: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_63525/2450233225.py\", line 31, in <module>\n",
            "    query = landmark_eval_data[i][\"input\"]\n",
            "            ~~~~~~~~~~~~~~~~~~^^^\n",
            "IndexError: list index out of range\n",
            "2025-09-03 10:30:41,643 - INFO - 💡 This might be due to API rate limits or model availability\n"
          ]
        }
      ],
      "source": [
        "if ARIZE_AVAILABLE and len(landmark_demo_results) > 0:\n",
        "    logger.info(\"🔍 Running comprehensive Phoenix evaluations...\")\n",
        "    \n",
        "    # Setup evaluator LLM (using OpenAI for consistency)\n",
        "    evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.1)\n",
        "    \n",
        "    # Prepare evaluation data with proper column names for Phoenix evaluators\n",
        "    landmark_eval_data = []\n",
        "    for _, row in landmark_results_df.iterrows():\n",
        "        landmark_eval_data.append({\n",
        "            \"input\": row[\"query\"],\n",
        "            \"output\": row[\"response\"],\n",
        "            \"reference\": \"A helpful and accurate response about landmarks with specific location information and practical details\",\n",
        "            \"text\": row[\"response\"]  # For toxicity evaluation\n",
        "        })\n",
        "    \n",
        "    landmark_eval_df = pd.DataFrame(landmark_eval_data)\n",
        "    \n",
        "    try:\n",
        "        # 1. Relevance Evaluation\n",
        "        logger.info(\"🔍 Running Relevance Evaluation...\")\n",
        "        landmark_relevance_results = llm_classify(\n",
        "            dataframe=landmark_eval_df[[\"input\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "            rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Relevance Evaluation Results:\")\n",
        "        for i, result in enumerate(landmark_relevance_results):\n",
        "            query = landmark_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Relevance: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 2. QA Evaluation\n",
        "        logger.info(\"🔍 Running QA Evaluation...\")\n",
        "        landmark_qa_results = llm_classify(\n",
        "            dataframe=landmark_eval_df[[\"input\", \"output\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=QA_PROMPT_TEMPLATE,\n",
        "            rails=list(QA_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ QA Evaluation Results:\")\n",
        "        for i, result in enumerate(landmark_qa_results):\n",
        "            query = landmark_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   QA Score: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 3. Hallucination Evaluation\n",
        "        logger.info(\"🔍 Running Hallucination Evaluation...\")\n",
        "        landmark_hallucination_results = llm_classify(\n",
        "            dataframe=landmark_eval_df[[\"input\", \"reference\", \"output\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=HALLUCINATION_PROMPT_TEMPLATE,\n",
        "            rails=list(HALLUCINATION_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Hallucination Evaluation Results:\")\n",
        "        for i, result in enumerate(landmark_hallucination_results):\n",
        "            query = landmark_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Hallucination: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 4. Toxicity Evaluation\n",
        "        logger.info(\"🔍 Running Toxicity Evaluation...\")\n",
        "        landmark_toxicity_results = llm_classify(\n",
        "            dataframe=landmark_eval_df[[\"text\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=TOXICITY_PROMPT_TEMPLATE,\n",
        "            rails=list(TOXICITY_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Toxicity Evaluation Results:\")\n",
        "        for i, result in enumerate(landmark_toxicity_results):\n",
        "            query = landmark_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Toxicity: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # Summary of all evaluations\n",
        "        logger.info(\"📊 EVALUATION SUMMARY\")\n",
        "        logger.info(\"=\" * 50)\n",
        "        \n",
        "        for i, query in enumerate([item[\"input\"] for item in landmark_eval_data]):\n",
        "            logger.info(f\"Query {i+1}: {query}\")\n",
        "            logger.info(f\"  Relevance: {landmark_relevance_results[i].label}\")\n",
        "            logger.info(f\"  QA Score: {landmark_qa_results[i].label}\")\n",
        "            logger.info(f\"  Hallucination: {landmark_hallucination_results[i].label}\")\n",
        "            logger.info(f\"  Toxicity: {landmark_toxicity_results[i].label}\")\n",
        "            logger.info(\"  \" + \"-\"*40)\n",
        "        \n",
        "        logger.info(\"✅ All Phoenix evaluations completed successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Phoenix evaluation failed: {e}\")\n",
        "        logger.info(\"💡 This might be due to API rate limits or model availability\")\n",
        "        \n",
        "else:\n",
        "    if not ARIZE_AVAILABLE:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - Arize dependencies not available\")\n",
        "    else:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - No demo results to evaluate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete landmark search agent implementation using:\n",
        "\n",
        "1. **Agent Catalog Integration**: Using agentc to find tools and prompts\n",
        "2. **LlamaIndex Framework**: ReAct agent pattern with semantic search capabilities\n",
        "3. **Couchbase Vector Store**: Storing and searching landmark data from travel-sample bucket\n",
        "4. **NVIDIA NIMs + Capella AI**: NVIDIA NIMs for LLM, Capella AI for embeddings\n",
        "5. **Single Tool Architecture**: Focused on `search_landmarks` for landmark discovery\n",
        "6. **Comprehensive Evaluation**: Phoenix-based evaluation with LlamaIndex instrumentation\n",
        "\n",
        "The agent can handle various landmark-related queries including:\n",
        "- Landmark search by location (Tokyo, London, Paris)\n",
        "- Finding specific types of attractions (museums, parks, monuments)\n",
        "- Cultural and historical site discovery\n",
        "- Tourist attraction recommendations\n",
        "\n",
        "## Phoenix Evaluation Metrics\n",
        "\n",
        "The notebook demonstrates all four key Phoenix evaluation types:\n",
        "\n",
        "1. **Relevance Evaluation**: Measures how relevant responses are to landmark queries\n",
        "2. **QA Evaluation**: Assesses the quality and accuracy of landmark information\n",
        "3. **Hallucination Detection**: Identifies fabricated or incorrect landmark information\n",
        "4. **Toxicity Detection**: Screens for harmful or inappropriate content\n",
        "\n",
        "Each evaluation provides:\n",
        "- Binary or categorical labels (e.g., \"relevant\"/\"irrelevant\", \"correct\"/\"incorrect\")\n",
        "- Detailed explanations of the evaluation reasoning\n",
        "- Confidence scores for the assessments\n",
        "\n",
        "## Key Features\n",
        "\n",
        "This landmark search agent implementation:\n",
        "- **Uses LlamaIndex**: Advanced RAG framework with ReAct agent pattern\n",
        "- **Uses travel-sample bucket**: Leverages existing Couchbase landmark data\n",
        "- **NVIDIA NIMs integration**: High-performance LLM inference\n",
        "- **Capella AI embeddings**: High-quality vector embeddings for semantic search\n",
        "- **OpenAI fallback**: Graceful fallback when Capella AI is unavailable\n",
        "- **Single focused tool**: Simplified architecture with one search tool\n",
        "- **Comprehensive evaluation**: Full Phoenix evaluation pipeline\n",
        "- **LlamaIndex instrumentation**: Integrated observability and tracing\n",
        "\n",
        "## Data Source\n",
        "\n",
        "The agent uses landmark data from the `travel-sample.inventory.landmark` collection, which contains:\n",
        "- Real landmark information with names, locations, and descriptions\n",
        "- Structured data with address, city, country, and type information\n",
        "- Rich text descriptions suitable for vector embedding\n",
        "- Global coverage of tourist attractions and points of interest\n",
        "\n",
        "## Architecture Differences\n",
        "\n",
        "This landmark search agent differs from the other agents:\n",
        "- **LlamaIndex** (not LangChain or LangGraph) - advanced RAG framework\n",
        "- **NVIDIA NIMs LLM**: High-performance inference instead of OpenAI/Capella LLM\n",
        "- **ReAct Pattern**: Built-in reasoning and action capabilities\n",
        "- **Landmark-specific**: Optimized for tourism and travel use cases\n",
        "- **Global Settings**: Uses LlamaIndex global settings for LLM and embeddings\n",
        "\n",
        "For production use, consider:\n",
        "- Setting up proper monitoring with Arize Phoenix\n",
        "- Implementing comprehensive evaluation pipelines\n",
        "- Adding error handling and retry logic\n",
        "- Scaling the vector store for larger datasets\n",
        "- Adding more sophisticated query understanding\n",
        "\n",
        "## Usage Instructions\n",
        "\n",
        "To run this notebook:\n",
        "1. Set up the required environment variables (Couchbase connection, API keys)\n",
        "2. Install dependencies: `pip install -r requirements.txt`\n",
        "3. Ensure travel-sample bucket is available in your Couchbase cluster\n",
        "4. Publish your agent catalog: `agentc index . && agentc publish`\n",
        "5. Run the notebook cells sequentially\n",
        "\n",
        "The agent will automatically load landmark data from travel-sample and create embeddings for semantic search capabilities. NVIDIA API key is required for LLM functionality.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "landmark-search-agent-2081kaWT-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
