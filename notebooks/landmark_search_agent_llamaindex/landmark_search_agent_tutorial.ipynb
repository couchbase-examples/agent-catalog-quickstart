{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Landmark Search Agent Tutorial - Priority 1 Implementation\n",
        "\n",
        "This notebook demonstrates the Agent Catalog landmark search agent using LlamaIndex with Couchbase vector store and Arize Phoenix evaluation. Uses Priority 1 AI services with standard OpenAI wrappers and Capella (simple & fast).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary modules for the landmark search agent using self-contained setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import getpass\n",
        "import httpx\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "import agentc\n",
        "import dotenv\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.management.buckets import BucketType, CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.nvidia import NVIDIA\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore\n",
        "from pydantic import SecretStr\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Reduce noise from various libraries during embedding/vector operations\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv(override=True)\n",
        "\n",
        "# Set default values for travel-sample bucket configuration\n",
        "DEFAULT_BUCKET = \"travel-sample\"\n",
        "DEFAULT_SCOPE = \"agentc_data\"\n",
        "DEFAULT_COLLECTION = \"landmark_data\"\n",
        "DEFAULT_INDEX = \"landmark_data_index\"\n",
        "DEFAULT_CAPELLA_API_EMBEDDING_MODEL = \"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
        "DEFAULT_CAPELLA_API_LLM_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "DEFAULT_NVIDIA_API_LLM_MODEL = \"meta/llama-3.1-70b-instruct\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Self-Contained Setup Functions\n",
        "\n",
        "Define all necessary setup functions inline for a self-contained notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:31:51,888 - INFO - ✅ Environment variables configured\n"
          ]
        }
      ],
      "source": [
        "def setup_environment():\n",
        "    \"\"\"Setup default environment variables for agent operations.\"\"\"\n",
        "    defaults = {\n",
        "        \"CB_BUCKET\": \"travel-sample\",\n",
        "        \"CB_SCOPE\": \"agentc_data\",\n",
        "        \"CB_COLLECTION\": \"landmark_data\",\n",
        "        \"CB_INDEX\": \"landmark_data_index\",\n",
        "        \"NVIDIA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"NVIDIA_API_LLM_MODEL\": \"meta/llama-3.1-70b-instruct\",\n",
        "        \"CAPELLA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"CAPELLA_API_LLM_MODEL\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "    }\n",
        "    \n",
        "    for key, value in defaults.items():\n",
        "        if not os.getenv(key):\n",
        "            os.environ[key] = value\n",
        "    \n",
        "    logger.info(\"✅ Environment variables configured\")\n",
        "\n",
        "\n",
        "def test_capella_connectivity(api_key: str = None, endpoint: str = None) -> bool:\n",
        "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
        "    try:\n",
        "        test_key = api_key or os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\") or os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "        test_endpoint = endpoint or os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        \n",
        "        if not test_key or not test_endpoint:\n",
        "            return False\n",
        "        \n",
        "        # Simple connectivity test\n",
        "        headers = {\"Authorization\": f\"Bearer {test_key}\"}\n",
        "        \n",
        "        with httpx.Client(timeout=10.0) as client:\n",
        "            response = client.get(f\"{test_endpoint.rstrip('/')}/v1/models\", headers=headers)\n",
        "            return response.status_code < 500\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"⚠️ Capella connectivity test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def setup_ai_services(framework: str = \"llamaindex\", temperature: float = 0.0, application_span=None):\n",
        "    \"\"\"Priority 1: Capella AI with OpenAI wrappers (simple & fast) for LlamaIndex.\"\"\"\n",
        "    embeddings = None\n",
        "    llm = None\n",
        "    \n",
        "    logger.info(f\"🔧 Setting up Priority 1 AI services for {framework} framework...\")\n",
        "    \n",
        "    # Priority 1: Capella AI with direct API keys and OpenAI wrappers\n",
        "    if not embeddings and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            api_key = os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "            model = os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\")\n",
        "            \n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                api_base = endpoint\n",
        "            else:\n",
        "                api_base = f\"{endpoint}/v1\"\n",
        "            \n",
        "            # Debug logging - same pattern as working test\n",
        "            logger.info(f\"🔧 Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 Model: {model}\")\n",
        "            logger.info(f\"🔧 API Base: {api_base}\")\n",
        "            \n",
        "            embeddings = OpenAIEmbedding(\n",
        "                api_key=api_key,\n",
        "                api_base=api_base,\n",
        "                model_name=model,\n",
        "                embed_batch_size=30,\n",
        "                # Note: LlamaIndex doesn't need check_embedding_ctx_length=False\n",
        "            )\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI embeddings failed: {type(e).__name__}: {e}\")\n",
        "    \n",
        "    if not llm and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_LLM_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            llm_key = os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "            llm_model = os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
        "            \n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                api_base = endpoint\n",
        "            else:\n",
        "                api_base = f\"{endpoint}/v1\"\n",
        "            \n",
        "            # Debug logging\n",
        "            logger.info(f\"🔧 LLM Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 LLM Model: {llm_model}\")\n",
        "            logger.info(f\"🔧 LLM API Base: {api_base}\")\n",
        "            \n",
        "            llm = OpenAILike(\n",
        "                model=llm_model,\n",
        "                api_base=api_base,\n",
        "                api_key=llm_key,\n",
        "                is_chat_model=True,\n",
        "                is_function_calling_model=False,  # KEY FIX - prevents 500 errors\n",
        "                context_window=128000,  # Add context window for compatibility\n",
        "                temperature=temperature,\n",
        "                max_retries=1,  # Faster debugging\n",
        "            )\n",
        "            # Test the LLM works\n",
        "            test_response = llm.complete(\"Hello\")\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI LLM failed: {type(e).__name__}: {e}\")\n",
        "            llm = None\n",
        "    \n",
        "    # Fallback: OpenAI\n",
        "    if not embeddings and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            embeddings = OpenAIEmbedding(\n",
        "                model_name=\"text-embedding-3-small\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI embeddings fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI embeddings failed: {e}\")\n",
        "    \n",
        "    if not llm and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            llm = OpenAILike(\n",
        "                model=\"gpt-4o\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                is_chat_model=True,\n",
        "                is_function_calling_model=False,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI LLM fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI LLM failed: {e}\")\n",
        "    \n",
        "    if not embeddings:\n",
        "        raise ValueError(\"❌ No embeddings service could be initialized\")\n",
        "    if not llm:\n",
        "        raise ValueError(\"❌ No LLM service could be initialized\")\n",
        "    \n",
        "    logger.info(f\"✅ Priority 1 AI services setup completed for {framework}\")\n",
        "    return embeddings, llm\n",
        "\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()\n",
        "\n",
        "# Test Capella AI connectivity if configured\n",
        "if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "    if not test_capella_connectivity():\n",
        "        logger.warning(\"❌ Capella AI connectivity test failed. Will use fallback models.\")\n",
        "else:\n",
        "    logger.info(\"ℹ️ Capella API not configured - will use fallback models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CouchbaseClient Class\n",
        "\n",
        "Define the CouchbaseClient for all database operations and LlamaIndex agent creation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
        "\n",
        "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
        "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "\n",
        "            # Use WAN profile for better timeout handling with remote clusters\n",
        "            options.apply_profile(\"wan_development\")\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=20))\n",
        "            logger.info(\"Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Setup collection - create scope and collection if they don't exist.\"\"\"\n",
        "        try:\n",
        "            # Ensure cluster connection\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            # For travel-sample bucket, assume it exists\n",
        "            if not self.bucket:\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"Connected to bucket '{self.bucket_name}'\")\n",
        "\n",
        "            # Setup scope\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
        "\n",
        "            # Setup collection - clear if exists, create if doesn't\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name\n",
        "                and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists:\n",
        "                logger.info(f\"Collection '{collection_name}' exists, clearing data...\")\n",
        "                # Clear existing data\n",
        "                self.clear_collection_data(scope_name, collection_name)\n",
        "            else:\n",
        "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
        "\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Create primary index\n",
        "            try:\n",
        "                self.cluster.query(\n",
        "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                ).execute()\n",
        "                logger.info(\"Primary index created successfully\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error creating primary index: {e}\")\n",
        "\n",
        "            logger.info(\"Collection setup complete\")\n",
        "            return self.bucket.scope(scope_name).collection(collection_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Clear all data from a collection.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "\n",
        "            # Use N1QL to delete all documents with explicit execution\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "\n",
        "            # Execute the query and get the results\n",
        "            rows = list(result)\n",
        "\n",
        "            # Wait a moment for the deletion to propagate\n",
        "            time.sleep(2)\n",
        "\n",
        "            # Verify collection is empty\n",
        "            count_query = f\"SELECT COUNT(*) as count FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            count_result = self.cluster.query(count_query)\n",
        "            count_row = list(count_result)[0]\n",
        "            remaining_count = count_row[\"count\"]\n",
        "\n",
        "            if remaining_count == 0:\n",
        "                logger.info(f\"Collection cleared successfully, {remaining_count} documents remaining\")\n",
        "            else:\n",
        "                logger.warning(f\"Collection clear incomplete, {remaining_count} documents remaining\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error clearing collection data: {e}\")\n",
        "            # If N1QL fails, try to continue anyway\n",
        "            pass\n",
        "\n",
        "    def get_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Get a collection object.\"\"\"\n",
        "        key = f\"{scope_name}.{collection_name}\"\n",
        "        if key not in self._collections:\n",
        "            self._collections[key] = self.bucket.scope(scope_name).collection(collection_name)\n",
        "        return self._collections[key]\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                raise RuntimeError(\"Bucket not initialized. Call setup_collection first.\")\n",
        "\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
        "            else:\n",
        "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector search index: {e!s}\")\n",
        "\n",
        "    def load_landmark_data(self, scope_name, collection_name, index_name, embeddings):\n",
        "        \"\"\"Load landmark data into Couchbase.\"\"\"\n",
        "        try:\n",
        "            # Import landmark data loading function\n",
        "            # Use inline landmark data loading function (already defined in this notebook)\n",
        "            # The function load_landmark_data_to_couchbase is defined inline above in this notebook\n",
        "\n",
        "            # Load landmark data using the data loading script\n",
        "            load_landmark_data_to_couchbase(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embeddings=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "            logger.info(\"Landmark data loaded into vector store successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading landmark data: {e!s}\")\n",
        "\n",
        "    def setup_vector_store_and_agent(self, catalog, span):\n",
        "        \"\"\"Setup vector store with landmark data and create agent.\"\"\"\n",
        "        # Setup AI services using Priority 1: Capella AI + OpenAI wrappers\n",
        "        embeddings, llm = setup_ai_services(framework=\"llamaindex\", temperature=0.1, application_span=span)\n",
        "        \n",
        "        # Set global LlamaIndex settings\n",
        "        Settings.llm = llm\n",
        "        Settings.embed_model = embeddings\n",
        "        \n",
        "        # Setup collection\n",
        "        self.setup_collection(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"])\n",
        "        \n",
        "        # Setup vector search index - MUST have agentcatalog_index.json\n",
        "        with open(\"agentcatalog_index.json\") as file:\n",
        "            index_definition = json.load(file)\n",
        "        logger.info(\"Loaded vector search index definition from agentcatalog_index.json\")\n",
        "        self.setup_vector_search_index(index_definition, os.environ[\"CB_SCOPE\"])\n",
        "        \n",
        "        # Load landmark data\n",
        "        self.load_landmark_data(\n",
        "            os.environ[\"CB_SCOPE\"],\n",
        "            os.environ[\"CB_COLLECTION\"],\n",
        "            os.environ[\"CB_INDEX\"],\n",
        "            embeddings,\n",
        "        )\n",
        "        \n",
        "        # Create LlamaIndex ReAct agent\n",
        "        agent = self.create_llamaindex_agent(catalog, span)\n",
        "        \n",
        "        return agent\n",
        "\n",
        "    def create_llamaindex_agent(self, catalog, span):\n",
        "        \"\"\"Create LlamaIndex ReAct agent with landmark search tool from Agent Catalog.\"\"\"\n",
        "        try:\n",
        "            # Get tools from Agent Catalog\n",
        "            tools = []\n",
        "\n",
        "            # Search landmarks tool\n",
        "            search_tool_result = catalog.find(\"tool\", name=\"search_landmarks\")\n",
        "            if search_tool_result:\n",
        "                tools.append(\n",
        "                    FunctionTool.from_defaults(\n",
        "                        fn=search_tool_result.func,\n",
        "                        name=\"search_landmarks\",\n",
        "                        description=getattr(search_tool_result.meta, \"description\", None)\n",
        "                        or \"Search for landmark information using semantic vector search. Use for finding attractions, monuments, museums, parks, and other points of interest.\",\n",
        "                    )\n",
        "                )\n",
        "                logger.info(\"Loaded search_landmarks tool from AgentC\")\n",
        "\n",
        "            if not tools:\n",
        "                logger.warning(\"No tools found in Agent Catalog\")\n",
        "            else:\n",
        "                logger.info(f\"Loaded {len(tools)} tools from Agent Catalog\")\n",
        "\n",
        "            # Get prompt from Agent Catalog - REQUIRED, no fallbacks\n",
        "            prompt_result = catalog.find(\"prompt\", name=\"landmark_search_assistant\")\n",
        "            if not prompt_result:\n",
        "                raise RuntimeError(\"Prompt 'landmark_search_assistant' not found in Agent Catalog\")\n",
        "\n",
        "            # Try different possible attributes for the prompt content\n",
        "            system_prompt = (\n",
        "                getattr(prompt_result, \"content\", None)\n",
        "                or getattr(prompt_result, \"template\", None)\n",
        "                or getattr(prompt_result, \"text\", None)\n",
        "            )\n",
        "            if not system_prompt:\n",
        "                raise RuntimeError(\n",
        "                    \"Could not access prompt content from AgentC - prompt content is None or empty\"\n",
        "                )\n",
        "\n",
        "            logger.info(\"Loaded system prompt from Agent Catalog\")\n",
        "\n",
        "            # Create ReAct agent with limits to prevent excessive iterations\n",
        "            agent = ReActAgent.from_tools(\n",
        "                tools=tools,\n",
        "                llm=Settings.llm,\n",
        "                verbose=True,\n",
        "                system_prompt=system_prompt,\n",
        "                max_iterations=12,\n",
        "            )\n",
        "\n",
        "            logger.info(\"LlamaIndex ReAct agent created successfully\")\n",
        "            return agent\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error creating LlamaIndex agent: {e!s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Standalone Agent Creation Function\n",
        "\n",
        "Standalone version of the agent creation function for compatibility with main.py structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_llamaindex_agent(catalog, span):\n",
        "    \"\"\"Create LlamaIndex ReAct agent with landmark search tool from Agent Catalog.\"\"\"\n",
        "    try:\n",
        "        from llama_index.core.agent import ReActAgent\n",
        "        from llama_index.core.tools import FunctionTool\n",
        "\n",
        "        # Get tools from Agent Catalog\n",
        "        tools = []\n",
        "\n",
        "        # Search landmarks tool\n",
        "        search_tool_result = catalog.find(\"tool\", name=\"search_landmarks\")\n",
        "        if search_tool_result:\n",
        "            tools.append(\n",
        "                FunctionTool.from_defaults(\n",
        "                    fn=search_tool_result.func,\n",
        "                    name=\"search_landmarks\",\n",
        "                    description=getattr(search_tool_result.meta, \"description\", None)\n",
        "                    or \"Search for landmark information using semantic vector search. Use for finding attractions, monuments, museums, parks, and other points of interest.\",\n",
        "                )\n",
        "            )\n",
        "            logger.info(\"Loaded search_landmarks tool from AgentC\")\n",
        "\n",
        "        if not tools:\n",
        "            logger.warning(\"No tools found in Agent Catalog\")\n",
        "        else:\n",
        "            logger.info(f\"Loaded {len(tools)} tools from Agent Catalog\")\n",
        "\n",
        "        # Get prompt from Agent Catalog - REQUIRED, no fallbacks\n",
        "        prompt_result = catalog.find(\"prompt\", name=\"landmark_search_assistant\")\n",
        "        if not prompt_result:\n",
        "            raise RuntimeError(\"Prompt 'landmark_search_assistant' not found in Agent Catalog\")\n",
        "\n",
        "        # Try different possible attributes for the prompt content\n",
        "        system_prompt = (\n",
        "            getattr(prompt_result, \"content\", None)\n",
        "            or getattr(prompt_result, \"template\", None)\n",
        "            or getattr(prompt_result, \"text\", None)\n",
        "        )\n",
        "        if not system_prompt:\n",
        "            raise RuntimeError(\n",
        "                \"Could not access prompt content from AgentC - prompt content is None or empty\"\n",
        "            )\n",
        "\n",
        "        logger.info(\"Loaded system prompt from Agent Catalog\")\n",
        "\n",
        "        # Create ReAct agent with reasonable iteration limit\n",
        "        agent = ReActAgent.from_tools(\n",
        "            tools=tools,\n",
        "            llm=Settings.llm,\n",
        "            verbose=True,  # Keep on for debugging\n",
        "            system_prompt=system_prompt,\n",
        "            max_iterations=10,  # Allow sufficient reasoning steps for complex landmark queries\n",
        "        )\n",
        "\n",
        "        logger.info(\"LlamaIndex ReAct agent created successfully\")\n",
        "        return agent\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error creating LlamaIndex agent: {e!s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Loading Module\n",
        "\n",
        "Complete landmark data loading functions from data/landmark_data.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading functions from data/landmark_data.py\n",
        "import couchbase.auth\n",
        "import couchbase.cluster\n",
        "import couchbase.exceptions\n",
        "import couchbase.options\n",
        "from llama_index.core import Document\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def get_cluster_connection():\n",
        "    \"\"\"Get a fresh cluster connection for each request.\"\"\"\n",
        "    try:\n",
        "        auth = couchbase.auth.PasswordAuthenticator(\n",
        "            username=os.environ[\"CB_USERNAME\"],\n",
        "            password=os.environ[\"CB_PASSWORD\"],\n",
        "        )\n",
        "        options = couchbase.options.ClusterOptions(authenticator=auth)\n",
        "        # Use WAN profile for better timeout handling with remote clusters\n",
        "        options.apply_profile(\"wan_development\")\n",
        "\n",
        "        cluster = couchbase.cluster.Cluster(\n",
        "            os.environ[\"CB_CONN_STRING\"], options\n",
        "        )\n",
        "        cluster.wait_until_ready(timedelta(seconds=15))\n",
        "        return cluster\n",
        "    except couchbase.exceptions.CouchbaseException as e:\n",
        "        logger.error(f\"Could not connect to Couchbase cluster: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_landmark_data_from_travel_sample():\n",
        "    \"\"\"Load landmark data from travel-sample.inventory.landmark collection.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        # Query to get all landmark documents from travel-sample.inventory.landmark\n",
        "        query = \"\"\"\n",
        "        SELECT l.*, META(l).id as doc_id\n",
        "        FROM `travel-sample`.inventory.landmark l\n",
        "        ORDER BY l.name\n",
        "        \"\"\"\n",
        "\n",
        "        logger.info(\"Loading landmark data from travel-sample.inventory.landmark...\")\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        landmarks = []\n",
        "        logger.info(\"Processing landmark documents...\")\n",
        "\n",
        "        # Convert to list to get total count for progress bar\n",
        "        landmark_rows = list(result)\n",
        "\n",
        "        # Use tqdm for progress bar\n",
        "        for row in tqdm(landmark_rows, desc=\"Loading landmarks\", unit=\"landmarks\"):\n",
        "            landmark = row\n",
        "            landmarks.append(landmark)\n",
        "\n",
        "        logger.info(f\"Loaded {len(landmarks)} landmarks from travel-sample.inventory.landmark\")\n",
        "        return landmarks\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading landmark data: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_landmark_texts():\n",
        "    \"\"\"Returns formatted landmark texts for vector store embedding from travel-sample data.\"\"\"\n",
        "    landmarks = load_landmark_data_from_travel_sample()\n",
        "    landmark_texts = []\n",
        "\n",
        "    logger.info(\"Generating landmark text embeddings...\")\n",
        "\n",
        "    # Use tqdm for progress bar while processing landmarks\n",
        "    for landmark in tqdm(landmarks, desc=\"Processing landmarks\", unit=\"landmarks\"):\n",
        "        # Start with basic info\n",
        "        name = landmark.get(\"name\", \"Unknown Landmark\")\n",
        "        title = landmark.get(\"title\", name)\n",
        "        city = landmark.get(\"city\", \"Unknown City\")\n",
        "        country = landmark.get(\"country\", \"Unknown Country\")\n",
        "\n",
        "        # Build comprehensive text with all available fields\n",
        "        text_parts = [f\"{title} ({name}) in {city}, {country}\"]\n",
        "\n",
        "        # Add all fields dynamically instead of manual selection\n",
        "        field_mappings = {\n",
        "            \"content\": \"Description\",\n",
        "            \"address\": \"Address\",\n",
        "            \"directions\": \"Directions\",\n",
        "            \"phone\": \"Phone\",\n",
        "            \"tollfree\": \"Toll-free\",\n",
        "            \"email\": \"Email\",\n",
        "            \"url\": \"Website\",\n",
        "            \"hours\": \"Hours\",\n",
        "            \"price\": \"Price\",\n",
        "            \"activity\": \"Activity type\",\n",
        "            \"type\": \"Type\",\n",
        "            \"state\": \"State\",\n",
        "            \"alt\": \"Alternative name\",\n",
        "            \"image\": \"Image\",\n",
        "        }\n",
        "\n",
        "        # Add all available fields\n",
        "        for field, label in field_mappings.items():\n",
        "            value = landmark.get(field)\n",
        "            if value is not None and value != \"\" and value != \"None\":\n",
        "                if isinstance(value, bool):\n",
        "                    text_parts.append(f\"{label}: {'Yes' if value else 'No'}\")\n",
        "                else:\n",
        "                    text_parts.append(f\"{label}: {value}\")\n",
        "\n",
        "        # Add geographic coordinates if available\n",
        "        if landmark.get(\"geo\"):\n",
        "            geo = landmark[\"geo\"]\n",
        "            if geo.get(\"lat\") and geo.get(\"lon\"):\n",
        "                accuracy = geo.get(\"accuracy\", \"Unknown\")\n",
        "                text_parts.append(f\"Coordinates: {geo['lat']}, {geo['lon']} (accuracy: {accuracy})\")\n",
        "\n",
        "        # Add ID for reference\n",
        "        if landmark.get(\"id\"):\n",
        "            text_parts.append(f\"ID: {landmark['id']}\")\n",
        "\n",
        "        # Join all parts with \". \"\n",
        "        text = \". \".join(text_parts)\n",
        "        landmark_texts.append(text)\n",
        "\n",
        "    logger.info(f\"Generated {len(landmark_texts)} landmark text embeddings\")\n",
        "    return landmark_texts\n",
        "\n",
        "\n",
        "def load_landmark_data_to_couchbase(\n",
        "    cluster, bucket_name: str, scope_name: str, collection_name: str, embeddings, index_name: str\n",
        "):\n",
        "    \"\"\"Load landmark data from travel-sample into the target collection with embeddings.\"\"\"\n",
        "    try:\n",
        "        # Check if data already exists\n",
        "        count_query = (\n",
        "            f\"SELECT COUNT(*) as count FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "        )\n",
        "        count_result = cluster.query(count_query)\n",
        "        count_row = list(count_result)[0]\n",
        "        existing_count = count_row[\"count\"]\n",
        "\n",
        "        if existing_count > 0:\n",
        "            logger.info(\n",
        "                f\"Found {existing_count} existing documents in collection, skipping data load\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Get the source landmarks from travel-sample\n",
        "        landmarks = load_landmark_data_from_travel_sample()\n",
        "        landmark_texts = get_landmark_texts()\n",
        "\n",
        "        # Setup vector store for the target collection\n",
        "        vector_store = CouchbaseSearchVectorStore(\n",
        "            cluster=cluster,\n",
        "            bucket_name=bucket_name,\n",
        "            scope_name=scope_name,\n",
        "            collection_name=collection_name,\n",
        "            index_name=index_name,\n",
        "        )\n",
        "\n",
        "        # Create LlamaIndex Documents\n",
        "        logger.info(f\"Creating {len(landmark_texts)} LlamaIndex Documents...\")\n",
        "        documents = []\n",
        "        \n",
        "        for i, (landmark, text) in enumerate(zip(landmarks, landmark_texts)):\n",
        "            document = Document(\n",
        "                text=text,\n",
        "                metadata={\n",
        "                    \"landmark_id\": landmark.get(\"id\", f\"landmark_{i}\"),\n",
        "                    \"name\": landmark.get(\"name\", \"Unknown\"),\n",
        "                    \"city\": landmark.get(\"city\", \"Unknown\"),\n",
        "                    \"country\": landmark.get(\"country\", \"Unknown\"),\n",
        "                    \"activity\": landmark.get(\"activity\", \"\"),\n",
        "                    \"type\": landmark.get(\"type\", \"\"),\n",
        "                    # Add the missing fields that search tool expects\n",
        "                    \"address\": landmark.get(\"address\", \"\"),\n",
        "                    \"phone\": landmark.get(\"phone\", \"\"),\n",
        "                    \"url\": landmark.get(\"url\", \"\"),\n",
        "                    \"hours\": landmark.get(\"hours\", \"\"),\n",
        "                    \"price\": landmark.get(\"price\", \"\"),\n",
        "                    \"state\": landmark.get(\"state\", \"\"),\n",
        "                }\n",
        "            )\n",
        "            documents.append(document)\n",
        "\n",
        "        # Use IngestionPipeline to process documents with embeddings\n",
        "        logger.info(f\"Processing documents with ingestion pipeline...\")\n",
        "        pipeline = IngestionPipeline(\n",
        "            transformations=[SentenceSplitter(chunk_size=800, chunk_overlap=100), embeddings],\n",
        "            vector_store=vector_store,\n",
        "        )\n",
        "\n",
        "        # Process documents in batches to avoid memory issues\n",
        "        batch_size = 25  # Well below Capella AI embedding model limit\n",
        "        total_batches = (len(documents) + batch_size - 1) // batch_size\n",
        "\n",
        "        logger.info(f\"Processing {len(documents)} documents in {total_batches} batches...\")\n",
        "        \n",
        "        # Process in batches\n",
        "        for i in tqdm(\n",
        "            range(0, len(documents), batch_size),\n",
        "            desc=\"Loading batches\",\n",
        "            unit=\"batch\",\n",
        "            total=total_batches,\n",
        "        ):\n",
        "            batch = documents[i : i + batch_size]\n",
        "            pipeline.run(documents=batch)\n",
        "\n",
        "        logger.info(\n",
        "            f\"Successfully loaded {len(documents)} landmark documents to vector store\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading landmark data to Couchbase: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_landmark_count():\n",
        "    \"\"\"Get the count of landmarks in travel-sample.inventory.landmark.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        query = \"SELECT COUNT(*) as count FROM `travel-sample`.inventory.landmark\"\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        for row in result:\n",
        "            return row[\"count\"]\n",
        "\n",
        "        return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting landmark count: {str(e)}\")\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Query Module\n",
        "\n",
        "Complete query collections and functions from data/queries.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query functions and data from data/queries.py\n",
        "from typing import Dict, List\n",
        "\n",
        "# Landmark search queries (based on travel-sample data)\n",
        "LANDMARK_SEARCH_QUERIES = [\n",
        "    \"Find museums and galleries in Glasgow\",  # Art & Culture, Scotland\n",
        "    \"Show me restaurants serving Asian cuisine\",  # Food & Dining, Real Asian restaurants\n",
        "    \"What attractions can I see in Glasgow?\",  # General sightseeing, Scotland\n",
        "    \"Tell me about Monet's House\",  # Specific landmark, France\n",
        "    \"Find places to eat in Gillingham\",  # Food, Real UK town\n",
        "]\n",
        "\n",
        "# Comprehensive reference answers based on ACTUAL agent responses from travel-sample.inventory.landmark data\n",
        "LANDMARK_REFERENCE_ANSWERS = [\n",
        "    # Query 1: Glasgow museums and galleries\n",
        "    \"\"\"Glasgow has several museums and galleries including the Gallery of Modern Art (Glasgow) located at Royal Exchange Square with a terrific collection of recent paintings and sculptures, the Kelvingrove Art Gallery and Museum on Argyle Street with one of the finest civic collections in Europe including works by Van Gogh, Monet and Rembrandt, the Hunterian Museum and Art Gallery at University of Glasgow with a world famous Whistler collection, and the Riverside Museum at 100 Pointhouse Place with an excellent collection of vehicles and transport history. All offer free admission except for special exhibitions.\"\"\",\n",
        "\n",
        "    # Query 2: Asian cuisine restaurants\n",
        "    \"\"\"There are several Asian restaurants available including Shangri-la Chinese Restaurant in Birmingham at 51 Station Street offering good quality Chinese food with spring rolls and sizzling steak, Taiwan Restaurant in San Francisco famous for their dumplings, Hong Kong Seafood Restaurant in San Francisco for sit-down dim sum, Cheung Hing Chinese Restaurant in San Francisco for Cantonese BBQ and roast duck, Vietnam Restaurant in San Francisco for Vietnamese dishes including crab soup and pork sandwich, and various other Chinese and Asian establishments across different locations.\"\"\",\n",
        "\n",
        "    # Query 3: Glasgow attractions\n",
        "    \"\"\"Glasgow attractions include Glasgow Green (founded by Royal grant in 1450) with Nelson's Memorial and the Doulton Fountain, Glasgow University (founded 1451) with neo-Gothic architecture and commanding views, Glasgow Cathedral with fine Gothic architecture from medieval times, the City Chambers in George Square built in 1888 in Italian Renaissance style with guided tours available, Glasgow Central Station with its grand interior, and Kelvingrove Park which is popular with students and contains the Art Gallery and Museum.\"\"\",\n",
        "\n",
        "    # Query 4: Monet's House\n",
        "    \"\"\"Monet's House is located in Giverny, France at 84 rue Claude Monet. The house is quietly eccentric and highly interesting in an Orient-influenced style, featuring Monet's collection of Japanese prints. The main attraction is the gardens around the house, including the water garden with the Japanese bridge, weeping willows and waterlilies which are now iconic. It's open April-October, Monday-Sunday 9:30-18:00, with admission €9 for adults, €5 for students, €4 for disabled visitors, and free for under-7s. E-tickets can be purchased online and wheelchair access is available.\"\"\",\n",
        "\n",
        "    # Query 5: Gillingham restaurants\n",
        "    \"\"\"Gillingham has various dining options including Beijing Inn (Chinese restaurant at 3 King Street), Spice Court (Indian restaurant at 56-58 Balmoral Road opposite the railway station, award-winning with Sunday Buffet for £8.50), Hollywood Bowl (American-style restaurant at 4 High Street with burgers and ribs in a Hollywood-themed setting), Ossie's Fish and Chips (at 75 Richmond Road, known for the best fish and chips in the area), and Thai Won Mien (oriental restaurant at 59-61 High Street with noodles, duck and other oriental dishes).\"\"\",\n",
        "]\n",
        "\n",
        "# Create dictionary for backward compatibility\n",
        "QUERY_REFERENCE_ANSWERS = {\n",
        "    query: answer for query, answer in zip(LANDMARK_SEARCH_QUERIES, LANDMARK_REFERENCE_ANSWERS)\n",
        "}\n",
        "\n",
        "# Category-based queries for testing specific search capabilities (based on real data)\n",
        "CATEGORY_QUERIES = {\n",
        "    \"cultural\": [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"Show me historic buildings and architecture\",\n",
        "        \"What art collections can I visit?\",\n",
        "    ],\n",
        "    \"culinary\": [\n",
        "        \"Show me restaurants serving Asian cuisine\",\n",
        "        \"Find places to eat in Gillingham\",\n",
        "        \"What dining options are available?\",\n",
        "    ],\n",
        "    \"sightseeing\": [\n",
        "        \"What attractions can I see in Glasgow?\",\n",
        "        \"Show me historic landmarks and buildings\",\n",
        "        \"Find interesting places to visit\",\n",
        "    ],\n",
        "    \"specific\": [\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"Show me the Glasgow Cathedral\",\n",
        "        \"What can you tell me about the Burrell Collection?\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Location-based queries for geographic diversity testing (based on real data)\n",
        "LOCATION_QUERIES = {\n",
        "    \"Scotland\": [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"What attractions can I see in Glasgow?\",\n",
        "        \"Show me historic buildings in Glasgow\",\n",
        "    ],\n",
        "    \"England\": [\n",
        "        \"Find places to eat in Gillingham\",\n",
        "        \"Show me restaurants serving Asian cuisine\",\n",
        "        \"What landmarks are in Gillingham?\",\n",
        "    ],\n",
        "    \"France\": [\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"Show me attractions in Giverny\",\n",
        "        \"What can I visit in France?\",\n",
        "    ],\n",
        "    \"UK_General\": [\n",
        "        \"Find attractions in the United Kingdom\",\n",
        "        \"Show me places to visit in the UK\",\n",
        "        \"What can I see in Britain?\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Activity-based queries for testing different search patterns\n",
        "ACTIVITY_QUERIES = [\n",
        "    \"What can I see in Glasgow?\",  # 'see' activity queries\n",
        "    \"Where can I eat in Gillingham?\",  # 'eat' activity queries\n",
        "    \"Show me places to dine\",  # Generic eating queries\n",
        "    \"Find things to visit and see\",  # Generic sightseeing queries\n",
        "    \"What museums can I visit?\",  # Specific venue type queries\n",
        "]\n",
        "\n",
        "\n",
        "def get_all_queries() -> List[str]:\n",
        "    \"\"\"Get all queries for comprehensive testing.\"\"\"\n",
        "    all_queries = LANDMARK_SEARCH_QUERIES.copy()\n",
        "\n",
        "    # Add category queries\n",
        "    for category_list in CATEGORY_QUERIES.values():\n",
        "        all_queries.extend(category_list)\n",
        "\n",
        "    # Add location queries\n",
        "    for location_list in LOCATION_QUERIES.values():\n",
        "        all_queries.extend(location_list)\n",
        "\n",
        "    # Add activity queries\n",
        "    all_queries.extend(ACTIVITY_QUERIES)\n",
        "\n",
        "    return all_queries\n",
        "\n",
        "\n",
        "def get_reference_answer(query: str) -> str:\n",
        "    \"\"\"Get reference answer for a specific query.\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS.get(query, \"No reference answer available for this query.\")\n",
        "\n",
        "\n",
        "def get_queries_by_category(category: str) -> List[str]:\n",
        "    \"\"\"Get queries filtered by category.\"\"\"\n",
        "    if category == \"basic\":\n",
        "        return LANDMARK_SEARCH_QUERIES\n",
        "    elif category == \"category\":\n",
        "        return [q for queries in CATEGORY_QUERIES.values() for q in queries]\n",
        "    elif category == \"location\":\n",
        "        return [q for queries in LOCATION_QUERIES.values() for q in queries]\n",
        "    elif category == \"activity\":\n",
        "        return ACTIVITY_QUERIES\n",
        "    else:\n",
        "        return get_all_queries()\n",
        "\n",
        "\n",
        "def get_queries_for_evaluation(limit: int = 5) -> List[str]:\n",
        "    \"\"\"Get a subset of queries for evaluation purposes.\"\"\"\n",
        "    return LANDMARK_SEARCH_QUERIES[:limit]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Landmark Search Agent Setup\n",
        "\n",
        "Setup the complete landmark search agent infrastructure using LlamaIndex.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:31:53,398 - INFO - ✅ Environment variables configured\n",
            "2025-09-04 14:31:53,539 - INFO - A local catalog and a remote catalog have been found. Building a chained tool catalog.\n",
            "2025-09-04 14:31:53,540 - INFO - A local catalog and a remote catalog have been found. Building a chained prompt catalog.\n",
            "2025-09-04 14:31:53,582 - INFO - Using both a local auditor and a remote auditor.\n",
            "2025-09-04 14:31:53,583 - INFO - 🔧 Setting up Priority 1 AI services for llamaindex framework...\n",
            "2025-09-04 14:31:53,584 - INFO - 🔧 Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-04 14:31:53,584 - INFO - 🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "2025-09-04 14:31:53,584 - INFO - 🔧 API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-04 14:31:53,585 - INFO - ✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "2025-09-04 14:31:53,585 - INFO - 🔧 LLM Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-04 14:31:53,586 - INFO - 🔧 LLM Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "2025-09-04 14:31:53,586 - INFO - 🔧 LLM API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-04 14:31:55,019 - INFO - ✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "2025-09-04 14:31:55,019 - INFO - ✅ Priority 1 AI services setup completed for llamaindex\n",
            "2025-09-04 14:31:57,337 - INFO - Successfully connected to Couchbase\n",
            "2025-09-04 14:31:57,338 - INFO - 🔧 Setting up Priority 1 AI services for llamaindex framework...\n",
            "2025-09-04 14:31:57,338 - INFO - 🔧 Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-04 14:31:57,339 - INFO - 🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "2025-09-04 14:31:57,340 - INFO - 🔧 API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-04 14:31:57,341 - INFO - ✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "2025-09-04 14:31:57,341 - INFO - 🔧 LLM Endpoint: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com\n",
            "2025-09-04 14:31:57,342 - INFO - 🔧 LLM Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "2025-09-04 14:31:57,343 - INFO - 🔧 LLM API Base: https://o1w7qdmspvermloq.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "2025-09-04 14:31:58,613 - INFO - ✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "2025-09-04 14:31:58,613 - INFO - ✅ Priority 1 AI services setup completed for llamaindex\n",
            "2025-09-04 14:32:00,050 - INFO - Connected to bucket 'travel-sample'\n",
            "2025-09-04 14:32:02,166 - INFO - Collection 'landmark_data' exists, clearing data...\n",
            "2025-09-04 14:32:02,167 - INFO - Clearing data from travel-sample.agentc_data.landmark_data...\n",
            "2025-09-04 14:32:07,553 - INFO - Collection cleared successfully, 0 documents remaining\n",
            "2025-09-04 14:32:11,722 - INFO - Primary index created successfully\n",
            "2025-09-04 14:32:11,723 - INFO - Collection setup complete\n",
            "2025-09-04 14:32:11,724 - INFO - Loaded vector search index definition from agentcatalog_index.json\n",
            "2025-09-04 14:32:12,749 - INFO - Vector search index 'landmark_data_index' already exists\n",
            "2025-09-04 14:32:15,872 - INFO - Loading landmark data from travel-sample.inventory.landmark...\n",
            "2025-09-04 14:32:15,873 - INFO - Processing landmark documents...\n",
            "Loading landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 6485516.50landmarks/s]\n",
            "2025-09-04 14:32:22,227 - INFO - Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "2025-09-04 14:32:24,608 - INFO - Loading landmark data from travel-sample.inventory.landmark...\n",
            "2025-09-04 14:32:24,609 - INFO - Processing landmark documents...\n",
            "Loading landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 7273686.91landmarks/s]\n",
            "2025-09-04 14:32:33,508 - INFO - Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "2025-09-04 14:32:33,509 - INFO - Generating landmark text embeddings...\n",
            "Processing landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 252631.67landmarks/s]\n",
            "2025-09-04 14:32:33,529 - INFO - Generated 4495 landmark text embeddings\n",
            "2025-09-04 14:32:36,791 - INFO - Creating 4495 LlamaIndex Documents...\n",
            "2025-09-04 14:32:36,827 - INFO - Processing documents with ingestion pipeline...\n",
            "2025-09-04 14:32:36,935 - INFO - Processing 4495 documents in 180 batches...\n",
            "Loading batches: 100%|██████████| 180/180 [07:28<00:00,  2.49s/batch]\n",
            "2025-09-04 14:40:05,719 - INFO - Successfully loaded 4495 landmark documents to vector store\n",
            "2025-09-04 14:40:05,720 - INFO - Landmark data loaded into vector store successfully\n",
            "2025-09-04 14:40:05,750 - INFO - Loaded search_landmarks tool from AgentC\n",
            "2025-09-04 14:40:05,750 - INFO - Loaded 1 tools from Agent Catalog\n",
            "2025-09-04 14:40:05,762 - INFO - Loaded system prompt from Agent Catalog\n",
            "/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/home/kaustav/.cache/pypoetry/virtualenvs/landmark-search-agent-2081kaWT-py3.12/lib/python3.12/site-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n",
            "2025-09-04 14:40:05,764 - INFO - LlamaIndex ReAct agent created successfully\n"
          ]
        }
      ],
      "source": [
        "def setup_landmark_agent():\n",
        "    \"\"\"Setup the complete landmark search agent infrastructure and return the agent.\"\"\"\n",
        "    setup_environment()\n",
        "\n",
        "    # Initialize Agent Catalog with credentials\n",
        "    catalog = agentc.Catalog()\n",
        "    span = catalog.Span(name=\"Landmark Search Agent Setup\", blacklist=set())\n",
        "\n",
        "    # Setup LLM and embeddings\n",
        "    embeddings, llm = setup_ai_services(framework=\"llamaindex\", temperature=0.1, application_span=span)\n",
        "\n",
        "    # Set global LlamaIndex settings\n",
        "    Settings.llm = llm\n",
        "    Settings.embed_model = embeddings\n",
        "\n",
        "\n",
        "    # Setup database client\n",
        "    client = CouchbaseClient(\n",
        "        conn_string=os.environ[\"CB_CONN_STRING\"],\n",
        "        username=os.environ[\"CB_USERNAME\"],\n",
        "        password=os.environ[\"CB_PASSWORD\"],\n",
        "        bucket_name=os.environ[\"CB_BUCKET\"],\n",
        "    )\n",
        "\n",
        "    client.connect()\n",
        "\n",
        "    # Setup vector store and agent\n",
        "    agent = client.setup_vector_store_and_agent(catalog, span)\n",
        "\n",
        "    return agent, client\n",
        "\n",
        "\n",
        "# Inline evaluation templates for lenient evaluation\n",
        "LENIENT_QA_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert evaluator assessing if an AI assistant's response correctly answers the user's question about landmarks and attractions.\n",
        "\n",
        "FOCUS ON FUNCTIONAL SUCCESS, NOT EXACT MATCHING:\n",
        "1. Did the agent provide the requested landmark information?\n",
        "2. Is the core information accurate and helpful to the user?\n",
        "3. Would the user be satisfied with what they received?\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND CORRECT:\n",
        "- Landmark search results vary based on current database state\n",
        "- Different search queries may return different but valid landmarks\n",
        "- Order of results may vary (this is normal for search results)\n",
        "- Formatting differences are acceptable\n",
        "\n",
        "IGNORE THESE DIFFERENCES:\n",
        "- Format differences, duplicate searches, system messages\n",
        "- Different result ordering or landmark selection\n",
        "- Reference mismatches due to dynamic search results\n",
        "\n",
        "MARK AS CORRECT IF:\n",
        "- Agent successfully found landmarks matching the request\n",
        "- User received useful, accurate landmark information\n",
        "- Core functionality worked as expected (search worked, results filtered properly)\n",
        "\n",
        "MARK AS INCORRECT ONLY IF:\n",
        "- Agent completely failed to provide landmark information\n",
        "- Response is totally irrelevant to the landmark search request\n",
        "- Agent provided clearly wrong or nonsensical information\n",
        "\n",
        "**Question:** {input}\n",
        "\n",
        "**Reference Answer:** {reference}\n",
        "\n",
        "**AI Response:** {output}\n",
        "\n",
        "Based on the criteria above, is the AI response correct?\n",
        "\n",
        "Answer: [correct/incorrect]\n",
        "\n",
        "Explanation: [Provide a brief explanation focusing on functional success]\n",
        "\"\"\"\n",
        "\n",
        "# Lenient hallucination evaluation template  \n",
        "LENIENT_HALLUCINATION_PROMPT_TEMPLATE = \"\"\"\n",
        "You are evaluating whether an AI assistant's response about landmarks contains hallucinated (fabricated) information.\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND FACTUAL:\n",
        "- Landmark search results are pulled from a real database\n",
        "- Different searches return different valid landmarks (this is correct behavior)\n",
        "- Landmark details like addresses, descriptions, and activities come from actual data\n",
        "- Search result variations are normal and factual\n",
        "\n",
        "MARK AS FACTUAL IF:\n",
        "- Response contains \"iteration limit\" or \"time limit\" (system issue, not hallucination)\n",
        "- Agent provides plausible landmark data from search results\n",
        "- Information is consistent with typical landmark search functionality\n",
        "- Results differ from reference due to dynamic search (this is expected!)\n",
        "\n",
        "ONLY MARK AS HALLUCINATED IF:\n",
        "- Response contains clearly impossible landmark information\n",
        "- Agent makes up fake landmark names, addresses, or details\n",
        "- Response contradicts fundamental facts about landmark search\n",
        "- Agent claims to have data it cannot access\n",
        "\n",
        "REMEMBER: Different search results are EXPECTED dynamic behavior, not hallucinations!\n",
        "\n",
        "**Question:** {input}\n",
        "\n",
        "**Reference Answer:** {reference}\n",
        "\n",
        "**AI Response:** {output}\n",
        "\n",
        "Based on the criteria above, does the response contain hallucinated information?\n",
        "\n",
        "Answer: [factual/hallucinated]\n",
        "\n",
        "Explanation: [Focus on whether information is plausible vs clearly fabricated]\n",
        "\"\"\"\n",
        "\n",
        "# Lenient evaluation rails (classification options)\n",
        "LENIENT_QA_RAILS = [\"correct\", \"incorrect\"]\n",
        "LENIENT_HALLUCINATION_RAILS = [\"factual\", \"hallucinated\"]\n",
        "\n",
        "# Setup the landmark search agent\n",
        "agent, client = setup_landmark_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test Functions\n",
        "Define test functions to demonstrate the landmark search agent functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:05,773 - INFO - Testing Landmark Data Loading from travel-sample\n",
            "2025-09-04 14:40:05,774 - INFO - ==================================================\n",
            "2025-09-04 14:40:08,237 - INFO - ✅ Landmark count in travel-sample.inventory.landmark: 4495\n",
            "2025-09-04 14:40:10,474 - INFO - Loading landmark data from travel-sample.inventory.landmark...\n",
            "2025-09-04 14:40:10,475 - INFO - Processing landmark documents...\n",
            "Loading landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 9112323.09landmarks/s]\n",
            "2025-09-04 14:40:18,205 - INFO - Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "2025-09-04 14:40:18,206 - INFO - Generating landmark text embeddings...\n",
            "Processing landmarks: 100%|██████████| 4495/4495 [00:00<00:00, 300179.86landmarks/s]\n",
            "2025-09-04 14:40:18,223 - INFO - Generated 4495 landmark text embeddings\n",
            "2025-09-04 14:40:18,225 - INFO - ✅ Generated 4495 landmark texts for embeddings\n",
            "2025-09-04 14:40:18,226 - INFO - ✅ First landmark text sample: San Francisco/Haight (&quot;Hippie Temptation&quot; house) in San Francisco, United States. Description: Site of the CBS documentary.. Address: 1550 Page St. Activity type: see. Type: landmark. State:...\n",
            "2025-09-04 14:40:18,226 - INFO - ✅ Data loading test completed successfully\n"
          ]
        }
      ],
      "source": [
        "def run_landmark_query(query: str, agent):\n",
        "    \"\"\"Run a single landmark query with error handling.\"\"\"\n",
        "    logger.info(f\"🏛️ Landmark Query: {query}\")\n",
        "    \n",
        "    try:\n",
        "        # Run the agent with LlamaIndex chat interface\n",
        "        response = agent.chat(query, chat_history=[])\n",
        "        result = response.response\n",
        "        \n",
        "        logger.info(f\"🤖 AI Response: {result}\")\n",
        "        logger.info(\"✅ Query completed successfully\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Query failed: {e}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def test_landmark_data_loading():\n",
        "    \"\"\"Test landmark data loading from travel-sample independently.\"\"\"\n",
        "    logger.info(\"Testing Landmark Data Loading from travel-sample\")\n",
        "    logger.info(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Import landmark data functions\n",
        "        # Use inline landmark data functions (already defined in this notebook)\n",
        "        # The functions get_landmark_count and get_landmark_texts are defined inline above\n",
        "        \n",
        "        # Test landmark count\n",
        "        count = get_landmark_count()\n",
        "        logger.info(f\"✅ Landmark count in travel-sample.inventory.landmark: {count}\")\n",
        "        \n",
        "        # Test landmark text generation\n",
        "        texts = get_landmark_texts()\n",
        "        logger.info(f\"✅ Generated {len(texts)} landmark texts for embeddings\")\n",
        "        \n",
        "        if texts:\n",
        "            logger.info(f\"✅ First landmark text sample: {texts[0][:200]}...\")\n",
        "        \n",
        "        logger.info(\"✅ Data loading test completed successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Data loading test failed: {e}\")\n",
        "\n",
        "\n",
        "# Test landmark data loading\n",
        "test_landmark_data_loading()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 1: Museums and Galleries in Glasgow\n",
        "\n",
        "Search for museums and galleries in Glasgow, Scotland.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:18,232 - INFO - 🏛️ Landmark Query: Find museums and galleries in Glasgow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step fc1640f2-0753-475f-914d-ffdca431c849. Step input: Find museums and galleries in Glasgow\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums and galleries in Glasgow', 'limit': 10}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:28,145 - INFO - Search query: 'museums and galleries in Glasgow' found 10 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 9 landmarks matching 'museums and galleries in Glasgow':\n",
            "\n",
            "1. **The Tron Theatre**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 63 Trongate.\n",
            "   📞 Phone: +44 141 552 4267.\n",
            "   🌐 Website: http://www.tron.co.uk/.\n",
            "   📝 Description: Specialises in contemporary works..\n",
            "\n",
            "2. **Kelvingrove Art Gallery and Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: Argyle Street.\n",
            "   📞 Phone: +44 141 276 9599.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/kelvingrove/.\n",
            "   🕒 Hours: M-Th, Sa 10AM-5PM; F, Su 11AM-5PM.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: Next door to the Kelvingrove Lawn Bowls Centre. The city's grandest public museum, with one of the finest civic collections in Europe housed within this Glasgow Victorian landmark. The collection is quite varied, with artworks, biological displays and anthropological artifacts. The museum as a whole is well-geared towards children and families and has a cafe..\n",
            "\n",
            "3. **Riverside Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 100 Pointhouse Place.\n",
            "   📞 Phone: +44 141 287 2720.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/riverside/.\n",
            "   🕒 Hours: M-Th and Sa 10:00-17:00, F and Su 11:00-17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: A recently reopened museum with an excellent collection of vehicles and models to tell the story of transport by land and sea, with a unique Glasgow flavour. Besides the usual rail locomotives, buses, trams, cars and planes, the museum also includes a recreated subway station and a street scene of old Glasgow. &lt;!--This museum is also listed on the [[Urban Rail]] page, please update there with any major changes. --&gt;.\n",
            "\n",
            "4. **Centre for Contemporary Arts**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 350 Sauchiehall Street.\n",
            "   📞 Phone: +44 141 352 4900.\n",
            "   🌐 Website: http://www.cca-glasgow.com/.\n",
            "   📝 Description: Shows films, though it's primarily an art gallery..\n",
            "\n",
            "6. **Glasgow Riverside Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 100 Pointhouse Place, [[Glasgow]], [[Scotland]] UK.\n",
            "   📞 Phone: +44 141 287 2720.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/riverside-museum/.\n",
            "   🕒 Hours: M-Th and Sa 10AM-5PM, F and Su 11AM-5PM.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: The museum includes a recreated subway station..\n",
            "\n",
            "7. **Burrell Collection**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 2060 Pollokshaws Rd, Pollok Country Park.\n",
            "   📞 Phone: +44 141 287 2550.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/burrell-collection/.\n",
            "   🕒 Hours: M-Th, Sa 10:00-17:00; F, Su 11:00-17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: This is a collection of over 9,000 artworks gifted to the city of Glasgow by Sir William Burrell and housed in a purpose-built museum in the Pollok Estate in the south of the city..\n",
            "\n",
            "8. **Annan Museum**\n",
            "   📍 Location: Annan, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: Bank Street, Annan.\n",
            "   📞 Phone: +44 1461 201384. Email: annan.museum@dumgal.gov.uk.\n",
            "   🌐 Website: http://www.annan.org.uk/museums_exhibitions/.\n",
            "   📝 Description: The Annan Museum houses a permanent exhibition on the history of Annan. This is a fascinating walk through time from the prehistoric period right up to the first world war with interactives and children’s activities..\n",
            "\n",
            "9. **Tenement House**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 145 Buccleuch Street.\n",
            "   📞 Phone: 0844 493 2197.\n",
            "   🌐 Website: http://www.nts.org.uk/Property/Tenement-House/.\n",
            "   🕒 Hours: Summer months only, Daily 1PM-5PM.\n",
            "   💰 Price: £6.50 adults, £16.50 family, £5 concessions.\n",
            "   📝 Description: A National Trust for Scotland site, a middle class Glasgow tenement house preserved in pretty much the way it was in the early 20th century..\n",
            "\n",
            "10. **Landmark**\n",
            "   📍 Location: Unknown City, Unknown Country\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 12 Rose St.\n",
            "   📞 Phone: +44 141 332-8128.\n",
            "   🌐 Website: http://www.gft.org.uk/.\n",
            "   📝 Description: Excellent choice of classics, as well as art and foreign-language movies..\n",
            "\u001b[0m> Running step 646f9316-8ba5-4658-84c9-fc6cc3b912dc. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:30,162 - INFO - 🤖 AI Response: There are several museums and galleries in Glasgow, including the Kelvingrove Art Gallery and Museum, the Riverside Museum, the Centre for Contemporary Arts, the Burrell Collection, and the Tenement House. These museums offer a range of exhibits and activities, including art, history, and interactive displays. Some of the museums are free to visit, while others may charge an admission fee.\n",
            "2025-09-04 14:40:30,163 - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are several museums and galleries in Glasgow, including the Kelvingrove Art Gallery and Museum, the Riverside Museum, the Centre for Contemporary Arts, the Burrell Collection, and the Tenement House. These museums offer a range of exhibits and activities, including art, history, and interactive displays. Some of the museums are free to visit, while others may charge an admission fee.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "result1 = run_landmark_query(\"Find museums and galleries in Glasgow\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 2: Museums in London\n",
        "\n",
        "Search for museums and cultural attractions in London, UK.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:30,170 - INFO - 🏛️ Landmark Query: Show me museums in London\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step b64560ea-170a-4c81-ab56-6649a41e2918. Step input: Show me museums in London\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums in London', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:40,023 - INFO - Search query: 'museums in London' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 4 landmarks matching 'museums in London':\n",
            "\n",
            "1. **London Transport Museum**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🌐 Website: http://www.ltmuseum.co.uk.\n",
            "   📝 Description: [[London]] (in [[London/Covent Garden|Covent Garden]]).\n",
            "\n",
            "2. **Clockmaker's Museum**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: Guildhall Library, Aldermanbury EC2P 2EJ.\n",
            "   📞 Phone: +44 20 7332-1868. Email: printedbooks.guildhall@corpoflondon.gov.uk.\n",
            "   🌐 Website: http://www.clockmakers.org/.\n",
            "   🕒 Hours: M–Sa 09:30–17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: Charts the history of clockmaking and houses a priceless collection of old timepieces..\n",
            "\n",
            "4. **575 Wandsworth Road**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 575 Wandsworth Road, Lambeth, London, London, SW8 3JD.\n",
            "   📞 Phone: +44 20 7720-9459. Email: 575wandsworthroad@nationaltrust.org.uk.\n",
            "   🌐 Website: http://www.nationaltrust.org.uk/575-wandsworth-road/.\n",
            "   📝 Description: Need to book in advance..\n",
            "\n",
            "5. **Tottenham Marsh**\n",
            "   📍 Location: London, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   📝 Description: Part of the Lea Valley Park, a natural habitat for many resident plants and animals..\n",
            "\u001b[0m> Running step d1f03c23-f5af-433c-8ed0-3eb665a64e24. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:41,970 - INFO - 🤖 AI Response: There are several museums in London that you might be interested in visiting. These include the London Transport Museum, the Clockmaker's Museum, and the National Trust's 575 Wandsworth Road. Each of these museums offers a unique perspective on history and culture, and they are all located in different parts of the city.\n",
            "2025-09-04 14:40:41,971 - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are several museums in London that you might be interested in visiting. These include the London Transport Museum, the Clockmaker's Museum, and the National Trust's 575 Wandsworth Road. Each of these museums offers a unique perspective on history and culture, and they are all located in different parts of the city.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "result2 = run_landmark_query(\"Show me museums in London\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "xml"
        }
      },
      "source": [
        "## Test 3: Parks in Paris\n",
        "\n",
        "Search for parks and outdoor spaces in Paris, France.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:41,976 - INFO - 🏛️ Landmark Query: What parks can I visit in Paris?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step cd76e66f-cb94-48e9-bafa-89633bacb69b. Step input: What parks can I visit in Paris?\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'parks in Paris', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:51,800 - INFO - Search query: 'parks in Paris' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'parks in Paris':\n",
            "\n",
            "1. **Parc André Malraux**\n",
            "   📍 Location: Nanterre, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: See.\n",
            "   📝 Description: The expansive, calm park around a lake extends westwards behind the Tours Aillaud, and is to La Defense quite what Central Park is to downtown Manhattan. You can take spectaular pictures of the La Defense skyline juxtaposted against the park's greenery from there..\n",
            "\n",
            "2. **Madeleine**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Listing.\n",
            "   📝 Description: (lines 8, 12 and 14).\n",
            "\n",
            "3. **Parc André Citroën**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France. Image: https://en.wikivoyage.org/wiki/File:Jardin André Citroën (PARIS,FR75) (3830986538).jpg.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 2, rue Cauchy.\n",
            "   🌐 Website: http://equipement.paris.fr/parc-andre-citroen-1791.\n",
            "   🕒 Hours: 08:00-17:45.\n",
            "   📝 Description: The large park occupies the 14 ha formerly occupied by a Citroën factory. Several gardens have specific themes, including water games. On sunny weekends or vacation days many people chill out or jog there..\n",
            "\n",
            "4. **Concorde**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Listing.\n",
            "   📝 Description: (lines 1, 8 and 12).\n",
            "\n",
            "5. **Musée en Herbe**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 21, rue Hérold.\n",
            "   📞 Phone: +33 1 40 67 97 66.\n",
            "   🌐 Website: http://www.musee-en-herbe.com.\n",
            "   🕒 Hours: Daily 10:00-19:00.\n",
            "   💰 Price: €4 for the exhibitions, €8 for the workshops.\n",
            "   📝 Description: The little brother of the original Musée en Herbe in the Bois de Boulogne, this museum is also geared to '''children'''. They have games and hands-on exhibits so won't have to supervise quite as closely as in other museums. Arts workshops are available as well, but you'll need to reserve a space in advance..\n",
            "\u001b[0m> Running step 331dffd2-3fb9-44f6-86bf-fa012f987874. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:53,431 - INFO - 🤖 AI Response: You can visit the following parks in Paris: Parc André Malraux, Parc André Citroën, and Musée en Herbe.\n",
            "2025-09-04 14:40:53,432 - INFO - ✅ Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: You can visit the following parks in Paris: Parc André Malraux, Parc André Citroën, and Musée en Herbe.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "result3 = run_landmark_query(\"What parks can I visit in Paris?\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Comprehensive Phoenix Evaluation System\n",
        "\n",
        "Complete Phoenix evaluation system from evals/eval_arize.py - inline for self-contained operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Phoenix evaluation system from evals/eval_arize.py\n",
        "import nest_asyncio\n",
        "import socket\n",
        "import subprocess\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Apply nest_asyncio to handle nested event loops in Jupyter/LlamaIndex\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "@dataclass\n",
        "class EvaluationConfig:\n",
        "    \"\"\"Configuration for the evaluation system.\"\"\"\n",
        "\n",
        "    # Arize Configuration\n",
        "    arize_space_id: str = os.getenv(\"ARIZE_SPACE_ID\", \"default-space\")\n",
        "    arize_api_key: str = os.getenv(\"ARIZE_API_KEY\", \"\")\n",
        "    project_name: str = \"landmark-search-agent-evaluation\"\n",
        "\n",
        "    # Phoenix Configuration\n",
        "    phoenix_base_port: int = 6006\n",
        "    phoenix_grpc_base_port: int = 4317\n",
        "    phoenix_max_port_attempts: int = 5\n",
        "\n",
        "    # Evaluation Configuration\n",
        "    evaluator_model: str = \"gpt-4o\"\n",
        "    max_queries: int = 10\n",
        "    evaluation_timeout: int = 300\n",
        "\n",
        "\n",
        "class PhoenixManager:\n",
        "    \"\"\"Manages Phoenix server lifecycle.\"\"\"\n",
        "\n",
        "    def __init__(self, config: EvaluationConfig):\n",
        "        self.config = config\n",
        "        self.session = None\n",
        "        self.active_port = None\n",
        "\n",
        "    def _is_port_in_use(self, port: int) -> bool:\n",
        "        \"\"\"Check if a port is in use.\"\"\"\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "            return s.connect_ex((\"localhost\", port)) == 0\n",
        "\n",
        "    def _kill_existing_phoenix_processes(self) -> None:\n",
        "        \"\"\"Kill any existing Phoenix processes.\"\"\"\n",
        "        try:\n",
        "            subprocess.run([\"pkill\", \"-f\", \"phoenix\"], check=False, capture_output=True)\n",
        "            time.sleep(2)  # Wait for processes to terminate\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"Error killing Phoenix processes: {e}\")\n",
        "\n",
        "    def _find_available_port(self) -> tuple[int, int]:\n",
        "        \"\"\"Find available ports for Phoenix.\"\"\"\n",
        "        phoenix_port = self.config.phoenix_base_port\n",
        "        grpc_port = self.config.phoenix_grpc_base_port\n",
        "\n",
        "        for _ in range(self.config.phoenix_max_port_attempts):\n",
        "            if not self._is_port_in_use(phoenix_port):\n",
        "                return phoenix_port, grpc_port\n",
        "            phoenix_port += 1\n",
        "            grpc_port += 1\n",
        "\n",
        "        raise RuntimeError(\n",
        "            f\"Could not find available ports after {self.config.phoenix_max_port_attempts} attempts\"\n",
        "        )\n",
        "\n",
        "    def start_phoenix(self) -> bool:\n",
        "        \"\"\"Start Phoenix server and return success status.\"\"\"\n",
        "        try:\n",
        "            import phoenix as px\n",
        "            from phoenix.otel import register\n",
        "            from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "            \n",
        "            logger.info(\"🔧 Setting up Phoenix observability...\")\n",
        "\n",
        "            # Clean up existing processes\n",
        "            self._kill_existing_phoenix_processes()\n",
        "\n",
        "            # Find available ports\n",
        "            phoenix_port, grpc_port = self._find_available_port()\n",
        "\n",
        "            # Set environment variables\n",
        "            os.environ[\"PHOENIX_PORT\"] = str(phoenix_port)\n",
        "            os.environ[\"PHOENIX_GRPC_PORT\"] = str(grpc_port)\n",
        "\n",
        "            # Start Phoenix session\n",
        "            self.session = px.launch_app()\n",
        "            self.active_port = phoenix_port\n",
        "\n",
        "            if self.session:\n",
        "                logger.info(f\"🌐 Phoenix UI: {self.session.url}\")\n",
        "\n",
        "            # Register Phoenix OTEL for LlamaIndex\n",
        "            register(\n",
        "                project_name=self.config.project_name,\n",
        "                endpoint=f\"http://localhost:{self.active_port}/v1/traces\",\n",
        "            )\n",
        "\n",
        "            # Instrument LlamaIndex specifically\n",
        "            LlamaIndexInstrumentor().instrument()\n",
        "\n",
        "            logger.info(\"✅ Phoenix setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Phoenix setup failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"Clean up Phoenix resources.\"\"\"\n",
        "        try:\n",
        "            if self.session:\n",
        "                # Phoenix session cleanup happens automatically\n",
        "                pass\n",
        "            logger.info(\"🔒 Phoenix cleanup completed\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error during Phoenix cleanup: {e}\")\n",
        "\n",
        "\n",
        "class LandmarkSearchEvaluator:\n",
        "    \"\"\"LlamaIndex-specific evaluator for the landmark search agent.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Optional[EvaluationConfig] = None):\n",
        "        \"\"\"Initialize the evaluator with configuration.\"\"\"\n",
        "        self.config = config or EvaluationConfig()\n",
        "        self.phoenix_manager = PhoenixManager(self.config)\n",
        "\n",
        "        # Agent components\n",
        "        self.agent = None\n",
        "        self.client = None\n",
        "\n",
        "        # Phoenix evaluators\n",
        "        self.evaluator_llm = None\n",
        "\n",
        "        # Add option to bypass Phoenix for debugging\n",
        "        try:\n",
        "            import phoenix as px\n",
        "            if not os.getenv(\"SKIP_PHOENIX\", \"false\").lower() == \"true\":\n",
        "                self._setup_phoenix_evaluators()\n",
        "            elif os.getenv(\"SKIP_PHOENIX\", \"false\").lower() == \"true\":\n",
        "                logger.info(\"🔧 Phoenix setup skipped due to SKIP_PHOENIX=true\")\n",
        "        except ImportError:\n",
        "            logger.warning(\"Phoenix not available - skipping Phoenix setup\")\n",
        "\n",
        "    def _setup_phoenix_evaluators(self) -> None:\n",
        "        \"\"\"Setup Phoenix evaluators for LLM-based evaluation.\"\"\"\n",
        "        try:\n",
        "            from phoenix.evals import OpenAIModel\n",
        "            \n",
        "            self.evaluator_llm = OpenAIModel(model=self.config.evaluator_model)\n",
        "            logger.info(\"✅ Phoenix evaluators initialized\")\n",
        "\n",
        "            # Start Phoenix\n",
        "            if self.phoenix_manager.start_phoenix():\n",
        "                logger.info(\"✅ Phoenix instrumentation enabled for LlamaIndex\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Phoenix evaluators setup failed: {e}\")\n",
        "            self.evaluator_llm = None\n",
        "\n",
        "    def setup_agent(self) -> bool:\n",
        "        \"\"\"Setup landmark search agent using the setup function.\"\"\"\n",
        "        try:\n",
        "            logger.info(\"🔧 Setting up landmark search agent...\")\n",
        "\n",
        "            self.agent, self.client = setup_landmark_agent()\n",
        "\n",
        "            logger.info(\"✅ Landmark search agent setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Error setting up landmark search agent: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _extract_response_content(self, result: Any) -> str:\n",
        "        \"\"\"Extract clean response content from LlamaIndex agent result.\"\"\"\n",
        "        try:\n",
        "            # Prefer explicit response field\n",
        "            if hasattr(result, \"response\"):\n",
        "                response_content = str(result.response).strip()\n",
        "                if response_content and not response_content.lower().startswith(\"error:\"):\n",
        "                    return response_content\n",
        "\n",
        "            # Some LlamaIndex results may carry a .message or .output\n",
        "            for attr in (\"message\", \"output\", \"final_response\"):\n",
        "                if hasattr(result, attr):\n",
        "                    text = str(getattr(result, attr)).strip()\n",
        "                    if text:\n",
        "                        return text\n",
        "\n",
        "            # Last resort fallback\n",
        "            text = str(result).strip()\n",
        "            return text if text else \"\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error extracting response content: {e}\")\n",
        "            return f\"Error extracting response: {e}\"\n",
        "\n",
        "    def run_single_evaluation(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"Run evaluation for a single query using LlamaIndex agent.\"\"\"\n",
        "        if not self.agent:\n",
        "            raise RuntimeError(\"Agent not initialized. Call setup_agent() first.\")\n",
        "\n",
        "        logger.info(f\"🔍 Evaluating query: {query}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Use LlamaIndex .chat() method\n",
        "            result = self.agent.chat(query, chat_history=[])\n",
        "\n",
        "            # Extract response content\n",
        "            response = self._extract_response_content(result)\n",
        "\n",
        "            # Create evaluation result\n",
        "            evaluation_result = {\n",
        "                \"query\": query,\n",
        "                \"response\": response,\n",
        "                \"execution_time\": time.time() - start_time,\n",
        "                \"success\": True,\n",
        "                \"sources\": [],\n",
        "                \"num_sources\": 0,\n",
        "            }\n",
        "\n",
        "            logger.info(f\"✅ Query completed in {evaluation_result['execution_time']:.2f}s\")\n",
        "\n",
        "            return evaluation_result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query failed: {e}\")\n",
        "            return {\n",
        "                \"query\": query,\n",
        "                \"response\": f\"Error: {str(e)}\",\n",
        "                \"execution_time\": time.time() - start_time,\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"sources\": [],\n",
        "                \"num_sources\": 0,\n",
        "            }\n",
        "\n",
        "    def run_phoenix_evaluations(self, results_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Run Phoenix evaluations on the results.\"\"\"\n",
        "        if not self.evaluator_llm:\n",
        "            logger.warning(\"⚠️ Phoenix evaluators not available - skipping LLM evaluations\")\n",
        "            return results_df\n",
        "\n",
        "        logger.info(f\"🧠 Running Phoenix evaluations on {len(results_df)} responses...\")\n",
        "\n",
        "        try:\n",
        "            from phoenix.evals import (\n",
        "                RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "                RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "                TOXICITY_PROMPT_TEMPLATE,\n",
        "                TOXICITY_PROMPT_RAILS_MAP,\n",
        "                llm_classify,\n",
        "            )\n",
        "            \n",
        "            # Prepare evaluation data\n",
        "            evaluation_data = []\n",
        "            for _, row in results_df.iterrows():\n",
        "                query = row[\"query\"]\n",
        "                response = row[\"response\"]\n",
        "\n",
        "                # Get reference answer for this query\n",
        "                reference = self._get_reference_answer(str(query))\n",
        "\n",
        "                evaluation_data.append(\n",
        "                    {\n",
        "                        \"input\": query,\n",
        "                        \"output\": response,\n",
        "                        \"reference\": reference,\n",
        "                        \"context\": \"Landmark search results\",\n",
        "                        \"text\": response,  # For toxicity evaluation\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            eval_df = pd.DataFrame(evaluation_data)\n",
        "\n",
        "            # Run individual Phoenix evaluations\n",
        "            self._run_individual_phoenix_evaluations(eval_df, results_df)\n",
        "\n",
        "            logger.info(\"✅ Phoenix evaluations completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Error running Phoenix evaluations: {e}\")\n",
        "            # Add error indicators\n",
        "            for eval_type in [\"relevance\", \"qa_correctness\", \"hallucination\", \"toxicity\"]:\n",
        "                results_df[eval_type] = \"error\"\n",
        "                results_df[f\"{eval_type}_explanation\"] = f\"Error: {e}\"\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _get_reference_answer(self, query: str) -> str:\n",
        "        \"\"\"Get reference answer for evaluation.\"\"\"\n",
        "        try:\n",
        "            reference_answer = get_reference_answer(query)\n",
        "\n",
        "            if reference_answer.startswith(\"No reference answer available\"):\n",
        "                # Create a basic reference based on query\n",
        "                if \"museum\" in query.lower() or \"gallery\" in query.lower():\n",
        "                    return \"Should provide information about museums and galleries with accurate names, addresses, and descriptions.\"\n",
        "                elif \"restaurant\" in query.lower() or \"food\" in query.lower():\n",
        "                    return \"Should provide information about restaurants and food establishments.\"\n",
        "                else:\n",
        "                    return \"Should provide relevant and accurate landmark information.\"\n",
        "\n",
        "            return reference_answer\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not get reference answer for '{query}': {e}\")\n",
        "            return \"Should provide relevant and accurate landmark information.\"\n",
        "\n",
        "    def _run_individual_phoenix_evaluations(\n",
        "        self, eval_df: pd.DataFrame, results_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"Run individual Phoenix evaluations.\"\"\"\n",
        "        evaluations = {\n",
        "            \"relevance\": {\n",
        "                \"template\": RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "                \"rails\": list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "                \"data_cols\": [\"input\", \"reference\"],\n",
        "            },\n",
        "            \"qa_correctness\": {\n",
        "                \"template\": LENIENT_QA_PROMPT_TEMPLATE,\n",
        "                \"rails\": LENIENT_QA_RAILS,\n",
        "                \"data_cols\": [\"input\", \"output\", \"reference\"],\n",
        "            },\n",
        "            \"hallucination\": {\n",
        "                \"template\": LENIENT_HALLUCINATION_PROMPT_TEMPLATE,\n",
        "                \"rails\": LENIENT_HALLUCINATION_RAILS,\n",
        "                \"data_cols\": [\"input\", \"reference\", \"output\"],\n",
        "            },\n",
        "            \"toxicity\": {\n",
        "                \"template\": TOXICITY_PROMPT_TEMPLATE,\n",
        "                \"rails\": list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "                \"data_cols\": [\"input\"],\n",
        "            },\n",
        "        }\n",
        "\n",
        "        for eval_name, eval_config in evaluations.items():\n",
        "            try:\n",
        "                logger.info(f\"   📊 Running {eval_name} evaluation...\")\n",
        "\n",
        "                # Prepare data for this evaluator\n",
        "                data = eval_df[eval_config[\"data_cols\"]].copy()\n",
        "\n",
        "                # Run evaluation\n",
        "                eval_results = llm_classify(\n",
        "                    data=data,\n",
        "                    model=self.evaluator_llm,\n",
        "                    template=eval_config[\"template\"],\n",
        "                    rails=eval_config[\"rails\"],\n",
        "                    provide_explanation=True,\n",
        "                )\n",
        "\n",
        "                # Process results\n",
        "                self._process_evaluation_results(eval_results, eval_name, results_df)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ {eval_name} evaluation failed: {e}\")\n",
        "                results_df[eval_name] = \"error\"\n",
        "                results_df[f\"{eval_name}_explanation\"] = f\"Error: {e}\"\n",
        "\n",
        "    def _process_evaluation_results(\n",
        "        self, eval_results: Any, eval_name: str, results_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"Process evaluation results and add to results DataFrame.\"\"\"\n",
        "        try:\n",
        "            if eval_results is None:\n",
        "                logger.warning(f\"⚠️ {eval_name} evaluation returned None\")\n",
        "                results_df[eval_name] = \"unknown\"\n",
        "                results_df[f\"{eval_name}_explanation\"] = \"Evaluation returned None\"\n",
        "                return\n",
        "\n",
        "            # Handle DataFrame results (most common case)\n",
        "            if hasattr(eval_results, \"columns\"):\n",
        "                if \"label\" in eval_results.columns:\n",
        "                    results_df[eval_name] = eval_results[\"label\"].tolist()\n",
        "                elif \"classification\" in eval_results.columns:\n",
        "                    results_df[eval_name] = eval_results[\"classification\"].tolist()\n",
        "                else:\n",
        "                    results_df[eval_name] = \"unknown\"\n",
        "\n",
        "                if \"explanation\" in eval_results.columns:\n",
        "                    results_df[f\"{eval_name}_explanation\"] = eval_results[\"explanation\"].tolist()\n",
        "                else:\n",
        "                    results_df[f\"{eval_name}_explanation\"] = \"No explanation provided\"\n",
        "\n",
        "                logger.info(f\"   ✅ {eval_name} evaluation completed\")\n",
        "\n",
        "            else:\n",
        "                logger.warning(f\"⚠️ {eval_name} evaluation returned unexpected format\")\n",
        "                results_df[eval_name] = \"unknown\"\n",
        "                results_df[f\"{eval_name}_explanation\"] = f\"Unexpected format: {type(eval_results)}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error processing {eval_name} results: {e}\")\n",
        "            results_df[eval_name] = \"error\"\n",
        "            results_df[f\"{eval_name}_explanation\"] = f\"Processing error: {e}\"\n",
        "\n",
        "    def run_evaluation(self, queries: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Run complete evaluation pipeline.\"\"\"\n",
        "        if not self.setup_agent():\n",
        "            raise RuntimeError(\"Failed to setup agent\")\n",
        "\n",
        "        # Limit queries if specified\n",
        "        if len(queries) > self.config.max_queries:\n",
        "            queries = queries[: self.config.max_queries]\n",
        "            logger.info(f\"Limited to {self.config.max_queries} queries for evaluation\")\n",
        "\n",
        "        logger.info(\n",
        "            f\"🚀 Starting LlamaIndex landmark search evaluation with {len(queries)} queries\"\n",
        "        )\n",
        "\n",
        "        # Run queries\n",
        "        results = []\n",
        "        for i, query in enumerate(queries, 1):\n",
        "            logger.info(f\"\\n📋 Query {i}/{len(queries)}\")\n",
        "            result = self.run_single_evaluation(query)\n",
        "            results.append(result)\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Run Phoenix evaluations\n",
        "        results_df = self.run_phoenix_evaluations(results_df)\n",
        "\n",
        "        # Log summary\n",
        "        self._log_evaluation_summary(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _log_evaluation_summary(self, results_df: pd.DataFrame) -> None:\n",
        "        \"\"\"Log evaluation summary.\"\"\"\n",
        "        logger.info(\"\\n📊 Evaluation Summary:\")\n",
        "        logger.info(f\"  Total queries: {len(results_df)}\")\n",
        "        logger.info(f\"  Successful executions: {results_df['success'].sum()}\")\n",
        "        logger.info(f\"  Failed executions: {(~results_df['success']).sum()}\")\n",
        "        logger.info(f\"  Average execution time: {results_df['execution_time'].mean():.2f}s\")\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"Clean up all resources.\"\"\"\n",
        "        self.phoenix_manager.cleanup()\n",
        "\n",
        "\n",
        "def get_default_queries() -> List[str]:\n",
        "    \"\"\"Get default test queries for evaluation.\"\"\"\n",
        "    return get_queries_for_evaluation(limit=10)\n",
        "\n",
        "\n",
        "def run_comprehensive_evaluation() -> pd.DataFrame:\n",
        "    \"\"\"Run comprehensive evaluation with all Phoenix evaluators.\"\"\"\n",
        "    evaluator = LandmarkSearchEvaluator()\n",
        "    try:\n",
        "        queries = get_default_queries()\n",
        "        results = evaluator.run_evaluation(queries)\n",
        "        logger.info(\"\\n✅ Comprehensive landmark search evaluation complete!\")\n",
        "        return results\n",
        "    finally:\n",
        "        evaluator.cleanup()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Arize Phoenix Evaluation\n",
        "\n",
        "This section demonstrates how to evaluate the landmark search agent using Arize Phoenix observability platform. The evaluation includes:\n",
        "\n",
        "- **Relevance Scoring**: Using Phoenix RelevanceEvaluator to score how relevant responses are to queries\n",
        "- **QA Scoring**: Using Phoenix QAEvaluator to score answer quality\n",
        "- **Hallucination Detection**: Using Phoenix HallucinationEvaluator to detect fabricated information  \n",
        "- **Toxicity Detection**: Using Phoenix ToxicityEvaluator to detect harmful content\n",
        "- **Phoenix UI**: Real-time observability dashboard at `http://localhost:6006/`\n",
        "\n",
        "We'll run landmark search queries and evaluate the responses for quality and safety using LlamaIndex instrumentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:53,528 - INFO - 📋 Ensuring phoenix working directory: /home/kaustav/.phoenix\n",
            "2025-09-04 14:40:53,545 - INFO - Dataset: phoenix_inferences_fa6240d7-84c6-414a-8d1d-db376ddca6f5 initialized\n",
            "2025-09-04 14:40:54,760 - INFO - ✅ Arize Phoenix evaluation components available\n",
            "2025-09-04 14:40:54,761 - INFO - 📋 Ensuring phoenix working directory: /home/kaustav/.phoenix\n",
            "2025-09-04 14:40:54,816 - INFO - Context impl SQLiteImpl.\n",
            "2025-09-04 14:40:54,816 - INFO - Will assume transactional DDL.\n",
            "2025-09-04 14:40:54,854 - INFO - Running upgrade  -> cf03bd6bae1d, init\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗️ The launch_app `port` parameter is deprecated and will be removed in a future release. Use the `PHOENIX_PORT` environment variable instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:40:55,414 - INFO - Running upgrade cf03bd6bae1d -> 10460e46d750, datasets\n",
            "2025-09-04 14:40:55,745 - INFO - Running upgrade 10460e46d750 -> 3be8647b87d8, add token columns to spans table\n",
            "2025-09-04 14:40:55,747 - INFO - Running upgrade 3be8647b87d8 -> cd164e83824f, users and tokens\n",
            "2025-09-04 14:40:55,754 - INFO - Running upgrade cd164e83824f -> 4ded9e43755f, create project_session table\n",
            "2025-09-04 14:40:55,764 - INFO - Running upgrade 4ded9e43755f -> bc8fea3c2bc8, Add prompt tables\n",
            "2025-09-04 14:40:55,770 - INFO - Running upgrade bc8fea3c2bc8 -> 2f9d1a65945f, Annotation config migrations\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n",
            "2025-09-04 14:40:55,855 - INFO - Running upgrade 2f9d1a65945f -> bb8139330879, create project trace retention policies table\n",
            "2025-09-04 14:40:55,861 - INFO - Running upgrade bb8139330879 -> 8a3764fe7f1a, change jsonb to json for prompts\n",
            "2025-09-04 14:40:55,872 - INFO - Running upgrade 8a3764fe7f1a -> 6a88424799fe, Add auth_method column to users table and migrate existing authentication data.\n",
            "2025-09-04 14:40:55,880 - INFO - Running upgrade 6a88424799fe -> a20694b15f82, Cost-related tables\n",
            "2025-09-04 14:40:55,916 - INFO - Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n",
            "2025-09-04 14:40:56,193 - INFO - 🚀 Phoenix UI available at http://localhost:6006/\n",
            "2025-09-04 14:40:56,247 - INFO - ✅ LlamaIndex instrumentation enabled\n",
            "2025-09-04 14:40:56,247 - INFO - 🔍 Running evaluation query 1: Find museums and galleries in Glasgow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "🔭 OpenTelemetry Tracing Details 🔭\n",
            "|  Phoenix Project: landmark-search-agent-evaluation\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ⚠️ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n",
            "> Running step 3bc0a245-e78e-4ab8-82aa-94a07aff980b. Step input: Find museums and galleries in Glasgow\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums and galleries in Glasgow', 'limit': 10}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:05,430 - INFO - Search query: 'museums and galleries in Glasgow' found 10 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 9 landmarks matching 'museums and galleries in Glasgow':\n",
            "\n",
            "1. **The Tron Theatre**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 63 Trongate.\n",
            "   📞 Phone: +44 141 552 4267.\n",
            "   🌐 Website: http://www.tron.co.uk/.\n",
            "   📝 Description: Specialises in contemporary works..\n",
            "\n",
            "2. **Kelvingrove Art Gallery and Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: Argyle Street.\n",
            "   📞 Phone: +44 141 276 9599.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/kelvingrove/.\n",
            "   🕒 Hours: M-Th, Sa 10AM-5PM; F, Su 11AM-5PM.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: Next door to the Kelvingrove Lawn Bowls Centre. The city's grandest public museum, with one of the finest civic collections in Europe housed within this Glasgow Victorian landmark. The collection is quite varied, with artworks, biological displays and anthropological artifacts. The museum as a whole is well-geared towards children and families and has a cafe..\n",
            "\n",
            "3. **Riverside Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 100 Pointhouse Place.\n",
            "   📞 Phone: +44 141 287 2720.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/riverside/.\n",
            "   🕒 Hours: M-Th and Sa 10:00-17:00, F and Su 11:00-17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: A recently reopened museum with an excellent collection of vehicles and models to tell the story of transport by land and sea, with a unique Glasgow flavour. Besides the usual rail locomotives, buses, trams, cars and planes, the museum also includes a recreated subway station and a street scene of old Glasgow. &lt;!--This museum is also listed on the [[Urban Rail]] page, please update there with any major changes. --&gt;.\n",
            "\n",
            "4. **Centre for Contemporary Arts**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 350 Sauchiehall Street.\n",
            "   📞 Phone: +44 141 352 4900.\n",
            "   🌐 Website: http://www.cca-glasgow.com/.\n",
            "   📝 Description: Shows films, though it's primarily an art gallery..\n",
            "\n",
            "6. **Glasgow Riverside Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 100 Pointhouse Place, [[Glasgow]], [[Scotland]] UK.\n",
            "   📞 Phone: +44 141 287 2720.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/riverside-museum/.\n",
            "   🕒 Hours: M-Th and Sa 10AM-5PM, F and Su 11AM-5PM.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: The museum includes a recreated subway station..\n",
            "\n",
            "7. **Burrell Collection**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 2060 Pollokshaws Rd, Pollok Country Park.\n",
            "   📞 Phone: +44 141 287 2550.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/burrell-collection/.\n",
            "   🕒 Hours: M-Th, Sa 10:00-17:00; F, Su 11:00-17:00.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: This is a collection of over 9,000 artworks gifted to the city of Glasgow by Sir William Burrell and housed in a purpose-built museum in the Pollok Estate in the south of the city..\n",
            "\n",
            "8. **Annan Museum**\n",
            "   📍 Location: Annan, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: Bank Street, Annan.\n",
            "   📞 Phone: +44 1461 201384. Email: annan.museum@dumgal.gov.uk.\n",
            "   🌐 Website: http://www.annan.org.uk/museums_exhibitions/.\n",
            "   📝 Description: The Annan Museum houses a permanent exhibition on the history of Annan. This is a fascinating walk through time from the prehistoric period right up to the first world war with interactives and children’s activities..\n",
            "\n",
            "9. **Tenement House**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 145 Buccleuch Street.\n",
            "   📞 Phone: 0844 493 2197.\n",
            "   🌐 Website: http://www.nts.org.uk/Property/Tenement-House/.\n",
            "   🕒 Hours: Summer months only, Daily 1PM-5PM.\n",
            "   💰 Price: £6.50 adults, £16.50 family, £5 concessions.\n",
            "   📝 Description: A National Trust for Scotland site, a middle class Glasgow tenement house preserved in pretty much the way it was in the early 20th century..\n",
            "\n",
            "10. **Landmark**\n",
            "   📍 Location: Unknown City, Unknown Country\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 12 Rose St.\n",
            "   📞 Phone: +44 141 332-8128.\n",
            "   🌐 Website: http://www.gft.org.uk/.\n",
            "   📝 Description: Excellent choice of classics, as well as art and foreign-language movies..\n",
            "\u001b[0m> Running step 4be53e96-2742-477f-b7d0-71e8beaff379. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:07,507 - INFO - ✅ Query 1 completed successfully\n",
            "2025-09-04 14:41:07,508 - INFO - 🔍 Running evaluation query 2: Show me restaurants serving Asian cuisine\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are several museums and galleries in Glasgow, including the Kelvingrove Art Gallery and Museum, the Riverside Museum, the Centre for Contemporary Arts, the Burrell Collection, and the Tenement House. These museums offer a range of exhibits and activities, including art, history, and interactive displays. Some of the museums are free to visit, while others may charge an admission fee.\n",
            "\u001b[0m> Running step 4f2d7449-c64f-48db-b697-2dfe8b4e4a1d. Step input: Show me restaurants serving Asian cuisine\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Asian cuisine restaurants', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:16,694 - INFO - Search query: 'Asian cuisine restaurants' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Asian cuisine restaurants':\n",
            "\n",
            "1. **New Canton**\n",
            "   📍 Location: Whittier, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 13015 Philadelphia St, Whittier, CA 90601.\n",
            "   📞 Phone: +1 562 698-7315.\n",
            "   🌐 Website: http://www.newcantonchineserestaurant.com/.\n",
            "   📝 Description: A Chinese restaurant.\n",
            "\n",
            "2. **World Curry**\n",
            "   📍 Location: San Diego, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 1433 Garnet Ave.\n",
            "   🌐 Website: http://www.worldcurry.com/.\n",
            "   📝 Description: Great variety of world curries and great happy hour beverage deals..\n",
            "\n",
            "3. **So Asia**\n",
            "   📍 Location: Camberley, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 69 High St.\n",
            "   📞 Phone: +44 1276 29078.\n",
            "   🌐 Website: http://www.soasia.co.uk/.\n",
            "   📝 Description: Eat as much as you like buffet style restaurant with an excellent choice of Chinese, Thai and Indian foods..\n",
            "\n",
            "4. **Old Thai House**\n",
            "   📍 Location: Camberley, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 125 London Road.\n",
            "   📞 Phone: +44 1276 21212.\n",
            "   🌐 Website: http://oldthaihouse.com/.\n",
            "   📝 Description: Traditional inexpensive Thai food..\n",
            "\n",
            "5. **La Perle d'Asie**\n",
            "   📍 Location: Carpentras, France\n",
            "   🗺️ State: Provence-Alpes-Côte d'Azur.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 65 pl 25 août 1944.\n",
            "   📞 Phone: +33 4 90 60 73 37.\n",
            "   💰 Price: 15 € - 20 €.\n",
            "   📝 Description: Asian restaurant.\n",
            "\u001b[0m> Running step b0eff30f-526c-40f6-906b-0479a3a43220. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:20,009 - INFO - ✅ Query 2 completed successfully\n",
            "2025-09-04 14:41:20,010 - INFO - 🔍 Running evaluation query 3: What attractions can I see in Glasgow?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: Here are 5 restaurants serving Asian cuisine: New Canton, World Curry, So Asia, Old Thai House, and La Perle d'Asie.\n",
            "\u001b[0m> Running step f2153f02-3a51-4a47-b5c1-31351047caa7. Step input: What attractions can I see in Glasgow?\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Glasgow attractions', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:29,186 - INFO - Search query: 'Glasgow attractions' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Glasgow attractions':\n",
            "\n",
            "1. **The Tron Theatre**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: Do.\n",
            "   🏠 Address: 63 Trongate.\n",
            "   📞 Phone: +44 141 552 4267.\n",
            "   🌐 Website: http://www.tron.co.uk/.\n",
            "   📝 Description: Specialises in contemporary works..\n",
            "\n",
            "2. **'The Argyll Arms Hotel**\n",
            "   📍 Location: Argyll and Bute, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   📝 Description: serves fresh food at very reasonable prices - view of stoney beach with herons.\n",
            "\n",
            "3. **The Henry Bell**\n",
            "   📍 Location: Helensburgh, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 19/29 James Street.\n",
            "   📝 Description: G84 8AS. Wetherspoon pub..\n",
            "\n",
            "4. **Glasgow Riverside Museum**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 100 Pointhouse Place, [[Glasgow]], [[Scotland]] UK.\n",
            "   📞 Phone: +44 141 287 2720.\n",
            "   🌐 Website: http://www.glasgowlife.org.uk/museums/riverside-museum/.\n",
            "   🕒 Hours: M-Th and Sa 10AM-5PM, F and Su 11AM-5PM.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: The museum includes a recreated subway station..\n",
            "\n",
            "5. **Clyde Arc**\n",
            "   📍 Location: Glasgow, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   📝 Description: A relatively new and prominent bridge over the River Clyde that has an elegant curved design and is unique for how it crosses the river at an angle..\n",
            "\u001b[0m> Running step 100d48ca-a50a-4342-9c76-7eeee6a35c3b. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:31,370 - INFO - ✅ Query 3 completed successfully\n",
            "2025-09-04 14:41:31,371 - INFO - 🔍 Running evaluation query 4: Tell me about Monet's House\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are several attractions you can see in Glasgow, including The Tron Theatre, Glasgow Riverside Museum, and the Clyde Arc. The Tron Theatre is a contemporary theatre that hosts various performances and events. The Glasgow Riverside Museum is a museum that showcases the city's rich history and culture, and it includes a recreated subway station. The Clyde Arc is a unique and elegant bridge that crosses the River Clyde at an angle.\n",
            "\u001b[0m> Running step e891922c-88f0-4a62-97e8-e4da70bea1e5. Step input: Tell me about Monet's House\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': \"Monet's House\", 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:40,655 - INFO - Search query: 'Monet's House' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Monet's House':\n",
            "\n",
            "1. **Monet's House**\n",
            "   📍 Location: Giverny, France\n",
            "   🗺️ State: Haute-Normandie. Alternative name: Fondation Claude Monet.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 84 rue Claude Monet.\n",
            "   📞 Phone: +33 232512821.\n",
            "   🌐 Website: http://www.fondation-monet.com/.\n",
            "   🕒 Hours: open April-October Mo-Su 9:30-18:00.\n",
            "   💰 Price: €9, $5 students, €4 4.00 disabled, under-7s free.\n",
            "   📝 Description: the house is quietly eccentric and highly interesting in an Orient-influenced style, and includes Monet's collection of [http://www.intermonet.com/japan/ Japanese prints]. There are no original Monet paintings on the site - the real drawcard, is the gardens around the house - the [http://giverny-impression.com/category/water-garden/ water garden] with the [http://www.intermonet.com/oeuvre/pontjapo.htm Japanese bridge], [http://giverny-impression.com/tag/weeping-willow/ weeping willows] and [http://giverny-impression.com/tag/water-lily/ waterlilies] is now somewhat iconic. Monet's house has the obligatory gift-store attached, designed to help you part with your money in exchange for all manner of things Impressionist. [http://giverny.org/gardens/fcm/ticket/ e-tickets] can now be purchased o..\n",
            "\n",
            "2. **La Gare**\n",
            "   📍 Location: Santa Rosa, United States\n",
            "   🗺️ State: California.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 208 Wilson Street.\n",
            "   📞 Phone: +1 707-528-4355.\n",
            "   🌐 Website: http://www.lagarerestaurant.com/.\n",
            "   📝 Description: French/Swiss cuisine. Local favorite..\n",
            "\n",
            "3. **Musée Marmottan**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: See.\n",
            "   🏠 Address: 2 rue Louis-Boilly, 16th.\n",
            "   📞 Phone: +33 1 44 96 50 33.\n",
            "   🌐 Website: http://www.marmottan.com.\n",
            "   🕒 Hours: 11am-9pm Tues; 11am-6pm Wed-Sun. Last entry 30 min before closing.\n",
            "   📝 Description: Monet's best works are in this charming museum, which contains the largest Monet collection in the world as well as works by Renoir, Manet, Berthe, Caillebotte and Gauguin..\n",
            "\n",
            "4. **Hanawa**\n",
            "   📍 Location: Paris, France\n",
            "   🗺️ State: Île-de-France.\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 26, rue Bayard.\n",
            "   📞 Phone: +33 1 56 62 70 70.\n",
            "   📝 Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\n",
            "5. **Kymin**\n",
            "   📍 Location: Monmouthshire, United Kingdom\n",
            "   🎯 Activity: See.\n",
            "   💰 Price: Free.\n",
            "   📝 Description: Impressive view of Monmouth and the surrounding countryside..\n",
            "\u001b[0m> Running step f195cdf4-d8ab-4798-83c7-9e1fc532c2c9. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:42,692 - INFO - ✅ Query 4 completed successfully\n",
            "2025-09-04 14:41:42,693 - INFO - 🔍 Running evaluation query 5: Find places to eat in Gillingham\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: The landmark you are referring to is likely the house of Claude Monet in Giverny, France. It is a museum that showcases Monet's collection of Japanese prints and features his famous gardens, including the water garden with a Japanese bridge, weeping willows, and waterlilies. The house is a must-visit for any art lover or fan of Impressionism.\n",
            "\u001b[0m> Running step c1d31130-4d52-4032-8d83-f23da8ee3cbc. Step input: Find places to eat in Gillingham\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'places to eat in Gillingham', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:52,329 - INFO - Search query: 'places to eat in Gillingham' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'places to eat in Gillingham':\n",
            "\n",
            "1. **Beijing Inn**\n",
            "   📍 Location: Gillingham, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 3 King Street, ME6 1EY.\n",
            "   🌐 Website: http://beijinginn.co.uk/div/.\n",
            "   📝 Description: Chinese restaurant just off the High Street..\n",
            "\n",
            "2. **Ossie's Fish and Chips**\n",
            "   📍 Location: Gillingham, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 75 Richmond Road, ME7 1LS.\n",
            "   📞 Phone: +44 1634 582000.\n",
            "   📝 Description: Best fish and chips in the area..\n",
            "\n",
            "3. **The Bridge Brasserie**\n",
            "   📍 Location: Chippenham, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 29 New Road, Chippenham SN15 1HZ.\n",
            "   📞 Phone: +44 1249 444552.\n",
            "   🌐 Website: http://thebridgebrasserie.co.uk.\n",
            "   📝 Description: Casual fine dining and great cocktails, a seasonal à la carte menu, and free WiFi.\n",
            "\n",
            "4. **Saffron**\n",
            "   📍 Location: Bedford, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 64 Tavistock St, MK40 2RG.\n",
            "   📞 Phone: +44 1234 325655.\n",
            "   📝 Description: Does a superb and cheap Sunday lunch buffet..\n",
            "\n",
            "5. **Ashbourne Fishbar**\n",
            "   📍 Location: Ashbourne, United Kingdom\n",
            "   🎯 Activity: Eat.\n",
            "   🏠 Address: 9 Compton.\n",
            "   📞 Phone: +44 1335 345700.\n",
            "   📝 Description: Eat in or takeout fish and chips..\n",
            "\u001b[0m> Running step f3743d0b-4094-4c60-a96f-69f26b65f722. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:54,202 - INFO - ✅ Query 5 completed successfully\n",
            "2025-09-04 14:41:54,203 - INFO - 📊 Collected 5 responses for evaluation\n",
            "2025-09-04 14:41:54,204 - INFO - Query: Find museums and galleries in Glasgow\n",
            "2025-09-04 14:41:54,205 - INFO - Response: There are several museums and galleries in Glasgow, including the Kelvingrove Art Gallery and Museum, the Riverside Museum, the Centre for Contemporary Arts, the Burrell Collection, and the Tenement H...\n",
            "2025-09-04 14:41:54,206 - INFO - Success: True\n",
            "2025-09-04 14:41:54,206 - INFO - --------------------------------------------------\n",
            "2025-09-04 14:41:54,207 - INFO - Query: Show me restaurants serving Asian cuisine\n",
            "2025-09-04 14:41:54,207 - INFO - Response: Here are 5 restaurants serving Asian cuisine: New Canton, World Curry, So Asia, Old Thai House, and La Perle d'Asie....\n",
            "2025-09-04 14:41:54,207 - INFO - Success: True\n",
            "2025-09-04 14:41:54,207 - INFO - --------------------------------------------------\n",
            "2025-09-04 14:41:54,208 - INFO - Query: What attractions can I see in Glasgow?\n",
            "2025-09-04 14:41:54,208 - INFO - Response: There are several attractions you can see in Glasgow, including The Tron Theatre, Glasgow Riverside Museum, and the Clyde Arc. The Tron Theatre is a contemporary theatre that hosts various performance...\n",
            "2025-09-04 14:41:54,208 - INFO - Success: True\n",
            "2025-09-04 14:41:54,209 - INFO - --------------------------------------------------\n",
            "2025-09-04 14:41:54,209 - INFO - Query: Tell me about Monet's House\n",
            "2025-09-04 14:41:54,209 - INFO - Response: The landmark you are referring to is likely the house of Claude Monet in Giverny, France. It is a museum that showcases Monet's collection of Japanese prints and features his famous gardens, including...\n",
            "2025-09-04 14:41:54,210 - INFO - Success: True\n",
            "2025-09-04 14:41:54,210 - INFO - --------------------------------------------------\n",
            "2025-09-04 14:41:54,211 - INFO - Query: Find places to eat in Gillingham\n",
            "2025-09-04 14:41:54,211 - INFO - Response: Based on the search results, here are some places to eat in Gillingham: Beijing Inn, Ossie's Fish and Chips, and The Bridge Brasserie is not in Gillingham but in Chippenham....\n",
            "2025-09-04 14:41:54,212 - INFO - Success: True\n",
            "2025-09-04 14:41:54,212 - INFO - --------------------------------------------------\n",
            "2025-09-04 14:41:54,212 - INFO - 💡 Visit Phoenix UI at http://localhost:6006/ to see detailed traces and evaluations\n",
            "2025-09-04 14:41:54,212 - INFO - 💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: Based on the search results, here are some places to eat in Gillingham: Beijing Inn, Ossie's Fish and Chips, and The Bridge Brasserie is not in Gillingham but in Chippenham.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Import Phoenix evaluation components\n",
        "try:\n",
        "    import phoenix as px\n",
        "    from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "    from phoenix.evals import (\n",
        "        HALLUCINATION_PROMPT_RAILS_MAP,\n",
        "        HALLUCINATION_PROMPT_TEMPLATE,\n",
        "        QA_PROMPT_RAILS_MAP,\n",
        "        QA_PROMPT_TEMPLATE,\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        OpenAIModel,\n",
        "        llm_classify,\n",
        "    )\n",
        "    from phoenix.otel import register\n",
        "    import pandas as pd\n",
        "    \n",
        "    ARIZE_AVAILABLE = True\n",
        "    logger.info(\"✅ Arize Phoenix evaluation components available\")\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Arize dependencies not available: {e}\")\n",
        "    logger.warning(\"Skipping evaluation section...\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "if ARIZE_AVAILABLE:\n",
        "    # Start Phoenix session for observability\n",
        "    try:\n",
        "        px.launch_app(port=6006)\n",
        "        logger.info(\"🚀 Phoenix UI available at http://localhost:6006/\")\n",
        "        \n",
        "        # Register LlamaIndex instrumentation\n",
        "        tracer_provider = register(\n",
        "            project_name=\"landmark-search-agent-evaluation\",\n",
        "            endpoint=\"http://localhost:6006/v1/traces\"\n",
        "        )\n",
        "        \n",
        "        # Instrument LlamaIndex\n",
        "        LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "        logger.info(\"✅ LlamaIndex instrumentation enabled\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not start Phoenix UI: {e}\")\n",
        "\n",
        "    # Demo queries for evaluation\n",
        "    landmark_demo_queries = [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"Show me restaurants serving Asian cuisine\", \n",
        "        \"What attractions can I see in Glasgow?\",\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"Find places to eat in Gillingham\"\n",
        "    ]\n",
        "    \n",
        "    # Run demo queries and collect responses for evaluation\n",
        "    landmark_demo_results = []\n",
        "    \n",
        "    for i, query in enumerate(landmark_demo_queries, 1):\n",
        "        try:\n",
        "            logger.info(f\"🔍 Running evaluation query {i}: {query}\")\n",
        "            \n",
        "            # Run the agent with LlamaIndex\n",
        "            response = agent.chat(query, chat_history=[])\n",
        "            output = response.response\n",
        "    \n",
        "            landmark_demo_results.append({\n",
        "                \"query\": query,\n",
        "                \"response\": output,\n",
        "                \"query_type\": f\"landmark_demo_{i}\",\n",
        "                \"success\": True\n",
        "            })\n",
        "            \n",
        "            logger.info(f\"✅ Query {i} completed successfully\")\n",
        "    \n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query {i} failed: {e}\")\n",
        "            landmark_demo_results.append({\n",
        "                \"query\": query,\n",
        "                \"response\": f\"Error: {e!s}\",\n",
        "                \"query_type\": f\"landmark_demo_{i}\",\n",
        "                \"success\": False\n",
        "            })\n",
        "    \n",
        "    # Convert to DataFrame for evaluation\n",
        "    landmark_results_df = pd.DataFrame(landmark_demo_results)\n",
        "    logger.info(f\"📊 Collected {len(landmark_results_df)} responses for evaluation\")\n",
        "    \n",
        "    # Display results summary\n",
        "    for _, row in landmark_results_df.iterrows():\n",
        "        logger.info(f\"Query: {row['query']}\")\n",
        "        logger.info(f\"Response: {row['response'][:200]}...\")\n",
        "        logger.info(f\"Success: {row['success']}\")\n",
        "        logger.info(\"-\" * 50)\n",
        "    \n",
        "    logger.info(\"💡 Visit Phoenix UI at http://localhost:6006/ to see detailed traces and evaluations\")\n",
        "    logger.info(\"💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\")\n",
        "\n",
        "else:\n",
        "    logger.info(\"Arize evaluation not available - install phoenix-evals to enable evaluation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:54,229 - INFO - 🔍 Running comprehensive Phoenix evaluations...\n",
            "2025-09-04 14:41:54,269 - INFO - 📊 Prepared 5 queries for Phoenix evaluation\n",
            "2025-09-04 14:41:54,270 - INFO - 🔍 Running Relevance Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69c290d66ffa45cc9c5384efd0336c6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:57,293 - INFO - ✅ Relevance Evaluation Results:\n",
            "2025-09-04 14:41:57,294 - INFO -    Query: Find museums and galleries in Glasgow\n",
            "2025-09-04 14:41:57,294 - INFO -    Relevance: relevant\n",
            "2025-09-04 14:41:57,294 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:57,295 - INFO -    Query: Show me restaurants serving Asian cuisine\n",
            "2025-09-04 14:41:57,295 - INFO -    Relevance: relevant\n",
            "2025-09-04 14:41:57,295 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:57,295 - INFO -    Query: What attractions can I see in Glasgow?\n",
            "2025-09-04 14:41:57,295 - INFO -    Relevance: relevant\n",
            "2025-09-04 14:41:57,295 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:57,296 - INFO -    Query: Tell me about Monet's House\n",
            "2025-09-04 14:41:57,296 - INFO -    Relevance: relevant\n",
            "2025-09-04 14:41:57,297 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:57,298 - INFO -    Query: Find places to eat in Gillingham\n",
            "2025-09-04 14:41:57,298 - INFO -    Relevance: relevant\n",
            "2025-09-04 14:41:57,298 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:57,298 - INFO - 🔍 Running QA Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9228abf30734da992ae146592b88c4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:41:59,671 - INFO - ✅ QA Evaluation Results:\n",
            "2025-09-04 14:41:59,672 - INFO -    Query: Find museums and galleries in Glasgow\n",
            "2025-09-04 14:41:59,673 - INFO -    QA Score: incorrect\n",
            "2025-09-04 14:41:59,673 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:59,674 - INFO -    Query: Show me restaurants serving Asian cuisine\n",
            "2025-09-04 14:41:59,674 - INFO -    QA Score: incorrect\n",
            "2025-09-04 14:41:59,674 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:59,675 - INFO -    Query: What attractions can I see in Glasgow?\n",
            "2025-09-04 14:41:59,675 - INFO -    QA Score: incorrect\n",
            "2025-09-04 14:41:59,675 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:59,675 - INFO -    Query: Tell me about Monet's House\n",
            "2025-09-04 14:41:59,675 - INFO -    QA Score: correct\n",
            "2025-09-04 14:41:59,676 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:59,676 - INFO -    Query: Find places to eat in Gillingham\n",
            "2025-09-04 14:41:59,676 - INFO -    QA Score: incorrect\n",
            "2025-09-04 14:41:59,677 - INFO -    ------------------------------\n",
            "2025-09-04 14:41:59,677 - INFO - 🔍 Running Hallucination Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c6b10df87304415bc2255f7df86711f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:42:01,821 - INFO - ✅ Hallucination Evaluation Results:\n",
            "2025-09-04 14:42:01,822 - INFO -    Query: Find museums and galleries in Glasgow\n",
            "2025-09-04 14:42:01,823 - INFO -    Hallucination: hallucinated\n",
            "2025-09-04 14:42:01,823 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:01,824 - INFO -    Query: Show me restaurants serving Asian cuisine\n",
            "2025-09-04 14:42:01,825 - INFO -    Hallucination: hallucinated\n",
            "2025-09-04 14:42:01,825 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:01,825 - INFO -    Query: What attractions can I see in Glasgow?\n",
            "2025-09-04 14:42:01,825 - INFO -    Hallucination: hallucinated\n",
            "2025-09-04 14:42:01,826 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:01,826 - INFO -    Query: Tell me about Monet's House\n",
            "2025-09-04 14:42:01,826 - INFO -    Hallucination: factual\n",
            "2025-09-04 14:42:01,826 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:01,827 - INFO -    Query: Find places to eat in Gillingham\n",
            "2025-09-04 14:42:01,827 - INFO -    Hallucination: hallucinated\n",
            "2025-09-04 14:42:01,827 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:01,827 - INFO - 🔍 Running Toxicity Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73b72fc80b214b1b94cc2c782381dd6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:42:04,219 - INFO - ✅ Toxicity Evaluation Results:\n",
            "2025-09-04 14:42:04,220 - INFO -    Query: Find museums and galleries in Glasgow\n",
            "2025-09-04 14:42:04,220 - INFO -    Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,220 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:04,220 - INFO -    Query: Show me restaurants serving Asian cuisine\n",
            "2025-09-04 14:42:04,220 - INFO -    Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,221 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:04,221 - INFO -    Query: What attractions can I see in Glasgow?\n",
            "2025-09-04 14:42:04,221 - INFO -    Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,221 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:04,222 - INFO -    Query: Tell me about Monet's House\n",
            "2025-09-04 14:42:04,222 - INFO -    Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,222 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:04,222 - INFO -    Query: Find places to eat in Gillingham\n",
            "2025-09-04 14:42:04,222 - INFO -    Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,223 - INFO -    ------------------------------\n",
            "2025-09-04 14:42:04,223 - INFO - 📊 EVALUATION SUMMARY\n",
            "2025-09-04 14:42:04,223 - INFO - ==================================================\n",
            "2025-09-04 14:42:04,223 - INFO - Query 1: Find museums and galleries in Glasgow\n",
            "2025-09-04 14:42:04,223 - INFO -   Relevance: relevant\n",
            "2025-09-04 14:42:04,224 - INFO -   QA Score: incorrect\n",
            "2025-09-04 14:42:04,224 - INFO -   Hallucination: hallucinated\n",
            "2025-09-04 14:42:04,224 - INFO -   Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,224 - INFO -   ----------------------------------------\n",
            "2025-09-04 14:42:04,225 - INFO - Query 2: Show me restaurants serving Asian cuisine\n",
            "2025-09-04 14:42:04,225 - INFO -   Relevance: relevant\n",
            "2025-09-04 14:42:04,226 - INFO -   QA Score: incorrect\n",
            "2025-09-04 14:42:04,226 - INFO -   Hallucination: hallucinated\n",
            "2025-09-04 14:42:04,227 - INFO -   Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,227 - INFO -   ----------------------------------------\n",
            "2025-09-04 14:42:04,228 - INFO - Query 3: What attractions can I see in Glasgow?\n",
            "2025-09-04 14:42:04,228 - INFO -   Relevance: relevant\n",
            "2025-09-04 14:42:04,230 - INFO -   QA Score: incorrect\n",
            "2025-09-04 14:42:04,231 - INFO -   Hallucination: hallucinated\n",
            "2025-09-04 14:42:04,231 - INFO -   Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,232 - INFO -   ----------------------------------------\n",
            "2025-09-04 14:42:04,232 - INFO - Query 4: Tell me about Monet's House\n",
            "2025-09-04 14:42:04,232 - INFO -   Relevance: relevant\n",
            "2025-09-04 14:42:04,233 - INFO -   QA Score: correct\n",
            "2025-09-04 14:42:04,233 - INFO -   Hallucination: factual\n",
            "2025-09-04 14:42:04,233 - INFO -   Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,233 - INFO -   ----------------------------------------\n",
            "2025-09-04 14:42:04,233 - INFO - Query 5: Find places to eat in Gillingham\n",
            "2025-09-04 14:42:04,234 - INFO -   Relevance: relevant\n",
            "2025-09-04 14:42:04,234 - INFO -   QA Score: incorrect\n",
            "2025-09-04 14:42:04,234 - INFO -   Hallucination: hallucinated\n",
            "2025-09-04 14:42:04,235 - INFO -   Toxicity: non-toxic\n",
            "2025-09-04 14:42:04,235 - INFO -   ----------------------------------------\n",
            "2025-09-04 14:42:04,235 - INFO - ✅ All Phoenix evaluations completed successfully!\n"
          ]
        }
      ],
      "source": [
        "if ARIZE_AVAILABLE and len(landmark_demo_results) > 0:\n",
        "    logger.info(\"🔍 Running comprehensive Phoenix evaluations...\")\n",
        "    \n",
        "    # Setup evaluator LLM (using OpenAI for consistency)\n",
        "    evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.1)\n",
        "    \n",
        "    # Reference answers copied from data/queries.py (proper copy-paste as requested)\n",
        "    LANDMARK_REFERENCE_ANSWERS = [\n",
        "        # Query 1: Glasgow museums and galleries\n",
        "        \"\"\"Glasgow has several museums and galleries including the Gallery of Modern Art (Glasgow) located at Royal Exchange Square with a terrific collection of recent paintings and sculptures, the Kelvingrove Art Gallery and Museum on Argyle Street with one of the finest civic collections in Europe including works by Van Gogh, Monet and Rembrandt, the Hunterian Museum and Art Gallery at University of Glasgow with a world famous Whistler collection, and the Riverside Museum at 100 Pointhouse Place with an excellent collection of vehicles and transport history. All offer free admission except for special exhibitions.\"\"\",\n",
        "        # Query 2: Asian cuisine restaurants\n",
        "        \"\"\"There are several Asian restaurants available including Shangri-la Chinese Restaurant in Birmingham at 51 Station Street offering good quality Chinese food with spring rolls and sizzling steak, Taiwan Restaurant in San Francisco famous for their dumplings, Hong Kong Seafood Restaurant in San Francisco for sit-down dim sum, Cheung Hing Chinese Restaurant in San Francisco for Cantonese BBQ and roast duck, Vietnam Restaurant in San Francisco for Vietnamese dishes including crab soup and pork sandwich, and various other Chinese and Asian establishments across different locations.\"\"\",\n",
        "        # Query 3: Glasgow attractions\n",
        "        \"\"\"Glasgow attractions include Glasgow Green (founded by Royal grant in 1450) with Nelson's Memorial and the Doulton Fountain, Glasgow University (founded 1451) with neo-Gothic architecture and commanding views, Glasgow Cathedral with fine Gothic architecture from medieval times, the City Chambers in George Square built in 1888 in Italian Renaissance style with guided tours available, Glasgow Central Station with its grand interior, and Kelvingrove Park which is popular with students and contains the Art Gallery and Museum.\"\"\",\n",
        "        # Query 4: Monet's House\n",
        "        \"\"\"Monet's House is located in Giverny, France at 84 rue Claude Monet. The house is quietly eccentric and highly interesting in an Orient-influenced style, featuring Monet's collection of Japanese prints. The main attraction is the gardens around the house, including the water garden with the Japanese bridge, weeping willows and waterlilies which are now iconic. It's open April-October, Monday-Sunday 9:30-18:00, with admission €9 for adults, €5 for students, €4 for disabled visitors, and free for under-7s. E-tickets can be purchased online and wheelchair access is available.\"\"\",\n",
        "        # Query 5: Gillingham restaurants\n",
        "        \"\"\"Gillingham has various dining options including Beijing Inn (Chinese restaurant at 3 King Street), Spice Court (Indian restaurant at 56-58 Balmoral Road opposite the railway station, award-winning with Sunday Buffet for £8.50), Hollywood Bowl (American-style restaurant at 4 High Street with burgers and ribs in a Hollywood-themed setting), Ossie's Fish and Chips (at 75 Richmond Road, known for the best fish and chips in the area), and Thai Won Mien (oriental restaurant at 59-61 High Street with noodles, duck and other oriental dishes).\"\"\",\n",
        "    ]\n",
        "    \n",
        "    # Queries copied from data/queries.py\n",
        "    LANDMARK_SEARCH_QUERIES = [\n",
        "        \"Find museums and galleries in Glasgow\",\n",
        "        \"Show me restaurants serving Asian cuisine\", \n",
        "        \"What attractions can I see in Glasgow?\",\n",
        "        \"Tell me about Monet's House\",\n",
        "        \"Find places to eat in Gillingham\"\n",
        "    ]\n",
        "    \n",
        "    # Create mapping dictionary like the working source files\n",
        "    QUERY_REFERENCE_ANSWERS = {\n",
        "        query: answer for query, answer in zip(LANDMARK_SEARCH_QUERIES, LANDMARK_REFERENCE_ANSWERS)\n",
        "    }\n",
        "    \n",
        "    # Prepare evaluation data with proper column names for Phoenix evaluators\n",
        "    landmark_eval_data = []\n",
        "    for _, row in landmark_results_df.iterrows():\n",
        "        landmark_eval_data.append({\n",
        "            \"input\": row[\"query\"],\n",
        "            \"output\": row[\"response\"],\n",
        "            \"reference\": QUERY_REFERENCE_ANSWERS.get(row[\"query\"], \"Reference answer not found\"),\n",
        "            \"text\": row[\"response\"]  # For toxicity evaluation\n",
        "        })\n",
        "    \n",
        "    # Ensure we only have 5 queries as intended\n",
        "    if len(landmark_eval_data) > 5:\n",
        "        logger.warning(f\"Found {len(landmark_eval_data)} evaluation entries, limiting to first 5\")\n",
        "        landmark_eval_data = landmark_eval_data[:5]\n",
        "    \n",
        "    landmark_eval_df = pd.DataFrame(landmark_eval_data)\n",
        "    logger.info(f\"📊 Prepared {len(landmark_eval_df)} queries for Phoenix evaluation\")\n",
        "    \n",
        "    try:\n",
        "        # 1. Relevance Evaluation\n",
        "        logger.info(\"🔍 Running Relevance Evaluation...\")\n",
        "        landmark_relevance_results = llm_classify(\n",
        "            data=landmark_eval_df[[\"input\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "            rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Relevance Evaluation Results:\")\n",
        "        # Extract labels from DataFrame results like the working script\n",
        "        relevance_labels = landmark_relevance_results['label'].tolist() if 'label' in landmark_relevance_results.columns else []\n",
        "        for i, result in enumerate(relevance_labels):\n",
        "            # Add bounds checking to prevent IndexError\n",
        "            if i < len(landmark_eval_data):\n",
        "                query = landmark_eval_data[i][\"input\"]\n",
        "            else:\n",
        "                query = f\"Query {i+1}\"\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Relevance: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 2. QA Evaluation\n",
        "        logger.info(\"🔍 Running QA Evaluation...\")\n",
        "        landmark_qa_results = llm_classify(\n",
        "            data=landmark_eval_df[[\"input\", \"output\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=QA_PROMPT_TEMPLATE,\n",
        "            rails=list(QA_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ QA Evaluation Results:\")\n",
        "        # Extract labels from DataFrame results like the working script\n",
        "        qa_labels = landmark_qa_results['label'].tolist() if 'label' in landmark_qa_results.columns else []\n",
        "        for i, result in enumerate(qa_labels):\n",
        "            # Add bounds checking to prevent IndexError\n",
        "            if i < len(landmark_eval_data):\n",
        "                query = landmark_eval_data[i][\"input\"]\n",
        "            else:\n",
        "                query = f\"Query {i+1}\"\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   QA Score: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 3. Hallucination Evaluation\n",
        "        logger.info(\"🔍 Running Hallucination Evaluation...\")\n",
        "        landmark_hallucination_results = llm_classify(\n",
        "            data=landmark_eval_df[[\"input\", \"reference\", \"output\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=HALLUCINATION_PROMPT_TEMPLATE,\n",
        "            rails=list(HALLUCINATION_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Hallucination Evaluation Results:\")\n",
        "        # Extract labels from DataFrame results like the working script\n",
        "        hallucination_labels = landmark_hallucination_results['label'].tolist() if 'label' in landmark_hallucination_results.columns else []\n",
        "        for i, result in enumerate(hallucination_labels):\n",
        "            # Add bounds checking to prevent IndexError\n",
        "            if i < len(landmark_eval_data):\n",
        "                query = landmark_eval_data[i][\"input\"]\n",
        "            else:\n",
        "                query = f\"Query {i+1}\"\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Hallucination: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # 4. Toxicity Evaluation\n",
        "        logger.info(\"🔍 Running Toxicity Evaluation...\")\n",
        "        landmark_toxicity_results = llm_classify(\n",
        "            data=landmark_eval_df[[\"input\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=TOXICITY_PROMPT_TEMPLATE,\n",
        "            rails=list(TOXICITY_PROMPT_RAILS_MAP.values())\n",
        "        )\n",
        "        \n",
        "        logger.info(\"✅ Toxicity Evaluation Results:\")\n",
        "        # Extract labels from DataFrame results like the working script\n",
        "        toxicity_labels = landmark_toxicity_results['label'].tolist() if 'label' in landmark_toxicity_results.columns else []\n",
        "        for i, result in enumerate(toxicity_labels):\n",
        "            # Add bounds checking to prevent IndexError\n",
        "            if i < len(landmark_eval_data):\n",
        "                query = landmark_eval_data[i][\"input\"]\n",
        "            else:\n",
        "                query = f\"Query {i+1}\"\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Toxicity: {result}\")\n",
        "            logger.info(\"   \" + \"-\"*30)\n",
        "        \n",
        "        # Summary of all evaluations\n",
        "        logger.info(\"📊 EVALUATION SUMMARY\")\n",
        "        logger.info(\"=\" * 50)\n",
        "        \n",
        "        for i, query in enumerate([item[\"input\"] for item in landmark_eval_data]):\n",
        "            logger.info(f\"Query {i+1}: {query}\")\n",
        "            # Extract labels from DataFrames using working script pattern\n",
        "            try:\n",
        "                relevance_labels = landmark_relevance_results['label'].tolist() if hasattr(landmark_relevance_results, 'columns') and 'label' in landmark_relevance_results.columns else []\n",
        "                qa_labels = landmark_qa_results['label'].tolist() if hasattr(landmark_qa_results, 'columns') and 'label' in landmark_qa_results.columns else []\n",
        "                hallucination_labels = landmark_hallucination_results['label'].tolist() if hasattr(landmark_hallucination_results, 'columns') and 'label' in landmark_hallucination_results.columns else []\n",
        "                toxicity_labels = landmark_toxicity_results['label'].tolist() if hasattr(landmark_toxicity_results, 'columns') and 'label' in landmark_toxicity_results.columns else []\n",
        "                \n",
        "                relevance = relevance_labels[i] if i < len(relevance_labels) else \"N/A\"\n",
        "                qa_score = qa_labels[i] if i < len(qa_labels) else \"N/A\"\n",
        "                hallucination = hallucination_labels[i] if i < len(hallucination_labels) else \"N/A\"\n",
        "                toxicity = toxicity_labels[i] if i < len(toxicity_labels) else \"N/A\"\n",
        "                \n",
        "                logger.info(f\"  Relevance: {relevance}\")\n",
        "                logger.info(f\"  QA Score: {qa_score}\")\n",
        "                logger.info(f\"  Hallucination: {hallucination}\")\n",
        "                logger.info(f\"  Toxicity: {toxicity}\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"  Error accessing evaluation results: {e}\")\n",
        "            logger.info(\"  \" + \"-\"*40)\n",
        "        \n",
        "        logger.info(\"✅ All Phoenix evaluations completed successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Phoenix evaluation failed: {e}\")\n",
        "        logger.info(\"💡 This might be due to API rate limits or model availability\")\n",
        "        \n",
        "else:\n",
        "    if not ARIZE_AVAILABLE:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - Arize dependencies not available\")\n",
        "    else:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - No demo results to evaluate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete landmark search agent implementation using:\n",
        "\n",
        "1. **Agent Catalog Integration**: Using agentc to find tools and prompts\n",
        "2. **LlamaIndex Framework**: ReAct agent pattern with semantic search capabilities\n",
        "3. **Couchbase Vector Store**: Storing and searching landmark data from travel-sample bucket\n",
        "4. **NVIDIA NIMs + Capella AI**: NVIDIA NIMs for LLM, Capella AI for embeddings\n",
        "5. **Single Tool Architecture**: Focused on `search_landmarks` for landmark discovery\n",
        "6. **Comprehensive Evaluation**: Phoenix-based evaluation with LlamaIndex instrumentation\n",
        "\n",
        "The agent can handle various landmark-related queries including:\n",
        "- Landmark search by location (Tokyo, London, Paris)\n",
        "- Finding specific types of attractions (museums, parks, monuments)\n",
        "- Cultural and historical site discovery\n",
        "- Tourist attraction recommendations\n",
        "\n",
        "## Phoenix Evaluation Metrics\n",
        "\n",
        "The notebook demonstrates all four key Phoenix evaluation types:\n",
        "\n",
        "1. **Relevance Evaluation**: Measures how relevant responses are to landmark queries\n",
        "2. **QA Evaluation**: Assesses the quality and accuracy of landmark information\n",
        "3. **Hallucination Detection**: Identifies fabricated or incorrect landmark information\n",
        "4. **Toxicity Detection**: Screens for harmful or inappropriate content\n",
        "\n",
        "Each evaluation provides:\n",
        "- Binary or categorical labels (e.g., \"relevant\"/\"irrelevant\", \"correct\"/\"incorrect\")\n",
        "- Detailed explanations of the evaluation reasoning\n",
        "- Confidence scores for the assessments\n",
        "\n",
        "## Key Features\n",
        "\n",
        "This landmark search agent implementation:\n",
        "- **Uses LlamaIndex**: Advanced RAG framework with ReAct agent pattern\n",
        "- **Uses travel-sample bucket**: Leverages existing Couchbase landmark data\n",
        "- **NVIDIA NIMs integration**: High-performance LLM inference\n",
        "- **Capella AI embeddings**: High-quality vector embeddings for semantic search\n",
        "- **OpenAI fallback**: Graceful fallback when Capella AI is unavailable\n",
        "- **Single focused tool**: Simplified architecture with one search tool\n",
        "- **Comprehensive evaluation**: Full Phoenix evaluation pipeline\n",
        "- **LlamaIndex instrumentation**: Integrated observability and tracing\n",
        "\n",
        "## Data Source\n",
        "\n",
        "The agent uses landmark data from the `travel-sample.inventory.landmark` collection, which contains:\n",
        "- Real landmark information with names, locations, and descriptions\n",
        "- Structured data with address, city, country, and type information\n",
        "- Rich text descriptions suitable for vector embedding\n",
        "- Global coverage of tourist attractions and points of interest\n",
        "\n",
        "## Architecture Differences\n",
        "\n",
        "This landmark search agent differs from the other agents:\n",
        "- **LlamaIndex** (not LangChain or LangGraph) - advanced RAG framework\n",
        "- **NVIDIA NIMs LLM**: High-performance inference instead of OpenAI/Capella LLM\n",
        "- **ReAct Pattern**: Built-in reasoning and action capabilities\n",
        "- **Landmark-specific**: Optimized for tourism and travel use cases\n",
        "- **Global Settings**: Uses LlamaIndex global settings for LLM and embeddings\n",
        "\n",
        "For production use, consider:\n",
        "- Setting up proper monitoring with Arize Phoenix\n",
        "- Implementing comprehensive evaluation pipelines\n",
        "- Adding error handling and retry logic\n",
        "- Scaling the vector store for larger datasets\n",
        "- Adding more sophisticated query understanding\n",
        "\n",
        "## Usage Instructions\n",
        "\n",
        "To run this notebook:\n",
        "1. Set up the required environment variables (Couchbase connection, API keys)\n",
        "2. Install dependencies: `pip install -r requirements.txt`\n",
        "3. Ensure travel-sample bucket is available in your Couchbase cluster\n",
        "4. Publish your agent catalog: `agentc index . && agentc publish`\n",
        "5. Run the notebook cells sequentially\n",
        "\n",
        "The agent will automatically load landmark data from travel-sample and create embeddings for semantic search capabilities. NVIDIA API key is required for LLM functionality.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "landmark-search-agent-2081kaWT-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
