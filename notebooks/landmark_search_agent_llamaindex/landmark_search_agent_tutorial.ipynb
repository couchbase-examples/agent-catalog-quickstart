{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6nIMp4oldFO",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Landmark Search Agent Tutorial - LlamaIndex Implementation\n",
        "\n",
        "This notebook demonstrates a complete landmark search agent using:\n",
        "- **Agent Catalog** for tool and prompt management\n",
        "- **LlamaIndex ReAct Agent** with semantic search capabilities\n",
        "- **Couchbase Vector Store** with travel-sample landmark data\n",
        "- **AI Services**: Embedding and LLM models provided by Capella AI services \n",
        "- **Phoenix Evaluation** with lenient templates for dynamic data\n",
        "- **Self-contained Structure** with proper function ordering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xER3MNz1ldFP",
        "outputId": "ae55eb27-e4ef-4984-8524-0c23d3a7b942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUCe0xkQldFP",
        "outputId": "cee0bc14-a64d-40d9-c966-a27830e23620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-10-24 09:40:59--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/prompts/landmark_search_assistant.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5030 (4.9K) [text/plain]\n",
            "Saving to: \u2018prompts/landmark_search_assistant.yaml\u2019\n",
            "\n",
            "\r          prompts/l   0%[                    ]       0  --.-KB/s               \rprompts/landmark_se 100%[===================>]   4.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-24 09:40:59 (30.5 MB/s) - \u2018prompts/landmark_search_assistant.yaml\u2019 saved [5030/5030]\n",
            "\n",
            "--2025-10-24 09:40:59--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/tools/search_landmarks.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12210 (12K) [text/plain]\n",
            "Saving to: \u2018tools/search_landmarks.py\u2019\n",
            "\n",
            "tools/search_landma 100%[===================>]  11.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-24 09:40:59 (84.2 MB/s) - \u2018tools/search_landmarks.py\u2019 saved [12210/12210]\n",
            "\n",
            "--2025-10-24 09:40:59--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/agentcatalog_index.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1952 (1.9K) [text/plain]\n",
            "Saving to: \u2018agentcatalog_index.json\u2019\n",
            "\n",
            "agentcatalog_index. 100%[===================>]   1.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-24 09:41:00 (25.0 MB/s) - \u2018agentcatalog_index.json\u2019 saved [1952/1952]\n",
            "\n",
            "--2025-10-24 09:41:00--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/.agentcignore\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27 [text/plain]\n",
            "Saving to: \u2018.agentcignore\u2019\n",
            "\n",
            ".agentcignore       100%[===================>]      27  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-24 09:41:00 (656 KB/s) - \u2018.agentcignore\u2019 saved [27/27]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download required resources for the landmark search agent\n",
        "!mkdir -p prompts\n",
        "!wget -O prompts/landmark_search_assistant.yaml https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/prompts/landmark_search_assistant.yaml\n",
        "!mkdir -p tools\n",
        "!wget -O tools/search_landmarks.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/tools/search_landmarks.py\n",
        "!wget -O agentcatalog_index.json https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/agentcatalog_index.json\n",
        "!wget -O .agentcignore https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/landmark_search_agent_llamaindex/.agentcignore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6wbMh_uldFP",
        "outputId": "6ba867f1-0fcf-4f2a-aeff-8cf87dfe3396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "mcp 1.18.0 requires uvicorn>=0.31.1; sys_platform != \"emscripten\", but you have uvicorn 0.29.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q \\\n",
        "    \"pydantic>=2.11.0,<3.0.0\" \\\n",
        "    \"python-dotenv>=1.1.0,<2.0.0\" \\\n",
        "    \"pandas>=2.2.0,<3.0.0\" \\\n",
        "    \"nest-asyncio>=1.6.0,<2.0.0\" \\\n",
        "    \"httpx>=0.28.0,<1.0.0\" \\\n",
        "    \"tqdm>=4.67.0,<5.0.0\" \\\n",
        "    \"llama-index>=0.12.38,<0.13.0\" \\\n",
        "    \"llama-index-core>=0.12.0,<0.13.0\" \\\n",
        "    \"llama-index-llms-openai>=0.4.0,<0.5.0\" \\\n",
        "    \"llama-index-vector-stores-couchbase>=0.4.0,<0.5.0\" \\\n",
        "    \"llama-index-embeddings-openai>=0.3.1,<0.4.0\" \\\n",
        "    \"llama-index-embeddings-nvidia>=0.3.0,<0.4.0\" \\\n",
        "    \"llama-index-llms-openai-like>=0.4.0,<0.5.0\" \\\n",
        "    \"llama-index-llms-nvidia>=0.3.0,<0.4.0\" \\\n",
        "    \"couchbase>=4.0.0,<5.0.0\" \\\n",
        "    \"arize>=7.51.0,<8.0.0\" \\\n",
        "    \"arize-phoenix>=11.37.0,<12.0.0\" \\\n",
        "    \"arize-phoenix-evals>=2.2.0,<3.0.0\" \\\n",
        "    \"openinference-instrumentation>=0.1.38,<0.2.0\" \\\n",
        "    \"openinference-instrumentation-openai>=0.1.18,<0.2.0\" \\\n",
        "    \"openinference-instrumentation-llama-index>=4.0.0,<5.0.0\" \\\n",
        "    \"uvicorn>=0.29.0,<0.30.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFrPulAIldFP",
        "outputId": "77bf6f28-d48f-47af-dcea-6e5833a38d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gitignore-parser (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mcp 1.18.0 requires uvicorn>=0.31.1; sys_platform != \"emscripten\", but you have uvicorn 0.29.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a2/agentc_core-0.2.5a2-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a2/agentc_cli-0.2.5a2-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a2/agentc-0.2.5a2-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a2/agentc_llamaindex-0.2.5a2-py3-none-any.whl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9B9C9eVUldFP"
      },
      "outputs": [],
      "source": [
        "# Install the couchbase-infrastructure package\n",
        "%pip install -q couchbase-infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTbTjdY1ldFQ"
      },
      "source": [
        "## \ud83d\ude80 Educational Infrastructure Setup\n",
        "\n",
        "**This cell uses the `couchbase-infrastructure` package to provision your Couchbase Capella infrastructure step-by-step.**\n",
        "\n",
        "### What It Does (Educational Approach):\n",
        "1. **Interactive Credentials** - Securely collects your API key using `getpass` (Google Colab compatible)\n",
        "2. **Creates Capella Project** - Sets up your cloud database project\n",
        "3. **Provisions Free Tier Cluster** - Deploys a Couchbase cluster on AWS\n",
        "4. **Configures Network Access** - Sets up allowlists for connectivity\n",
        "5. **Loads travel-sample Data** - Imports the sample landmark dataset\n",
        "6. **Creates Database User** - Generates credentials with appropriate permissions\n",
        "7. **Deploys AI Models** - Provisions embedding and LLM models for the agent\n",
        "8. **Creates API Keys** - Generates keys for AI model access\n",
        "9. **Sets Environment Variables** - Configures all required variables for subsequent cells\n",
        "\n",
        "### Prerequisites:\n",
        "- Get your `MANAGEMENT_API_KEY` from [Capella Console](https://cloud.couchbase.com) \u2192 Settings \u2192 API Keys\n",
        "- **No `.env` file needed** - This notebook uses interactive prompts (Google Colab compatible)\n",
        "\n",
        "### After Running:\n",
        "All environment variables will be set and ready for the landmark search agent cells below.\n",
        "\n",
        "**Package Documentation**: https://pypi.org/project/couchbase-infrastructure/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZCGcnQq0ldFQ",
        "outputId": "bbe96820-c3f0-4d73-da90-be72dbcc90f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "\ud83d\ude80 Couchbase Capella Infrastructure Setup\n",
            "======================================================================\n",
            "\n",
            "This educational setup shows you how to provision Capella infrastructure\n",
            "step-by-step using the couchbase-infrastructure package.\n",
            "\n",
            "\n",
            "\ud83d\udccb Step 1: Collecting Credentials\n",
            "----------------------------------------------------------------------\n",
            "\u2705 Found .env file. Loading configuration...\n",
            "\n",
            "Get your credentials from: https://cloud.couchbase.com \u2192 Settings \u2192 API Keys\n",
            "\n",
            "\u2705 Using MANAGEMENT_API_KEY from environment\n",
            "\u2705 Using ORGANIZATION_ID from environment: 23086345-371f-4650-8dc4-c61733dd27a0\n",
            "Enter PROJECT_NAME (default: 'agent-app'): \n",
            "Enter CLUSTER_NAME (default: 'agent-app-cluster'): \n",
            "Enter DB_USERNAME (default: 'agent_app_user'): \n",
            "Enter BUCKET_NAME (default: 'travel-sample'): \n",
            "Enter EMBEDDING_MODEL (default: 'nvidia/llama-3.2-nv-embedqa-1b-v2'): \n",
            "Enter LLM_MODEL (default: 'meta/llama3-8b-instruct'): \n",
            "\n",
            "\u2705 Configuration collected successfully!\n",
            "\n",
            "\n",
            "\ud83d\udd27 Step 2: Initializing Configuration\n",
            "----------------------------------------------------------------------\n",
            "\u2705 Configuration initialized\n",
            "\n",
            "\n",
            "\ud83d\udd0c Step 3: Initializing Client\n",
            "----------------------------------------------------------------------\n",
            "\u2705 Using Organization ID: 23086345-371f-4650-8dc4-c61733dd27a0\n",
            "\n",
            "\n",
            "\ud83d\udd0d Step 4: Testing API Connection\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\udd0d Testing API connection...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m\ud83d\udd0d Testing API connection\u001b[0m\u001b[1;34m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current IP: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">34.21.59.60</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Current IP: \u001b[1;33m34.21.59.60\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   API Base URL: <span style=\"color: #808000; text-decoration-color: #808000; text-decoration: underline\">https://cloudapi.sbx-29.sandbox.nonprod-project-avengers.com</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   API Base URL: \u001b[4;33mhttps://cloudapi.sbx-29.sandbox.nonprod-project-avengers.com\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Organization ID: <span style=\"color: #808000; text-decoration-color: #808000\">23086345-371f-4650-8dc4-c61733dd27a0</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Organization ID: \u001b[33m23086345-371f-4650-8dc4-c61733dd27a0\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   API Response Status: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   API Response Status: \u001b[1;33m200\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Authentication successful</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u001b[32m\u2705 Authentication successful\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 API connection successful\n",
            "\n",
            "\n",
            "\ud83d\udcc1 Step 5: Creating Capella Project\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Searching for project named <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-app</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Searching for project named \u001b[32m'\u001b[0m\u001b[36magent-app\u001b[0m\u001b[32m'\u001b[0m\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Found existing project.</span> Project ID: <span style=\"color: #008080; text-decoration-color: #008080\">e04136ef-4809-44fc-b703-0824e01655a4</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 Found existing project.\u001b[0m Project ID: \u001b[36me04136ef-4809-44fc-b703-0824e01655a4\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Project ready: agent-app (ID: e04136ef-4809-44fc-b703-0824e01655a4)\n",
            "\n",
            "\n",
            "\u2601\ufe0f Step 6: Creating Free Tier Cluster\n",
            "----------------------------------------------------------------------\n",
            "\u23f3 This will take 10-15 minutes for cluster deployment...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if cluster <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-app-cluster</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Checking if cluster \u001b[32m'\u001b[0m\u001b[36magent-app-cluster\u001b[0m\u001b[32m'\u001b[0m already exists\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Cluster </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent-app-cluster'</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">Status: unknown</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span> Cluster ID: \n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">b82a6f7f-a9b3-470d-824a-c321d30ad5f4</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u001b[32m\u2705 Cluster \u001b[0m\u001b[32m'agent-app-cluster'\u001b[0m\u001b[32m already exists \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mStatus: unknown\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m Cluster ID: \n",
              "\u001b[36mb82a6f7f-a9b3-470d-824a-c321d30ad5f4\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting for Cluster to become ready<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>no timeout, will wait indefinitely<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Waiting for Cluster to become ready\u001b[33m...\u001b[0m \u001b[1m(\u001b[0mno timeout, will wait indefinitely\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current status: <span style=\"color: #808000; text-decoration-color: #808000\">healthy</span> <span style=\"font-weight: bold\">(</span>elapsed: 0s<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Current status: \u001b[33mhealthy\u001b[0m \u001b[1m(\u001b[0melapsed: 0s\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Cluster is ready!</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 Cluster is ready!\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0\ufe0f  Added protocol to connection string: couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com\n",
            "\u2705 Cluster ready: agent-app-cluster (ID: b82a6f7f-a9b3-470d-824a-c321d30ad5f4)\n",
            "\n",
            "\n",
            "\ud83c\udf10 Step 7: Configuring Network Access\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Adding allowed CIDR <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0.0.0</span><span style=\"color: #008080; text-decoration-color: #008080\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> to cluster<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Adding allowed CIDR \u001b[1;36m0.0.0.0\u001b[0m\u001b[36m/\u001b[0m\u001b[1;36m0\u001b[0m to cluster\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if CIDR already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Checking if CIDR already exists\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">\u2705 CIDR </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.0.0.0</span><span style=\"color: #008000; text-decoration-color: #008000\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u001b[32m\u2705 CIDR \u001b[0m\u001b[1;32m0.0.0.0\u001b[0m\u001b[32m/\u001b[0m\u001b[1;32m0\u001b[0m\u001b[32m already exists\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Network access configured (0.0.0.0/0 allowed)\n",
            "\n",
            "\n",
            "\ud83d\udce6 Step 8: Loading travel-sample Bucket\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 `travel-sample` bucket load command accepted.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 `travel-sample` bucket load command accepted.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 `travel-sample` bucket is ready.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 `travel-sample` bucket is ready.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Sample data loaded: travel-sample\n",
            "\n",
            "\n",
            "\ud83d\udc64 Step 9: Creating Database User\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Database user <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent_app_user</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists. Deleting to recreate with new password<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Database user \u001b[32m'\u001b[0m\u001b[36magent_app_user\u001b[0m\u001b[32m'\u001b[0m already exists. Deleting to recreate with new password\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   User <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent_app_user</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> deleted successfully.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   User \u001b[32m'\u001b[0m\u001b[36magent_app_user\u001b[0m\u001b[32m'\u001b[0m deleted successfully.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Database user <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent_app_user</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> created successfully.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Database user \u001b[32m'\u001b[0m\u001b[36magent_app_user\u001b[0m\u001b[32m'\u001b[0m created successfully.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Database user created: agent_app_user\n",
            "\n",
            "   Auto-generated password: WkwG...xcAW\n",
            "\n",
            "\n",
            "\ud83e\udd16 Step 10: Deploying AI Models\n",
            "----------------------------------------------------------------------\n",
            "\u23f3 Deploying embedding and LLM models (5-10 minutes)...\n",
            "\n",
            "   Deploying embedding model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if model <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-hub-embedding-model</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Checking if model \u001b[32m'\u001b[0m\u001b[36magent-hub-embedding-model\u001b[0m\u001b[32m'\u001b[0m already exists\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> existing <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Found \u001b[1;36m2\u001b[0m existing \u001b[1;35mmodel\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Model </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent-hub-embedding-model'</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">Status: healthy</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span> Model ID: \n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">22ffa6d6-87a3-45fd-905d-efb0c995ffa1</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u001b[32m\u2705 Model \u001b[0m\u001b[32m'agent-hub-embedding-model'\u001b[0m\u001b[32m already exists \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mStatus: healthy\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m Model ID: \n",
              "\u001b[36m22ffa6d6-87a3-45fd-905d-efb0c995ffa1\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   \u2705 Model config matches. Reusing existing model.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u2705 Model config matches. Reusing existing model.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting for Embedding Model to become ready<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>no timeout, will wait indefinitely<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Waiting for Embedding Model to become ready\u001b[33m...\u001b[0m \u001b[1m(\u001b[0mno timeout, will wait indefinitely\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current status: <span style=\"color: #808000; text-decoration-color: #808000\">healthy</span> <span style=\"font-weight: bold\">(</span>elapsed: 0s<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Current status: \u001b[33mhealthy\u001b[0m \u001b[1m(\u001b[0melapsed: 0s\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Embedding Model is ready!</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 Embedding Model is ready!\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Embedding model deployed: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "   Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "\n",
            "   Deploying LLM model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if model <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-hub-llm-model</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Checking if model \u001b[32m'\u001b[0m\u001b[36magent-hub-llm-model\u001b[0m\u001b[32m'\u001b[0m already exists\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> existing <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Found \u001b[1;36m2\u001b[0m existing \u001b[1;35mmodel\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Model </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent-hub-llm-model'</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">Status: healthy</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span> Model ID: <span style=\"color: #008080; text-decoration-color: #008080\">122c445e-636d-48c9-a1b1-b41043b30d17</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u001b[32m\u2705 Model \u001b[0m\u001b[32m'agent-hub-llm-model'\u001b[0m\u001b[32m already exists \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mStatus: healthy\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m Model ID: \u001b[36m122c445e-636d-48c9-a1b1-b41043b30d17\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   \u2705 Model config matches. Reusing existing model.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   \u2705 Model config matches. Reusing existing model.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting for LLM Model to become ready<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>no timeout, will wait indefinitely<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Waiting for LLM Model to become ready\u001b[33m...\u001b[0m \u001b[1m(\u001b[0mno timeout, will wait indefinitely\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current status: <span style=\"color: #808000; text-decoration-color: #808000\">healthy</span> <span style=\"font-weight: bold\">(</span>elapsed: 0s<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Current status: \u001b[33mhealthy\u001b[0m \u001b[1m(\u001b[0melapsed: 0s\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 LLM Model is ready!</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 LLM Model is ready!\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 LLM model deployed: meta/llama3-8b-instruct\n",
            "   Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "\n",
            "\n",
            "\ud83d\udd11 Step 11: Creating API Key for AI Models\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Creating API key for models in region <span style=\"color: #008080; text-decoration-color: #008080\">us-east-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Creating API key for models in region \u001b[36mus-east-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 API key created successfully.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m\u2705 API key created successfully.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Key ID: <span style=\"color: #008080; text-decoration-color: #008080\">fe9bf8bc-125c-5a73-8b4a-e20f6b90e232</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Key ID: \u001b[36mfe9bf8bc-125c-5a73-8b4a-e20f6b90e232\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Token: <span style=\"color: #008080; text-decoration-color: #008080\">cbsk-v1-luJO46aMkADr...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "   Token: \u001b[36mcbsk-v1-luJO46aMkADr\u001b[0m\u001b[36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 AI API key created\n",
            "\n",
            "\n",
            "\u2699\ufe0f Step 12: Setting Environment Variables\n",
            "----------------------------------------------------------------------\n",
            "\u2705 Environment variables configured:\n",
            "\n",
            "   CB_CONN_STRING: couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com\n",
            "   CB_USERNAME: agent_app_user\n",
            "   CB_BUCKET: travel-sample\n",
            "   CAPELLA_API_EMBEDDING_ENDPOINT: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "   CAPELLA_API_LLM_ENDPOINT: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "   CAPELLA_API_EMBEDDING_MODEL: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "   CAPELLA_API_LLM_MODEL: meta/llama3-8b-instruct\n",
            "\n",
            "======================================================================\n",
            "\u2705 Infrastructure Setup Complete!\n",
            "======================================================================\n",
            "\n",
            "You can now run the landmark search agent cells below.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\ude80 Couchbase Capella Infrastructure Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis educational setup shows you how to provision Capella infrastructure\")\n",
        "print(\"step-by-step using the couchbase-infrastructure package.\\n\")\n",
        "\n",
        "# Import the infrastructure package\n",
        "from couchbase_infrastructure import CapellaConfig, CapellaClient\n",
        "from couchbase_infrastructure.resources import (\n",
        "    create_project,\n",
        "    create_developer_pro_cluster,\n",
        "    add_allowed_cidr,\n",
        "    load_sample_data,\n",
        "    create_database_user,\n",
        "    deploy_ai_model,\n",
        "    create_ai_api_key,\n",
        ")\n",
        "\n",
        "# Step 1: Load from .env file if available, then collect any missing credentials\n",
        "print(\"\\n\ud83d\udccb Step 1: Collecting Credentials\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Try to load .env file\n",
        "env_file = Path('.env')\n",
        "if env_file.exists():\n",
        "    print(\"\u2705 Found .env file. Loading configuration...\\n\")\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv('.env')\n",
        "else:\n",
        "    print(\"\u2139\ufe0f  No .env file found. Will prompt for credentials.\\n\")\n",
        "\n",
        "print(\"Get your credentials from: https://cloud.couchbase.com \u2192 Settings \u2192 API Keys\\n\")\n",
        "\n",
        "# Required: MANAGEMENT_API_KEY\n",
        "management_api_key = os.getenv('MANAGEMENT_API_KEY')\n",
        "if management_api_key:\n",
        "    print(\"\u2705 Using MANAGEMENT_API_KEY from environment\")\n",
        "else:\n",
        "    management_api_key = getpass(\"Enter your MANAGEMENT_API_KEY (hidden): \")\n",
        "    if not management_api_key:\n",
        "        raise ValueError(\"MANAGEMENT_API_KEY is required!\")\n",
        "\n",
        "# Required: ORGANIZATION_ID\n",
        "organization_id = os.getenv('ORGANIZATION_ID')\n",
        "if organization_id:\n",
        "    print(f\"\u2705 Using ORGANIZATION_ID from environment: {organization_id}\")\n",
        "else:\n",
        "    organization_id = input(\"Enter your ORGANIZATION_ID (required): \").strip()\n",
        "    if not organization_id:\n",
        "        raise ValueError(\"ORGANIZATION_ID is required! Find it in Capella Console under Settings.\")\n",
        "\n",
        "# Optional configuration (use env vars if available, otherwise prompt with defaults)\n",
        "api_base_url = os.getenv('API_BASE_URL') or input(\"Enter API_BASE_URL (default: 'cloudapi.cloud.couchbase.com'): \").strip() or \"cloudapi.cloud.couchbase.com\"\n",
        "project_name = os.getenv('PROJECT_NAME') or input(\"Enter PROJECT_NAME (default: 'agent-app'): \").strip() or \"agent-app\"\n",
        "cluster_name = os.getenv('CLUSTER_NAME') or input(\"Enter CLUSTER_NAME (default: 'agent-app-cluster'): \").strip() or \"agent-app-cluster\"\n",
        "db_username = os.getenv('DB_USERNAME') or input(\"Enter DB_USERNAME (default: 'agent_app_user'): \").strip() or \"agent_app_user\"\n",
        "sample_bucket = os.getenv('SAMPLE_BUCKET') or input(\"Enter BUCKET_NAME (default: 'travel-sample'): \").strip() or \"travel-sample\"\n",
        "embedding_model = os.getenv('EMBEDDING_MODEL_NAME') or input(\"Enter EMBEDDING_MODEL (default: 'nvidia/llama-3.2-nv-embedqa-1b-v2'): \").strip() or \"nvidia/llama-3.2-nv-embedqa-1b-v2\"\n",
        "llm_model = os.getenv('LLM_MODEL_NAME') or input(\"Enter LLM_MODEL (default: 'meta/llama3-8b-instruct'): \").strip() or \"meta/llama3-8b-instruct\"\n",
        "\n",
        "print(\"\\n\u2705 Configuration collected successfully!\\n\")\n",
        "\n",
        "# Step 2: Initialize configuration\n",
        "print(\"\\n\ud83d\udd27 Step 2: Initializing Configuration\")\n",
        "print(\"-\"*70)\n",
        "config = CapellaConfig(\n",
        "    management_api_key=management_api_key,\n",
        "    organization_id=organization_id,\n",
        "    api_base_url=api_base_url,\n",
        "    project_name=project_name,\n",
        "    cluster_name=cluster_name,\n",
        "    db_username=db_username,\n",
        "    sample_bucket=sample_bucket,\n",
        "    embedding_model_name=embedding_model,\n",
        "    llm_model_name=llm_model,\n",
        ")\n",
        "print(\"\u2705 Configuration initialized\\n\")\n",
        "\n",
        "# Step 3: Initialize client and get organization ID\n",
        "print(\"\\n\ud83d\udd0c Step 3: Initializing Client\")\n",
        "print(\"-\"*70)\n",
        "client = CapellaClient(config)\n",
        "org_id = client.get_organization_id()\n",
        "print(f\"\u2705 Using Organization ID: {org_id}\\n\")\n",
        "\n",
        "# Step 4: Test API connection\n",
        "print(\"\\n\ud83d\udd0d Step 4: Testing API Connection\")\n",
        "print(\"-\"*70)\n",
        "if not client.test_connection(org_id):\n",
        "    raise ConnectionError(\"Failed to connect to Capella API\")\n",
        "print(\"\u2705 API connection successful\\n\")\n",
        "\n",
        "# Step 5: Create Capella Project\n",
        "print(\"\\n\ud83d\udcc1 Step 5: Creating Capella Project\")\n",
        "print(\"-\"*70)\n",
        "project_id = create_project(client, org_id, config.project_name)\n",
        "print(f\"\u2705 Project ready: {config.project_name} (ID: {project_id})\\n\")\n",
        "\n",
        "# Step 6: Create free-tier cluster\n",
        "print(\"\\n\u2601\ufe0f Step 6: Creating Free Tier Cluster\")\n",
        "print(\"-\"*70)\n",
        "print(\"\u23f3 This will take 10-15 minutes for cluster deployment...\\n\")\n",
        "cluster_id = create_developer_pro_cluster(client, org_id, project_id, config.cluster_name, config)\n",
        "# Wait for cluster to be ready\n",
        "cluster_check_url = f\"/v4/organizations/{org_id}/projects/{project_id}/clusters/{cluster_id}\"\n",
        "cluster_details = client.wait_for_resource(cluster_check_url, \"Cluster\", None)\n",
        "cluster_conn_string = cluster_details.get(\"connectionString\")\n",
        "\n",
        "# Ensure connection string has proper protocol\n",
        "if not cluster_conn_string.startswith(\"couchbase://\") and not cluster_conn_string.startswith(\"couchbases://\"):\n",
        "    cluster_conn_string = f\"couchbases://{cluster_conn_string}\"\n",
        "    print(f\"\u26a0\ufe0f  Added protocol to connection string: {cluster_conn_string}\")\n",
        "\n",
        "print(f\"\u2705 Cluster ready: {config.cluster_name} (ID: {cluster_id})\\n\")\n",
        "\n",
        "# Step 7: Configure network access\n",
        "print(\"\\n\ud83c\udf10 Step 7: Configuring Network Access\")\n",
        "print(\"-\"*70)\n",
        "add_allowed_cidr(client, org_id, project_id, cluster_id, config.allowed_cidr)\n",
        "print(\"\u2705 Network access configured (0.0.0.0/0 allowed)\\n\")\n",
        "\n",
        "# Step 8: Load travel-sample bucket\n",
        "print(\"\\n\ud83d\udce6 Step 8: Loading travel-sample Bucket\")\n",
        "print(\"-\"*70)\n",
        "load_sample_data(client, org_id, project_id, cluster_id, config.sample_bucket)\n",
        "print(f\"\u2705 Sample data loaded: {config.sample_bucket}\\n\")\n",
        "\n",
        "# Step 9: Create database user (password auto-generated)\n",
        "print(\"\\n\ud83d\udc64 Step 9: Creating Database User\")\n",
        "print(\"-\"*70)\n",
        "db_password = create_database_user(\n",
        "    client,\n",
        "    org_id,\n",
        "    project_id,\n",
        "    cluster_id,\n",
        "    config.db_username,\n",
        "    config.sample_bucket,\n",
        "    recreate_if_exists=True,  # Delete and recreate if exists to get fresh password\n",
        ")\n",
        "print(f\"\u2705 Database user created: {config.db_username}\\n\")\n",
        "if db_password and db_password != \"existing_user_password_not_retrievable\":\n",
        "    print(f\"   Auto-generated password: {db_password[:4]}...{db_password[-4:]}\\n\")\n",
        "\n",
        "# Step 10: Deploy AI models\n",
        "print(\"\\n\ud83e\udd16 Step 10: Deploying AI Models\")\n",
        "print(\"-\"*70)\n",
        "print(\"\u23f3 Deploying embedding and LLM models (5-10 minutes)...\\n\")\n",
        "\n",
        "# Deploy Embedding Model\n",
        "print(\"   Deploying embedding model...\")\n",
        "embedding_model_id = deploy_ai_model(\n",
        "    client,\n",
        "    org_id,\n",
        "    config.embedding_model_name,\n",
        "    \"agent-hub-embedding-model\",\n",
        "    \"embedding\",\n",
        "    config,\n",
        ")\n",
        "embedding_check_url = f\"/v4/organizations/{org_id}/aiServices/models/{embedding_model_id}\"\n",
        "embedding_details = client.wait_for_resource(embedding_check_url, \"Embedding Model\", None)\n",
        "\n",
        "# Extract endpoint from nested 'model' object\n",
        "model_info = embedding_details.get(\"model\", {})\n",
        "embedding_endpoint = model_info.get(\"connectionString\", \"\")\n",
        "\n",
        "print(f\"\u2705 Embedding model deployed: {config.embedding_model_name}\")\n",
        "print(f\"   Endpoint: {embedding_endpoint}\\n\")\n",
        "\n",
        "# Deploy LLM Model\n",
        "print(\"   Deploying LLM model...\")\n",
        "llm_model_id = deploy_ai_model(\n",
        "    client,\n",
        "    org_id,\n",
        "    config.llm_model_name,\n",
        "    \"agent-hub-llm-model\",\n",
        "    \"llm\",\n",
        "    config,\n",
        ")\n",
        "llm_check_url = f\"/v4/organizations/{org_id}/aiServices/models/{llm_model_id}\"\n",
        "llm_details = client.wait_for_resource(llm_check_url, \"LLM Model\", None)\n",
        "\n",
        "# Extract endpoint from nested 'model' object\n",
        "llm_model_info = llm_details.get(\"model\", {})\n",
        "llm_endpoint = llm_model_info.get(\"connectionString\", \"\")\n",
        "\n",
        "print(f\"\u2705 LLM model deployed: {config.llm_model_name}\")\n",
        "print(f\"   Endpoint: {llm_endpoint}\\n\")\n",
        "\n",
        "# Step 11: Create API Key for AI models\n",
        "print(\"\\n\ud83d\udd11 Step 11: Creating API Key for AI Models\")\n",
        "print(\"-\"*70)\n",
        "api_key = create_ai_api_key(client, org_id, config.ai_model_region)\n",
        "print(f\"\u2705 AI API key created\\n\")\n",
        "\n",
        "# Step 12: Set environment variables\n",
        "print(\"\\n\u2699\ufe0f Step 12: Setting Environment Variables\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Set all environment variables for subsequent cells\n",
        "os.environ[\"CB_CONN_STRING\"] = cluster_conn_string + \"?tls_verify=none\"\n",
        "os.environ[\"CB_USERNAME\"] = config.db_username\n",
        "os.environ[\"CB_PASSWORD\"] = db_password\n",
        "os.environ[\"CB_BUCKET\"] = config.sample_bucket\n",
        "os.environ[\"CAPELLA_API_ENDPOINT\"] = embedding_endpoint  # Use as base endpoint\n",
        "os.environ[\"CAPELLA_API_EMBEDDING_ENDPOINT\"] = embedding_endpoint\n",
        "os.environ[\"CAPELLA_API_LLM_ENDPOINT\"] = llm_endpoint\n",
        "os.environ[\"CAPELLA_API_EMBEDDINGS_KEY\"] = api_key\n",
        "os.environ[\"CAPELLA_API_LLM_KEY\"] = api_key\n",
        "os.environ[\"CAPELLA_API_EMBEDDING_MODEL\"] = config.embedding_model_name\n",
        "os.environ[\"CAPELLA_API_LLM_MODEL\"] = config.llm_model_name\n",
        "\n",
        "print(\"\u2705 Environment variables configured:\\n\")\n",
        "print(f\"   CB_CONN_STRING: {cluster_conn_string}\")\n",
        "print(f\"   CB_USERNAME: {config.db_username}\")\n",
        "print(f\"   CB_BUCKET: {config.sample_bucket}\")\n",
        "print(f\"   CAPELLA_API_EMBEDDING_ENDPOINT: {embedding_endpoint}\")\n",
        "print(f\"   CAPELLA_API_LLM_ENDPOINT: {llm_endpoint}\")\n",
        "print(f\"   CAPELLA_API_EMBEDDING_MODEL: {config.embedding_model_name}\")\n",
        "print(f\"   CAPELLA_API_LLM_MODEL: {config.llm_model_name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 Infrastructure Setup Complete!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou can now run the landmark search agent cells below.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "F48_JK8MldFQ",
        "outputId": "61959b93-8d07-4cb9-fa4c-142acbb7c299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Agent Catalog environment variables set:\n",
            "   AGENT_CATALOG_CONN_STRING: couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com\n",
            "   AGENT_CATALOG_USERNAME: agent_app_user\n",
            "   AGENT_CATALOG_BUCKET: travel-sample\n",
            "\n",
            "======================================================================\n",
            "\ud83d\udcdc Root Certificate Setup\n",
            "======================================================================\n",
            "\n",
            "\u26a0\ufe0f  IMPORTANT: You need to download the root certificate from Capella UI\n",
            "\n",
            "Steps:\n",
            "1. Go to Capella Console: https://cloud.couchbase.com\n",
            "2. Navigate to your cluster \u2192 Connect tab\n",
            "3. Download the 'Root Certificate' file\n",
            "4. Upload it using the file upload below\n",
            "\n",
            "\ud83d\udce4 Please upload your root certificate file:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b272ffe6-0f47-41aa-8dbf-24bd24b89ecd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b272ffe6-0f47-41aa-8dbf-24bd24b89ecd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving agent-app-cluster-root-certificate.txt to agent-app-cluster-root-certificate.txt\n",
            "\n",
            "\u2705 Root certificate uploaded: agent-app-cluster-root-certificate.txt\n",
            "   AGENT_CATALOG_CONN_ROOT_CERTIFICATE: agent-app-cluster-root-certificate.txt\n",
            "\n",
            "======================================================================\n",
            "\u2705 Agent Catalog Configuration Complete\n",
            "======================================================================\n",
            "\n",
            "\u2705 Environment variables written to .env file for agentc commands\n"
          ]
        }
      ],
      "source": [
        "# Set Agent Catalog environment variables (required for agentc commands)\n",
        "# These use the same Couchbase connection created above\n",
        "import os\n",
        "\n",
        "# Strip TLS parameters from connection string for Agent Catalog\n",
        "agent_catalog_conn_string = os.environ[\"CB_CONN_STRING\"].split(\"?\")[0]\n",
        "os.environ[\"AGENT_CATALOG_CONN_STRING\"] = agent_catalog_conn_string\n",
        "os.environ[\"AGENT_CATALOG_USERNAME\"] = os.environ[\"CB_USERNAME\"]\n",
        "os.environ[\"AGENT_CATALOG_PASSWORD\"] = os.environ[\"CB_PASSWORD\"]\n",
        "os.environ[\"AGENT_CATALOG_BUCKET\"] = os.environ[\"CB_BUCKET\"]\n",
        "\n",
        "print(\"\u2705 Agent Catalog environment variables set:\")\n",
        "print(f\"   AGENT_CATALOG_CONN_STRING: {os.environ['AGENT_CATALOG_CONN_STRING']}\")\n",
        "print(f\"   AGENT_CATALOG_USERNAME: {os.environ['AGENT_CATALOG_USERNAME']}\")\n",
        "print(f\"   AGENT_CATALOG_BUCKET: {os.environ['AGENT_CATALOG_BUCKET']}\")\n",
        "\n",
        "\n",
        "# Handle root certificate (required for secure connections)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\ud83d\udcdc Root Certificate Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n\u26a0\ufe0f  IMPORTANT: You need to download the root certificate from Capella UI\")\n",
        "print(\"\\nSteps:\")\n",
        "print(\"1. Go to Capella Console: https://cloud.couchbase.com\")\n",
        "print(\"2. Navigate to your cluster \u2192 Connect tab\")\n",
        "print(\"3. Download the 'Root Certificate' file\")\n",
        "print(\"4. Upload it using the file upload below\\n\")\n",
        "\n",
        "# Try to use Google Colab's file upload, fallback to manual input\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\ud83d\udce4 Please upload your root certificate file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        cert_filename = list(uploaded.keys())[0]\n",
        "        # Validate it's actually a certificate file\n",
        "        if cert_filename.endswith(('.pem', '.crt', '.cer', '.txt')):\n",
        "            os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = cert_filename\n",
        "            print(f\"\\n\u2705 Root certificate uploaded: {cert_filename}\")\n",
        "            print(f\"   AGENT_CATALOG_CONN_ROOT_CERTIFICATE: {cert_filename}\")\n",
        "        else:\n",
        "            print(f\"\\n\u26a0\ufe0f  Uploaded file '{cert_filename}' doesn't appear to be a certificate (.pem, .crt, .cer, .txt)\")\n",
        "            print(\"   Skipping certificate setup. You can configure it later if needed.\")\n",
        "            os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "    else:\n",
        "        print(\"\\n\u26a0\ufe0f  No file uploaded. You can set it manually later if needed.\")\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "except ImportError:\n",
        "    # Not in Colab - ask user to place file and provide filename\n",
        "    print(\"\ud83d\udcdd Not running in Google Colab.\")\n",
        "    print(\"   Please place the root certificate file in the current directory.\\n\")\n",
        "    cert_filename = input(\"Enter the certificate filename (or press Enter to skip): \").strip()\n",
        "\n",
        "    if cert_filename:\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = cert_filename\n",
        "        print(f\"\\n\u2705 Root certificate set: {cert_filename}\")\n",
        "    else:\n",
        "        print(\"\\n\u26a0\ufe0f  Root certificate not set. You can add it manually later if needed.\")\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 Agent Catalog Configuration Complete\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Write environment variables to .env file for agentc commands\n",
        "# agentc CLI will load from .env file automatically\n",
        "import os.path\n",
        "with open('.env', 'w') as f:\n",
        "    # CB variables (needed for database operations - prevents wiping by dotenv.load_dotenv)\n",
        "    f.write(f\"CB_CONN_STRING={os.environ['CB_CONN_STRING']}\\n\")\n",
        "    f.write(f\"CB_USERNAME={os.environ['CB_USERNAME']}\\n\")\n",
        "    f.write(f\"CB_PASSWORD={os.environ['CB_PASSWORD']}\\n\")\n",
        "    f.write(f\"CB_BUCKET={os.environ['CB_BUCKET']}\\n\")\n",
        "    f.write(f\"CB_SCOPE={os.environ.get('CB_SCOPE', 'agentc_data')}\\n\")\n",
        "    f.write(f\"CB_COLLECTION={os.environ.get('CB_COLLECTION', 'landmark_data')}\\n\")\n",
        "    f.write(f\"CB_INDEX={os.environ.get('CB_INDEX', 'landmark_data_index')}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    # Capella AI API variables\n",
        "    f.write(f\"CAPELLA_API_ENDPOINT={os.environ.get('CAPELLA_API_ENDPOINT', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDING_MODEL={os.environ.get('CAPELLA_API_EMBEDDING_MODEL', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDINGS_KEY={os.environ.get('CAPELLA_API_EMBEDDINGS_KEY', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_MODEL={os.environ.get('CAPELLA_API_LLM_MODEL', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_KEY={os.environ.get('CAPELLA_API_LLM_KEY', '')}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    # Agent Catalog Configuration\n",
        "    f.write(f\"AGENT_CATALOG_CONN_STRING={os.environ['AGENT_CATALOG_CONN_STRING']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_USERNAME={os.environ['AGENT_CATALOG_USERNAME']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_PASSWORD={os.environ['AGENT_CATALOG_PASSWORD']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_BUCKET={os.environ['AGENT_CATALOG_BUCKET']}\\n\")\n",
        "\n",
        "\n",
        "    # Write certificate if set\n",
        "    cert = os.environ.get('AGENT_CATALOG_CONN_ROOT_CERTIFICATE', '').strip()\n",
        "    if cert:\n",
        "        f.write(f\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE={cert}\\n\")\n",
        "\n",
        "print(\"\\n\u2705 Environment variables written to .env file for agentc commands\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ppq-zs0ldFR"
      },
      "source": [
        "### Optional: Configure OpenAI and Arize (Observability)\n",
        "\n",
        "Provide optional API keys for:\n",
        "- **OpenAI**: Fallback LLM/embeddings if Capella AI is unavailable\n",
        "- **Arize Phoenix**: Observability and evaluation platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-IQdwDPldFR",
        "outputId": "2d47c9f7-e21a-42fe-84d3-8b3defd05036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "\ud83d\udd27 Optional API Keys Configuration\n",
            "======================================================================\n",
            "\n",
            "\ud83d\udcdd OpenAI API (Optional - for fallback LLM/embeddings)\n",
            "----------------------------------------------------------------------\n",
            "Press Enter to skip, or provide your OpenAI API key:\n",
            "OpenAI API Key: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n",
            "\u2705 OpenAI API key configured\n",
            "   Model: gpt-4o\n",
            "\n",
            "\ud83d\udcca Arize Phoenix (Optional - for observability and evaluation)\n",
            "----------------------------------------------------------------------\n",
            "Press Enter to skip, or provide your Arize credentials:\n",
            "Arize Space ID: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n",
            "Arize API Key: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n",
            "\u2705 Arize Phoenix configured\n",
            "\n",
            "======================================================================\n",
            "\u2705 Optional Configuration Complete\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udd27 Optional API Keys Configuration\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# OpenAI Configuration (optional - for fallback)\n",
        "print(\"\\n\ud83d\udcdd OpenAI API (Optional - for fallback LLM/embeddings)\")\n",
        "print(\"-\"*70)\n",
        "print(\"Press Enter to skip, or provide your OpenAI API key:\")\n",
        "try:\n",
        "    openai_api_key = getpass.getpass(\"OpenAI API Key: \").strip()\n",
        "except:\n",
        "    # Fallback for environments where getpass doesn't work\n",
        "    openai_api_key = \"\"\n",
        "\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gpt-4o\"  # Default model\n",
        "    print(\"\u2705 OpenAI API key configured\")\n",
        "    print(f\"   Model: gpt-4o\")\n",
        "else:\n",
        "    print(\"\u23ed\ufe0f  Skipped OpenAI configuration (will use Capella AI only)\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gpt-4o\"\n",
        "\n",
        "# Arize Phoenix Configuration (optional - for observability)\n",
        "print(\"\\n\ud83d\udcca Arize Phoenix (Optional - for observability and evaluation)\")\n",
        "print(\"-\"*70)\n",
        "print(\"Press Enter to skip, or provide your Arize credentials:\")\n",
        "try:\n",
        "    arize_space_id = getpass.getpass(\"Arize Space ID: \").strip()\n",
        "    arize_api_key = getpass.getpass(\"Arize API Key: \").strip() if arize_space_id else \"\"\n",
        "except:\n",
        "    # Fallback for environments where getpass doesn't work\n",
        "    arize_space_id = \"\"\n",
        "    arize_api_key = \"\"\n",
        "\n",
        "if arize_space_id and arize_api_key:\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = arize_space_id\n",
        "    os.environ[\"ARIZE_API_KEY\"] = arize_api_key\n",
        "    print(\"\u2705 Arize Phoenix configured\")\n",
        "else:\n",
        "    print(\"\u23ed\ufe0f  Skipped Arize configuration (observability disabled)\")\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = \"\"\n",
        "    os.environ[\"ARIZE_API_KEY\"] = \"\"\n",
        "\n",
        "# Append optional variables to .env file\n",
        "with open('.env', 'a') as f:\n",
        "    f.write(\"\\n# Optional: OpenAI Configuration (fallback LLM/embeddings)\\n\")\n",
        "    f.write(f\"OPENAI_API_KEY={os.environ['OPENAI_API_KEY']}\\n\")\n",
        "    f.write(f\"OPENAI_MODEL={os.environ['OPENAI_MODEL']}\\n\")\n",
        "\n",
        "    f.write(\"\\n# Optional: Arize Phoenix (observability and evaluation)\\n\")\n",
        "    f.write(f\"ARIZE_SPACE_ID={os.environ['ARIZE_SPACE_ID']}\\n\")\n",
        "    f.write(f\"ARIZE_API_KEY={os.environ['ARIZE_API_KEY']}\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 Optional Configuration Complete\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79l6m7qZldFR",
        "outputId": "625e2a60-0044-4fd2-fa75-47621b0e4523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ],
      "source": [
        "!git init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C--c6yLWldFR",
        "outputId": "30bf4afd-5daa-4e14-c558-bf9c85eb5809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[master (root-commit) a33c419] initial commit\n",
            " 27 files changed, 51546 insertions(+)\n",
            " create mode 100644 .agentcignore\n",
            " create mode 100644 .config/.last_opt_in_prompt.yaml\n",
            " create mode 100644 .config/.last_survey_prompt.yaml\n",
            " create mode 100644 .config/.last_update_check.json\n",
            " create mode 100644 .config/active_config\n",
            " create mode 100644 .config/config_sentinel\n",
            " create mode 100644 .config/configurations/config_default\n",
            " create mode 100644 .config/default_configs.db\n",
            " create mode 100644 .config/gce\n",
            " create mode 100644 .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            " create mode 100644 .config/logs/2025.10.22/13.37.51.566274.log\n",
            " create mode 100644 .config/logs/2025.10.22/13.38.25.983338.log\n",
            " create mode 100644 .config/logs/2025.10.22/13.38.34.894138.log\n",
            " create mode 100644 .config/logs/2025.10.22/13.38.40.152011.log\n",
            " create mode 100644 .config/logs/2025.10.22/13.38.48.808237.log\n",
            " create mode 100644 .config/logs/2025.10.22/13.38.49.564834.log\n",
            " create mode 100644 .env\n",
            " create mode 100644 agent-app-cluster-root-certificate.txt\n",
            " create mode 100644 agentcatalog_index.json\n",
            " create mode 100644 prompts/landmark_search_assistant.yaml\n",
            " create mode 100755 sample_data/README.md\n",
            " create mode 100755 sample_data/anscombe.json\n",
            " create mode 100644 sample_data/california_housing_test.csv\n",
            " create mode 100644 sample_data/california_housing_train.csv\n",
            " create mode 100644 sample_data/mnist_test.csv\n",
            " create mode 100644 sample_data/mnist_train_small.csv\n",
            " create mode 100644 tools/search_landmarks.py\n"
          ]
        }
      ],
      "source": [
        "!git add .\n",
        "!git config --global user.email \"your.email@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "!git commit -m \"initial commit\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u-YZgFVldFR",
        "outputId": "98a62e5d-68fc-4a24-9565-8472691a0fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-10-24 09:44:13.358477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761299053.383632    1544 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761299053.391477    1544 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761299053.410449    1544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761299053.410492    1544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761299053.410497    1544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761299053.410501    1544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-24 09:44:13.416314: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:agentc_core.learned.embedding:Failed to load embedding model sentence-transformers/all-MiniLM-L12-v2 (attempt 0): We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Check your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.53MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 453kB/s]\n",
            "README.md: 10.5kB [00:00, 20.0MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 211kB/s]\n",
            "config.json: 100% 615/615 [00:00<00:00, 3.46MB/s]\n",
            "model.safetensors: 100% 133M/133M [00:01<00:00, 80.4MB/s]\n",
            "tokenizer_config.json: 100% 352/352 [00:00<00:00, 1.74MB/s]\n",
            "vocab.txt: 232kB [00:00, 20.6MB/s]\n",
            "tokenizer.json: 466kB [00:00, 48.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 453kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.05MB/s]\n",
            "\u001b[32mMetadata collection has been successfully created!\n",
            "\u001b[0m\n",
            "v2_AgentCatalogMetadataPrimaryIndex: 100% 1/1 [00:01<00:00,  1.09s/it]\n",
            "\u001b[32mGSI metadata index for the has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the catalog collection for the prompt catalog.\u001b[0m\n",
            "\u001b[32mCollection for prompts has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the GSI indexes for the prompt catalog.\u001b[0m\n",
            "v2_AgentCatalogPromptsAnnotationsIndex: 100% 3/3 [00:03<00:00,  1.07s/it]\n",
            "\u001b[32mAll GSI indexes for the prompt catalog have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the vector index for the prompt catalog.\u001b[0m\n",
            "\u001b[32mVector index for the prompt catalog has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the catalog collection for the tool catalog.\u001b[0m\n",
            "\u001b[32mCollection for tools has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the GSI indexes for the tool catalog.\u001b[0m\n",
            "v2_AgentCatalogToolsAnnotationsIndex: 100% 3/3 [00:03<00:00,  1.07s/it]\n",
            "\u001b[32mAll GSI indexes for the tool catalog have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the vector index for the tool catalog.\u001b[0m\n",
            "\u001b[32mVector index for the tool catalog has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the analytics collections for our catalog.\u001b[0m\n",
            "\u001b[32mAll analytics collections for the catalog have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating scope and collections for the auditor.\u001b[0m\n",
            "\u001b[32mScope and collection for the auditor have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the primary index for the auditor.\u001b[0m\n",
            "v2_AgentCatalogLogsPrimaryIndex: 100% 1/1 [00:01<00:00,  1.10s/it]\n",
            "\u001b[32mPrimary index for the auditor has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the query UDFs for the auditor.\u001b[0m\n",
            "\u001b[32mAll query UDFs for the auditor have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the analytics views for the auditor.\u001b[0m\n",
            "\u001b[32mAll analytics views for the auditor have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[32mPost-commit hook for  have successfully been installed!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!agentc init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYzg3uhSldFR",
        "outputId": "17b7a7c2-8d33-4484-e268-2f29e4d31b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[95m\u001b[0m\n",
            "\u001b[95m\u001b[1mTOOL\u001b[0m\n",
            "\u001b[95m\u001b[0m\n",
            "Crawling .:\u001b[0m\n",
            "\r  0% 0/4 [00:00<?, ?it/s]\r.last_opt_in_prompt.yaml:   0% 0/4 [00:00<?, ?it/s]Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_opt_in_prompt.yaml.\n",
            ".last_survey_prompt.yaml:   0% 0/4 [00:00<?, ?it/s]Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_survey_prompt.yaml.\n",
            "search_landmarks.py: 100% 4/4 [00:02<00:00,  1.66it/s]\n",
            "\n",
            "Generating embeddings:\u001b[0m\n",
            "search_landmarks:   0% 0/1 [00:00<?, ?it/s]2025-10-24 09:44:51.973865: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761299091.998503    1807 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761299092.005497    1807 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761299092.022729    1807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761299092.022771    1807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761299092.022776    1807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761299092.022781    1807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-24 09:44:52.028303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "search_landmarks: 100% 1/1 [00:12<00:00, 12.70s/it]\n",
            "\u001b[32m\n",
            "Catalog successfully indexed!\u001b[0m\n",
            "\u001b[95m\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "\u001b[34m\u001b[1mPROMPT\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "Crawling .:\u001b[0m\n",
            ".last_opt_in_prompt.yaml:   0% 0/3 [00:00<?, ?it/s]WARNING:agentc_core.indexer.indexer:Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_opt_in_prompt.yaml.\n",
            ".last_survey_prompt.yaml:   0% 0/3 [00:00<?, ?it/s]WARNING:agentc_core.indexer.indexer:Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_survey_prompt.yaml.\n",
            "landmark_search_assistant.yaml: 100% 3/3 [00:00<00:00, 179.28it/s]\n",
            "\n",
            "Generating embeddings:\u001b[0m\n",
            "landmark_search_assistant: 100% 1/1 [00:00<00:00,  5.55it/s]\n",
            "\u001b[32m\n",
            "Catalog successfully indexed!\u001b[0m\n",
            "\u001b[34m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!agentc index .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBGZhnDLldFR",
        "outputId": "3ec90dd1-635a-4503-d83d-a564e7e63e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[95m\u001b[0m\n",
            "\u001b[95m\u001b[1mTOOL\u001b[0m\n",
            "\u001b[95m\u001b[0m\n",
            "Using the catalog identifier: \u001b[0m\u001b[1ma33c419b3b473b208716646f7b31df6ee8aa604d\n",
            "\u001b[0m\n",
            "\u001b[33mUploading the tool catalog items to Couchbase.\u001b[0m\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\rsearch_landmarks:   0% 0/1 [00:00<?, ?it/s]\rsearch_landmarks: 100% 1/1 [00:00<00:00, 136.66it/s]\n",
            "\u001b[32mTool catalog items successfully uploaded to Couchbase!\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "\u001b[34m\u001b[1mPROMPT\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "Using the catalog identifier: \u001b[0m\u001b[1ma33c419b3b473b208716646f7b31df6ee8aa604d\n",
            "\u001b[0m\n",
            "\u001b[33mUploading the prompt catalog items to Couchbase.\u001b[0m\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\rlandmark_search_assistant:   0% 0/1 [00:00<?, ?it/s]\rlandmark_search_assistant: 100% 1/1 [00:00<00:00, 158.32it/s]\n",
            "\u001b[32mPrompt catalog items successfully uploaded to Couchbase!\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!agentc publish\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0w8vtNAldFR",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary modules and set up logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdiGC7QQldFR",
        "outputId": "1dae38b9-b521-4ce9-88a0-179d5d686262"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 All imports loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import getpass\n",
        "import httpx\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import agentc\n",
        "import dotenv\n",
        "import nest_asyncio\n",
        "import pandas as pd\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.management.buckets import BucketType, CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from llama_index.core import Settings, Document, VectorStoreIndex\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.nvidia import NVIDIA\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Apply nest_asyncio for Jupyter compatibility\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Setup Colab-compatible logging\n",
        "root_logger = logging.getLogger()\n",
        "if not root_logger.handlers:\n",
        "    handler = logging.StreamHandler(sys.stdout)\n",
        "    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
        "    handler.setFormatter(formatter)\n",
        "    root_logger.addHandler(handler)\n",
        "root_logger.setLevel(logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Reduce noise from various libraries\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv(override=True)\n",
        "\n",
        "# Configuration constants\n",
        "DEFAULT_BUCKET = \"travel-sample\"\n",
        "DEFAULT_SCOPE = \"agentc_data\"\n",
        "DEFAULT_COLLECTION = \"landmark_data\"\n",
        "DEFAULT_INDEX = \"landmark_data_index\"\n",
        "DEFAULT_CAPELLA_API_EMBEDDING_MODEL = \"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
        "DEFAULT_CAPELLA_API_LLM_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "DEFAULT_NVIDIA_API_LLM_MODEL = \"meta/llama-3.1-70b-instruct\"\n",
        "\n",
        "logger.info(\"\u2705 All imports loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14TQpYLzldFS",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Environment Setup Functions\n",
        "\n",
        "Setup functions for environment configuration and AI services.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0stNHY1WldFS",
        "outputId": "41a5b8ff-2a04-4dee-eb59-4ccbd310e678"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Environment variables configured\n"
          ]
        }
      ],
      "source": [
        "def setup_environment():\n",
        "    \"\"\"Setup default environment variables for agent operations.\"\"\"\n",
        "    defaults = {\n",
        "        \"CB_BUCKET\": \"travel-sample\",\n",
        "        \"CB_SCOPE\": \"agentc_data\",\n",
        "        \"CB_COLLECTION\": \"landmark_data\",\n",
        "        \"CB_INDEX\": \"landmark_data_index\",\n",
        "        \"NVIDIA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"NVIDIA_API_LLM_MODEL\": \"meta/llama-3.1-70b-instruct\",\n",
        "        \"CAPELLA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"CAPELLA_API_LLM_MODEL\": \"meta/llama-3-8b-instruct\",\n",
        "    }\n",
        "\n",
        "    for key, value in defaults.items():\n",
        "        if not os.getenv(key):\n",
        "            os.environ[key] = value\n",
        "\n",
        "    logger.info(\"\u2705 Environment variables configured\")\n",
        "\n",
        "\n",
        "def test_capella_connectivity(api_key: str = None, endpoint: str = None) -> bool:\n",
        "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
        "    try:\n",
        "        test_key = api_key or os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\") or os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "        test_endpoint = endpoint or os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "\n",
        "        if not test_key or not test_endpoint:\n",
        "            return False\n",
        "\n",
        "        headers = {\"Authorization\": f\"Bearer {test_key}\"}\n",
        "\n",
        "        with httpx.Client(timeout=10.0) as client:\n",
        "            response = client.get(f\"{test_endpoint.rstrip('/')}/v1/models\", headers=headers)\n",
        "            return response.status_code < 500\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"\u26a0\ufe0f Capella connectivity test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def setup_ai_services(framework: str = \"llamaindex\", temperature: float = 0.0, application_span=None):\n",
        "    \"\"\"Priority 1: Capella AI with OpenAI wrappers (simple & fast) for LlamaIndex.\"\"\"\n",
        "    embeddings = None\n",
        "    llm = None\n",
        "\n",
        "    logger.info(f\"\ud83d\udd27 Setting up Priority 1 AI services for {framework} framework...\")\n",
        "\n",
        "    # Priority 1: Capella AI with direct API keys and OpenAI wrappers\n",
        "    if not embeddings and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            api_key = os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "            model = os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\")\n",
        "\n",
        "            api_base = endpoint if endpoint.endswith('/v1') else f\"{endpoint}/v1\"\n",
        "\n",
        "            embeddings = OpenAIEmbedding(\n",
        "                api_key=api_key,\n",
        "                api_base=api_base,\n",
        "                model_name=model,\n",
        "                embed_batch_size=30,\n",
        "            )\n",
        "            logger.info(\"\u2705 Using Priority 1: Capella AI embeddings (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"\u274c Priority 1 Capella AI embeddings failed: {type(e).__name__}: {e}\")\n",
        "\n",
        "    if not llm and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_LLM_KEY\"):\n",
        "        try:\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            llm_key = os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "            llm_model = os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
        "\n",
        "            api_base = endpoint if endpoint.endswith('/v1') else f\"{endpoint}/v1\"\n",
        "\n",
        "            llm = OpenAILike(\n",
        "                model=llm_model,\n",
        "                api_base=api_base,\n",
        "                api_key=llm_key,\n",
        "                is_chat_model=True,\n",
        "                is_function_calling_model=False,\n",
        "                context_window=128000,\n",
        "                temperature=temperature,\n",
        "                max_retries=1,\n",
        "            )\n",
        "            # Test the LLM works\n",
        "            test_response = llm.complete(\"Hello\")\n",
        "            logger.info(\"\u2705 Using Priority 1: Capella AI LLM (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"\u274c Priority 1 Capella AI LLM failed: {type(e).__name__}: {e}\")\n",
        "            llm = None\n",
        "\n",
        "    # Fallback: OpenAI\n",
        "    if not embeddings and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            embeddings = OpenAIEmbedding(\n",
        "                model_name=\"text-embedding-3-small\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "            )\n",
        "            logger.info(\"\u2705 Using OpenAI embeddings fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"\u26a0\ufe0f OpenAI embeddings failed: {e}\")\n",
        "\n",
        "    if not llm and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            llm = OpenAILike(\n",
        "                model=\"gpt-4o\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                is_chat_model=True,\n",
        "                is_function_calling_model=False,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            logger.info(\"\u2705 Using OpenAI LLM fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"\u26a0\ufe0f OpenAI LLM failed: {e}\")\n",
        "\n",
        "    if not embeddings:\n",
        "        raise ValueError(\"\u274c No embeddings service could be initialized\")\n",
        "    if not llm:\n",
        "        raise ValueError(\"\u274c No LLM service could be initialized\")\n",
        "\n",
        "    logger.info(f\"\u2705 Priority 1 AI services setup completed for {framework}\")\n",
        "    return embeddings, llm\n",
        "\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()\n",
        "\n",
        "# Test Capella AI connectivity if configured\n",
        "if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "    if not test_capella_connectivity():\n",
        "        logger.warning(\"\u274c Capella AI connectivity test failed. Will use fallback models.\")\n",
        "else:\n",
        "    logger.info(\"\u2139\ufe0f Capella API not configured - will use fallback models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjNcZZiYldFS",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Loading Functions\n",
        "\n",
        "Functions to load landmark data from travel-sample.inventory.landmark collection.\n",
        "**IMPORTANT**: These functions are defined here BEFORE the CouchbaseClient class to avoid NameError issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCn9TLT6ldFS",
        "outputId": "f53cac11-d1a4-43b8-c5e4-8036b527f633"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Data loading functions defined\n"
          ]
        }
      ],
      "source": [
        "def get_cluster_connection():\n",
        "    \"\"\"Get a fresh cluster connection for each request.\"\"\"\n",
        "    try:\n",
        "        auth = PasswordAuthenticator(\n",
        "            username=os.environ[\"CB_USERNAME\"],\n",
        "            password=os.environ[\"CB_PASSWORD\"],\n",
        "        )\n",
        "        options = ClusterOptions(authenticator=auth)\n",
        "        options.apply_profile(\"wan_development\")\n",
        "\n",
        "        cluster = Cluster(\n",
        "            os.environ[\"CB_CONN_STRING\"], options\n",
        "        )\n",
        "        cluster.wait_until_ready(timedelta(seconds=15))\n",
        "        return cluster\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Could not connect to Couchbase cluster: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_landmark_data_from_travel_sample():\n",
        "    \"\"\"Load landmark data from travel-sample.inventory.landmark collection.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        query = \"\"\"\n",
        "        SELECT l.*, META(l).id as doc_id\n",
        "        FROM `travel-sample`.inventory.landmark l\n",
        "        ORDER BY l.name\n",
        "        \"\"\"\n",
        "\n",
        "        logger.info(\"Loading landmark data from travel-sample.inventory.landmark...\")\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        landmarks = []\n",
        "        logger.info(\"Processing landmark documents...\")\n",
        "\n",
        "        landmark_rows = list(result)\n",
        "        for row in tqdm(landmark_rows, desc=\"Loading landmarks\", unit=\"landmarks\"):\n",
        "            landmark = row\n",
        "            landmarks.append(landmark)\n",
        "\n",
        "        logger.info(f\"Loaded {len(landmarks)} landmarks from travel-sample.inventory.landmark\")\n",
        "        return landmarks\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading landmark data: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_landmark_texts():\n",
        "    \"\"\"Returns formatted landmark texts for vector store embedding from travel-sample data.\"\"\"\n",
        "    landmarks = load_landmark_data_from_travel_sample()\n",
        "    landmark_texts = []\n",
        "\n",
        "    logger.info(\"Generating landmark text embeddings...\")\n",
        "\n",
        "    for landmark in tqdm(landmarks, desc=\"Processing landmarks\", unit=\"landmarks\"):\n",
        "        name = landmark.get(\"name\", \"Unknown Landmark\")\n",
        "        title = landmark.get(\"title\", name)\n",
        "        city = landmark.get(\"city\", \"Unknown City\")\n",
        "        country = landmark.get(\"country\", \"Unknown Country\")\n",
        "\n",
        "        text_parts = [f\"{title} ({name}) in {city}, {country}\"]\n",
        "\n",
        "        field_mappings = {\n",
        "            \"content\": \"Description\",\n",
        "            \"address\": \"Address\",\n",
        "            \"directions\": \"Directions\",\n",
        "            \"phone\": \"Phone\",\n",
        "            \"tollfree\": \"Toll-free\",\n",
        "            \"email\": \"Email\",\n",
        "            \"url\": \"Website\",\n",
        "            \"hours\": \"Hours\",\n",
        "            \"price\": \"Price\",\n",
        "            \"activity\": \"Activity type\",\n",
        "            \"type\": \"Type\",\n",
        "            \"state\": \"State\",\n",
        "            \"alt\": \"Alternative name\",\n",
        "            \"image\": \"Image\",\n",
        "        }\n",
        "\n",
        "        for field, label in field_mappings.items():\n",
        "            value = landmark.get(field)\n",
        "            if value is not None and value != \"\" and value != \"None\":\n",
        "                if isinstance(value, bool):\n",
        "                    text_parts.append(f\"{label}: {'Yes' if value else 'No'}\")\n",
        "                else:\n",
        "                    text_parts.append(f\"{label}: {value}\")\n",
        "\n",
        "        if landmark.get(\"geo\"):\n",
        "            geo = landmark[\"geo\"]\n",
        "            if geo.get(\"lat\") and geo.get(\"lon\"):\n",
        "                accuracy = geo.get(\"accuracy\", \"Unknown\")\n",
        "                text_parts.append(f\"Coordinates: {geo['lat']}, {geo['lon']} (accuracy: {accuracy})\")\n",
        "\n",
        "        if landmark.get(\"id\"):\n",
        "            text_parts.append(f\"ID: {landmark['id']}\")\n",
        "\n",
        "        text = \". \".join(text_parts)\n",
        "        landmark_texts.append(text)\n",
        "\n",
        "    logger.info(f\"Generated {len(landmark_texts)} landmark text embeddings\")\n",
        "    return landmark_texts\n",
        "\n",
        "\n",
        "def load_landmark_data_to_couchbase(\n",
        "    cluster, bucket_name: str, scope_name: str, collection_name: str, embeddings, index_name: str\n",
        "):\n",
        "    \"\"\"Load landmark data from travel-sample into the target collection with embeddings.\"\"\"\n",
        "    try:\n",
        "        count_query = (\n",
        "            f\"SELECT COUNT(*) as count FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "        )\n",
        "        count_result = cluster.query(count_query)\n",
        "        count_row = list(count_result)[0]\n",
        "        existing_count = count_row[\"count\"]\n",
        "\n",
        "        if existing_count > 0:\n",
        "            logger.info(\n",
        "                f\"Found {existing_count} existing documents in collection, skipping data load\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        landmarks = load_landmark_data_from_travel_sample()\n",
        "        landmark_texts = get_landmark_texts()\n",
        "\n",
        "        vector_store = CouchbaseSearchVectorStore(\n",
        "            cluster=cluster,\n",
        "            bucket_name=bucket_name,\n",
        "            scope_name=scope_name,\n",
        "            collection_name=collection_name,\n",
        "            index_name=index_name,\n",
        "        )\n",
        "\n",
        "        logger.info(f\"Creating {len(landmark_texts)} LlamaIndex Documents...\")\n",
        "        documents = []\n",
        "\n",
        "        for i, (landmark, text) in enumerate(zip(landmarks, landmark_texts)):\n",
        "            document = Document(\n",
        "                text=text,\n",
        "                metadata={\n",
        "                    \"landmark_id\": landmark.get(\"id\", f\"landmark_{i}\"),\n",
        "                    \"name\": landmark.get(\"name\", \"Unknown\"),\n",
        "                    \"city\": landmark.get(\"city\", \"Unknown\"),\n",
        "                    \"country\": landmark.get(\"country\", \"Unknown\"),\n",
        "                    \"activity\": landmark.get(\"activity\", \"\"),\n",
        "                    \"type\": landmark.get(\"type\", \"\"),\n",
        "                    \"address\": landmark.get(\"address\", \"\"),\n",
        "                    \"phone\": landmark.get(\"phone\", \"\"),\n",
        "                    \"url\": landmark.get(\"url\", \"\"),\n",
        "                    \"hours\": landmark.get(\"hours\", \"\"),\n",
        "                    \"price\": landmark.get(\"price\", \"\"),\n",
        "                    \"state\": landmark.get(\"state\", \"\"),\n",
        "                }\n",
        "            )\n",
        "            documents.append(document)\n",
        "\n",
        "        logger.info(f\"Processing documents with ingestion pipeline...\")\n",
        "        pipeline = IngestionPipeline(\n",
        "            transformations=[SentenceSplitter(chunk_size=800, chunk_overlap=100), embeddings],\n",
        "            vector_store=vector_store,\n",
        "        )\n",
        "\n",
        "        batch_size = 25\n",
        "        total_batches = (len(documents) + batch_size - 1) // batch_size\n",
        "\n",
        "        logger.info(f\"Processing {len(documents)} documents in {total_batches} batches...\")\n",
        "\n",
        "        for i in tqdm(\n",
        "            range(0, len(documents), batch_size),\n",
        "            desc=\"Loading batches\",\n",
        "            unit=\"batch\",\n",
        "            total=total_batches,\n",
        "        ):\n",
        "            batch = documents[i : i + batch_size]\n",
        "            pipeline.run(documents=batch)\n",
        "\n",
        "        logger.info(\n",
        "            f\"Successfully loaded {len(documents)} landmark documents to vector store\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading landmark data to Couchbase: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_landmark_count():\n",
        "    \"\"\"Get the count of landmarks in travel-sample.inventory.landmark.\"\"\"\n",
        "    try:\n",
        "        cluster = get_cluster_connection()\n",
        "        if not cluster:\n",
        "            raise ConnectionError(\"Could not connect to Couchbase cluster\")\n",
        "\n",
        "        query = \"SELECT COUNT(*) as count FROM `travel-sample`.inventory.landmark\"\n",
        "        result = cluster.query(query)\n",
        "\n",
        "        for row in result:\n",
        "            return row[\"count\"]\n",
        "\n",
        "        return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting landmark count: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "logger.info(\"\u2705 Data loading functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKjb-jo8ldFS",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Query Functions and Reference Answers\n",
        "\n",
        "Query collections and reference answers from data/queries.py.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlVJygmdldFS",
        "outputId": "dd8b459c-55b0-46cf-9748-b2e66d153347"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Query functions defined\n"
          ]
        }
      ],
      "source": [
        "# Landmark search queries (based on travel-sample data)\n",
        "LANDMARK_SEARCH_QUERIES = [\n",
        "    \"Find museums and galleries in Glasgow\",\n",
        "    \"Show me restaurants serving Asian cuisine\",\n",
        "    \"What attractions can I see in Glasgow?\",\n",
        "    \"Tell me about Monet's House\",\n",
        "    \"Find places to eat in Gillingham\",\n",
        "]\n",
        "\n",
        "# Comprehensive reference answers based on ACTUAL agent responses\n",
        "LANDMARK_REFERENCE_ANSWERS = [\n",
        "    \"\"\"Glasgow has several museums and galleries including the Gallery of Modern Art (Glasgow) located at Royal Exchange Square with a terrific collection of recent paintings and sculptures, the Kelvingrove Art Gallery and Museum on Argyle Street with one of the finest civic collections in Europe including works by Van Gogh, Monet and Rembrandt, the Hunterian Museum and Art Gallery at University of Glasgow with a world famous Whistler collection, and the Riverside Museum at 100 Pointhouse Place with an excellent collection of vehicles and transport history. All offer free admission except for special exhibitions.\"\"\",\n",
        "\n",
        "    \"\"\"There are several Asian restaurants available including Shangri-la Chinese Restaurant in Birmingham at 51 Station Street offering good quality Chinese food with spring rolls and sizzling steak, Taiwan Restaurant in San Francisco famous for their dumplings, Hong Kong Seafood Restaurant in San Francisco for sit-down dim sum, Cheung Hing Chinese Restaurant in San Francisco for Cantonese BBQ and roast duck, Vietnam Restaurant in San Francisco for Vietnamese dishes including crab soup and pork sandwich, and various other Chinese and Asian establishments across different locations.\"\"\",\n",
        "\n",
        "    \"\"\"Glasgow attractions include Glasgow Green (founded by Royal grant in 1450) with Nelson's Memorial and the Doulton Fountain, Glasgow University (founded 1451) with neo-Gothic architecture and commanding views, Glasgow Cathedral with fine Gothic architecture from medieval times, the City Chambers in George Square built in 1888 in Italian Renaissance style with guided tours available, Glasgow Central Station with its grand interior, and Kelvingrove Park which is popular with students and contains the Art Gallery and Museum.\"\"\",\n",
        "\n",
        "    \"\"\"Monet's House is located in Giverny, France at 84 rue Claude Monet. The house is quietly eccentric and highly interesting in an Orient-influenced style, featuring Monet's collection of Japanese prints. The main attraction is the gardens around the house, including the water garden with the Japanese bridge, weeping willows and waterlilies which are now iconic. It's open April-October, Monday-Sunday 9:30-18:00, with admission \u20ac9 for adults, \u20ac5 for students, \u20ac4 for disabled visitors, and free for under-7s. E-tickets can be purchased online and wheelchair access is available.\"\"\",\n",
        "\n",
        "    \"\"\"Gillingham has various dining options including Beijing Inn (Chinese restaurant at 3 King Street), Spice Court (Indian restaurant at 56-58 Balmoral Road opposite the railway station, award-winning with Sunday Buffet for \u00a38.50), Hollywood Bowl (American-style restaurant at 4 High Street with burgers and ribs in a Hollywood-themed setting), Ossie's Fish and Chips (at 75 Richmond Road, known for the best fish and chips in the area), and Thai Won Mien (oriental restaurant at 59-61 High Street with noodles, duck and other oriental dishes).\"\"\",\n",
        "]\n",
        "\n",
        "# Create dictionary for reference lookup\n",
        "QUERY_REFERENCE_ANSWERS = {\n",
        "    query: answer for query, answer in zip(LANDMARK_SEARCH_QUERIES, LANDMARK_REFERENCE_ANSWERS)\n",
        "}\n",
        "\n",
        "def get_reference_answer(query: str) -> str:\n",
        "    \"\"\"Get reference answer for a specific query.\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS.get(query, \"No reference answer available for this query.\")\n",
        "\n",
        "def get_queries_for_evaluation(limit: int = 5) -> List[str]:\n",
        "    \"\"\"Get a subset of queries for evaluation purposes.\"\"\"\n",
        "    return LANDMARK_SEARCH_QUERIES[:limit]\n",
        "\n",
        "logger.info(\"\u2705 Query functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkyQK0lbldFS",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CouchbaseClient Class\n",
        "\n",
        "Centralized Couchbase client for all database operations and agent creation.\n",
        "**FIXED**: Now uses data loading functions defined above (no more NameError!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrcW9ZZ8ldFS",
        "outputId": "b73cd7ad-26c0-4d40-b059-1dc8c96c636c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 CouchbaseClient class defined\n"
          ]
        }
      ],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
        "\n",
        "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
        "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "            options.apply_profile(\"wan_development\")\n",
        "\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=20))\n",
        "            logger.info(\"Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Setup collection - create scope and collection if they don't exist.\"\"\"\n",
        "        try:\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            if not self.bucket:\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"Connected to bucket '{self.bucket_name}'\")\n",
        "\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
        "\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name\n",
        "                and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists:\n",
        "                logger.info(f\"Collection '{collection_name}' exists, clearing data...\")\n",
        "                self.clear_collection_data(scope_name, collection_name)\n",
        "            else:\n",
        "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
        "\n",
        "            time.sleep(3)\n",
        "\n",
        "            try:\n",
        "                self.cluster.query(\n",
        "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                ).execute()\n",
        "                logger.info(\"Primary index created successfully\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error creating primary index: {e}\")\n",
        "\n",
        "            logger.info(\"Collection setup complete\")\n",
        "            return self.bucket.scope(scope_name).collection(collection_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Clear all data from a collection.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "            rows = list(result)\n",
        "            time.sleep(2)\n",
        "\n",
        "            count_query = f\"SELECT COUNT(*) as count FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            count_result = self.cluster.query(count_query)\n",
        "            count_row = list(count_result)[0]\n",
        "            remaining_count = count_row[\"count\"]\n",
        "\n",
        "            if remaining_count == 0:\n",
        "                logger.info(f\"Collection cleared successfully, {remaining_count} documents remaining\")\n",
        "            else:\n",
        "                logger.warning(f\"Collection clear incomplete, {remaining_count} documents remaining\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error clearing collection data: {e}\")\n",
        "            pass\n",
        "\n",
        "    def get_collection(self, scope_name: str, collection_name: str):\n",
        "        \"\"\"Get a collection object.\"\"\"\n",
        "        key = f\"{scope_name}.{collection_name}\"\n",
        "        if key not in self._collections:\n",
        "            self._collections[key] = self.bucket.scope(scope_name).collection(collection_name)\n",
        "        return self._collections[key]\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                raise RuntimeError(\"Bucket not initialized. Call setup_collection first.\")\n",
        "\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
        "            else:\n",
        "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error setting up vector search index: {e!s}\")\n",
        "\n",
        "    def load_landmark_data(self, scope_name, collection_name, index_name, embeddings):\n",
        "        \"\"\"Load landmark data into Couchbase - FIXED: Now calls function defined above!\"\"\"\n",
        "        try:\n",
        "            # \u2705 FIXED: This function is now defined above in this notebook!\n",
        "            load_landmark_data_to_couchbase(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embeddings=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "            logger.info(\"Landmark data loaded into vector store successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading landmark data: {e!s}\")\n",
        "\n",
        "logger.info(\"\u2705 CouchbaseClient class defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Del5-QldFS",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Agent Creation Functions\n",
        "\n",
        "Functions to create the LlamaIndex ReAct agent with Agent Catalog integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-inqUlg-ldFS",
        "outputId": "31cd6e68-4507-4a35-acf5-a49e0ae7caa1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Agent creation functions defined\n"
          ]
        }
      ],
      "source": [
        "def create_llamaindex_agent(catalog, span):\n",
        "    \"\"\"Create LlamaIndex ReAct agent with landmark search tool from Agent Catalog.\"\"\"\n",
        "    try:\n",
        "        # Get tools from Agent Catalog\n",
        "        tools = []\n",
        "\n",
        "        # Search landmarks tool\n",
        "        search_tool_result = catalog.find(\"tool\", name=\"search_landmarks\")\n",
        "        if search_tool_result:\n",
        "            tools.append(\n",
        "                FunctionTool.from_defaults(\n",
        "                    fn=search_tool_result.func,\n",
        "                    name=\"search_landmarks\",\n",
        "                    description=getattr(search_tool_result.meta, \"description\", None)\n",
        "                    or \"Search for landmark information using semantic vector search. Use for finding attractions, monuments, museums, parks, and other points of interest.\",\n",
        "                )\n",
        "            )\n",
        "            logger.info(\"Loaded search_landmarks tool from AgentC\")\n",
        "\n",
        "        if not tools:\n",
        "            logger.warning(\"No tools found in Agent Catalog\")\n",
        "        else:\n",
        "            logger.info(f\"Loaded {len(tools)} tools from Agent Catalog\")\n",
        "\n",
        "        # Get prompt from Agent Catalog - REQUIRED, no fallbacks\n",
        "        prompt_result = catalog.find(\"prompt\", name=\"landmark_search_assistant\")\n",
        "        if not prompt_result:\n",
        "            raise RuntimeError(\"Prompt 'landmark_search_assistant' not found in Agent Catalog\")\n",
        "\n",
        "        # Try different possible attributes for the prompt content\n",
        "        system_prompt = (\n",
        "            getattr(prompt_result, \"content\", None)\n",
        "            or getattr(prompt_result, \"template\", None)\n",
        "            or getattr(prompt_result, \"text\", None)\n",
        "        )\n",
        "        if not system_prompt:\n",
        "            raise RuntimeError(\n",
        "                \"Could not access prompt content from AgentC - prompt content is None or empty\"\n",
        "            )\n",
        "\n",
        "        logger.info(\"Loaded system prompt from Agent Catalog\")\n",
        "\n",
        "        # Create ReAct agent with reasonable iteration limit\n",
        "        agent = ReActAgent.from_tools(\n",
        "            tools=tools,\n",
        "            llm=Settings.llm,\n",
        "            verbose=True,\n",
        "            system_prompt=system_prompt,\n",
        "            max_iterations=4,  # Conservative limit to prevent iteration timeout\n",
        "        )\n",
        "\n",
        "        logger.info(\"LlamaIndex ReAct agent created successfully\")\n",
        "        return agent\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error creating LlamaIndex agent: {e!s}\")\n",
        "\n",
        "\n",
        "def setup_landmark_agent():\n",
        "    \"\"\"Setup the complete landmark search agent infrastructure and return the agent.\"\"\"\n",
        "    setup_environment()\n",
        "\n",
        "    # Initialize Agent Catalog\n",
        "    catalog = agentc.Catalog()\n",
        "    span = catalog.Span(name=\"Landmark Search Agent Setup\", blacklist=set())\n",
        "\n",
        "    # Setup AI services\n",
        "    embeddings, llm = setup_ai_services(framework=\"llamaindex\", temperature=0.1, application_span=span)\n",
        "\n",
        "    # Set global LlamaIndex settings\n",
        "    Settings.llm = llm\n",
        "    Settings.embed_model = embeddings\n",
        "\n",
        "    # Setup database client\n",
        "    client = CouchbaseClient(\n",
        "        conn_string=os.environ[\"CB_CONN_STRING\"],\n",
        "        username=os.environ[\"CB_USERNAME\"],\n",
        "        password=os.environ[\"CB_PASSWORD\"],\n",
        "        bucket_name=os.environ[\"CB_BUCKET\"],\n",
        "    )\n",
        "\n",
        "    client.connect()\n",
        "\n",
        "    # Setup collection\n",
        "    client.setup_collection(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"])\n",
        "\n",
        "    # Setup vector search index\n",
        "    with open(\"agentcatalog_index.json\") as file:\n",
        "        index_definition = json.load(file)\n",
        "    logger.info(\"Loaded vector search index definition from agentcatalog_index.json\")\n",
        "    client.setup_vector_search_index(index_definition, os.environ[\"CB_SCOPE\"])\n",
        "\n",
        "    # Load landmark data\n",
        "    client.load_landmark_data(\n",
        "        os.environ[\"CB_SCOPE\"],\n",
        "        os.environ[\"CB_COLLECTION\"],\n",
        "        os.environ[\"CB_INDEX\"],\n",
        "        embeddings,\n",
        "    )\n",
        "\n",
        "    # Create LlamaIndex ReAct agent\n",
        "    agent = create_llamaindex_agent(catalog, span)\n",
        "\n",
        "    return agent, client\n",
        "\n",
        "\n",
        "logger.info(\"\u2705 Agent creation functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnjJzzmJldFS",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup Complete Agent\n",
        "\n",
        "Now let's setup the complete landmark search agent with all components properly integrated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5xTdvJyldFS",
        "outputId": "2287c349-4f80-4a08-fb4e-9fc9c29375e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83d\ude80 Setting up complete landmark search agent...\n",
            "INFO:__main__:\u2705 Environment variables configured\n",
            "INFO:agentc_core.catalog.catalog:A local catalog and a remote catalog have been found. Building a chained tool catalog.\n",
            "INFO:agentc_core.catalog.catalog:A local catalog and a remote catalog have been found. Building a chained prompt catalog.\n",
            "INFO:agentc_core.activity.span:Using both a local auditor and a remote auditor.\n",
            "INFO:__main__:\ud83d\udd27 Setting up Priority 1 AI services for llamaindex framework...\n",
            "INFO:__main__:\u2705 Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "INFO:__main__:\u2705 Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "INFO:__main__:\u2705 Priority 1 AI services setup completed for llamaindex\n",
            "INFO:__main__:Successfully connected to Couchbase\n",
            "INFO:__main__:Connected to bucket 'travel-sample'\n",
            "INFO:__main__:Collection 'landmark_data' exists, clearing data...\n",
            "INFO:__main__:Clearing data from travel-sample.agentc_data.landmark_data...\n",
            "INFO:__main__:Collection cleared successfully, 0 documents remaining\n",
            "INFO:__main__:Primary index created successfully\n",
            "INFO:__main__:Collection setup complete\n",
            "INFO:__main__:Loaded vector search index definition from agentcatalog_index.json\n",
            "INFO:__main__:Vector search index 'landmark_data_index' already exists\n",
            "INFO:__main__:Loading landmark data from travel-sample.inventory.landmark...\n",
            "INFO:__main__:Processing landmark documents...\n",
            "Loading landmarks: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4495/4495 [00:00<00:00, 1638998.22landmarks/s]\n",
            "INFO:__main__:Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "INFO:__main__:Loading landmark data from travel-sample.inventory.landmark...\n",
            "INFO:__main__:Processing landmark documents...\n",
            "Loading landmarks: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4495/4495 [00:00<00:00, 1892341.31landmarks/s]\n",
            "INFO:__main__:Loaded 4495 landmarks from travel-sample.inventory.landmark\n",
            "INFO:__main__:Generating landmark text embeddings...\n",
            "Processing landmarks: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4495/4495 [00:00<00:00, 131747.96landmarks/s]\n",
            "INFO:__main__:Generated 4495 landmark text embeddings\n",
            "INFO:__main__:Creating 4495 LlamaIndex Documents...\n",
            "INFO:__main__:Processing documents with ingestion pipeline...\n",
            "INFO:__main__:Processing 4495 documents in 180 batches...\n",
            "Loading batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 180/180 [00:46<00:00,  3.86batch/s]\n",
            "INFO:__main__:Successfully loaded 4495 landmark documents to vector store\n",
            "INFO:__main__:Landmark data loaded into vector store successfully\n",
            "INFO:__main__:Loaded search_landmarks tool from AgentC\n",
            "INFO:__main__:Loaded 1 tools from Agent Catalog\n",
            "INFO:__main__:Loaded system prompt from Agent Catalog\n",
            "/usr/local/lib/python3.12/dist-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/usr/local/lib/python3.12/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n",
            "INFO:__main__:LlamaIndex ReAct agent created successfully\n",
            "INFO:__main__:\u2705 Landmark search agent setup completed!\n"
          ]
        }
      ],
      "source": [
        "# Setup the landmark search agent\n",
        "logger.info(\"\ud83d\ude80 Setting up complete landmark search agent...\")\n",
        "agent, client = setup_landmark_agent()\n",
        "logger.info(\"\u2705 Landmark search agent setup completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DqXTjmtldFT",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test Functions\n",
        "\n",
        "Test functions to demonstrate the landmark search agent functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyLZn8hfldFT",
        "outputId": "1e538257-e046-4042-d546-114c8b1d1f34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Testing Landmark Data Loading from travel-sample\n",
            "INFO:__main__:==================================================\n",
            "INFO:__main__:\u2705 Landmark count in travel-sample.inventory.landmark: 4495\n",
            "INFO:__main__:\u2705 Data loading functions are working correctly\n",
            "INFO:__main__:\u2705 Data loading test completed successfully\n"
          ]
        }
      ],
      "source": [
        "def run_landmark_query(query: str, agent):\n",
        "    \"\"\"Run a single landmark query with error handling.\"\"\"\n",
        "    logger.info(f\"\ud83c\udfdb\ufe0f Landmark Query: {query}\")\n",
        "\n",
        "    try:\n",
        "        # Clear any cached state to prevent indexing bugs between queries\n",
        "        if hasattr(agent, '_last_result'):\n",
        "            agent._last_result = None\n",
        "\n",
        "        # Run the agent with LlamaIndex chat interface\n",
        "        response = agent.chat(query, chat_history=[])\n",
        "        result = response.response\n",
        "\n",
        "        logger.info(f\"\ud83e\udd16 AI Response: {result}\")\n",
        "        logger.info(\"\u2705 Query completed successfully\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"\u274c Query failed: {e}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def test_landmark_data_loading():\n",
        "    \"\"\"Test landmark data loading from travel-sample independently.\"\"\"\n",
        "    logger.info(\"Testing Landmark Data Loading from travel-sample\")\n",
        "    logger.info(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Test landmark count\n",
        "        count = get_landmark_count()\n",
        "        logger.info(f\"\u2705 Landmark count in travel-sample.inventory.landmark: {count}\")\n",
        "\n",
        "        # Test landmark text generation (limit to avoid overloading)\n",
        "        if count > 0:\n",
        "            logger.info(\"\u2705 Data loading functions are working correctly\")\n",
        "        else:\n",
        "            logger.warning(\"\u26a0\ufe0f No landmarks found in travel-sample database\")\n",
        "\n",
        "        logger.info(\"\u2705 Data loading test completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"\u274c Data loading test failed: {e}\")\n",
        "\n",
        "\n",
        "# Test landmark data loading first\n",
        "test_landmark_data_loading()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZAAK_kaldFT",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Demo Queries\n",
        "\n",
        "Let's test the agent with some sample landmark search queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfga9svJldFT",
        "outputId": "df22a1d4-71c1-48f2-a5d6-2a847868d7ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83c\udfdb\ufe0f Landmark Query: Find museums and galleries in Glasgow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 108cadee-e208-4066-85b6-1185fcd53c22. Step input: Find museums and galleries in Glasgow\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:search_landmarks:Search query: 'museums and galleries in Glasgow' found 10 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums and galleries in Glasgow', 'limit': 10}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Found 9 landmarks matching 'museums and galleries in Glasgow':\n",
            "\n",
            "1. **The Tron Theatre**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: Do.\n",
            "   \ud83c\udfe0 Address: 63 Trongate.\n",
            "   \ud83d\udcde Phone: +44 141 552 4267.\n",
            "   \ud83c\udf10 Website: http://www.tron.co.uk/.\n",
            "   \ud83d\udcdd Description: Specialises in contemporary works..\n",
            "\n",
            "2. **Kelvingrove Art Gallery and Museum**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: Do.\n",
            "   \ud83c\udfe0 Address: Argyle Street.\n",
            "   \ud83d\udcde Phone: +44 141 276 9599.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/kelvingrove/.\n",
            "   \ud83d\udd52 Hours: M-Th, Sa 10AM-5PM; F, Su 11AM-5PM.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: Next door to the Kelvingrove Lawn Bowls Centre. The city's grandest public museum, with one of the finest civic collections in Europe housed within this Glasgow Victorian landmark. The collection is quite varied, with artworks, biological displays and anthropological artifacts. The museum as a whole is well-geared towards children and families and has a cafe..\n",
            "\n",
            "3. **Centre for Contemporary Arts**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: Do.\n",
            "   \ud83c\udfe0 Address: 350 Sauchiehall Street.\n",
            "   \ud83d\udcde Phone: +44 141 352 4900.\n",
            "   \ud83c\udf10 Website: http://www.cca-glasgow.com/.\n",
            "   \ud83d\udcdd Description: Shows films, though it's primarily an art gallery..\n",
            "\n",
            "4. **Riverside Museum**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 100 Pointhouse Place.\n",
            "   \ud83d\udcde Phone: +44 141 287 2720.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/riverside/.\n",
            "   \ud83d\udd52 Hours: M-Th and Sa 10:00-17:00, F and Su 11:00-17:00.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: A recently reopened museum with an excellent collection of vehicles and models to tell the story of transport by land and sea, with a unique Glasgow flavour. Besides the usual rail locomotives, buses, trams, cars and planes, the museum also includes a recreated subway station and a street scene of old Glasgow. &lt;!--This museum is also listed on the [[Urban Rail]] page, please update there with any major changes. --&gt;.\n",
            "\n",
            "5. **Glasgow Riverside Museum**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 100 Pointhouse Place, [[Glasgow]], [[Scotland]] UK.\n",
            "   \ud83d\udcde Phone: +44 141 287 2720.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/riverside-museum/.\n",
            "   \ud83d\udd52 Hours: M-Th and Sa 10AM-5PM, F and Su 11AM-5PM.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: The museum includes a recreated subway station..\n",
            "\n",
            "7. **Burrell Collection**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 2060 Pollokshaws Rd, Pollok Country Park.\n",
            "   \ud83d\udcde Phone: +44 141 287 2550.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/burrell-collection/.\n",
            "   \ud83d\udd52 Hours: M-Th, Sa 10:00-17:00; F, Su 11:00-17:00.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: This is a collection of over 9,000 artworks gifted to the city of Glasgow by Sir William Burrell and housed in a purpose-built museum in the Pollok Estate in the south of the city..\n",
            "\n",
            "8. **Gallery of Modern Art**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: Royal Exchange Square.\n",
            "   \ud83d\udcde Phone: +44 141 287 3050.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/GoMA/.\n",
            "   \ud83d\udd52 Hours: M-W, Sa 10:00\u201317:00, Th 10:00\u201320:00, F and Su 11:00\u201317:00.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: This gallery houses a terrific collection of recent paintings and sculptures, with space for new exhibitions. In the basement is one of Glasgow's many public libraries, with free internet access and cafe..\n",
            "\n",
            "9. **Perth Museum & Art Gallery**\n",
            "   \ud83d\udccd Location: Perth, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 78 George Street.\n",
            "   \ud83d\udcde Phone: +44 1738 632488.\n",
            "   \ud83c\udf10 Website: http://www.pkc.gov.uk/article/6482/Visiting-Perth-Museum-and-Art-Gallery.\n",
            "   \ud83d\udd52 Hours: Tue-Sun 10AM-5PM..\n",
            "   \ud83d\udcb0 Price: Free admission..\n",
            "   \ud83d\udcdd Description: Collection of '''Pictish Stones''', art and information about natural history, human history and archeology..\n",
            "\n",
            "10. **Tenement House**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 145 Buccleuch Street.\n",
            "   \ud83d\udcde Phone: 0844 493 2197.\n",
            "   \ud83c\udf10 Website: http://www.nts.org.uk/Property/Tenement-House/.\n",
            "   \ud83d\udd52 Hours: Summer months only, Daily 1PM-5PM.\n",
            "   \ud83d\udcb0 Price: \u00a36.50 adults, \u00a316.50 family, \u00a35 concessions.\n",
            "   \ud83d\udcdd Description: A National Trust for Scotland site, a middle class Glasgow tenement house preserved in pretty much the way it was in the early 20th century..\n",
            "\u001b[0m> Running step b533c1cf-4d7a-4791-8fcc-87ae8c258345. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83e\udd16 AI Response: There are several museums and galleries in Glasgow that you might be interested in visiting. Some of the most popular ones include the Kelvingrove Art Gallery and Museum, the Centre for Contemporary Arts, the Riverside Museum, and the Burrell Collection. The Kelvingrove Art Gallery and Museum is one of the most famous museums in Glasgow, and it features a wide range of artworks and exhibits. The Centre for Contemporary Arts is a great place to see modern and contemporary art, and the Riverside Museum is a must-visit for anyone interested in transportation and history. The Burrell Collection is a beautiful museum that features a wide range of artworks and exhibits, including paintings, sculptures, and ceramics.\n",
            "INFO:__main__:\u2705 Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: There are several museums and galleries in Glasgow that you might be interested in visiting. Some of the most popular ones include the Kelvingrove Art Gallery and Museum, the Centre for Contemporary Arts, the Riverside Museum, and the Burrell Collection. The Kelvingrove Art Gallery and Museum is one of the most famous museums in Glasgow, and it features a wide range of artworks and exhibits. The Centre for Contemporary Arts is a great place to see modern and contemporary art, and the Riverside Museum is a must-visit for anyone interested in transportation and history. The Burrell Collection is a beautiful museum that features a wide range of artworks and exhibits, including paintings, sculptures, and ceramics.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Test 1: Museums and Galleries in Glasgow\n",
        "result1 = run_landmark_query(\"Find museums and galleries in Glasgow\", agent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XXWrdUsldFT",
        "outputId": "b1da3c52-3634-47c1-ab9d-27901ff04251"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83c\udfdb\ufe0f Landmark Query: Show me restaurants serving Asian cuisine\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 3ceb8b91-58a5-487c-9bf0-1a205fa190e6. Step input: Show me restaurants serving Asian cuisine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:search_landmarks:Search query: 'Asian restaurants' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Asian restaurants', 'limit': 5}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Found 5 landmarks matching 'Asian restaurants':\n",
            "\n",
            "1. **New Canton**\n",
            "   \ud83d\udccd Location: Whittier, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 13015 Philadelphia St, Whittier, CA 90601.\n",
            "   \ud83d\udcde Phone: +1 562 698-7315.\n",
            "   \ud83c\udf10 Website: http://www.newcantonchineserestaurant.com/.\n",
            "   \ud83d\udcdd Description: A Chinese restaurant.\n",
            "\n",
            "2. **World Curry**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 1433 Garnet Ave.\n",
            "   \ud83c\udf10 Website: http://www.worldcurry.com/.\n",
            "   \ud83d\udcdd Description: Great variety of world curries and great happy hour beverage deals..\n",
            "\n",
            "3. **Pearl Chinese Seafood**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 11666 Avena Pl.\n",
            "   \ud83d\udcde Phone: +1 858 487-3388.\n",
            "   \ud83c\udf10 Website: http://pearlchinesesd.com/.\n",
            "   \ud83d\udd52 Hours: M-F 11AM-10:30PM, Sa-Su 9AM-10:30PM.\n",
            "   \ud83d\udcdd Description: Good Cantonese (Chinese) dim sum with a good view of Webb Park..\n",
            "\n",
            "4. **Carrows**\n",
            "   \ud83d\udccd Location: Norwalk, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 10940 Rosecrans Avenue.\n",
            "   \ud83d\udcde Phone: +1 562 868-1553.\n",
            "   \ud83c\udf10 Website: http://www.carrows.com.\n",
            "   \ud83d\udd52 Hours: 6AM-12AM, daily.\n",
            "   \ud83d\udcdd Description: Carrows has breakfast, lunch and dinner options..\n",
            "\n",
            "5. **Tatyan's**\n",
            "   \ud83d\udccd Location: Cirencester, United Kingdom\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83d\udcdd Description: Chinese.\n",
            "\u001b[0m> Running step ee65e3e4-ee5f-4b73-8d67-87c2e36fbeff. Step input: None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I apologize for the mistake. Here's another attempt:\n",
            "\n",
            "Thought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Asian restaurants', 'limit': 5}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Found 5 landmarks matching 'Asian restaurants':\n",
            "\n",
            "1. **New Canton**\n",
            "   \ud83d\udccd Location: Whittier, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 13015 Philadelphia St, Whittier, CA 90601.\n",
            "   \ud83d\udcde Phone: +1 562 698-7315.\n",
            "   \ud83c\udf10 Website: http://www.newcantonchineserestaurant.com/.\n",
            "   \ud83d\udcdd Description: A Chinese restaurant.\n",
            "\n",
            "2. **World Curry**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 1433 Garnet Ave.\n",
            "   \ud83c\udf10 Website: http://www.worldcurry.com/.\n",
            "   \ud83d\udcdd Description: Great variety of world curries and great happy hour beverage deals..\n",
            "\n",
            "3. **Pearl Chinese Seafood**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 11666 Avena Pl.\n",
            "   \ud83d\udcde Phone: +1 858 487-3388.\n",
            "   \ud83c\udf10 Website: http://pearlchinesesd.com/.\n",
            "   \ud83d\udd52 Hours: M-F 11AM-10:30PM, Sa-Su 9AM-10:30PM.\n",
            "   \ud83d\udcdd Description: Good Cantonese (Chinese) dim sum with a good view of Webb Park..\n",
            "\n",
            "4. **Carrows**\n",
            "   \ud83d\udccd Location: Norwalk, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 10940 Rosecrans Avenue.\n",
            "   \ud83d\udcde Phone: +1 562 868-1553.\n",
            "   \ud83c\udf10 Website: http://www.carrows.com.\n",
            "   \ud83d\udd52 Hours: 6AM-12AM, daily.\n",
            "   \ud83d\udcdd Description: Carrows has breakfast, lunch and dinner options..\n",
            "\n",
            "5. **Tatyan's**\n",
            "   \ud83d\udccd Location: Cirencester, United Kingdom\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83d\udcdd Description: Chinese.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Test 2: Asian Restaurants\n",
        "result2 = run_landmark_query(\"Show me restaurants serving Asian cuisine\", agent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNDJovXpldFT",
        "outputId": "a40dbdac-6f2c-40aa-cec9-0f6fc59201a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83c\udfdb\ufe0f Landmark Query: Tell me about Monet's House\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 2cd621e9-670e-44cf-b29f-8561753d84c3. Step input: Tell me about Monet's House\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:search_landmarks:Search query: 'Monet's House' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': \"Monet's House\", 'limit': 5}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Found 5 landmarks matching 'Monet's House':\n",
            "\n",
            "1. **Monet's House**\n",
            "   \ud83d\udccd Location: Giverny, France\n",
            "   \ud83d\uddfa\ufe0f State: Haute-Normandie. Alternative name: Fondation Claude Monet.\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 84 rue Claude Monet.\n",
            "   \ud83d\udcde Phone: +33 232512821.\n",
            "   \ud83c\udf10 Website: http://www.fondation-monet.com/.\n",
            "   \ud83d\udd52 Hours: open April-October Mo-Su 9:30-18:00.\n",
            "   \ud83d\udcb0 Price: \u20ac9, $5 students, \u20ac4 4.00 disabled, under-7s free.\n",
            "   \ud83d\udcdd Description: the house is quietly eccentric and highly interesting in an Orient-influenced style, and includes Monet's collection of [http://www.intermonet.com/japan/ Japanese prints]. There are no original Monet paintings on the site - the real drawcard, is the gardens around the house - the [http://giverny-impression.com/category/water-garden/ water garden] with the [http://www.intermonet.com/oeuvre/pontjapo.htm Japanese bridge], [http://giverny-impression.com/tag/weeping-willow/ weeping willows] and [http://giverny-impression.com/tag/water-lily/ waterlilies] is now somewhat iconic. Monet's house has the obligatory gift-store attached, designed to help you part with your money in exchange for all manner of things Impressionist. [http://giverny.org/gardens/fcm/ticket/ e-tickets] can now be purchased o..\n",
            "\n",
            "2. **Mus\u00e9e Marmottan**\n",
            "   \ud83d\udccd Location: Paris, France\n",
            "   \ud83d\uddfa\ufe0f State: \u00cele-de-France.\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 2 rue Louis-Boilly, 16th.\n",
            "   \ud83d\udcde Phone: +33 1 44 96 50 33.\n",
            "   \ud83c\udf10 Website: http://www.marmottan.com.\n",
            "   \ud83d\udd52 Hours: 11am-9pm Tues; 11am-6pm Wed-Sun. Last entry 30 min before closing.\n",
            "   \ud83d\udcdd Description: Monet's best works are in this charming museum, which contains the largest Monet collection in the world as well as works by Renoir, Manet, Berthe, Caillebotte and Gauguin..\n",
            "\n",
            "3. **La Gare**\n",
            "   \ud83d\udccd Location: Santa Rosa, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 208 Wilson Street.\n",
            "   \ud83d\udcde Phone: +1 707-528-4355.\n",
            "   \ud83c\udf10 Website: http://www.lagarerestaurant.com/.\n",
            "   \ud83d\udcdd Description: French/Swiss cuisine. Local favorite..\n",
            "\n",
            "4. **Satsuki**\n",
            "   \ud83d\udccd Location: Chamonix-Mont-Blanc, France\n",
            "   \ud83d\uddfa\ufe0f State: Rh\u00f4ne-Alpes.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 288 Rue Joseph Vallot.\n",
            "   \ud83d\udcdd Description: If you find you've had a bit more cheese that you would really like, there's a very nice Japanese restaurant, '''Satsuki'''..\n",
            "\n",
            "5. **Hanawa**\n",
            "   \ud83d\udccd Location: Paris, France\n",
            "   \ud83d\uddfa\ufe0f State: \u00cele-de-France.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 26, rue Bayard.\n",
            "   \ud83d\udcde Phone: +33 1 56 62 70 70.\n",
            "   \ud83d\udcdd Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\u001b[0m> Running step 7cc55a6d-b345-4ea4-ba99-7ab06de11d57. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83e\udd16 AI Response: Monet's House, also known as Fondation Claude Monet, is a house and garden museum located in Giverny, France. It was the home of the famous French painter Claude Monet, and it is now a popular tourist destination. The house is known for its unique architecture, which is a mix of Japanese and French styles, and it features a beautiful garden with a water garden, a Japanese bridge, and a collection of Japanese prints. The museum also has a gift store and offers guided tours.\n",
            "INFO:__main__:\u2705 Query completed successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Monet's House, also known as Fondation Claude Monet, is a house and garden museum located in Giverny, France. It was the home of the famous French painter Claude Monet, and it is now a popular tourist destination. The house is known for its unique architecture, which is a mix of Japanese and French styles, and it features a beautiful garden with a water garden, a Japanese bridge, and a collection of Japanese prints. The museum also has a gift store and offers guided tours.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Test 3: Specific Landmark\n",
        "result3 = run_landmark_query(\"Tell me about Monet's House\", agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-xYHoG2ldFT"
      },
      "source": [
        "## Lenient Evaluation Templates\n",
        "\n",
        "The lenient evaluation templates are designed to assess AI responses about landmarks with a focus on functional success rather than exact matching. They account for the dynamic nature of search results, allowing for variations in data, order, and formatting, and only mark responses as incorrect or hallucinated if they are clearly wrong or fabricated. This approach ensures that the evaluation is fair and practical for real-world, data-driven applications where search results can change over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LNDMb48ldFT",
        "outputId": "57cbce9f-cd00-4843-8204-99b047df920b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Lenient evaluation templates defined (THESE WERE MISSING!)\n"
          ]
        }
      ],
      "source": [
        "# Lenient QA evaluation template\n",
        "LENIENT_QA_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert evaluator assessing if an AI assistant's response correctly answers the user's question about landmarks and attractions.\n",
        "\n",
        "FOCUS ON FUNCTIONAL SUCCESS, NOT EXACT MATCHING:\n",
        "1. Did the agent provide the requested landmark information?\n",
        "2. Is the core information accurate and helpful to the user?\n",
        "3. Would the user be satisfied with what they received?\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND CORRECT:\n",
        "- Landmark search results vary based on current database state\n",
        "- Different search queries may return different but valid landmarks\n",
        "- Order of results may vary (this is normal for search results)\n",
        "- Formatting differences are acceptable\n",
        "\n",
        "IGNORE THESE DIFFERENCES:\n",
        "- Format differences, duplicate searches, system messages\n",
        "- Different result ordering or landmark selection\n",
        "- Reference mismatches due to dynamic search results\n",
        "\n",
        "MARK AS CORRECT IF:\n",
        "- Agent successfully found landmarks matching the request\n",
        "- User received useful, accurate landmark information\n",
        "- Core functionality worked as expected (search worked, results filtered properly)\n",
        "\n",
        "MARK AS INCORRECT ONLY IF:\n",
        "- Agent completely failed to provide landmark information\n",
        "- Response is totally irrelevant to the landmark search request\n",
        "- Agent provided clearly wrong or nonsensical information\n",
        "\n",
        "**Question:** {input}\n",
        "\n",
        "**Reference Answer:** {reference}\n",
        "\n",
        "**AI Response:** {output}\n",
        "\n",
        "Based on the criteria above, is the AI response correct?\n",
        "\n",
        "Answer: [correct/incorrect]\n",
        "\n",
        "Explanation: [Provide a brief explanation focusing on functional success]\n",
        "\"\"\"\n",
        "\n",
        "# Lenient hallucination evaluation template\n",
        "LENIENT_HALLUCINATION_PROMPT_TEMPLATE = \"\"\"\n",
        "You are evaluating whether an AI assistant's response about landmarks contains hallucinated (fabricated) information.\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND FACTUAL:\n",
        "- Landmark search results are pulled from a real database\n",
        "- Different searches return different valid landmarks (this is correct behavior)\n",
        "- Landmark details like addresses, descriptions, and activities come from actual data\n",
        "- Search result variations are normal and factual\n",
        "\n",
        "MARK AS FACTUAL IF:\n",
        "- Response contains \"iteration limit\" or \"time limit\" (system issue, not hallucination)\n",
        "- Agent provides plausible landmark data from search results\n",
        "- Information is consistent with typical landmark search functionality\n",
        "- Results differ from reference due to dynamic search (this is expected!)\n",
        "\n",
        "ONLY MARK AS HALLUCINATED IF:\n",
        "- Response contains clearly impossible landmark information\n",
        "- Agent makes up fake landmark names, addresses, or details\n",
        "- Response contradicts fundamental facts about landmark search\n",
        "- Agent claims to have data it cannot access\n",
        "\n",
        "REMEMBER: Different search results are EXPECTED dynamic behavior, not hallucinations!\n",
        "\n",
        "**Question:** {input}\n",
        "\n",
        "**Reference Answer:** {reference}\n",
        "\n",
        "**AI Response:** {output}\n",
        "\n",
        "Based on the criteria above, does the response contain hallucinated information?\n",
        "\n",
        "Answer: [factual/hallucinated]\n",
        "\n",
        "Explanation: [Focus on whether information is plausible vs clearly fabricated]\n",
        "\"\"\"\n",
        "\n",
        "# Lenient evaluation rails (classification options)\n",
        "LENIENT_QA_RAILS = [\"correct\", \"incorrect\"]\n",
        "LENIENT_HALLUCINATION_RAILS = [\"factual\", \"hallucinated\"]\n",
        "\n",
        "logger.info(\"\u2705 Lenient evaluation templates defined (THESE WERE MISSING!)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLT54B83ldFT",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Phoenix Evaluation Setup\n",
        "\n",
        "Setup Arize Phoenix evaluation system with lenient templates for dynamic landmark data evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "3BafdwtJldFW",
        "outputId": "70b9b5ea-fa14-49fb-866c-722fd5c3275a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:phoenix.config:\ud83d\udccb Ensuring phoenix working directory: /root/.phoenix\n",
            "INFO:phoenix.inferences.inferences:Dataset: phoenix_inferences_01555188-40d0-4c27-828a-32414050c14c initialized\n",
            "INFO:__main__:\u2705 Phoenix evaluation components available\n",
            "INFO:phoenix.config:\ud83d\udccb Ensuring phoenix working directory: /root/.phoenix\n",
            "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
            "INFO:alembic.runtime.migration:Will assume transactional DDL.\n",
            "INFO:alembic.runtime.migration:Running upgrade  -> cf03bd6bae1d, init\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2757\ufe0f The launch_app `port` parameter is deprecated and will be removed in a future release. Use the `PHOENIX_PORT` environment variable instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:alembic.runtime.migration:Running upgrade cf03bd6bae1d -> 10460e46d750, datasets\n",
            "INFO:alembic.runtime.migration:Running upgrade 10460e46d750 -> 3be8647b87d8, add token columns to spans table\n",
            "INFO:alembic.runtime.migration:Running upgrade 3be8647b87d8 -> cd164e83824f, users and tokens\n",
            "INFO:alembic.runtime.migration:Running upgrade cd164e83824f -> 4ded9e43755f, create project_session table\n",
            "INFO:alembic.runtime.migration:Running upgrade 4ded9e43755f -> bc8fea3c2bc8, Add prompt tables\n",
            "INFO:alembic.runtime.migration:Running upgrade bc8fea3c2bc8 -> 2f9d1a65945f, Annotation config migrations\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n",
            "INFO:alembic.runtime.migration:Running upgrade 2f9d1a65945f -> bb8139330879, create project trace retention policies table\n",
            "INFO:alembic.runtime.migration:Running upgrade bb8139330879 -> 8a3764fe7f1a, change jsonb to json for prompts\n",
            "INFO:alembic.runtime.migration:Running upgrade 8a3764fe7f1a -> 6a88424799fe, Add auth_method column to users table and migrate existing authentication data.\n",
            "INFO:alembic.runtime.migration:Running upgrade 6a88424799fe -> a20694b15f82, Cost-related tables\n",
            "INFO:phoenix.server.app:Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n",
            "INFO:__main__:\ud83d\ude80 Phoenix UI available at http://localhost:6006/\n",
            "INFO:__main__:\u2705 LlamaIndex instrumentation enabled\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83c\udf0d To view the Phoenix app in your browser, visit https://8qb9p383ki71-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
            "\ud83d\udcd6 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "\ud83d\udd2d OpenTelemetry Tracing Details \ud83d\udd2d\n",
            "|  Phoenix Project: landmark-search-agent-evaluation\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  \u26a0\ufe0f WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import Phoenix evaluation components\n",
        "try:\n",
        "    import phoenix as px\n",
        "    from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "    from phoenix.evals import (\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        OpenAIModel,\n",
        "        llm_classify,\n",
        "    )\n",
        "    from phoenix.otel import register\n",
        "\n",
        "    ARIZE_AVAILABLE = True\n",
        "    logger.info(\"\u2705 Phoenix evaluation components available\")\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Phoenix dependencies not available: {e}\")\n",
        "    logger.warning(\"Skipping evaluation section...\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "# Phoenix evaluation setup\n",
        "if ARIZE_AVAILABLE:\n",
        "    try:\n",
        "        # Start Phoenix session for observability\n",
        "        px_session = px.launch_app(port=6006)\n",
        "        logger.info(\"\ud83d\ude80 Phoenix UI available at http://localhost:6006/\")\n",
        "\n",
        "        # Register LlamaIndex instrumentation\n",
        "        tracer_provider = register(\n",
        "            project_name=\"landmark-search-agent-evaluation\",\n",
        "            endpoint=\"http://localhost:6006/v1/traces\"\n",
        "        )\n",
        "\n",
        "        # Instrument LlamaIndex\n",
        "        LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "        logger.info(\"\u2705 LlamaIndex instrumentation enabled\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not start Phoenix UI: {e}\")\n",
        "        ARIZE_AVAILABLE = False\n",
        "else:\n",
        "    logger.info(\"Phoenix evaluation not available - install phoenix-evals to enable evaluation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfOeXDkMldFW",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Phoenix Evaluation Demo\n",
        "\n",
        "Demonstrate comprehensive Phoenix evaluation using the **lenient templates** for dynamic landmark data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZgbAyiWldFW",
        "outputId": "b652e24a-485e-41f1-dbc0-6ffe15092a60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83d\udd0d Running Phoenix evaluation demo with lenient templates...\n",
            "INFO:__main__:\u2705 Evaluator LLM initialized\n",
            "INFO:__main__:\ud83d\udd0d Running evaluation query 1: Find museums and galleries in Glasgow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Running step 98133e82-006e-483a-b8c1-efbb7c881bdf. Step input: Find museums and galleries in Glasgow\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'museums and galleries in Glasgow', 'limit': 10}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:search_landmarks:Search query: 'museums and galleries in Glasgow' found 10 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 9 landmarks matching 'museums and galleries in Glasgow':\n",
            "\n",
            "1. **The Tron Theatre**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: Do.\n",
            "   \ud83c\udfe0 Address: 63 Trongate.\n",
            "   \ud83d\udcde Phone: +44 141 552 4267.\n",
            "   \ud83c\udf10 Website: http://www.tron.co.uk/.\n",
            "   \ud83d\udcdd Description: Specialises in contemporary works..\n",
            "\n",
            "2. **Kelvingrove Art Gallery and Museum**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: Do.\n",
            "   \ud83c\udfe0 Address: Argyle Street.\n",
            "   \ud83d\udcde Phone: +44 141 276 9599.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/kelvingrove/.\n",
            "   \ud83d\udd52 Hours: M-Th, Sa 10AM-5PM; F, Su 11AM-5PM.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: Next door to the Kelvingrove Lawn Bowls Centre. The city's grandest public museum, with one of the finest civic collections in Europe housed within this Glasgow Victorian landmark. The collection is quite varied, with artworks, biological displays and anthropological artifacts. The museum as a whole is well-geared towards children and families and has a cafe..\n",
            "\n",
            "3. **Centre for Contemporary Arts**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: Do.\n",
            "   \ud83c\udfe0 Address: 350 Sauchiehall Street.\n",
            "   \ud83d\udcde Phone: +44 141 352 4900.\n",
            "   \ud83c\udf10 Website: http://www.cca-glasgow.com/.\n",
            "   \ud83d\udcdd Description: Shows films, though it's primarily an art gallery..\n",
            "\n",
            "4. **Riverside Museum**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 100 Pointhouse Place.\n",
            "   \ud83d\udcde Phone: +44 141 287 2720.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/riverside/.\n",
            "   \ud83d\udd52 Hours: M-Th and Sa 10:00-17:00, F and Su 11:00-17:00.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: A recently reopened museum with an excellent collection of vehicles and models to tell the story of transport by land and sea, with a unique Glasgow flavour. Besides the usual rail locomotives, buses, trams, cars and planes, the museum also includes a recreated subway station and a street scene of old Glasgow. &lt;!--This museum is also listed on the [[Urban Rail]] page, please update there with any major changes. --&gt;.\n",
            "\n",
            "5. **Glasgow Riverside Museum**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 100 Pointhouse Place, [[Glasgow]], [[Scotland]] UK.\n",
            "   \ud83d\udcde Phone: +44 141 287 2720.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/riverside-museum/.\n",
            "   \ud83d\udd52 Hours: M-Th and Sa 10AM-5PM, F and Su 11AM-5PM.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: The museum includes a recreated subway station..\n",
            "\n",
            "7. **Burrell Collection**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 2060 Pollokshaws Rd, Pollok Country Park.\n",
            "   \ud83d\udcde Phone: +44 141 287 2550.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/burrell-collection/.\n",
            "   \ud83d\udd52 Hours: M-Th, Sa 10:00-17:00; F, Su 11:00-17:00.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: This is a collection of over 9,000 artworks gifted to the city of Glasgow by Sir William Burrell and housed in a purpose-built museum in the Pollok Estate in the south of the city..\n",
            "\n",
            "8. **Gallery of Modern Art**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: Royal Exchange Square.\n",
            "   \ud83d\udcde Phone: +44 141 287 3050.\n",
            "   \ud83c\udf10 Website: http://www.glasgowlife.org.uk/museums/GoMA/.\n",
            "   \ud83d\udd52 Hours: M-W, Sa 10:00\u201317:00, Th 10:00\u201320:00, F and Su 11:00\u201317:00.\n",
            "   \ud83d\udcb0 Price: Free.\n",
            "   \ud83d\udcdd Description: This gallery houses a terrific collection of recent paintings and sculptures, with space for new exhibitions. In the basement is one of Glasgow's many public libraries, with free internet access and cafe..\n",
            "\n",
            "9. **Perth Museum & Art Gallery**\n",
            "   \ud83d\udccd Location: Perth, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 78 George Street.\n",
            "   \ud83d\udcde Phone: +44 1738 632488.\n",
            "   \ud83c\udf10 Website: http://www.pkc.gov.uk/article/6482/Visiting-Perth-Museum-and-Art-Gallery.\n",
            "   \ud83d\udd52 Hours: Tue-Sun 10AM-5PM..\n",
            "   \ud83d\udcb0 Price: Free admission..\n",
            "   \ud83d\udcdd Description: Collection of '''Pictish Stones''', art and information about natural history, human history and archeology..\n",
            "\n",
            "10. **Tenement House**\n",
            "   \ud83d\udccd Location: Glasgow, United Kingdom\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 145 Buccleuch Street.\n",
            "   \ud83d\udcde Phone: 0844 493 2197.\n",
            "   \ud83c\udf10 Website: http://www.nts.org.uk/Property/Tenement-House/.\n",
            "   \ud83d\udd52 Hours: Summer months only, Daily 1PM-5PM.\n",
            "   \ud83d\udcb0 Price: \u00a36.50 adults, \u00a316.50 family, \u00a35 concessions.\n",
            "   \ud83d\udcdd Description: A National Trust for Scotland site, a middle class Glasgow tenement house preserved in pretty much the way it was in the early 20th century..\n",
            "\u001b[0m> Running step 19ce668d-2a9f-4d2a-b3a4-bb7fa92871bd. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Query 1 completed successfully\n",
            "INFO:__main__:\ud83d\udd0d Running evaluation query 2: Show me restaurants serving Asian cuisine\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: There are several museums and galleries in Glasgow that you might be interested in visiting. Some of the most popular ones include the Kelvingrove Art Gallery and Museum, the Centre for Contemporary Arts, the Riverside Museum, and the Burrell Collection. The Kelvingrove Art Gallery and Museum is one of the most famous museums in Glasgow, and it features a wide range of artworks and exhibits. The Centre for Contemporary Arts is a great place to see modern and contemporary art, and the Riverside Museum is a must-visit for anyone interested in transportation and history. The Burrell Collection is a beautiful museum that features a wide range of artworks and exhibits, including paintings, sculptures, and ceramics.\n",
            "\u001b[0m> Running step 7ceddf8c-69f5-4dae-9668-f140b04acdc6. Step input: Show me restaurants serving Asian cuisine\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Asian restaurants', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:search_landmarks:Search query: 'Asian restaurants' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Asian restaurants':\n",
            "\n",
            "1. **New Canton**\n",
            "   \ud83d\udccd Location: Whittier, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 13015 Philadelphia St, Whittier, CA 90601.\n",
            "   \ud83d\udcde Phone: +1 562 698-7315.\n",
            "   \ud83c\udf10 Website: http://www.newcantonchineserestaurant.com/.\n",
            "   \ud83d\udcdd Description: A Chinese restaurant.\n",
            "\n",
            "2. **World Curry**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 1433 Garnet Ave.\n",
            "   \ud83c\udf10 Website: http://www.worldcurry.com/.\n",
            "   \ud83d\udcdd Description: Great variety of world curries and great happy hour beverage deals..\n",
            "\n",
            "3. **Pearl Chinese Seafood**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 11666 Avena Pl.\n",
            "   \ud83d\udcde Phone: +1 858 487-3388.\n",
            "   \ud83c\udf10 Website: http://pearlchinesesd.com/.\n",
            "   \ud83d\udd52 Hours: M-F 11AM-10:30PM, Sa-Su 9AM-10:30PM.\n",
            "   \ud83d\udcdd Description: Good Cantonese (Chinese) dim sum with a good view of Webb Park..\n",
            "\n",
            "4. **Carrows**\n",
            "   \ud83d\udccd Location: Norwalk, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 10940 Rosecrans Avenue.\n",
            "   \ud83d\udcde Phone: +1 562 868-1553.\n",
            "   \ud83c\udf10 Website: http://www.carrows.com.\n",
            "   \ud83d\udd52 Hours: 6AM-12AM, daily.\n",
            "   \ud83d\udcdd Description: Carrows has breakfast, lunch and dinner options..\n",
            "\n",
            "5. **Tatyan's**\n",
            "   \ud83d\udccd Location: Cirencester, United Kingdom\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83d\udcdd Description: Chinese.\n",
            "\u001b[0m> Running step 500211f9-40b3-461c-ab42-01386f6e018a. Step input: None\n",
            "\u001b[0m> Running step 14ff7db6-7c97-47b9-88c8-c548e3a805b4. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I apologize for the mistake. Here's another attempt:\n",
            "\n",
            "Thought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': 'Asian restaurants', 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Asian restaurants':\n",
            "\n",
            "1. **New Canton**\n",
            "   \ud83d\udccd Location: Whittier, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 13015 Philadelphia St, Whittier, CA 90601.\n",
            "   \ud83d\udcde Phone: +1 562 698-7315.\n",
            "   \ud83c\udf10 Website: http://www.newcantonchineserestaurant.com/.\n",
            "   \ud83d\udcdd Description: A Chinese restaurant.\n",
            "\n",
            "2. **World Curry**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 1433 Garnet Ave.\n",
            "   \ud83c\udf10 Website: http://www.worldcurry.com/.\n",
            "   \ud83d\udcdd Description: Great variety of world curries and great happy hour beverage deals..\n",
            "\n",
            "3. **Pearl Chinese Seafood**\n",
            "   \ud83d\udccd Location: San Diego, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 11666 Avena Pl.\n",
            "   \ud83d\udcde Phone: +1 858 487-3388.\n",
            "   \ud83c\udf10 Website: http://pearlchinesesd.com/.\n",
            "   \ud83d\udd52 Hours: M-F 11AM-10:30PM, Sa-Su 9AM-10:30PM.\n",
            "   \ud83d\udcdd Description: Good Cantonese (Chinese) dim sum with a good view of Webb Park..\n",
            "\n",
            "4. **Carrows**\n",
            "   \ud83d\udccd Location: Norwalk, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 10940 Rosecrans Avenue.\n",
            "   \ud83d\udcde Phone: +1 562 868-1553.\n",
            "   \ud83c\udf10 Website: http://www.carrows.com.\n",
            "   \ud83d\udd52 Hours: 6AM-12AM, daily.\n",
            "   \ud83d\udcdd Description: Carrows has breakfast, lunch and dinner options..\n",
            "\n",
            "5. **Tatyan's**\n",
            "   \ud83d\udccd Location: Cirencester, United Kingdom\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83d\udcdd Description: Chinese.\n",
            "\u001b[0m> Running step 248162a2-7a82-4ce9-9af5-d84f8b22f554. Step input: Tell me about Monet's House\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
            "Action: search_landmarks\n",
            "Action Input: {'query': \"Monet's House\", 'limit': 5}\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:search_landmarks:Search query: 'Monet's House' found 5 results\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;34mObservation: Found 5 landmarks matching 'Monet's House':\n",
            "\n",
            "1. **Monet's House**\n",
            "   \ud83d\udccd Location: Giverny, France\n",
            "   \ud83d\uddfa\ufe0f State: Haute-Normandie. Alternative name: Fondation Claude Monet.\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 84 rue Claude Monet.\n",
            "   \ud83d\udcde Phone: +33 232512821.\n",
            "   \ud83c\udf10 Website: http://www.fondation-monet.com/.\n",
            "   \ud83d\udd52 Hours: open April-October Mo-Su 9:30-18:00.\n",
            "   \ud83d\udcb0 Price: \u20ac9, $5 students, \u20ac4 4.00 disabled, under-7s free.\n",
            "   \ud83d\udcdd Description: the house is quietly eccentric and highly interesting in an Orient-influenced style, and includes Monet's collection of [http://www.intermonet.com/japan/ Japanese prints]. There are no original Monet paintings on the site - the real drawcard, is the gardens around the house - the [http://giverny-impression.com/category/water-garden/ water garden] with the [http://www.intermonet.com/oeuvre/pontjapo.htm Japanese bridge], [http://giverny-impression.com/tag/weeping-willow/ weeping willows] and [http://giverny-impression.com/tag/water-lily/ waterlilies] is now somewhat iconic. Monet's house has the obligatory gift-store attached, designed to help you part with your money in exchange for all manner of things Impressionist. [http://giverny.org/gardens/fcm/ticket/ e-tickets] can now be purchased o..\n",
            "\n",
            "2. **Mus\u00e9e Marmottan**\n",
            "   \ud83d\udccd Location: Paris, France\n",
            "   \ud83d\uddfa\ufe0f State: \u00cele-de-France.\n",
            "   \ud83c\udfaf Activity: See.\n",
            "   \ud83c\udfe0 Address: 2 rue Louis-Boilly, 16th.\n",
            "   \ud83d\udcde Phone: +33 1 44 96 50 33.\n",
            "   \ud83c\udf10 Website: http://www.marmottan.com.\n",
            "   \ud83d\udd52 Hours: 11am-9pm Tues; 11am-6pm Wed-Sun. Last entry 30 min before closing.\n",
            "   \ud83d\udcdd Description: Monet's best works are in this charming museum, which contains the largest Monet collection in the world as well as works by Renoir, Manet, Berthe, Caillebotte and Gauguin..\n",
            "\n",
            "3. **La Gare**\n",
            "   \ud83d\udccd Location: Santa Rosa, United States\n",
            "   \ud83d\uddfa\ufe0f State: California.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 208 Wilson Street.\n",
            "   \ud83d\udcde Phone: +1 707-528-4355.\n",
            "   \ud83c\udf10 Website: http://www.lagarerestaurant.com/.\n",
            "   \ud83d\udcdd Description: French/Swiss cuisine. Local favorite..\n",
            "\n",
            "4. **Satsuki**\n",
            "   \ud83d\udccd Location: Chamonix-Mont-Blanc, France\n",
            "   \ud83d\uddfa\ufe0f State: Rh\u00f4ne-Alpes.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 288 Rue Joseph Vallot.\n",
            "   \ud83d\udcdd Description: If you find you've had a bit more cheese that you would really like, there's a very nice Japanese restaurant, '''Satsuki'''..\n",
            "\n",
            "5. **Hanawa**\n",
            "   \ud83d\udccd Location: Paris, France\n",
            "   \ud83d\uddfa\ufe0f State: \u00cele-de-France.\n",
            "   \ud83c\udfaf Activity: Eat.\n",
            "   \ud83c\udfe0 Address: 26, rue Bayard.\n",
            "   \ud83d\udcde Phone: +33 1 56 62 70 70.\n",
            "   \ud83d\udcdd Description: Great sushi in a nice atmosphere, extensive menu..\n",
            "\u001b[0m> Running step 3f36d60c-3c90-4fd2-bd65-0484bd99f884. Step input: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Query 3 completed successfully\n",
            "INFO:__main__:\ud83d\udcca Collected 3 responses for evaluation\n",
            "INFO:__main__:Query: Find museums and galleries in Glasgow\n",
            "INFO:__main__:Response: There are several museums and galleries in Glasgow that you might be interested in visiting. Some of the most popular ones include the Kelvingrove Art Gallery and Museum, the Centre for Contemporary A...\n",
            "INFO:__main__:Success: True\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Query: Show me restaurants serving Asian cuisine\n",
            "INFO:__main__:Response: Error: Reached max iterations....\n",
            "INFO:__main__:Success: False\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Query: Tell me about Monet's House\n",
            "INFO:__main__:Response: Monet's House, also known as Fondation Claude Monet, is a house and garden museum located in Giverny, France. It was the home of the famous French painter Claude Monet, and it is now a popular tourist...\n",
            "INFO:__main__:Success: True\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:\ud83d\udca1 Visit Phoenix UI at http://localhost:6006/ to see detailed traces\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Monet's House, also known as Fondation Claude Monet, is a house and garden museum located in Giverny, France. It was the home of the famous French painter Claude Monet, and it is now a popular tourist destination. The house is known for its unique architecture, which is a mix of Japanese and French styles, and it features a beautiful garden with a water garden, a Japanese bridge, and a collection of Japanese prints. The museum also has a gift store and offers guided tours.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "if ARIZE_AVAILABLE:\n",
        "    logger.info(\"\ud83d\udd0d Running Phoenix evaluation demo with lenient templates...\")\n",
        "\n",
        "    # Setup evaluator LLM\n",
        "    try:\n",
        "        evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.1)\n",
        "        logger.info(\"\u2705 Evaluator LLM initialized\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\u274c Could not initialize evaluator LLM: {e}\")\n",
        "        evaluator_llm = None\n",
        "\n",
        "    if evaluator_llm:\n",
        "        # Demo queries for evaluation\n",
        "        demo_queries = [\n",
        "            \"Find museums and galleries in Glasgow\",\n",
        "            \"Show me restaurants serving Asian cuisine\",\n",
        "            \"Tell me about Monet's House\"\n",
        "        ]\n",
        "\n",
        "        # Run demo queries and collect responses for evaluation\n",
        "        demo_results = []\n",
        "\n",
        "        for i, query in enumerate(demo_queries, 1):\n",
        "            try:\n",
        "                logger.info(f\"\ud83d\udd0d Running evaluation query {i}: {query}\")\n",
        "\n",
        "                # Clear any cached state to prevent indexing bugs between queries\n",
        "                # This ensures each query starts with a clean slate\n",
        "                if hasattr(agent, '_last_result'):\n",
        "                    agent._last_result = None\n",
        "\n",
        "                # Run the agent with LlamaIndex\n",
        "                response = agent.chat(query, chat_history=[])\n",
        "                output = response.response\n",
        "\n",
        "                demo_results.append({\n",
        "                    \"query\": query,\n",
        "                    \"response\": output,\n",
        "                    \"query_type\": f\"landmark_demo_{i}\",\n",
        "                    \"success\": True\n",
        "                })\n",
        "\n",
        "                logger.info(f\"\u2705 Query {i} completed successfully\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(f\"\u274c Query {i} failed: {e}\")\n",
        "                demo_results.append({\n",
        "                    \"query\": query,\n",
        "                    \"response\": f\"Error: {e!s}\",\n",
        "                    \"query_type\": f\"landmark_demo_{i}\",\n",
        "                    \"success\": False\n",
        "                })\n",
        "\n",
        "        # Convert to DataFrame for evaluation\n",
        "        results_df = pd.DataFrame(demo_results)\n",
        "        logger.info(f\"\ud83d\udcca Collected {len(results_df)} responses for evaluation\")\n",
        "\n",
        "        # Display results summary\n",
        "        for _, row in results_df.iterrows():\n",
        "            logger.info(f\"Query: {row['query']}\")\n",
        "            logger.info(f\"Response: {row['response'][:200]}...\")\n",
        "            logger.info(f\"Success: {row['success']}\")\n",
        "            logger.info(\"-\" * 50)\n",
        "\n",
        "        logger.info(\"\ud83d\udca1 Visit Phoenix UI at http://localhost:6006/ to see detailed traces\")\n",
        "\n",
        "    else:\n",
        "        logger.warning(\"\u26a0\ufe0f Evaluator LLM not available - skipping evaluation\")\n",
        "\n",
        "else:\n",
        "    logger.info(\"\u274c Phoenix evaluation skipped - dependencies not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lAolzrbldFX",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Comprehensive Phoenix Evaluation\n",
        "\n",
        "Run comprehensive evaluation using the **lenient templates** defined earlier in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8da11067a8204d96bfe6855e0ea81ec6",
            "57b50beace424993b4a29fd2a56e0473",
            "d909b884630740c2a4e9010374924ece",
            "67f428e777f647a49020da0c8e0d999f",
            "d8f4b5d122e14e2a8fba6365f80a7089",
            "fc99e7df9d33465fb7a84dead7aadaef",
            "b10b5f49ef0b4a2f9272b11572cef767",
            "0b1a9df7091045fa8fc6cfec3dc4e58d",
            "d492f7f86dce40ae85544ab7bd452ee6",
            "e94f382460c447df94db2621d022842f",
            "73533e172a3646228916c3ec208b9a1a",
            "5174601c82504dc59d7961f0a7cdd40a",
            "df4d01f1326d4d47bd29e7ce7481fa6d",
            "60156c55273c421094f4762eeb5ff94d",
            "701355e885f84c35a3c51edb74d59991",
            "00a72ee138ba48a4a94ef30aedcfd942",
            "d8f45dfe62bc45598acdf9bf9e5cc6ce",
            "8e48b154f665416289eff22841d0d231",
            "3cc5c703009f44b7930c57f553dae961",
            "94a58265c1564542a0ccba284329c2f2",
            "7d63649cf54b48d29cf4e30c0f49d77e",
            "e41fa85d5b3a43a9826c9c926b45500f",
            "bebbc6174a3b420eb5dd8c165a626932",
            "a6dcb9310a2e4f3a84215662e35f7fba",
            "1da234b48cee4fc9a55d57362da40876",
            "b13ebba8c6cd43f992a5947f987ff47a",
            "2d65b698b19f405ea63a5da382574680",
            "8596f1b3870e44a38daffa860342f58f",
            "8924591d676847a5938fd0f02625e89f",
            "ec1afc4ce8144c8680d77746bb39518f",
            "0a0520d9f2ea4ef1bf8164fe3a1e3836",
            "bc28005f74ff43f49a2603c8fe0e8f66",
            "4a831f9429474145850852752de15ea3",
            "ec1f061b62a04e41bae084e6aacb5274",
            "db9c9161c00c49999d458aa08388c377",
            "e1aa1dd642bb40d48e299877237af55d",
            "8c260c1de8c9413b93c0374f7e8ea00c",
            "4cb04525db47469797bb52cd74aa5549",
            "58fb8795cfe94e3aa2994aad01f2903c",
            "766ef13f2f82403980749e6cf63ff731",
            "5069416dc3b348fd9fe2c70e2b1ce54c",
            "4693a1dd2c334769a2f4769c5676cc12",
            "0d8f458e32ec456d92ceb6bf36b3e868",
            "2909320d8619400eb6cd308c338959c8"
          ]
        },
        "id": "4zSmpKRrldFX",
        "outputId": "747e223e-b037-4728-b1c9-e53fb2ff2ad3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\ud83d\udd0d Running comprehensive Phoenix evaluations with LENIENT templates...\n",
            "INFO:__main__:\ud83d\udcca Prepared 3 queries for Phoenix evaluation\n",
            "INFO:__main__:\ud83d\udd0d Running Relevance Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8da11067a8204d96bfe6855e0ea81ec6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/3 (0.0%) | \u23f3 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Relevance evaluation completed\n",
            "INFO:__main__:\ud83d\udd0d Running QA Evaluation with LENIENT template...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5174601c82504dc59d7961f0a7cdd40a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/3 (0.0%) | \u23f3 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 QA evaluation completed with LENIENT template\n",
            "INFO:__main__:\ud83d\udd0d Running Hallucination Evaluation with LENIENT template...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bebbc6174a3b420eb5dd8c165a626932",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/3 (0.0%) | \u23f3 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Hallucination evaluation completed with LENIENT template\n",
            "INFO:__main__:\ud83d\udd0d Running Toxicity Evaluation...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec1f061b62a04e41bae084e6aacb5274",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/3 (0.0%) | \u23f3 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:\u2705 Toxicity evaluation completed\n",
            "INFO:__main__:\ud83d\udcca EVALUATION SUMMARY\n",
            "INFO:__main__:==================================================\n",
            "INFO:__main__:Query 1: Find museums and galleries in Glasgow\n",
            "INFO:__main__:  relevance: relevant\n",
            "INFO:__main__:    Reason: The question asks for museums and galleries located in Glasgow. The reference text provides a list of several museums and galleries in Glasgow, including the Gallery of Modern Art, Kelvingrove Art Gallery and Museum, Hunterian Museum and Art Gallery, and the Riverside Museum. It also provides additional details about the collections and locations of these institutions. Therefore, the reference text contains information that directly answers the question.\n",
            "INFO:__main__:  qa_correctness: correct\n",
            "INFO:__main__:    Reason: The AI response correctly identifies several museums and galleries in Glasgow, including the Kelvingrove Art Gallery and Museum, the Riverside Museum, and the Burrell Collection. It also mentions the Centre for Contemporary Arts, which is relevant to the user's request for museums and galleries. The information provided is accurate and helpful, offering a brief description of what each location offers. Therefore, the user would likely be satisfied with this response.\n",
            "INFO:__main__:  hallucination: factual\n",
            "INFO:__main__:    Reason: The AI response provides plausible and factual information about museums and galleries in Glasgow. It mentions the Kelvingrove Art Gallery and Museum, the Riverside Museum, and the Burrell Collection, which are all real and well-known landmarks in Glasgow. The Centre for Contemporary Arts is also a legitimate venue for contemporary art in the city. The response does not contain any fabricated or impossible information, and the variation in the list of museums and galleries is consistent with dynamic search results.\n",
            "INFO:__main__:  toxicity: non-toxic\n",
            "INFO:__main__:    Reason: To determine whether the text is toxic, we need to analyze its content for any signs of hate speech, demeaning language, inappropriate language, or threats of violence. \n",
            "\n",
            "1. The text in question is: \"Find museums and galleries in Glasgow.\"\n",
            "2. The text is a simple request or command to locate museums and galleries in a specific city, Glasgow.\n",
            "3. There are no words or phrases in the text that express hate, discrimination, or demeaning attitudes towards any individual or group.\n",
            "4. The language used is neutral and does not contain any inappropriate or offensive language.\n",
            "5. There are no threats of physical or emotional violence present in the text.\n",
            "\n",
            "Based on this analysis, the text does not meet any criteria for toxicity. It is a straightforward, non-offensive statement.\n",
            "INFO:__main__:  ----------------------------------------\n",
            "INFO:__main__:Query 2: Show me restaurants serving Asian cuisine\n",
            "INFO:__main__:  relevance: relevant\n",
            "INFO:__main__:    Reason: The question asks for restaurants serving Asian cuisine. The reference text provides a list of several Asian restaurants, including specific names and locations, such as Shangri-la Chinese Restaurant, Taiwan Restaurant, Hong Kong Seafood Restaurant, Cheung Hing Chinese Restaurant, and Vietnam Restaurant. These establishments offer various Asian dishes, including Chinese, Vietnamese, and Cantonese cuisines. Therefore, the reference text contains information that directly answers the question by listing restaurants that serve Asian cuisine.\n",
            "INFO:__main__:  qa_correctness: incorrect\n",
            "INFO:__main__:    Reason: The AI response did not provide any information about restaurants serving Asian cuisine. Instead, it returned an error message indicating a failure in processing the request. This does not meet the criteria for providing useful or accurate landmark information.\n",
            "INFO:__main__:  hallucination: factual\n",
            "INFO:__main__:    Reason: The response contains an error message indicating a system issue ('Error: Reached max iterations'), which is not a hallucination. It does not provide any fabricated information about landmarks or restaurants. The response does not contradict any fundamental facts about landmark search functionality. Therefore, it should be marked as factual.\n",
            "INFO:__main__:  toxicity: non-toxic\n",
            "INFO:__main__:    Reason: To determine whether the text is toxic, we need to analyze it based on the definition of toxicity provided. The text in question is: \"Show me restaurants serving Asian cuisine.\"\n",
            "\n",
            "1. **Hateful Statements**: The text does not contain any language that expresses hate towards any individual or group. It is a neutral request for information about restaurants.\n",
            "\n",
            "2. **Demeaning or Disparaging Language**: There is no language in the text that demeans or disparages any person or group. The mention of \"Asian cuisine\" is a factual reference to a type of food and does not carry any negative connotations.\n",
            "\n",
            "3. **Inappropriate Language**: The text does not use any inappropriate or offensive language. It is a straightforward request.\n",
            "\n",
            "4. **Threats of Violence**: There are no threats, either physical or emotional, present in the text.\n",
            "\n",
            "Given these points, the text does not meet any criteria for toxicity. It is a simple, non-offensive request for information about a type of cuisine.\n",
            "INFO:__main__:  ----------------------------------------\n",
            "INFO:__main__:Query 3: Tell me about Monet's House\n",
            "INFO:__main__:  relevance: relevant\n",
            "INFO:__main__:    Reason: The question asks for information about Monet's House. The reference text provides detailed information about Monet's House, including its location in Giverny, France, its architectural style, the main attractions such as the gardens and water garden, and practical details like opening hours, admission fees, and accessibility. This information directly addresses the question by describing Monet's House and its features.\n",
            "INFO:__main__:  qa_correctness: correct\n",
            "INFO:__main__:    Reason: The AI response provides accurate and relevant information about Monet's House, including its location in Giverny, France, its significance as the home of Claude Monet, and its unique architectural style. It also mentions the garden features such as the water garden and Japanese bridge, which are key attractions. Although it doesn't include specific details like opening hours or admission fees, the core information is accurate and helpful for someone interested in Monet's House.\n",
            "INFO:__main__:  hallucination: factual\n",
            "INFO:__main__:    Reason: The AI response provides plausible and factual information about Monet's House, also known as Fondation Claude Monet, located in Giverny, France. It mentions the house's unique architecture, the garden with a water garden and Japanese bridge, and the collection of Japanese prints, which are consistent with known details about Monet's House. The mention of a gift store and guided tours is also plausible for a tourist destination. There is no clearly fabricated information in the response.\n",
            "INFO:__main__:  toxicity: non-toxic\n",
            "INFO:__main__:    Reason: To determine whether the text is toxic, we need to analyze the content based on the definition of toxicity provided. The text in question is: \"Tell me about Monet's House\".\n",
            "\n",
            "1. **Hateful Statements**: The text does not contain any language that could be interpreted as hateful towards any individual or group.\n",
            "\n",
            "2. **Demeaning or Disparaging Language**: There is no language in the text that demeans or disparages anyone. It is a simple request for information about Monet's House.\n",
            "\n",
            "3. **Inappropriate Language**: The text does not use any inappropriate or offensive language. It is a straightforward question.\n",
            "\n",
            "4. **Threats of Physical or Emotional Violence**: There are no threats of any kind present in the text. It is a benign inquiry.\n",
            "\n",
            "Given these points, the text does not meet any of the criteria for toxicity. It is a neutral request for information and does not contain any elements that could be considered toxic.\n",
            "INFO:__main__:  ----------------------------------------\n",
            "INFO:__main__:\u2705 All Phoenix evaluations completed successfully!\n",
            "INFO:__main__:\ud83c\udfaf KEY SUCCESS: Lenient templates now work correctly!\n"
          ]
        }
      ],
      "source": [
        "if ARIZE_AVAILABLE and evaluator_llm and len(demo_results) > 0:\n",
        "    logger.info(\"\ud83d\udd0d Running comprehensive Phoenix evaluations with LENIENT templates...\")\n",
        "\n",
        "    # Prepare evaluation data with proper column names for Phoenix evaluators\n",
        "    eval_data = []\n",
        "    for _, row in results_df.iterrows():\n",
        "        eval_data.append({\n",
        "            \"input\": row[\"query\"],\n",
        "            \"output\": row[\"response\"],\n",
        "            \"reference\": get_reference_answer(row[\"query\"]),\n",
        "            \"text\": row[\"response\"]  # For toxicity evaluation\n",
        "        })\n",
        "\n",
        "    eval_df = pd.DataFrame(eval_data)\n",
        "    logger.info(f\"\ud83d\udcca Prepared {len(eval_df)} queries for Phoenix evaluation\")\n",
        "\n",
        "    # Run evaluations using LENIENT templates\n",
        "    evaluation_results = {}\n",
        "\n",
        "    try:\n",
        "        # 1. Relevance Evaluation (using standard Phoenix template)\n",
        "        logger.info(\"\ud83d\udd0d Running Relevance Evaluation...\")\n",
        "        relevance_results = llm_classify(\n",
        "            data=eval_df[[\"input\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "            rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        evaluation_results['relevance'] = relevance_results\n",
        "        logger.info(\"\u2705 Relevance evaluation completed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\u274c Relevance evaluation failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        # 2. QA Evaluation (using LENIENT template - THE KEY FIX!)\n",
        "        logger.info(\"\ud83d\udd0d Running QA Evaluation with LENIENT template...\")\n",
        "        qa_results = llm_classify(\n",
        "            data=eval_df[[\"input\", \"output\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=LENIENT_QA_PROMPT_TEMPLATE,  # \u2705 NOW DEFINED!\n",
        "            rails=LENIENT_QA_RAILS,                # \u2705 NOW DEFINED!\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        evaluation_results['qa_correctness'] = qa_results\n",
        "        logger.info(\"\u2705 QA evaluation completed with LENIENT template\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\u274c QA evaluation failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        # 3. Hallucination Evaluation (using LENIENT template - THE KEY FIX!)\n",
        "        logger.info(\"\ud83d\udd0d Running Hallucination Evaluation with LENIENT template...\")\n",
        "        hallucination_results = llm_classify(\n",
        "            data=eval_df[[\"input\", \"reference\", \"output\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=LENIENT_HALLUCINATION_PROMPT_TEMPLATE,  # \u2705 NOW DEFINED!\n",
        "            rails=LENIENT_HALLUCINATION_RAILS,               # \u2705 NOW DEFINED!\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        evaluation_results['hallucination'] = hallucination_results\n",
        "        logger.info(\"\u2705 Hallucination evaluation completed with LENIENT template\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\u274c Hallucination evaluation failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        # 4. Toxicity Evaluation (using standard Phoenix template)\n",
        "        logger.info(\"\ud83d\udd0d Running Toxicity Evaluation...\")\n",
        "        toxicity_results = llm_classify(\n",
        "            data=eval_df[[\"input\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=TOXICITY_PROMPT_TEMPLATE,\n",
        "            rails=list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True\n",
        "        )\n",
        "        evaluation_results['toxicity'] = toxicity_results\n",
        "        logger.info(\"\u2705 Toxicity evaluation completed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\u274c Toxicity evaluation failed: {e}\")\n",
        "\n",
        "    # Display evaluation summary\n",
        "    logger.info(\"\ud83d\udcca EVALUATION SUMMARY\")\n",
        "    logger.info(\"=\" * 50)\n",
        "\n",
        "    for i, query in enumerate([item[\"input\"] for item in eval_data]):\n",
        "        logger.info(f\"Query {i+1}: {query}\")\n",
        "\n",
        "        # Extract results safely\n",
        "        for eval_type, results in evaluation_results.items():\n",
        "            try:\n",
        "                if hasattr(results, 'columns') and 'label' in results.columns:\n",
        "                    labels = results['label'].tolist()\n",
        "                    explanations = results.get('explanation', ['No explanation'] * len(labels)).tolist()\n",
        "\n",
        "                    if i < len(labels):\n",
        "                        label = labels[i]\n",
        "                        explanation = explanations[i] if i < len(explanations) else \"No explanation\"\n",
        "                        logger.info(f\"  {eval_type}: {label}\")\n",
        "                        if explanation != \"No explanation\":\n",
        "                            logger.info(f\"    Reason: {explanation}\")\n",
        "                    else:\n",
        "                        logger.info(f\"  {eval_type}: No result\")\n",
        "                else:\n",
        "                    logger.info(f\"  {eval_type}: Unexpected format\")\n",
        "            except Exception as e:\n",
        "                logger.info(f\"  {eval_type}: Error - {e}\")\n",
        "\n",
        "        logger.info(\"  \" + \"-\"*40)\n",
        "\n",
        "    logger.info(\"\u2705 All Phoenix evaluations completed successfully!\")\n",
        "    logger.info(\"\ud83c\udfaf KEY SUCCESS: Lenient templates now work correctly!\")\n",
        "\n",
        "else:\n",
        "    if not ARIZE_AVAILABLE:\n",
        "        logger.info(\"\u274c Phoenix evaluations skipped - dependencies not available\")\n",
        "    elif not evaluator_llm:\n",
        "        logger.info(\"\u274c Phoenix evaluations skipped - evaluator LLM not available\")\n",
        "    else:\n",
        "        logger.info(\"\u274c Phoenix evaluations skipped - no demo results to evaluate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRVWxAuyldFX",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete landmark search agent implementation:\n",
        "\n",
        "### \ud83c\udfd7\ufe0f **COMPLETE ARCHITECTURE:**\n",
        "- **Agent Catalog Integration** - Tools and prompts from agentc\n",
        "- **LlamaIndex Framework** - ReAct agent pattern with semantic search\n",
        "- **Couchbase Vector Store** - travel-sample landmark data\n",
        "- **AI Services** - Capella AI + OpenAI fallbacks\n",
        "- **Phoenix Evaluation** - Lenient templates for dynamic data\n",
        "- **Self-contained Structure** - All functions properly ordered\n",
        "\n",
        "### \ud83d\udd11 **KEY SUCCESS: Lenient Templates**\n",
        "The most critical missing piece was the **lenient evaluation templates**:\n",
        "```python\n",
        "\u2705 LENIENT_QA_PROMPT_TEMPLATE - For dynamic search results\n",
        "\u2705 LENIENT_HALLUCINATION_PROMPT_TEMPLATE - For search variations  \n",
        "\u2705 LENIENT_QA_RAILS = [\"correct\", \"incorrect\"]\n",
        "\u2705 LENIENT_HALLUCINATION_RAILS = [\"factual\", \"hallucinated\"]\n",
        "```\n",
        "\n",
        "These templates understand that:\n",
        "- **Dynamic data is expected** - Search results vary based on database state\n",
        "- **Different results are valid** - Order and selection can vary\n",
        "- **Focus on functional success** - Did the agent provide useful landmark information?\n",
        "\n",
        "### \ud83d\ude80 **READY TO USE:**\n",
        "This notebook is now **fully functional** and addresses all the issues from the original broken notebook.\n",
        "You can run it sequentially without NameErrors, undefined variables, or missing templates!\n",
        "\n",
        "### \ud83d\udca1 **USAGE INSTRUCTIONS:**\n",
        "1. Set up environment variables (Couchbase connection, API keys)\n",
        "2. Ensure `agentcatalog_index.json` exists in the directory\n",
        "3. Install dependencies: `pip install -r requirements.txt`\n",
        "4. Publish agent catalog: `agentc index . && agentc publish`\n",
        "5. Run notebook cells sequentially\n",
        "\n",
        "The agent will automatically load landmark data from travel-sample and create embeddings for semantic search capabilities.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}