{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDGGbfZlmTCq",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Flight Search Agent Tutorial - Priority 1 Implementation\n",
        "\n",
        "This notebook demonstrates the Agent Catalog flight search agent using LangGraph with Couchbase vector store and Arize evaluation. Uses Priority 1 AI services with standard OpenAI wrappers and Capella (simple & fast).\n",
        "\n",
        "The agent provides comprehensive flight search capabilities including:\n",
        "- Flight lookup and search\n",
        "- Flight booking management\n",
        "- Airline review search\n",
        "- Booking retrieval and management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmfZF6U8gH12",
        "outputId": "6b4e3b64-4729-4d10-8ebb-e247b6a274ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWQCmIIngH12",
        "outputId": "75e25443-ce11-41e4-fbe2-9d78e26655e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-23 11:18:22--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/prompts/flight_search_assistant.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9279 (9.1K) [text/plain]\n",
            "Saving to: ‘prompts/flight_search_assistant.yaml’\n",
            "\n",
            "prompts/flight_sear 100%[===================>]   9.06K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-10-23 11:18:22 (12.4 MB/s) - ‘prompts/flight_search_assistant.yaml’ saved [9279/9279]\n",
            "\n",
            "--2025-10-23 11:18:23--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/lookup_flight_info.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3302 (3.2K) [text/plain]\n",
            "Saving to: ‘tools/lookup_flight_info.py’\n",
            "\n",
            "tools/lookup_flight 100%[===================>]   3.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 11:18:23 (39.8 MB/s) - ‘tools/lookup_flight_info.py’ saved [3302/3302]\n",
            "\n",
            "--2025-10-23 11:18:23--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/retrieve_flight_bookings.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6550 (6.4K) [text/plain]\n",
            "Saving to: ‘tools/retrieve_flight_bookings.py’\n",
            "\n",
            "tools/retrieve_flig 100%[===================>]   6.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 11:18:23 (65.2 MB/s) - ‘tools/retrieve_flight_bookings.py’ saved [6550/6550]\n",
            "\n",
            "--2025-10-23 11:18:23--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/save_flight_booking.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9381 (9.2K) [text/plain]\n",
            "Saving to: ‘tools/save_flight_booking.py’\n",
            "\n",
            "tools/save_flight_b 100%[===================>]   9.16K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-10-23 11:18:24 (7.46 MB/s) - ‘tools/save_flight_booking.py’ saved [9381/9381]\n",
            "\n",
            "--2025-10-23 11:18:24--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/search_airline_reviews.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5240 (5.1K) [text/plain]\n",
            "Saving to: ‘tools/search_airline_reviews.py’\n",
            "\n",
            "tools/search_airlin 100%[===================>]   5.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 11:18:24 (62.8 MB/s) - ‘tools/search_airline_reviews.py’ saved [5240/5240]\n",
            "\n",
            "--2025-10-23 11:18:24--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/schemas.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3615 (3.5K) [text/plain]\n",
            "Saving to: ‘tools/schemas.py’\n",
            "\n",
            "tools/schemas.py    100%[===================>]   3.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 11:18:25 (43.9 MB/s) - ‘tools/schemas.py’ saved [3615/3615]\n",
            "\n",
            "--2025-10-23 11:18:25--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/agentcatalog_index.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1956 (1.9K) [text/plain]\n",
            "Saving to: ‘agentcatalog_index.json’\n",
            "\n",
            "agentcatalog_index. 100%[===================>]   1.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 11:18:25 (24.6 MB/s) - ‘agentcatalog_index.json’ saved [1956/1956]\n",
            "\n",
            "--2025-10-23 11:18:25--  https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/.agentcignore\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27 [text/plain]\n",
            "Saving to: ‘.agentcignore’\n",
            "\n",
            ".agentcignore       100%[===================>]      27  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 11:18:25 (2.08 MB/s) - ‘.agentcignore’ saved [27/27]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download required resources for the flight search agent\n",
        "!mkdir -p prompts\n",
        "!wget -O prompts/flight_search_assistant.yaml https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/prompts/flight_search_assistant.yaml\n",
        "!mkdir -p tools\n",
        "!wget -O tools/lookup_flight_info.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/lookup_flight_info.py\n",
        "!wget -O tools/retrieve_flight_bookings.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/retrieve_flight_bookings.py\n",
        "!wget -O tools/save_flight_booking.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/save_flight_booking.py\n",
        "!wget -O tools/search_airline_reviews.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/search_airline_reviews.py\n",
        "!wget -O tools/schemas.py https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/tools/schemas.py\n",
        "!wget -O agentcatalog_index.json https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/agentcatalog_index.json\n",
        "!wget -O .agentcignore https://raw.githubusercontent.com/couchbase-examples/agent-catalog-quickstart/refs/heads/main/notebooks/flight_search_agent_langraph/.agentcignore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld1O6CqSgH13",
        "outputId": "5ef453ae-b43e-4dea-bbf6-515eff3d9796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.29.0 which is incompatible.\n",
            "mcp 1.18.0 requires uvicorn>=0.31.1; sys_platform != \"emscripten\", but you have uvicorn 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q \\\n",
        "    \"pydantic>=2.0.0,<3.0.0\" \\\n",
        "    \"pydantic-settings>=2.10.1,<3.0.0\" \\\n",
        "    \"python-dotenv>=1.0.0,<2.0.0\" \\\n",
        "    \"pandas>=2.0.0,<3.0.0\" \\\n",
        "    \"nest-asyncio>=1.6.0,<2.0.0\" \\\n",
        "    \"uvicorn>=0.29.0,<0.30.0\" \\\n",
        "    \"kagglehub>=0.2.0,<1.0.0\" \\\n",
        "    \"langchain-couchbase>=0.4.0,<0.5.0\" \\\n",
        "    \"langchain-openai>=0.3.11,<0.4.0\" \\\n",
        "    \"langchain-nvidia-ai-endpoints>=0.3.13,<0.4.0\" \\\n",
        "    \"langgraph>=0.5.1,<0.6.0\" \\\n",
        "    \"arize>=7.51.0,<8.0.0\" \\\n",
        "    \"arize-phoenix>=11.37.0,<12.0.0\" \\\n",
        "    \"arize-phoenix-evals>=2.2.0,<3.0.0\" \\\n",
        "    \"openinference-instrumentation-langchain>=0.1.29,<0.2.0\" \\\n",
        "    \"openinference-instrumentation-openai>=0.1.18,<0.2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPxLBXu4gH13",
        "outputId": "7ce39cbf-d50d-4b59-dd1c-d83572786b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/98.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m71.7/98.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m71.7/98.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m92.2/98.5 kB\u001b[0m \u001b[31m552.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m483.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gitignore-parser (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.29.0 which is incompatible.\n",
            "mcp 1.18.0 requires uvicorn>=0.31.1; sys_platform != \"emscripten\", but you have uvicorn 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_core-0.2.5a3-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_cli-0.2.5a3-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc-0.2.5a3-py3-none-any.whl\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_langchain-0.2.5a3-py3-none-any.whl # Explicitly install agentc_langchain a3\n",
        "%pip install -q https://github.com/couchbaselabs/agent-catalog/releases/download/v0.2.5a3/agentc_langgraph-0.2.5a3-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "94jTF0e6gH13"
      },
      "outputs": [],
      "source": [
        "# Install the couchbase-infrastructure package\n",
        "%pip install -q couchbase-infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QaglXlSgH13"
      },
      "source": [
        "## 🚀 Educational Infrastructure Setup\n",
        "\n",
        "**This cell sets up your Couchbase Capella infrastructure step-by-step using the `couchbase-infrastructure` package.**\n",
        "\n",
        "### What It Does:\n",
        "1. **Prompts for Credentials** - Securely collects your API key (no .env file needed for Colab!)\n",
        "2. **Creates Capella Project & Cluster** - Sets up your cloud database infrastructure\n",
        "3. **Loads travel-sample Data** - Imports the sample dataset for the tutorial\n",
        "4. **Deploys AI Models** - Provisions embedding (Mistral 7B) and LLM (Llama 3 8B) models\n",
        "5. **Configures Network Access** - Sets up CIDR allowlists for connectivity\n",
        "6. **Creates Database User** - Generates credentials with appropriate permissions\n",
        "7. **Sets Environment Variables** - Configures all required variables for the tutorial\n",
        "\n",
        "### You'll Be Prompted For:\n",
        "- `MANAGEMENT_API_KEY` (required) - Get from [Capella Console](https://cloud.couchbase.com) → Settings → API Keys\n",
        "- Optional: `ORGANIZATION_ID`, `PROJECT_NAME`, `CLUSTER_NAME` (defaults provided)\n",
        "\n",
        "### Process Time:\n",
        "⏳ This will take **10-15 minutes** for cluster and AI model deployment. You'll see step-by-step progress!\n",
        "\n",
        "### After Running:\n",
        "All subsequent cells will automatically use the provisioned infrastructure. No manual configuration needed!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yhwo9axFgH13",
        "outputId": "cea5bdfb-2a21-40c1-9f1f-86650f6040b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "🚀 Couchbase Capella Infrastructure Setup\n",
            "======================================================================\n",
            "\n",
            "This educational setup shows you how to provision Capella infrastructure\n",
            "step-by-step using the couchbase-infrastructure package.\n",
            "\n",
            "\n",
            "📋 Step 1: Collecting Credentials\n",
            "----------------------------------------------------------------------\n",
            "✅ Found .env file. Loading configuration...\n",
            "\n",
            "Get your credentials from: https://cloud.couchbase.com → Settings → API Keys\n",
            "\n",
            "✅ Using MANAGEMENT_API_KEY from environment\n",
            "✅ Using ORGANIZATION_ID from environment: 23086345-371f-4650-8dc4-c61733dd27a0\n",
            "Enter PROJECT_NAME (default: 'agent-app'): \n",
            "Enter CLUSTER_NAME (default: 'agent-app-cluster'): \n",
            "Enter DB_USERNAME (default: 'agent_app_user'): \n",
            "Enter BUCKET_NAME (default: 'travel-sample'): \n",
            "Enter EMBEDDING_MODEL (default: 'nvidia/llama-3.2-nv-embedqa-1b-v2'): \n",
            "Enter LLM_MODEL (default: 'meta/llama3-8b-instruct'): \n",
            "\n",
            "✅ Configuration collected successfully!\n",
            "\n",
            "\n",
            "🔧 Step 2: Initializing Configuration\n",
            "----------------------------------------------------------------------\n",
            "✅ Configuration initialized\n",
            "\n",
            "\n",
            "🔌 Step 3: Initializing Client\n",
            "----------------------------------------------------------------------\n",
            "✅ Using Organization ID: 23086345-371f-4650-8dc4-c61733dd27a0\n",
            "\n",
            "\n",
            "🔍 Step 4: Testing API Connection\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m🔍 Testing API connection\u001b[0m\u001b[1;34m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🔍 Testing API connection...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Current IP: \u001b[1;33m34.80.211.37\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current IP: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">34.80.211.37</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   API Base URL: \u001b[4;33mhttps://cloudapi.sbx-29.sandbox.nonprod-project-avengers.com\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   API Base URL: <span style=\"color: #808000; text-decoration-color: #808000; text-decoration: underline\">https://cloudapi.sbx-29.sandbox.nonprod-project-avengers.com</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Organization ID: \u001b[33m23086345-371f-4650-8dc4-c61733dd27a0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Organization ID: <span style=\"color: #808000; text-decoration-color: #808000\">23086345-371f-4650-8dc4-c61733dd27a0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   API Response Status: \u001b[1;33m200\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   API Response Status: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   \u001b[32m✅ Authentication successful\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">✅ Authentication successful</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API connection successful\n",
            "\n",
            "\n",
            "📁 Step 5: Creating Capella Project\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Searching for project named \u001b[32m'\u001b[0m\u001b[36magent-app\u001b[0m\u001b[32m'\u001b[0m\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Searching for project named <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-app</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ Found existing project.\u001b[0m Project ID: \u001b[36me04136ef-4809-44fc-b703-0824e01655a4\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Found existing project.</span> Project ID: <span style=\"color: #008080; text-decoration-color: #008080\">e04136ef-4809-44fc-b703-0824e01655a4</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Project ready: agent-app (ID: e04136ef-4809-44fc-b703-0824e01655a4)\n",
            "\n",
            "\n",
            "☁️ Step 6: Creating Developer Pro Cluster with Analytics\n",
            "----------------------------------------------------------------------\n",
            "⏳ This will take 10-15 minutes for cluster deployment...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Checking if cluster \u001b[32m'\u001b[0m\u001b[36magent-app-cluster\u001b[0m\u001b[32m'\u001b[0m already exists\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if cluster <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-app-cluster</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   \u001b[32m✅ Cluster \u001b[0m\u001b[32m'agent-app-cluster'\u001b[0m\u001b[32m already exists \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mStatus: unknown\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m Cluster ID: \n",
              "\u001b[36mb82a6f7f-a9b3-470d-824a-c321d30ad5f4\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">✅ Cluster </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent-app-cluster'</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">Status: unknown</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span> Cluster ID: \n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">b82a6f7f-a9b3-470d-824a-c321d30ad5f4</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Waiting for Cluster to become ready\u001b[33m...\u001b[0m \u001b[1m(\u001b[0mno timeout, will wait indefinitely\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting for Cluster to become ready<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>no timeout, will wait indefinitely<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Current status: \u001b[33mhealthy\u001b[0m \u001b[1m(\u001b[0melapsed: 0s\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current status: <span style=\"color: #808000; text-decoration-color: #808000\">healthy</span> <span style=\"font-weight: bold\">(</span>elapsed: 0s<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ Cluster is ready!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Cluster is ready!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cluster ready: agent-app-cluster (ID: b82a6f7f-a9b3-470d-824a-c321d30ad5f4)\n",
            "\n",
            "\n",
            "🌐 Step 7: Configuring Network Access\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Adding allowed CIDR \u001b[1;36m0.0.0.0\u001b[0m\u001b[36m/\u001b[0m\u001b[1;36m0\u001b[0m to cluster\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Adding allowed CIDR <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0.0.0</span><span style=\"color: #008080; text-decoration-color: #008080\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> to cluster<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Checking if CIDR already exists\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if CIDR already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   \u001b[32m✅ CIDR \u001b[0m\u001b[1;32m0.0.0.0\u001b[0m\u001b[32m/\u001b[0m\u001b[1;32m0\u001b[0m\u001b[32m already exists\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">✅ CIDR </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.0.0.0</span><span style=\"color: #008000; text-decoration-color: #008000\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Network access configured (0.0.0.0/0 allowed)\n",
            "\n",
            "\n",
            "📦 Step 8: Loading travel-sample Bucket\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ `travel-sample` bucket load command accepted.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ `travel-sample` bucket load command accepted.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ `travel-sample` bucket is ready.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ `travel-sample` bucket is ready.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sample data loaded: travel-sample\n",
            "\n",
            "\n",
            "👤 Step 9: Creating Database User\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Database user \u001b[32m'\u001b[0m\u001b[36magent_app_user\u001b[0m\u001b[32m'\u001b[0m already exists. Deleting to recreate with new password\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Database user <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent_app_user</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists. Deleting to recreate with new password<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   User \u001b[32m'\u001b[0m\u001b[36magent_app_user\u001b[0m\u001b[32m'\u001b[0m deleted successfully.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   User <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent_app_user</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> deleted successfully.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Database user \u001b[32m'\u001b[0m\u001b[36magent_app_user\u001b[0m\u001b[32m'\u001b[0m created successfully.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Database user <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent_app_user</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> created successfully.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Database user created: agent_app_user\n",
            "\n",
            "   Auto-generated password: Yadj...ift#\n",
            "\n",
            "\n",
            "🤖 Step 10: Deploying AI Models\n",
            "----------------------------------------------------------------------\n",
            "⏳ Deploying embedding and LLM models (5-10 minutes)...\n",
            "\n",
            "   Deploying embedding model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Checking if model \u001b[32m'\u001b[0m\u001b[36magent-hub-embedding-model\u001b[0m\u001b[32m'\u001b[0m already exists\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if model <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-hub-embedding-model</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Found \u001b[1;36m2\u001b[0m existing \u001b[1;35mmodel\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> existing <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   \u001b[32m✅ Model \u001b[0m\u001b[32m'agent-hub-embedding-model'\u001b[0m\u001b[32m already exists \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mStatus: healthy\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m Model ID: \n",
              "\u001b[36m22ffa6d6-87a3-45fd-905d-efb0c995ffa1\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">✅ Model </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent-hub-embedding-model'</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">Status: healthy</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span> Model ID: \n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">22ffa6d6-87a3-45fd-905d-efb0c995ffa1</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ✅ Model config matches. Reusing existing model.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ Model config matches. Reusing existing model.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Waiting for Embedding Model to become ready\u001b[33m...\u001b[0m \u001b[1m(\u001b[0mno timeout, will wait indefinitely\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting for Embedding Model to become ready<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>no timeout, will wait indefinitely<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Current status: \u001b[33mhealthy\u001b[0m \u001b[1m(\u001b[0melapsed: 0s\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current status: <span style=\"color: #808000; text-decoration-color: #808000\">healthy</span> <span style=\"font-weight: bold\">(</span>elapsed: 0s<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ Embedding Model is ready!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Embedding Model is ready!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embedding model deployed: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "   Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "\n",
            "   Deploying LLM model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Checking if model \u001b[32m'\u001b[0m\u001b[36magent-hub-llm-model\u001b[0m\u001b[32m'\u001b[0m already exists\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Checking if model <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008080; text-decoration-color: #008080\">agent-hub-llm-model</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> already exists<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Found \u001b[1;36m2\u001b[0m existing \u001b[1;35mmodel\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> existing <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   \u001b[32m✅ Model \u001b[0m\u001b[32m'agent-hub-llm-model'\u001b[0m\u001b[32m already exists \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mStatus: healthy\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m Model ID: \u001b[36m122c445e-636d-48c9-a1b1-b41043b30d17\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000\">✅ Model </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent-hub-llm-model'</span><span style=\"color: #008000; text-decoration-color: #008000\"> already exists </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">Status: healthy</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span> Model ID: <span style=\"color: #008080; text-decoration-color: #008080\">122c445e-636d-48c9-a1b1-b41043b30d17</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ✅ Model config matches. Reusing existing model.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ Model config matches. Reusing existing model.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Waiting for LLM Model to become ready\u001b[33m...\u001b[0m \u001b[1m(\u001b[0mno timeout, will wait indefinitely\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting for LLM Model to become ready<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>no timeout, will wait indefinitely<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Current status: \u001b[33mhealthy\u001b[0m \u001b[1m(\u001b[0melapsed: 0s\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Current status: <span style=\"color: #808000; text-decoration-color: #808000\">healthy</span> <span style=\"font-weight: bold\">(</span>elapsed: 0s<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ LLM Model is ready!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ LLM Model is ready!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM model deployed: meta/llama3-8b-instruct\n",
            "   Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "\n",
            "\n",
            "🔑 Step 11: Creating API Key for AI Models\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Creating API key for models in region \u001b[36mus-east-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Creating API key for models in region <span style=\"color: #008080; text-decoration-color: #008080\">us-east-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m✅ API key created successfully.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ API key created successfully.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Key ID: \u001b[36m7badc27f-10e0-5335-b04c-acba4d0fa3bc\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Key ID: <span style=\"color: #008080; text-decoration-color: #008080\">7badc27f-10e0-5335-b04c-acba4d0fa3bc</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Token: \u001b[36mcbsk-v1-N6xVwGDmGUuw\u001b[0m\u001b[36m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Token: <span style=\"color: #008080; text-decoration-color: #008080\">cbsk-v1-N6xVwGDmGUuw...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ AI API key created\n",
            "\n",
            "\n",
            "⚙️ Step 12: Setting Environment Variables\n",
            "----------------------------------------------------------------------\n",
            "⚠️  Added protocol to connection string: couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com\n",
            "✅ Environment variables configured:\n",
            "\n",
            "   CB_CONN_STRING: couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com\n",
            "   CB_USERNAME: agent_app_user\n",
            "   CB_BUCKET: travel-sample\n",
            "   CAPELLA_API_EMBEDDING_ENDPOINT: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "   CAPELLA_API_LLM_ENDPOINT: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "   CAPELLA_API_EMBEDDING_MODEL: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "   CAPELLA_API_LLM_MODEL: meta/llama3-8b-instruct\n",
            "\n",
            "======================================================================\n",
            "✅ Infrastructure Setup Complete!\n",
            "======================================================================\n",
            "\n",
            "You can now run the flight search agent cells below.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"🚀 Couchbase Capella Infrastructure Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis educational setup shows you how to provision Capella infrastructure\")\n",
        "print(\"step-by-step using the couchbase-infrastructure package.\\n\")\n",
        "\n",
        "# Import the infrastructure package\n",
        "from couchbase_infrastructure import CapellaConfig, CapellaClient\n",
        "from couchbase_infrastructure.resources import (\n",
        "    create_project,\n",
        "    create_developer_pro_cluster,\n",
        "    add_allowed_cidr,\n",
        "    load_sample_data,\n",
        "    create_database_user,\n",
        "    deploy_ai_model,\n",
        "    create_ai_api_key,\n",
        ")\n",
        "\n",
        "# Step 1: Load from .env file if available, then collect any missing credentials\n",
        "print(\"\\n📋 Step 1: Collecting Credentials\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Try to load .env file\n",
        "env_file = Path('.env')\n",
        "if env_file.exists():\n",
        "    print(\"✅ Found .env file. Loading configuration...\\n\")\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv('.env')\n",
        "else:\n",
        "    print(\"ℹ️  No .env file found. Will prompt for credentials.\\n\")\n",
        "\n",
        "print(\"Get your credentials from: https://cloud.couchbase.com → Settings → API Keys\\n\")\n",
        "\n",
        "# Required: MANAGEMENT_API_KEY\n",
        "management_api_key = os.getenv('MANAGEMENT_API_KEY')\n",
        "if management_api_key:\n",
        "    print(\"✅ Using MANAGEMENT_API_KEY from environment\")\n",
        "else:\n",
        "    management_api_key = getpass(\"Enter your MANAGEMENT_API_KEY (hidden): \")\n",
        "    if not management_api_key:\n",
        "        raise ValueError(\"MANAGEMENT_API_KEY is required!\")\n",
        "\n",
        "# Required: ORGANIZATION_ID\n",
        "organization_id = os.getenv('ORGANIZATION_ID')\n",
        "if organization_id:\n",
        "    print(f\"✅ Using ORGANIZATION_ID from environment: {organization_id}\")\n",
        "else:\n",
        "    organization_id = input(\"Enter your ORGANIZATION_ID (required): \").strip()\n",
        "    if not organization_id:\n",
        "        raise ValueError(\"ORGANIZATION_ID is required! Find it in Capella Console under Settings.\")\n",
        "\n",
        "# Optional configuration (use env vars if available, otherwise prompt with defaults)\n",
        "api_base_url = os.getenv('API_BASE_URL') or input(\"Enter API_BASE_URL (default: 'cloudapi.cloud.couchbase.com'): \").strip() or \"cloudapi.cloud.couchbase.com\"\n",
        "project_name = os.getenv('PROJECT_NAME') or input(\"Enter PROJECT_NAME (default: 'agent-app'): \").strip() or \"agent-app\"\n",
        "cluster_name = os.getenv('CLUSTER_NAME') or input(\"Enter CLUSTER_NAME (default: 'agent-app-cluster'): \").strip() or \"agent-app-cluster\"\n",
        "db_username = os.getenv('DB_USERNAME') or input(\"Enter DB_USERNAME (default: 'agent_app_user'): \").strip() or \"agent_app_user\"\n",
        "sample_bucket = os.getenv('SAMPLE_BUCKET') or input(\"Enter BUCKET_NAME (default: 'travel-sample'): \").strip() or \"travel-sample\"\n",
        "embedding_model = os.getenv('EMBEDDING_MODEL_NAME') or input(\"Enter EMBEDDING_MODEL (default: 'nvidia/llama-3.2-nv-embedqa-1b-v2'): \").strip() or \"nvidia/llama-3.2-nv-embedqa-1b-v2\"\n",
        "llm_model = os.getenv('LLM_MODEL_NAME') or input(\"Enter LLM_MODEL (default: 'meta/llama3-8b-instruct'): \").strip() or \"meta/llama3-8b-instruct\"\n",
        "\n",
        "print(\"\\n✅ Configuration collected successfully!\\n\")\n",
        "\n",
        "# Step 2: Initialize configuration\n",
        "print(\"\\n🔧 Step 2: Initializing Configuration\")\n",
        "print(\"-\"*70)\n",
        "config = CapellaConfig(\n",
        "    management_api_key=management_api_key,\n",
        "    organization_id=organization_id,\n",
        "    api_base_url=api_base_url,\n",
        "    project_name=project_name,\n",
        "    cluster_name=cluster_name,\n",
        "    db_username=db_username,\n",
        "    sample_bucket=sample_bucket,\n",
        "    embedding_model_name=embedding_model,\n",
        "    llm_model_name=llm_model,\n",
        ")\n",
        "print(\"✅ Configuration initialized\\n\")\n",
        "\n",
        "# Step 3: Initialize client and get organization ID\n",
        "print(\"\\n🔌 Step 3: Initializing Client\")\n",
        "print(\"-\"*70)\n",
        "client = CapellaClient(config)\n",
        "org_id = client.get_organization_id()\n",
        "print(f\"✅ Using Organization ID: {org_id}\\n\")\n",
        "\n",
        "# Step 4: Test API connection\n",
        "print(\"\\n🔍 Step 4: Testing API Connection\")\n",
        "print(\"-\"*70)\n",
        "if not client.test_connection(org_id):\n",
        "    raise ConnectionError(\"Failed to connect to Capella API\")\n",
        "print(\"✅ API connection successful\\n\")\n",
        "\n",
        "# Step 5: Create Capella Project\n",
        "print(\"\\n📁 Step 5: Creating Capella Project\")\n",
        "print(\"-\"*70)\n",
        "project_id = create_project(client, org_id, config.project_name)\n",
        "print(f\"✅ Project ready: {config.project_name} (ID: {project_id})\\n\")\n",
        "\n",
        "# Step 6: Create Developer Pro cluster with Analytics\n",
        "print(\"\\n☁️ Step 6: Creating Developer Pro Cluster with Analytics\")\n",
        "print(\"-\"*70)\n",
        "print(\"⏳ This will take 10-15 minutes for cluster deployment...\\n\")\n",
        "cluster_id = create_developer_pro_cluster(\n",
        "    client, org_id, project_id, config.cluster_name,\n",
        "    cloud_provider=config.cluster_cloud_provider,\n",
        "    region=config.cluster_region,\n",
        "    cidr=config.cluster_cidr\n",
        ")\n",
        "# Wait for cluster to be ready\n",
        "cluster_check_url = f\"/v4/organizations/{org_id}/projects/{project_id}/clusters/{cluster_id}\"\n",
        "cluster_details = client.wait_for_resource(cluster_check_url, \"Cluster\", None)\n",
        "cluster_conn_string = cluster_details.get(\"connectionString\")\n",
        "print(f\"✅ Cluster ready: {config.cluster_name} (ID: {cluster_id})\\n\")\n",
        "\n",
        "# Step 7: Configure network access\n",
        "print(\"\\n🌐 Step 7: Configuring Network Access\")\n",
        "print(\"-\"*70)\n",
        "add_allowed_cidr(client, org_id, project_id, cluster_id, config.allowed_cidr)\n",
        "print(\"✅ Network access configured (0.0.0.0/0 allowed)\\n\")\n",
        "\n",
        "# Step 8: Load travel-sample bucket\n",
        "print(\"\\n📦 Step 8: Loading travel-sample Bucket\")\n",
        "print(\"-\"*70)\n",
        "load_sample_data(client, org_id, project_id, cluster_id, config.sample_bucket)\n",
        "print(f\"✅ Sample data loaded: {config.sample_bucket}\\n\")\n",
        "\n",
        "# Step 9: Create database user (password auto-generated)\n",
        "print(\"\\n👤 Step 9: Creating Database User\")\n",
        "print(\"-\"*70)\n",
        "db_password = create_database_user(\n",
        "    client,\n",
        "    org_id,\n",
        "    project_id,\n",
        "    cluster_id,\n",
        "    config.db_username,\n",
        "    config.sample_bucket,\n",
        "    recreate_if_exists=True,  # Delete and recreate if exists to get fresh password\n",
        ")\n",
        "print(f\"✅ Database user created: {config.db_username}\\n\")\n",
        "if db_password and db_password != \"existing_user_password_not_retrievable\":\n",
        "    print(f\"   Auto-generated password: {db_password[:4]}...{db_password[-4:]}\\n\")\n",
        "\n",
        "# Step 10: Deploy AI models\n",
        "print(\"\\n🤖 Step 10: Deploying AI Models\")\n",
        "print(\"-\"*70)\n",
        "print(\"⏳ Deploying embedding and LLM models (5-10 minutes)...\\n\")\n",
        "\n",
        "# Deploy Embedding Model\n",
        "print(\"   Deploying embedding model...\")\n",
        "embedding_model_id = deploy_ai_model(\n",
        "    client,\n",
        "    org_id,\n",
        "    config.embedding_model_name,\n",
        "    \"agent-hub-embedding-model\",\n",
        "    \"embedding\",\n",
        "    config,\n",
        ")\n",
        "embedding_check_url = f\"/v4/organizations/{org_id}/aiServices/models/{embedding_model_id}\"\n",
        "embedding_details = client.wait_for_resource(embedding_check_url, \"Embedding Model\", None)\n",
        "\n",
        "# Extract endpoint from nested 'model' object\n",
        "model_info = embedding_details.get(\"model\", {})\n",
        "embedding_endpoint = model_info.get(\"connectionString\", \"\")\n",
        "\n",
        "print(f\"✅ Embedding model deployed: {config.embedding_model_name}\")\n",
        "print(f\"   Endpoint: {embedding_endpoint}\\n\")\n",
        "\n",
        "# Deploy LLM Model\n",
        "print(\"   Deploying LLM model...\")\n",
        "llm_model_id = deploy_ai_model(\n",
        "    client,\n",
        "    org_id,\n",
        "    config.llm_model_name,\n",
        "    \"agent-hub-llm-model\",\n",
        "    \"llm\",\n",
        "    config,\n",
        ")\n",
        "llm_check_url = f\"/v4/organizations/{org_id}/aiServices/models/{llm_model_id}\"\n",
        "llm_details = client.wait_for_resource(llm_check_url, \"LLM Model\", None)\n",
        "\n",
        "# Extract endpoint from nested 'model' object\n",
        "model_info = llm_details.get(\"model\", {})\n",
        "llm_endpoint = model_info.get(\"connectionString\", \"\")\n",
        "\n",
        "print(f\"✅ LLM model deployed: {config.llm_model_name}\")\n",
        "print(f\"   Endpoint: {llm_endpoint}\\n\")\n",
        "\n",
        "# Step 11: Create API Key for AI models\n",
        "print(\"\\n🔑 Step 11: Creating API Key for AI Models\")\n",
        "print(\"-\"*70)\n",
        "api_key = create_ai_api_key(client, org_id, config.ai_model_region)\n",
        "print(f\"✅ AI API key created\\n\")\n",
        "\n",
        "# Step 12: Set environment variables\n",
        "print(\"\\n⚙️ Step 12: Setting Environment Variables\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Set all environment variables for subsequent cells\n",
        "# Ensure connection string has proper protocol\n",
        "if not cluster_conn_string.startswith(\"couchbase://\") and not cluster_conn_string.startswith(\"couchbases://\"):\n",
        "    cluster_conn_string = f\"couchbases://{cluster_conn_string}\"\n",
        "    print(f\"⚠️  Added protocol to connection string: {cluster_conn_string}\")\n",
        "\n",
        "os.environ[\"CB_CONN_STRING\"] = cluster_conn_string + \"?tls_verify=none\"\n",
        "os.environ[\"CB_USERNAME\"] = config.db_username\n",
        "os.environ[\"CB_PASSWORD\"] = db_password\n",
        "os.environ[\"CB_BUCKET\"] = config.sample_bucket\n",
        "os.environ[\"CAPELLA_API_ENDPOINT\"] = embedding_endpoint  # Use as base endpoint\n",
        "os.environ[\"CAPELLA_API_EMBEDDING_ENDPOINT\"] = embedding_endpoint\n",
        "os.environ[\"CAPELLA_API_LLM_ENDPOINT\"] = llm_endpoint\n",
        "os.environ[\"CAPELLA_API_EMBEDDINGS_KEY\"] = api_key\n",
        "os.environ[\"CAPELLA_API_LLM_KEY\"] = api_key\n",
        "os.environ[\"CAPELLA_API_EMBEDDING_MODEL\"] = config.embedding_model_name\n",
        "os.environ[\"CAPELLA_API_LLM_MODEL\"] = config.llm_model_name\n",
        "\n",
        "print(\"✅ Environment variables configured:\\n\")\n",
        "print(f\"   CB_CONN_STRING: {cluster_conn_string}\")\n",
        "print(f\"   CB_USERNAME: {config.db_username}\")\n",
        "print(f\"   CB_BUCKET: {config.sample_bucket}\")\n",
        "print(f\"   CAPELLA_API_EMBEDDING_ENDPOINT: {embedding_endpoint}\")\n",
        "print(f\"   CAPELLA_API_LLM_ENDPOINT: {llm_endpoint}\")\n",
        "print(f\"   CAPELLA_API_EMBEDDING_MODEL: {config.embedding_model_name}\")\n",
        "print(f\"   CAPELLA_API_LLM_MODEL: {config.llm_model_name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Infrastructure Setup Complete!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou can now run the flight search agent cells below.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0cNe4nUmgH14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "outputId": "f32b177f-9487-4df9-b754-8a03a3c59620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent Catalog environment variables set:\n",
            "   AGENT_CATALOG_CONN_STRING: couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com\n",
            "   AGENT_CATALOG_USERNAME: agent_app_user\n",
            "   AGENT_CATALOG_BUCKET: travel-sample\n",
            "\n",
            "======================================================================\n",
            "📜 Root Certificate Setup\n",
            "======================================================================\n",
            "\n",
            "⚠️  IMPORTANT: You need to download the root certificate from Capella UI\n",
            "\n",
            "Steps:\n",
            "1. Go to Capella Console: https://cloud.couchbase.com\n",
            "2. Navigate to your cluster → Connect tab\n",
            "3. Download the 'Root Certificate' file\n",
            "4. Upload it using the file upload below\n",
            "\n",
            "📤 Please upload your root certificate file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be711dae-09fd-43a5-8f5b-25f17b12c294\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be711dae-09fd-43a5-8f5b-25f17b12c294\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving agent-app-cluster-root-certificate.txt to agent-app-cluster-root-certificate.txt\n",
            "\n",
            "✅ Root certificate uploaded: agent-app-cluster-root-certificate.txt\n",
            "   AGENT_CATALOG_CONN_ROOT_CERTIFICATE: agent-app-cluster-root-certificate.txt\n",
            "\n",
            "======================================================================\n",
            "✅ Agent Catalog Configuration Complete\n",
            "======================================================================\n",
            "\n",
            "✅ Environment variables written to .env file for agentc commands\n",
            "\n",
            "🔍 Verifying .env file contents:\n",
            "/content\n",
            "-rw-r--r-- 1 root root 1022 Oct 23 11:21 .env\n",
            "\n",
            "First 5 lines of .env (passwords masked):\n",
            "  CB_CONN_STRING=couchbases://cb.maggf6p2qyrvsjib.sandbox.nonprod-project-avengers.com?tls_verify=none\n",
            "  CB_USERNAME=agent_app_user\n",
            "  CB_PASSWORD=***\n",
            "  CB_BUCKET=travel-sample\n",
            "  CAPELLA_API_ENDPOINT=https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n"
          ]
        }
      ],
      "source": [
        "# Set Agent Catalog environment variables (required for agentc commands)\n",
        "# These use the same Couchbase connection created above\n",
        "import os\n",
        "\n",
        "# Strip the ?tls_verify=none from the connection string for agentc\n",
        "conn_string = os.environ[\"CB_CONN_STRING\"]\n",
        "if conn_string.endswith(\"?tls_verify=none\"):\n",
        "    conn_string_clean = conn_string[:-len(\"?tls_verify=none\")]\n",
        "else:\n",
        "    conn_string_clean = conn_string\n",
        "\n",
        "# Ensure connection string has proper protocol (agentc requires couchbase:// or couchbases://)\n",
        "if not conn_string_clean.startswith(\"couchbase://\") and not conn_string_clean.startswith(\"couchbases://\"):\n",
        "    # Add couchbases:// protocol for secure connections\n",
        "    conn_string_clean = f\"couchbases://{conn_string_clean}\"\n",
        "    print(f\"⚠️  Added protocol to connection string: {conn_string_clean}\")\n",
        "\n",
        "os.environ[\"AGENT_CATALOG_CONN_STRING\"] = conn_string_clean\n",
        "\n",
        "os.environ[\"AGENT_CATALOG_USERNAME\"] = os.environ[\"CB_USERNAME\"]\n",
        "os.environ[\"AGENT_CATALOG_PASSWORD\"] = os.environ[\"CB_PASSWORD\"]\n",
        "os.environ[\"AGENT_CATALOG_BUCKET\"] = os.environ[\"CB_BUCKET\"]\n",
        "\n",
        "print(\"✅ Agent Catalog environment variables set:\")\n",
        "print(f\"   AGENT_CATALOG_CONN_STRING: {os.environ['AGENT_CATALOG_CONN_STRING']}\")\n",
        "print(f\"   AGENT_CATALOG_USERNAME: {os.environ['AGENT_CATALOG_USERNAME']}\")\n",
        "print(f\"   AGENT_CATALOG_BUCKET: {os.environ['AGENT_CATALOG_BUCKET']}\")\n",
        "\n",
        "# Handle root certificate (required for secure connections)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📜 Root Certificate Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n⚠️  IMPORTANT: You need to download the root certificate from Capella UI\")\n",
        "print(\"\\nSteps:\")\n",
        "print(\"1. Go to Capella Console: https://cloud.couchbase.com\")\n",
        "print(\"2. Navigate to your cluster → Connect tab\")\n",
        "print(\"3. Download the 'Root Certificate' file\")\n",
        "print(\"4. Upload it using the file upload below\\n\")\n",
        "\n",
        "# Try to use Google Colab's file upload, fallback to manual input\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"📤 Please upload your root certificate file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        cert_filename = list(uploaded.keys())[0]\n",
        "        # Validate it's actually a certificate file\n",
        "        if cert_filename.endswith(('.pem', '.crt', '.cer', '.txt')):\n",
        "            os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = cert_filename\n",
        "            print(f\"\\n✅ Root certificate uploaded: {cert_filename}\")\n",
        "            print(f\"   AGENT_CATALOG_CONN_ROOT_CERTIFICATE: {cert_filename}\")\n",
        "        else:\n",
        "            print(f\"\\n⚠️  Uploaded file '{cert_filename}' doesn't appear to be a certificate (.pem, .crt, .cer, .txt)\")\n",
        "            print(\"   Skipping certificate setup. You can configure it later if needed.\")\n",
        "            os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "    else:\n",
        "        print(\"\\n⚠️  No file uploaded. You can set it manually later if needed.\")\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "except ImportError:\n",
        "    # Not in Colab - ask user to place file and provide filename\n",
        "    print(\"📝 Not running in Google Colab.\")\n",
        "    print(\"   Please place the root certificate file in the current directory.\\n\")\n",
        "    cert_filename = input(\"Enter the certificate filename (or press Enter to skip): \").strip()\n",
        "\n",
        "    if cert_filename:\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = cert_filename\n",
        "        print(f\"\\n✅ Root certificate set: {cert_filename}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️  Root certificate not set. You can add it manually later if needed.\")\n",
        "        os.environ[\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE\"] = \"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Agent Catalog Configuration Complete\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Write environment variables to .env file for agentc commands\n",
        "# agentc CLI will load from .env file automatically\n",
        "import os.path\n",
        "with open('.env', 'w') as f:\n",
        "    # CB variables (needed for database operations - prevents wiping by dotenv.load_dotenv)\n",
        "    f.write(f\"CB_CONN_STRING={os.environ['CB_CONN_STRING']}\\n\")\n",
        "    f.write(f\"CB_USERNAME={os.environ['CB_USERNAME']}\\n\")\n",
        "    f.write(f\"CB_PASSWORD={os.environ['CB_PASSWORD']}\\n\")\n",
        "    f.write(f\"CB_BUCKET={os.environ['CB_BUCKET']}\\n\")\n",
        "\n",
        "    # CAPELLA_API variables (needed for AI services - prevents wiping by dotenv.load_dotenv)\n",
        "    f.write(f\"CAPELLA_API_ENDPOINT={os.environ.get('CAPELLA_API_ENDPOINT', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDING_ENDPOINT={os.environ.get('CAPELLA_API_EMBEDDING_ENDPOINT', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_ENDPOINT={os.environ.get('CAPELLA_API_LLM_ENDPOINT', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDINGS_KEY={os.environ.get('CAPELLA_API_EMBEDDINGS_KEY', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_KEY={os.environ.get('CAPELLA_API_LLM_KEY', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_EMBEDDING_MODEL={os.environ.get('CAPELLA_API_EMBEDDING_MODEL', '')}\\n\")\n",
        "    f.write(f\"CAPELLA_API_LLM_MODEL={os.environ.get('CAPELLA_API_LLM_MODEL', '')}\\n\")\n",
        "\n",
        "    # AGENT_CATALOG variables (for agentc CLI)\n",
        "    f.write(f\"AGENT_CATALOG_CONN_STRING={os.environ['AGENT_CATALOG_CONN_STRING']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_USERNAME={os.environ['AGENT_CATALOG_USERNAME']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_PASSWORD={os.environ['AGENT_CATALOG_PASSWORD']}\\n\")\n",
        "    f.write(f\"AGENT_CATALOG_BUCKET={os.environ['AGENT_CATALOG_BUCKET']}\\n\")\n",
        "\n",
        "    # Only write certificate if it exists and is a valid file\n",
        "    cert = os.environ.get('AGENT_CATALOG_CONN_ROOT_CERTIFICATE', '').strip()\n",
        "    if cert and os.path.isfile(cert):\n",
        "        f.write(f\"AGENT_CATALOG_CONN_ROOT_CERTIFICATE={cert}\\n\")\n",
        "    elif cert:\n",
        "        print(f\"⚠️  Warning: Certificate file '{cert}' not found, skipping from .env\")\n",
        "\n",
        "print(\"\\n✅ Environment variables written to .env file for agentc commands\")\n",
        "\n",
        "# Verify .env file was created correctly\n",
        "print(\"\\n🔍 Verifying .env file contents:\")\n",
        "!pwd\n",
        "!ls -la .env\n",
        "print(\"\\nFirst 5 lines of .env (passwords masked):\")\n",
        "with open('.env', 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i < 5:\n",
        "            if 'PASSWORD' in line:\n",
        "                print(f\"  {line.split('=')[0]}=***\")\n",
        "            else:\n",
        "                print(f\"  {line.strip()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYyHXwKlyZy8"
      },
      "source": [
        "### Optional: Configure OpenAI and Arize (Observability)\n",
        "\n",
        "Provide optional API keys for:\n",
        "- **OpenAI**: Fallback LLM/embeddings if Capella AI is unavailable\n",
        "- **Arize Phoenix**: Observability and evaluation platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uwDtVrNyZy9",
        "outputId": "defb1d3c-bfab-4ef3-e113-538d92d79910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "🔧 Optional API Keys Configuration\n",
            "======================================================================\n",
            "\n",
            "📝 OpenAI API (Optional - for fallback LLM/embeddings)\n",
            "----------------------------------------------------------------------\n",
            "Press Enter to skip, or provide your OpenAI API key:\n",
            "OpenAI API Key: ··········\n",
            "✅ OpenAI API key configured\n",
            "   Model: gpt-4o\n",
            "\n",
            "📊 Arize Phoenix (Optional - for observability and evaluation)\n",
            "----------------------------------------------------------------------\n",
            "Press Enter to skip, or provide your Arize credentials:\n",
            "Arize Space ID: ··········\n",
            "Arize API Key: ··········\n",
            "✅ Arize Phoenix configured\n",
            "\n",
            "======================================================================\n",
            "✅ Optional Configuration Complete\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"🔧 Optional API Keys Configuration\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# OpenAI Configuration (optional - for fallback)\n",
        "print(\"\\n📝 OpenAI API (Optional - for fallback LLM/embeddings)\")\n",
        "print(\"-\"*70)\n",
        "print(\"Press Enter to skip, or provide your OpenAI API key:\")\n",
        "try:\n",
        "    openai_api_key = getpass.getpass(\"OpenAI API Key: \").strip()\n",
        "except:\n",
        "    # Fallback for environments where getpass doesn't work\n",
        "    openai_api_key = \"\"\n",
        "\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gpt-4o\"  # Default model\n",
        "    print(\"✅ OpenAI API key configured\")\n",
        "    print(f\"   Model: gpt-4o\")\n",
        "else:\n",
        "    print(\"⏭️  Skipped OpenAI configuration (will use Capella AI only)\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gpt-4o\"\n",
        "\n",
        "# Arize Phoenix Configuration (optional - for observability)\n",
        "print(\"\\n📊 Arize Phoenix (Optional - for observability and evaluation)\")\n",
        "print(\"-\"*70)\n",
        "print(\"Press Enter to skip, or provide your Arize credentials:\")\n",
        "try:\n",
        "    arize_space_id = getpass.getpass(\"Arize Space ID: \").strip()\n",
        "    arize_api_key = getpass.getpass(\"Arize API Key: \").strip() if arize_space_id else \"\"\n",
        "except:\n",
        "    # Fallback for environments where getpass doesn't work\n",
        "    arize_space_id = \"\"\n",
        "    arize_api_key = \"\"\n",
        "\n",
        "if arize_space_id and arize_api_key:\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = arize_space_id\n",
        "    os.environ[\"ARIZE_API_KEY\"] = arize_api_key\n",
        "    print(\"✅ Arize Phoenix configured\")\n",
        "else:\n",
        "    print(\"⏭️  Skipped Arize configuration (observability disabled)\")\n",
        "    os.environ[\"ARIZE_SPACE_ID\"] = \"\"\n",
        "    os.environ[\"ARIZE_API_KEY\"] = \"\"\n",
        "\n",
        "# Append optional variables to .env file\n",
        "with open('.env', 'a') as f:\n",
        "    f.write(\"\\n# Optional: OpenAI Configuration (fallback LLM/embeddings)\\n\")\n",
        "    f.write(f\"OPENAI_API_KEY={os.environ['OPENAI_API_KEY']}\\n\")\n",
        "    f.write(f\"OPENAI_MODEL={os.environ['OPENAI_MODEL']}\\n\")\n",
        "\n",
        "    f.write(\"\\n# Optional: Arize Phoenix (observability and evaluation)\\n\")\n",
        "    f.write(f\"ARIZE_SPACE_ID={os.environ['ARIZE_SPACE_ID']}\\n\")\n",
        "    f.write(f\"ARIZE_API_KEY={os.environ['ARIZE_API_KEY']}\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Optional Configuration Complete\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Czit8mxTgH14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2213a7e-58ca-4fd2-e5aa-50db8f72eb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ],
      "source": [
        "!git init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-dza6HeygH14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb014b9-6951-4fe2-fd8e-4b0e418c950b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[master (root-commit) a9db1ca] initial commit\n",
            " 31 files changed, 52109 insertions(+)\n",
            " create mode 100644 .agentcignore\n",
            " create mode 100644 .config/.last_opt_in_prompt.yaml\n",
            " create mode 100644 .config/.last_survey_prompt.yaml\n",
            " create mode 100644 .config/.last_update_check.json\n",
            " create mode 100644 .config/active_config\n",
            " create mode 100644 .config/config_sentinel\n",
            " create mode 100644 .config/configurations/config_default\n",
            " create mode 100644 .config/default_configs.db\n",
            " create mode 100644 .config/gce\n",
            " create mode 100644 .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            " create mode 100644 .config/logs/2025.10.21/16.51.10.047293.log\n",
            " create mode 100644 .config/logs/2025.10.21/16.51.30.790200.log\n",
            " create mode 100644 .config/logs/2025.10.21/16.51.39.965567.log\n",
            " create mode 100644 .config/logs/2025.10.21/16.51.41.225539.log\n",
            " create mode 100644 .config/logs/2025.10.21/16.51.50.106792.log\n",
            " create mode 100644 .config/logs/2025.10.21/16.51.50.856899.log\n",
            " create mode 100644 .env\n",
            " create mode 100644 agent-app-cluster-root-certificate.txt\n",
            " create mode 100644 agentcatalog_index.json\n",
            " create mode 100644 prompts/flight_search_assistant.yaml\n",
            " create mode 100755 sample_data/README.md\n",
            " create mode 100755 sample_data/anscombe.json\n",
            " create mode 100644 sample_data/california_housing_test.csv\n",
            " create mode 100644 sample_data/california_housing_train.csv\n",
            " create mode 100644 sample_data/mnist_test.csv\n",
            " create mode 100644 sample_data/mnist_train_small.csv\n",
            " create mode 100644 tools/lookup_flight_info.py\n",
            " create mode 100644 tools/retrieve_flight_bookings.py\n",
            " create mode 100644 tools/save_flight_booking.py\n",
            " create mode 100644 tools/schemas.py\n",
            " create mode 100644 tools/search_airline_reviews.py\n"
          ]
        }
      ],
      "source": [
        "!git add .\n",
        "!git config --global user.email \"your.email@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "!git commit -m \"initial commit\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TrqZAWxagH14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e189e810-e2e0-4127-fe8b-630ba57310e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-23 11:22:40.241967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761218560.266108    1738 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761218560.273794    1738 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761218560.292157    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761218560.292200    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761218560.292205    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761218560.292209    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-23 11:22:40.297773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:agentc_core.learned.embedding:Failed to load embedding model sentence-transformers/all-MiniLM-L12-v2 (attempt 0): We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Check your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.97MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 738kB/s]\n",
            "README.md: 10.5kB [00:00, 25.5MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 368kB/s]\n",
            "config.json: 100% 615/615 [00:00<00:00, 4.33MB/s]\n",
            "model.safetensors: 100% 133M/133M [00:02<00:00, 50.0MB/s]\n",
            "tokenizer_config.json: 100% 352/352 [00:00<00:00, 2.34MB/s]\n",
            "vocab.txt: 232kB [00:00, 8.39MB/s]\n",
            "tokenizer.json: 466kB [00:00, 21.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 848kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.34MB/s]\n",
            "\u001b[32mMetadata collection has been successfully created!\n",
            "\u001b[0m\n",
            "v2_AgentCatalogMetadataPrimaryIndex: 100% 1/1 [00:02<00:00,  2.71s/it]\n",
            "\u001b[32mGSI metadata index for the has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the catalog collection for the prompt catalog.\u001b[0m\n",
            "\u001b[32mCollection for prompts has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the GSI indexes for the prompt catalog.\u001b[0m\n",
            "v2_AgentCatalogPromptsAnnotationsIndex: 100% 3/3 [00:06<00:00,  2.09s/it]\n",
            "\u001b[32mAll GSI indexes for the prompt catalog have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the vector index for the prompt catalog.\u001b[0m\n",
            "\u001b[32mVector index for the prompt catalog has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the catalog collection for the tool catalog.\u001b[0m\n",
            "\u001b[32mCollection for tools has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the GSI indexes for the tool catalog.\u001b[0m\n",
            "v2_AgentCatalogToolsAnnotationsIndex: 100% 3/3 [00:06<00:00,  2.09s/it]\n",
            "\u001b[32mAll GSI indexes for the tool catalog have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow building the vector index for the tool catalog.\u001b[0m\n",
            "\u001b[32mVector index for the tool catalog has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the analytics collections for our catalog.\u001b[0m\n",
            "\u001b[32mAll analytics collections for the catalog have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating scope and collections for the auditor.\u001b[0m\n",
            "\u001b[32mScope and collection for the auditor have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the primary index for the auditor.\u001b[0m\n",
            "v2_AgentCatalogLogsPrimaryIndex: 100% 1/1 [00:02<00:00,  2.93s/it]\n",
            "\u001b[32mPrimary index for the auditor has been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the query UDFs for the auditor.\u001b[0m\n",
            "\u001b[32mAll query UDFs for the auditor have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[33mNow creating the analytics views for the auditor.\u001b[0m\n",
            "\u001b[32mAll analytics views for the auditor have been successfully created!\n",
            "\u001b[0m\n",
            "\u001b[32mPost-commit hook for  have successfully been installed!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!agentc init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NefIjKW_gH14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d67915-26c7-4aae-c14c-016c352ee35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[95m\u001b[0m\n",
            "\u001b[95m\u001b[1mTOOL\u001b[0m\n",
            "\u001b[95m\u001b[0m\n",
            "Crawling .:\u001b[0m\n",
            "\r  0% 0/8 [00:00<?, ?it/s]\r.last_survey_prompt.yaml:   0% 0/8 [00:00<?, ?it/s]Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_survey_prompt.yaml.\n",
            ".last_opt_in_prompt.yaml:   0% 0/8 [00:00<?, ?it/s]Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_opt_in_prompt.yaml.\n",
            "flight_search_assistant.yaml: 100% 8/8 [00:06<00:00,  1.21it/s]\n",
            "\n",
            "Generating embeddings:\u001b[0m\n",
            "save_flight_booking:   0% 0/4 [00:00<?, ?it/s]2025-10-23 11:23:53.297830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761218633.321112    2143 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761218633.328212    2143 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761218633.345099    2143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761218633.345139    2143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761218633.345144    2143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761218633.345149    2143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-23 11:23:53.350181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "lookup_flight_info: 100% 4/4 [00:08<00:00,  2.21s/it]\n",
            "\u001b[32m\n",
            "Catalog successfully indexed!\u001b[0m\n",
            "\u001b[95m\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "\u001b[34m\u001b[1mPROMPT\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "Crawling .:\u001b[0m\n",
            ".last_survey_prompt.yaml:   0% 0/3 [00:00<?, ?it/s]WARNING:agentc_core.indexer.indexer:Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_survey_prompt.yaml.\n",
            ".last_opt_in_prompt.yaml:   0% 0/3 [00:00<?, ?it/s]WARNING:agentc_core.indexer.indexer:Encountered .yaml file with unknown record_kind field. Not indexing /content/.config/.last_opt_in_prompt.yaml.\n",
            "flight_search_assistant.yaml: 100% 3/3 [00:00<00:00, 152.21it/s]\n",
            "\n",
            "Generating embeddings:\u001b[0m\n",
            "flight_search_assistant: 100% 1/1 [00:00<00:00,  4.99it/s]\n",
            "\u001b[32m\n",
            "Catalog successfully indexed!\u001b[0m\n",
            "\u001b[34m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!agentc index .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OgV2nmNpgH14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22dc5d4-e312-481f-b160-e3669590ead9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[95m\u001b[0m\n",
            "\u001b[95m\u001b[1mTOOL\u001b[0m\n",
            "\u001b[95m\u001b[0m\n",
            "Using the catalog identifier: \u001b[0m\u001b[1ma9db1ca17c99d64c4bc9bce1b1386f1694d9c62a\n",
            "\u001b[0m\n",
            "\u001b[33mUploading the tool catalog items to Couchbase.\u001b[0m\n",
            "search_airline_reviews: 100% 4/4 [00:00<00:00,  4.37it/s]\n",
            "\u001b[32mTool catalog items successfully uploaded to Couchbase!\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "\u001b[34m\u001b[1mPROMPT\u001b[0m\n",
            "\u001b[34m\u001b[0m\n",
            "Using the catalog identifier: \u001b[0m\u001b[1ma9db1ca17c99d64c4bc9bce1b1386f1694d9c62a\n",
            "\u001b[0m\n",
            "\u001b[33mUploading the prompt catalog items to Couchbase.\u001b[0m\n",
            "flight_search_assistant: 100% 1/1 [00:00<00:00,  2.74it/s]\n",
            "\u001b[32mPrompt catalog items successfully uploaded to Couchbase!\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!agentc publish\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abGx3vEkmTCr",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary modules for the flight search agent using the latest code structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fp4GDdukmTCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5037ec6f-2eec-4c28-c348-017fe780bb5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "import agentc\n",
        "import agentc_langgraph.agent\n",
        "import agentc_langgraph.graph\n",
        "import dotenv\n",
        "import langchain_core.messages\n",
        "import langchain_core.runnables\n",
        "import langchain_openai.chat_models\n",
        "import langgraph.graph\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.exceptions import KeyspaceNotFoundException\n",
        "from couchbase.options import ClusterOptions\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from pydantic import SecretStr\n",
        "\n",
        "# Setup logging for Colab (must use stdout instead of stderr)\n",
        "root_logger = logging.getLogger()\n",
        "if not root_logger.handlers:\n",
        "    handler = logging.StreamHandler(sys.stdout)\n",
        "    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
        "    handler.setFormatter(formatter)\n",
        "    root_logger.addHandler(handler)\n",
        "root_logger.setLevel(logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress verbose logging from external libraries\n",
        "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"agentc_core\").setLevel(logging.WARNING)\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv(override=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7AQo_w5mTCs",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Project Root Discovery and Shared Imports\n",
        "\n",
        "Essential project root discovery and shared module imports exactly as in working main.py.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G2f3bgI_mTCs"
      },
      "outputs": [],
      "source": [
        "# INLINE IMPLEMENTATION - Universal AI Services and Couchbase Client\n",
        "import base64\n",
        "import time\n",
        "from typing import Tuple, Any, Optional, List\n",
        "from datetime import timedelta\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.exceptions import KeyspaceNotFoundException\n",
        "from couchbase.management.buckets import BucketType, CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "\n",
        "# We'll add the function implementations in the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umeyMLs0mTCs",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Universal AI Services Setup\n",
        "\n",
        "5-case priority AI service setup implementation inline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d3EuELHqmTCs"
      },
      "outputs": [],
      "source": [
        "def setup_ai_services(\n",
        "    framework: str = \"langchain\",\n",
        "    temperature: float = 0.0,\n",
        "    callbacks: Optional[List] = None,\n",
        "    application_span: Optional[Any] = None\n",
        ") -> Tuple[Any, Any]:\n",
        "    \"\"\"Priority 1 AI service setup - Capella with direct API keys + OpenAI wrappers only.\"\"\"\n",
        "    embeddings = None\n",
        "    llm = None\n",
        "\n",
        "    logger.info(f\"🔧 Setting up Priority 1 AI services for {framework} framework...\")\n",
        "\n",
        "    # PRIORITY 1: LATEST CAPELLA (OpenAI wrappers with direct API keys)\n",
        "    if (\n",
        "        not embeddings\n",
        "        and os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        and os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "    ):\n",
        "        try:\n",
        "            if framework == \"llamaindex\":\n",
        "                from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "                embeddings = OpenAIEmbedding(\n",
        "                    api_key=os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\"),\n",
        "                    api_base=f\"{os.getenv('CAPELLA_API_ENDPOINT')}/v1\",\n",
        "                    model_name=os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\"),\n",
        "                    embed_batch_size=30,\n",
        "                )\n",
        "            else:  # langchain, langgraph\n",
        "                from langchain_openai import OpenAIEmbeddings\n",
        "                embeddings = OpenAIEmbeddings(\n",
        "                    model=os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\"),\n",
        "                    api_key=os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\"),\n",
        "                    base_url=f\"{os.getenv('CAPELLA_API_ENDPOINT')}/v1\",\n",
        "                    check_embedding_ctx_length=False,  # Fix for asymmetric models\n",
        "                )\n",
        "            logger.info(\"✅ Using latest Capella AI embeddings (direct API key + OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Latest Capella AI embeddings failed: {e}\")\n",
        "\n",
        "    if (\n",
        "        not llm\n",
        "        and os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        and os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "    ):\n",
        "        try:\n",
        "            if framework == \"llamaindex\":\n",
        "                from llama_index.llms.openai_like import OpenAILike\n",
        "                llm = OpenAILike(\n",
        "                    model=os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
        "                    api_base=f\"{os.getenv('CAPELLA_API_ENDPOINT')}/v1\",\n",
        "                    api_key=os.getenv(\"CAPELLA_API_LLM_KEY\"),\n",
        "                    is_chat_model=True,\n",
        "                    temperature=temperature,\n",
        "                )\n",
        "            else:  # langchain, langgraph\n",
        "                from langchain_openai import ChatOpenAI\n",
        "\n",
        "                chat_kwargs = {\n",
        "                    \"api_key\": os.getenv(\"CAPELLA_API_LLM_KEY\"),\n",
        "                    \"base_url\": f\"{os.getenv('CAPELLA_API_ENDPOINT')}/v1\",\n",
        "                    \"model\": os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
        "                    \"temperature\": temperature,\n",
        "                }\n",
        "                if callbacks:\n",
        "                    chat_kwargs[\"callbacks\"] = callbacks\n",
        "\n",
        "                llm = ChatOpenAI(**chat_kwargs)\n",
        "\n",
        "            # Test the LLM works\n",
        "            if framework == \"llamaindex\":\n",
        "                llm.complete(\"Hello\")\n",
        "            else:\n",
        "                llm.invoke(\"Hello\")\n",
        "\n",
        "            logger.info(\"✅ Using latest Capella AI LLM (direct API key + OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Latest Capella AI LLM failed: {e}\")\n",
        "            llm = None\n",
        "\n",
        "    # VALIDATION\n",
        "    if not embeddings:\n",
        "        raise ValueError(\"❌ No embeddings service could be initialized\")\n",
        "    if not llm:\n",
        "        raise ValueError(\"❌ No LLM service could be initialized\")\n",
        "\n",
        "    logger.info(f\"✅ AI services setup completed for {framework}\")\n",
        "    return embeddings, llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfKX0OpmTCt",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "Environment setup and connectivity test functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dU591dHNmTCt"
      },
      "outputs": [],
      "source": [
        "def setup_environment():\n",
        "    \"\"\"Setup default environment variables for agent operations.\"\"\"\n",
        "    defaults = {\n",
        "        \"CB_BUCKET\": \"travel-sample\",\n",
        "        \"CB_SCOPE\": \"agentc_data\",\n",
        "        \"CB_COLLECTION\": \"airline_reviews\",\n",
        "        \"CB_INDEX\": \"airline_reviews_index\",\n",
        "        \"CAPELLA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"CAPELLA_API_LLM_MODEL\": \"meta/llama-3-8b-instruct\",\n",
        "        \"CAPELLA_API_EMBEDDING_MAX_TOKENS\": \"512\",\n",
        "        \"NVIDIA_API_EMBEDDING_MODEL\": \"nvidia/nv-embedqa-e5-v5\",\n",
        "        \"NVIDIA_API_LLM_MODEL\": \"meta/llama-3.1-70b-instruct\",\n",
        "    }\n",
        "\n",
        "    for key, value in defaults.items():\n",
        "        if not os.getenv(key):\n",
        "            os.environ[key] = value\n",
        "\n",
        "    logger.info(\"✅ Environment variables configured\")\n",
        "\n",
        "\n",
        "def test_capella_connectivity(api_key: str = None, endpoint: str = None) -> bool:\n",
        "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
        "    try:\n",
        "        import httpx\n",
        "\n",
        "        test_key = api_key or os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\") or os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "        test_endpoint = endpoint or os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "\n",
        "        if not test_key or not test_endpoint:\n",
        "            return False\n",
        "\n",
        "        headers = {\"Authorization\": f\"Bearer {test_key}\"}\n",
        "\n",
        "        with httpx.Client(timeout=10.0) as client:\n",
        "            response = client.get(f\"{test_endpoint.rstrip('/')}/v1/models\", headers=headers)\n",
        "            return response.status_code < 500\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"⚠️ Capella connectivity test failed: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-8xkvOnmTCt",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Universal Couchbase Client\n",
        "\n",
        "Complete Couchbase client implementation with database operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Cz7oscM9mTCt"
      },
      "outputs": [],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Universal Couchbase client for all database operations across agent frameworks.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        conn_string: str,\n",
        "        username: str,\n",
        "        password: str,\n",
        "        bucket_name: str,\n",
        "        wan_profile: bool = True,\n",
        "        timeout_seconds: int = 20,\n",
        "    ):\n",
        "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.wan_profile = wan_profile\n",
        "        self.timeout_seconds = timeout_seconds\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "\n",
        "            if self.wan_profile:\n",
        "                options.apply_profile(\"wan_development\")\n",
        "\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=self.timeout_seconds))\n",
        "            logger.info(\"✅ Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"❌ Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_bucket(self, create_if_missing: bool = True):\n",
        "        \"\"\"Setup bucket - connect to existing or create if missing.\"\"\"\n",
        "        try:\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            try:\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"✅ Connected to existing bucket '{self.bucket_name}'\")\n",
        "                return self.bucket\n",
        "            except Exception as e:\n",
        "                logger.info(f\"⚠️ Bucket '{self.bucket_name}' not accessible: {e}\")\n",
        "\n",
        "            if create_if_missing:\n",
        "                logger.info(f\"🔧 Creating bucket '{self.bucket_name}'...\")\n",
        "                bucket_settings = CreateBucketSettings(\n",
        "                    name=self.bucket_name,\n",
        "                    bucket_type=BucketType.COUCHBASE,\n",
        "                    ram_quota_mb=1024,\n",
        "                    flush_enabled=True,\n",
        "                    num_replicas=0,\n",
        "                )\n",
        "                self.cluster.buckets().create_bucket(bucket_settings)\n",
        "                time.sleep(5)\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                logger.info(f\"✅ Bucket '{self.bucket_name}' created successfully\")\n",
        "                return self.bucket\n",
        "            else:\n",
        "                raise RuntimeError(f\"❌ Bucket '{self.bucket_name}' not found\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"❌ Error setting up bucket: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str, clear_existing_data: bool = True, create_primary_index: bool = True):\n",
        "        \"\"\"Setup collection with comprehensive options.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                self.setup_bucket()\n",
        "\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                logger.info(f\"🔧 Creating scope '{scope_name}'...\")\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "                logger.info(f\"✅ Scope '{scope_name}' created successfully\")\n",
        "\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name\n",
        "                and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists:\n",
        "                if clear_existing_data:\n",
        "                    logger.info(f\"🗑️ Collection '{collection_name}' exists, clearing data...\")\n",
        "                    self.clear_collection_data(scope_name, collection_name)\n",
        "                else:\n",
        "                    logger.info(f\"ℹ️ Collection '{collection_name}' exists, keeping existing data\")\n",
        "            else:\n",
        "                logger.info(f\"🔧 Creating collection '{collection_name}'...\")\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "                logger.info(f\"✅ Collection '{collection_name}' created successfully\")\n",
        "\n",
        "            time.sleep(3)\n",
        "\n",
        "            if create_primary_index:\n",
        "                try:\n",
        "                    self.cluster.query(\n",
        "                        f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                    ).execute()\n",
        "                    logger.info(\"✅ Primary index created successfully\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"⚠️ Error creating primary index: {e}\")\n",
        "\n",
        "            collection_key = f\"{scope_name}.{collection_name}\"\n",
        "            collection = self.bucket.scope(scope_name).collection(collection_name)\n",
        "            self._collections[collection_key] = collection\n",
        "\n",
        "            logger.info(f\"✅ Collection setup complete: {scope_name}.{collection_name}\")\n",
        "            return collection\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"❌ Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str, verify_cleared: bool = True):\n",
        "        \"\"\"Clear all data from a collection.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"🗑️ Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "            list(result)\n",
        "\n",
        "            time.sleep(2)\n",
        "\n",
        "            if verify_cleared:\n",
        "                count_query = f\"SELECT COUNT(*) as count FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                count_result = self.cluster.query(count_query)\n",
        "                count_row = list(count_result)[0]\n",
        "                remaining_count = count_row[\"count\"]\n",
        "\n",
        "                if remaining_count == 0:\n",
        "                    logger.info(f\"✅ Collection cleared successfully\")\n",
        "                else:\n",
        "                    logger.warning(f\"⚠️ Collection clear incomplete, {remaining_count} documents remaining\")\n",
        "\n",
        "        except KeyspaceNotFoundException:\n",
        "            logger.info(f\"ℹ️ Collection doesn't exist, nothing to clear\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error clearing collection data: {e}\")\n",
        "\n",
        "    def clear_scope(self, scope_name: str):\n",
        "        \"\"\"Clear all collections in the specified scope.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                self.setup_bucket()\n",
        "\n",
        "            logger.info(f\"🗑️ Clearing scope: {self.bucket_name}.{scope_name}\")\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "\n",
        "            target_scope = None\n",
        "            for scope in scopes:\n",
        "                if scope.name == scope_name:\n",
        "                    target_scope = scope\n",
        "                    break\n",
        "\n",
        "            if not target_scope:\n",
        "                logger.info(f\"ℹ️ Scope '{self.bucket_name}.{scope_name}' does not exist\")\n",
        "                return\n",
        "\n",
        "            for collection in target_scope.collections:\n",
        "                try:\n",
        "                    self.clear_collection_data(scope_name, collection.name, verify_cleared=False)\n",
        "                    logger.info(f\"✅ Cleared collection: {collection.name}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"⚠️ Could not clear collection {collection.name}: {e}\")\n",
        "\n",
        "            logger.info(f\"✅ Completed clearing scope: {self.bucket_name}.{scope_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"❌ Could not clear scope: {e}\")\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                raise RuntimeError(\"❌ Bucket not initialized. Call setup_bucket first.\")\n",
        "\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                logger.info(f\"🔧 Creating vector search index '{index_name}'...\")\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"✅ Vector search index '{index_name}' created successfully\")\n",
        "            else:\n",
        "                logger.info(f\"ℹ️ Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"❌ Error setting up vector search index: {e!s}\")\n",
        "\n",
        "    def load_index_definition(self, index_file_path: str = \"agentcatalog_index.json\"):\n",
        "        \"\"\"Load vector search index definition from JSON file.\"\"\"\n",
        "        try:\n",
        "            with open(index_file_path) as file:\n",
        "                index_definition = json.load(file)\n",
        "            logger.info(f\"✅ Loaded index definition from {index_file_path}\")\n",
        "            return index_definition\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(f\"⚠️ {index_file_path} not found\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error loading index definition: {e!s}\")\n",
        "            return None\n",
        "\n",
        "    def setup_vector_store_langchain(self, scope_name: str, collection_name: str, index_name: str, embeddings, data_loader_func=None, **loader_kwargs):\n",
        "        \"\"\"Setup LangChain CouchbaseSearchVectorStore with optional data loading.\"\"\"\n",
        "        try:\n",
        "            from langchain_couchbase.vectorstores import CouchbaseSearchVectorStore\n",
        "\n",
        "            if data_loader_func:\n",
        "                logger.info(\"🔄 Loading data into vector store...\")\n",
        "                data_loader_func(\n",
        "                    cluster=self.cluster,\n",
        "                    bucket_name=self.bucket_name,\n",
        "                    scope_name=scope_name,\n",
        "                    collection_name=collection_name,\n",
        "                    embeddings=embeddings,\n",
        "                    index_name=index_name,\n",
        "                    **loader_kwargs,\n",
        "                )\n",
        "                logger.info(\"✅ Data loaded into vector store successfully\")\n",
        "\n",
        "            vector_store = CouchbaseSearchVectorStore(\n",
        "                cluster=self.cluster,\n",
        "                bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embedding=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "\n",
        "            logger.info(f\"✅ LangChain vector store setup complete\")\n",
        "            return vector_store\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"❌ Error setting up LangChain vector store: {e!s}\")\n",
        "\n",
        "\n",
        "def create_couchbase_client(\n",
        "    conn_string: str = None,\n",
        "    username: str = None,\n",
        "    password: str = None,\n",
        "    bucket_name: str = None,\n",
        "    wan_profile: bool = True,\n",
        "    timeout_seconds: int = 20,\n",
        ") -> CouchbaseClient:\n",
        "    \"\"\"Factory function to create CouchbaseClient with environment variable defaults.\"\"\"\n",
        "    return CouchbaseClient(\n",
        "        conn_string=conn_string or os.getenv(\"CB_CONN_STRING\", \"couchbase://localhost\"),\n",
        "        username=username or os.getenv(\"CB_USERNAME\", \"Administrator\"),\n",
        "        password=password or os.getenv(\"CB_PASSWORD\", \"password\"),\n",
        "        bucket_name=bucket_name or os.getenv(\"CB_BUCKET\", \"travel-sample\"),\n",
        "        wan_profile=wan_profile,\n",
        "        timeout_seconds=timeout_seconds,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-F17qGvmTCu",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Shared Flight Search Queries\n",
        "\n",
        "Exact code from queries.py - flight search queries and reference answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "78O608HUmTCu"
      },
      "outputs": [],
      "source": [
        "# Flight search queries (for evaluation and testing)\n",
        "FLIGHT_SEARCH_QUERIES = [\n",
        "    \"Find flights from JFK to LAX\",\n",
        "    \"Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\",\n",
        "    \"Book an economy flight from JFK to MIA for next week, 1 passenger\",\n",
        "    \"Show me my current flight bookings\",\n",
        "    \"What do passengers say about SpiceJet's service quality?\",\n",
        "]\n",
        "\n",
        "# Comprehensive reference answers based on actual system responses\n",
        "FLIGHT_REFERENCE_ANSWERS = [\n",
        "    # Query 1: Flight search JFK to LAX\n",
        "    \"\"\"Available flights from JFK to LAX:\n",
        "\n",
        "1. AS flight from JFK to LAX using 321 762\n",
        "2. B6 flight from JFK to LAX using 320\n",
        "3. DL flight from JFK to LAX using 76W 752\n",
        "4. QF flight from JFK to LAX using 744\n",
        "5. AA flight from JFK to LAX using 32B 762\n",
        "6. UA flight from JFK to LAX using 757\n",
        "7. US flight from JFK to LAX using 32B 762\n",
        "8. VX flight from JFK to LAX using 320\"\"\",\n",
        "\n",
        "    # Query 2: Flight booking LAX to JFK for tomorrow, 2 passengers, business class\n",
        "    \"\"\"Flight Booking Confirmed!\n",
        "\n",
        "Booking ID: FL08061563CACD\n",
        "Route: LAX → JFK\n",
        "Departure Date: 2025-08-06\n",
        "Passengers: 2\n",
        "Class: business\n",
        "Total Price: $1500.00\n",
        "\n",
        "Next Steps:\n",
        "1. Check-in opens 24 hours before departure\n",
        "2. Arrive at airport 2 hours early for domestic flights\n",
        "3. Bring valid government-issued photo ID\n",
        "\n",
        "Thank you for choosing our airline!\"\"\",\n",
        "\n",
        "    # Query 3: Flight booking JFK to MIA for next week\n",
        "    \"\"\"Flight Booking Confirmed!\n",
        "\n",
        "Booking ID: FL08124E7B9C2A\n",
        "Route: JFK → MIA\n",
        "Departure Date: 2025-08-12\n",
        "Passengers: 1\n",
        "Class: economy\n",
        "Total Price: $250.00\n",
        "\n",
        "Next Steps:\n",
        "1. Check-in opens 24 hours before departure\n",
        "2. Arrive at airport 2 hours early for domestic flights\n",
        "3. Bring valid government-issued photo ID\n",
        "\n",
        "Thank you for choosing our airline!\"\"\",\n",
        "\n",
        "    # Query 4: Show current flight bookings\n",
        "    \"\"\"Your Current Bookings (2 found):\n",
        "\n",
        "Booking 1:\n",
        "  Booking ID: FL08061563CACD\n",
        "  Route: LAX → JFK\n",
        "  Date: 2025-08-06\n",
        "  Passengers: 2\n",
        "  Class: business\n",
        "  Total: $1500.00\n",
        "  Status: confirmed\n",
        "  Booked: 2025-08-05\n",
        "\n",
        "Booking 2:\n",
        "  Booking ID: FL08124E7B9C2A\n",
        "  Route: JFK → MIA\n",
        "  Date: 2025-08-12\n",
        "  Passengers: 1\n",
        "  Class: economy\n",
        "  Total: $250.00\n",
        "  Status: confirmed\n",
        "  Booked: 2025-08-05\"\"\",\n",
        "\n",
        "    # Query 5: SpiceJet service quality reviews\n",
        "    \"\"\"Found 5 relevant airline reviews for 'SpiceJet service':\n",
        "\n",
        "Review 1:\n",
        "Airline: SpiceJet. Title: \"Service is impeccable\". Review: ✅ Trip Verified | Much better than airbus models. Even the basic economy class has ambient lighting. Better personal air vents and better spotlights. Even overhead storage bins are good. Service is impeccable with proper care taken of guests...\n",
        "\n",
        "Review 2:\n",
        "Airline: SpiceJet. Title: \"good service by the crew\". Review: ✅ Trip Verified | I have had good service by the crew. It was amazing, the crew was very enthusiastic and warm welcome. It was one of the best services in my experience.. Rating: 10.0/10. Reviewer: K Mansour. Date: 10th August 2024. Recom...\n",
        "\n",
        "Review 3:\n",
        "Airline: SpiceJet. Title: \"outstanding service I experienced\". Review: Not Verified |  I wanted to take a moment to express my sincere thanks for the outstanding service I experienced on my recent flight from Pune to Delhi. SG-8937. From the moment I boarded, the warmth and friendliness of the air h...\n",
        "\n",
        "Review 4:\n",
        "Airline: SpiceJet. Title: \"efficient and warm onboard service\". Review: ✅ Trip Verified |  New Delhi to Kolkata. Delighted with the prompt, efficient and warm onboard service provided by the crew. Appreciate their efforts towards customer centricity.. Rating: 10.0/10. Reviewer: Debashis Roy. Date: 2...\n",
        "\n",
        "Review 5:\n",
        "Airline: SpiceJet. Title: \"Service is very good\". Review: Service is very good,  I am impressed with Miss Renu  who gave the best services ever. Thanks to Renu who is very sweet by her nature as well as her service. Rating: 9.0/10. Reviewer: Sanjay Patnaik. Date: 21st September 2023. Recommended: ye...\"\"\",\n",
        "]\n",
        "\n",
        "# Create dictionary for backward compatibility\n",
        "QUERY_REFERENCE_ANSWERS = {\n",
        "    query: answer for query, answer in zip(FLIGHT_SEARCH_QUERIES, FLIGHT_REFERENCE_ANSWERS)\n",
        "}\n",
        "\n",
        "def get_test_queries():\n",
        "    \"\"\"Return test queries for evaluation.\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_evaluation_queries():\n",
        "    \"\"\"Get queries for evaluation\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_all_queries():\n",
        "    \"\"\"Get all available queries\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_simple_queries():\n",
        "    \"\"\"Get simple queries for basic testing\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_flight_policy_queries():\n",
        "    \"\"\"Return flight policy queries (for backward compatibility).\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_reference_answer(query: str) -> str:\n",
        "    \"\"\"Get the correct reference answer for a given query\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS.get(query, f\"No reference answer available for: {query}\")\n",
        "\n",
        "def get_all_query_references():\n",
        "    \"\"\"Get all query-reference pairs\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyAUlqTImTCv",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Airline Reviews Data Module\n",
        "\n",
        "Exact code from airline_reviews_data.py - data loading and processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BzF7cnZTmTCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a53bff-e0e8-4770-f2c1-4bf03f5a874e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from langchain_couchbase.vectorstores import CouchbaseSearchVectorStore\n",
        "\n",
        "# Import kagglehub only when needed\n",
        "try:\n",
        "    import kagglehub\n",
        "except ImportError:\n",
        "    kagglehub = None\n",
        "\n",
        "class AirlineReviewsDataManager:\n",
        "    \"\"\"Manages airline reviews data loading, processing, and embedding.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._raw_data_cache = None\n",
        "        self._processed_texts_cache = None\n",
        "\n",
        "    def load_raw_data(self):\n",
        "        \"\"\"Load raw airline reviews data from Kaggle dataset (with caching).\"\"\"\n",
        "        if self._raw_data_cache is not None:\n",
        "            return self._raw_data_cache\n",
        "\n",
        "        try:\n",
        "            if kagglehub is None:\n",
        "                raise ImportError(\"kagglehub is not available\")\n",
        "\n",
        "            logger.info(\"Downloading Indian Airlines Customer Reviews dataset from Kaggle...\")\n",
        "            path = kagglehub.dataset_download(\"jagathratchakan/indian-airlines-customer-reviews\")\n",
        "\n",
        "            csv_file = None\n",
        "            for file in os.listdir(path):\n",
        "                if file.endswith(\".csv\"):\n",
        "                    csv_file = os.path.join(path, file)\n",
        "                    break\n",
        "\n",
        "            if not csv_file:\n",
        "                msg = \"No CSV file found in downloaded dataset\"\n",
        "                raise FileNotFoundError(msg)\n",
        "\n",
        "            logger.info(f\"Loading reviews from {csv_file}\")\n",
        "            df = pd.read_csv(csv_file)\n",
        "\n",
        "            self._raw_data_cache = df.to_dict(\"records\")\n",
        "            logger.info(f\"Loaded {len(self._raw_data_cache)} airline reviews from Kaggle dataset\")\n",
        "            return self._raw_data_cache\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"Error loading airline reviews from Kaggle: {e!s}\")\n",
        "            raise\n",
        "\n",
        "    def process_to_texts(self):\n",
        "        \"\"\"Process raw data into formatted text strings for embedding (with caching).\"\"\"\n",
        "        if self._processed_texts_cache is not None:\n",
        "            return self._processed_texts_cache\n",
        "\n",
        "        reviews = self.load_raw_data()\n",
        "        review_texts = []\n",
        "\n",
        "        for review in reviews:\n",
        "            text_parts = []\n",
        "\n",
        "            if review.get(\"AirLine_Name\"):\n",
        "                text_parts.append(f\"Airline: {review['AirLine_Name']}\")\n",
        "\n",
        "            if review.get(\"Title\"):\n",
        "                text_parts.append(f\"Title: {review['Title']}\")\n",
        "\n",
        "            if review.get(\"Review\"):\n",
        "                text_parts.append(f\"Review: {review['Review']}\")\n",
        "\n",
        "            if review.get(\"Rating - 10\"):\n",
        "                text_parts.append(f\"Rating: {review['Rating - 10']}/10\")\n",
        "\n",
        "            if review.get(\"Name\"):\n",
        "                text_parts.append(f\"Reviewer: {review['Name']}\")\n",
        "\n",
        "            if review.get(\"Date\"):\n",
        "                text_parts.append(f\"Date: {review['Date']}\")\n",
        "\n",
        "            if review.get(\"Recommond\"):\n",
        "                text_parts.append(f\"Recommended: {review['Recommond']}\")\n",
        "\n",
        "            text = \". \".join(text_parts)\n",
        "            review_texts.append(text)\n",
        "\n",
        "        self._processed_texts_cache = review_texts\n",
        "        logger.info(f\"Processed {len(review_texts)} airline reviews into text format\")\n",
        "        return review_texts\n",
        "\n",
        "    def load_to_vector_store(\n",
        "        self,\n",
        "        cluster,\n",
        "        bucket_name: str,\n",
        "        scope_name: str,\n",
        "        collection_name: str,\n",
        "        embeddings,\n",
        "        index_name: str,\n",
        "    ):\n",
        "        \"\"\"Load airline reviews into Couchbase vector store with embeddings.\"\"\"\n",
        "        try:\n",
        "            count_query = (\n",
        "                f\"SELECT COUNT(*) as count FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            )\n",
        "            count_result = cluster.query(count_query)\n",
        "            count_row = next(iter(count_result))\n",
        "            existing_count = count_row[\"count\"]\n",
        "\n",
        "            if existing_count > 0:\n",
        "                logger.info(\n",
        "                    f\"Found {existing_count} existing documents in collection, skipping data load\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            review_texts = self.process_to_texts()\n",
        "\n",
        "            vector_store = CouchbaseSearchVectorStore(\n",
        "                cluster=cluster,\n",
        "                bucket_name=bucket_name,\n",
        "                scope_name=scope_name,\n",
        "                collection_name=collection_name,\n",
        "                embedding=embeddings,\n",
        "                index_name=index_name,\n",
        "            )\n",
        "\n",
        "            logger.info(\n",
        "                f\"Loading {len(review_texts)} airline review embeddings to {bucket_name}.{scope_name}.{collection_name}\"\n",
        "            )\n",
        "\n",
        "            batch_size = 10  # Conservative batch size for stability\n",
        "            total_batches = (len(review_texts) + batch_size - 1) // batch_size\n",
        "\n",
        "            with tqdm(\n",
        "                total=len(review_texts), desc=\"Loading airline reviews\", unit=\"reviews\"\n",
        "            ) as pbar:\n",
        "                for i in range(0, len(review_texts), batch_size):\n",
        "                    batch_num = i // batch_size + 1\n",
        "                    batch = review_texts[i : i + batch_size]\n",
        "\n",
        "                    vector_store.add_texts(texts=batch, batch_size=len(batch))\n",
        "\n",
        "                    pbar.update(len(batch))\n",
        "                    pbar.set_postfix(batch=f\"{batch_num}/{total_batches}\")\n",
        "\n",
        "            logger.info(\n",
        "                f\"Successfully loaded {len(review_texts)} airline review embeddings to vector store\"\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"Error loading airline reviews to Couchbase: {e!s}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "# Global instance for reuse\n",
        "_data_manager = AirlineReviewsDataManager()\n",
        "\n",
        "\n",
        "def get_airline_review_texts():\n",
        "    \"\"\"Get processed airline review texts (uses global cached instance).\"\"\"\n",
        "    return _data_manager.process_to_texts()\n",
        "\n",
        "\n",
        "def load_airline_reviews_from_kaggle():\n",
        "    \"\"\"Load raw airline reviews data from Kaggle (uses global cached instance).\"\"\"\n",
        "    return _data_manager.load_raw_data()\n",
        "\n",
        "\n",
        "def load_airline_reviews_to_couchbase(\n",
        "    cluster, bucket_name: str, scope_name: str, collection_name: str, embeddings, index_name: str\n",
        "):\n",
        "    \"\"\"Load airline reviews into Couchbase vector store (uses global cached instance).\"\"\"\n",
        "    return _data_manager.load_to_vector_store(\n",
        "        cluster, bucket_name, scope_name, collection_name, embeddings, index_name\n",
        "    )\n",
        "\n",
        "\n",
        "def load_airline_reviews():\n",
        "    \"\"\"Simple function to load airline reviews - called by main.py.\"\"\"\n",
        "    try:\n",
        "        # Just return the processed texts for embedding\n",
        "        # This eliminates the need for separate cluster connection here\n",
        "        logger.info(\"Loading airline reviews data...\")\n",
        "        reviews = _data_manager.process_to_texts()\n",
        "        logger.info(f\"Successfully loaded {len(reviews)} airline reviews\")\n",
        "        return reviews\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in load_airline_reviews: {e!s}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ajWVAemTCv",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Agent Classes and Core Implementation\n",
        "\n",
        "Core agent classes and implementation from working main.py script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "P2tjFmkimTCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449d2627-bb40-4151-d2c1-3bc87dfef895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Environment variables configured\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All setup functions and client implementations are now available inline.\n"
          ]
        }
      ],
      "source": [
        "# Agent classes are implemented using the inline AI services and Couchbase client above\n",
        "print(\"All setup functions and client implementations are now available inline.\")\n",
        "def setup_ai_services(\n",
        "    framework: str = \"langchain\",\n",
        "    temperature: float = 0.0,\n",
        "    callbacks: Optional[List] = None,\n",
        "    application_span: Optional[Any] = None\n",
        ") -> Tuple[Any, Any]:\n",
        "    \"\"\"Priority 1 AI service setup - Capella with direct API keys + OpenAI wrappers only.\"\"\"\n",
        "    embeddings = None\n",
        "    llm = None\n",
        "\n",
        "    logger.info(f\"🔧 Setting up Priority 1 AI services for {framework} framework...\")\n",
        "\n",
        "    # PRIORITY 1: LATEST CAPELLA (OpenAI wrappers with direct API keys)\n",
        "    if (\n",
        "        not embeddings\n",
        "        and os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "        and os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "    ):\n",
        "        try:\n",
        "            from langchain_openai import OpenAIEmbeddings\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            api_key = os.getenv(\"CAPELLA_API_EMBEDDINGS_KEY\")\n",
        "            model = os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\")\n",
        "\n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                base_url = endpoint\n",
        "            else:\n",
        "                base_url = f\"{endpoint}/v1\"\n",
        "\n",
        "            # Debug logging - same pattern as working test\n",
        "            logger.info(f\"🔧 Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 Model: {model}\")\n",
        "            logger.info(f\"🔧 Base URL: {base_url}\")\n",
        "\n",
        "            embeddings = OpenAIEmbeddings(\n",
        "                model=model,\n",
        "                api_key=api_key,\n",
        "                base_url=base_url,\n",
        "                check_embedding_ctx_length=False,  # KEY FIX for asymmetric models in LangChain/LangGraph\n",
        "            )\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI embeddings failed: {type(e).__name__}: {e}\")\n",
        "\n",
        "    if not llm and os.getenv(\"CAPELLA_API_ENDPOINT\") and os.getenv(\"CAPELLA_API_LLM_KEY\"):\n",
        "        try:\n",
        "            from langchain_openai import ChatOpenAI\n",
        "\n",
        "            endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
        "            llm_key = os.getenv(\"CAPELLA_API_LLM_KEY\")\n",
        "            llm_model = os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
        "\n",
        "            # Handle endpoint that may or may not already have /v1 suffix\n",
        "            if endpoint.endswith('/v1'):\n",
        "                base_url = endpoint\n",
        "            else:\n",
        "                base_url = f\"{endpoint}/v1\"\n",
        "\n",
        "            # Debug logging\n",
        "            logger.info(f\"🔧 LLM Endpoint: {endpoint}\")\n",
        "            logger.info(f\"🔧 LLM Model: {llm_model}\")\n",
        "            logger.info(f\"🔧 LLM Base URL: {base_url}\")\n",
        "\n",
        "            llm = ChatOpenAI(\n",
        "                api_key=llm_key,\n",
        "                base_url=base_url,\n",
        "                model=llm_model,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            # Test the LLM works\n",
        "            from langchain_core.messages import HumanMessage\n",
        "            test_response = llm.invoke([HumanMessage(content=\"Hello\")])\n",
        "            logger.info(\"✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Priority 1 Capella AI LLM failed: {type(e).__name__}: {e}\")\n",
        "            llm = None\n",
        "\n",
        "    # Fallback: OpenAI\n",
        "    if not embeddings and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            from langchain_openai import OpenAIEmbeddings\n",
        "            embeddings = OpenAIEmbeddings(\n",
        "                model=\"text-embedding-3-small\",\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI embeddings fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI embeddings failed: {e}\")\n",
        "\n",
        "    if not llm and os.getenv(\"OPENAI_API_KEY\"):\n",
        "        try:\n",
        "            from langchain_openai import ChatOpenAI\n",
        "            llm = ChatOpenAI(\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                model=\"gpt-4o\",\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            logger.info(\"✅ Using OpenAI LLM fallback\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ OpenAI LLM failed: {e}\")\n",
        "\n",
        "    if not embeddings:\n",
        "        raise ValueError(\"❌ No embeddings service could be initialized\")\n",
        "    if not llm:\n",
        "        raise ValueError(\"❌ No LLM service could be initialized\")\n",
        "\n",
        "    logger.info(f\"✅ Priority 1 AI services setup completed for {framework}\")\n",
        "    return embeddings, llm\n",
        "\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()\n",
        "\n",
        "# Test Capella AI connectivity if configured\n",
        "if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "    if not test_capella_connectivity():\n",
        "        logger.warning(\"❌ Capella AI connectivity test failed. Will use fallback models.\")\n",
        "else:\n",
        "    logger.info(\"ℹ️ Capella API not configured - will use fallback models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBnkb9fUmTCv",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## CouchbaseClient Class\n",
        "\n",
        "Define the CouchbaseClient for all database operations inline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1ZpmJfgVmTCv"
      },
      "outputs": [],
      "source": [
        "class CouchbaseClient:\n",
        "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
        "\n",
        "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
        "        self.conn_string = conn_string\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.bucket_name = bucket_name\n",
        "        self.cluster = None\n",
        "        self.bucket = None\n",
        "        self._collections = {}\n",
        "\n",
        "    def connect(self):\n",
        "        try:\n",
        "            auth = PasswordAuthenticator(self.username, self.password)\n",
        "            options = ClusterOptions(auth)\n",
        "            options.apply_profile(\"wan_development\")\n",
        "            self.cluster = Cluster(self.conn_string, options)\n",
        "            self.cluster.wait_until_ready(timedelta(seconds=15))\n",
        "            logger.info(\"✅ Successfully connected to Couchbase\")\n",
        "            return self.cluster\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"❌ Failed to connect to Couchbase: {e!s}\")\n",
        "\n",
        "    def setup_collection(self, scope_name: str, collection_name: str, clear_existing_data: bool = False):\n",
        "        try:\n",
        "            if not self.cluster:\n",
        "                self.connect()\n",
        "\n",
        "            if not self.bucket:\n",
        "                try:\n",
        "                    self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "                except Exception:\n",
        "                    logger.info(f\"Creating bucket '{self.bucket_name}'...\")\n",
        "                    bucket_settings = CreateBucketSettings(\n",
        "                        name=self.bucket_name, bucket_type=BucketType.COUCHBASE,\n",
        "                        ram_quota_mb=1024, flush_enabled=True, num_replicas=0\n",
        "                    )\n",
        "                    self.cluster.buckets().create_bucket(bucket_settings)\n",
        "                    time.sleep(5)\n",
        "                    self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "\n",
        "            if not scope_exists and scope_name != \"_default\":\n",
        "                bucket_manager.create_scope(scope_name)\n",
        "\n",
        "            collections = bucket_manager.get_all_scopes()\n",
        "            collection_exists = any(\n",
        "                scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
        "                for scope in collections\n",
        "            )\n",
        "\n",
        "            if collection_exists and clear_existing_data:\n",
        "                self.clear_collection_data(scope_name, collection_name)\n",
        "            elif not collection_exists:\n",
        "                bucket_manager.create_collection(scope_name, collection_name)\n",
        "\n",
        "            time.sleep(3)\n",
        "            try:\n",
        "                self.cluster.query(\n",
        "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "                ).execute()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            collection = self.bucket.scope(scope_name).collection(collection_name)\n",
        "            self._collections[f\"{scope_name}.{collection_name}\"] = collection\n",
        "            logger.info(f\"✅ Collection setup complete: {scope_name}.{collection_name}\")\n",
        "            return collection\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"❌ Error setting up collection: {e!s}\")\n",
        "\n",
        "    def clear_collection_data(self, scope_name: str, collection_name: str):\n",
        "        try:\n",
        "            logger.info(f\"🗑️ Clearing data from {self.bucket_name}.{scope_name}.{collection_name}...\")\n",
        "            delete_query = f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            result = self.cluster.query(delete_query)\n",
        "            list(result)\n",
        "            time.sleep(2)\n",
        "        except KeyspaceNotFoundException:\n",
        "            logger.info(f\"ℹ️ Collection {self.bucket_name}.{scope_name}.{collection_name} doesn't exist, nothing to clear\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error clearing collection data: {e}\")\n",
        "\n",
        "    def clear_scope(self, scope_name: str):\n",
        "        try:\n",
        "            if not self.bucket:\n",
        "                if not self.cluster:\n",
        "                    self.connect()\n",
        "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
        "\n",
        "            bucket_manager = self.bucket.collections()\n",
        "            scopes = bucket_manager.get_all_scopes()\n",
        "            target_scope = next((s for s in scopes if s.name == scope_name), None)\n",
        "\n",
        "            if target_scope:\n",
        "                for collection in target_scope.collections:\n",
        "                    try:\n",
        "                        self.clear_collection_data(scope_name, collection.name)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                logger.info(f\"✅ Completed clearing scope: {self.bucket_name}.{scope_name}\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"❌ Could not clear scope: {e}\")\n",
        "\n",
        "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
        "        try:\n",
        "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
        "            existing_indexes = scope_index_manager.get_all_indexes()\n",
        "            index_name = index_definition[\"name\"]\n",
        "\n",
        "            if index_name not in [index.name for index in existing_indexes]:\n",
        "                search_index = SearchIndex.from_json(index_definition)\n",
        "                scope_index_manager.upsert_index(search_index)\n",
        "                logger.info(f\"✅ Vector search index '{index_name}' created\")\n",
        "            else:\n",
        "                logger.info(f\"ℹ️ Vector search index '{index_name}' already exists\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error setting up vector search index: {e}\")\n",
        "\n",
        "    def setup_vector_store_langchain(self, scope_name: str, collection_name: str, index_name: str, embeddings, data_loader_func=None, **loader_kwargs):\n",
        "        try:\n",
        "            if data_loader_func:\n",
        "                logger.info(\"🔄 Loading data into vector store...\")\n",
        "                data_loader_func(\n",
        "                    cluster=self.cluster, bucket_name=self.bucket_name,\n",
        "                    scope_name=scope_name, collection_name=collection_name,\n",
        "                    embeddings=embeddings, index_name=index_name, **loader_kwargs\n",
        "                )\n",
        "\n",
        "            vector_store = CouchbaseSearchVectorStore(\n",
        "                cluster=self.cluster, bucket_name=self.bucket_name,\n",
        "                scope_name=scope_name, collection_name=collection_name,\n",
        "                embedding=embeddings, index_name=index_name\n",
        "            )\n",
        "            logger.info(f\"✅ Vector store setup complete: {self.bucket_name}.{scope_name}.{collection_name}\")\n",
        "            return vector_store\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"❌ Error setting up vector store: {e!s}\")\n",
        "\n",
        "\n",
        "def create_couchbase_client():\n",
        "    \"\"\"Factory function to create CouchbaseClient with environment defaults.\"\"\"\n",
        "    return CouchbaseClient(\n",
        "        conn_string=os.getenv(\"CB_CONN_STRING\", \"couchbase://localhost\"),\n",
        "        username=os.getenv(\"CB_USERNAME\", \"Administrator\"),\n",
        "        password=os.getenv(\"CB_PASSWORD\", \"password\"),\n",
        "        bucket_name=os.getenv(\"CB_BUCKET\", \"travel-sample\"),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPIVbrffmTCw"
      },
      "source": [
        "## Flight Search Agent Classes\n",
        "\n",
        "This cell contains the classes for the flight search agent.\n",
        "\n",
        "### FlightSearchGraph\n",
        "\n",
        "The `FlightSearchGraph` class is the main class for the flight search agent. It is a subclass of `langgraph.graph.StateGraph` and is used to define the graph of the flight search agent.\n",
        "\n",
        "### FlightSearchGraphState\n",
        "\n",
        "The `FlightSearchGraphState` class is the state of the flight search agent. It is a subclass of `langgraph.graph.State` and is used to define the state of the flight search agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gH84eu2ImTCw"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Agent Classes\n",
        "\n",
        "class FlightSearchState(agentc_langgraph.agent.State):\n",
        "    \"\"\"State for flight search conversations - single user system.\"\"\"\n",
        "\n",
        "    query: str\n",
        "    resolved: bool\n",
        "    search_results: list[dict]\n",
        "\n",
        "\n",
        "class FlightSearchAgent(agentc_langgraph.agent.ReActAgent):\n",
        "    \"\"\"Flight search agent using Agent Catalog tools and ReActAgent framework.\"\"\"\n",
        "\n",
        "    def __init__(self, catalog: agentc.Catalog, span: agentc.Span, chat_model=None):\n",
        "        \"\"\"Initialize the flight search agent.\"\"\"\n",
        "\n",
        "        if chat_model is None:\n",
        "            # Fallback to OpenAI if no chat model provided\n",
        "            model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
        "            chat_model = langchain_openai.chat_models.ChatOpenAI(model=model_name, temperature=0.1)\n",
        "\n",
        "        super().__init__(\n",
        "            chat_model=chat_model, catalog=catalog, span=span, prompt_name=\"flight_search_assistant\"\n",
        "        )\n",
        "\n",
        "    def _invoke(\n",
        "        self,\n",
        "        span: agentc.Span,\n",
        "        state: FlightSearchState,\n",
        "        config: langchain_core.runnables.RunnableConfig,\n",
        "    ) -> FlightSearchState:\n",
        "        \"\"\"Handle flight search conversation using ReActAgent.\"\"\"\n",
        "\n",
        "        # Initialize conversation if this is the first message\n",
        "        if not state[\"messages\"]:\n",
        "            initial_msg = langchain_core.messages.HumanMessage(content=state[\"query\"])\n",
        "            state[\"messages\"].append(initial_msg)\n",
        "            logger.info(f\"Flight Query: {state['query']}\")\n",
        "\n",
        "        # Get prompt resource first - we'll need it for the ReAct agent\n",
        "        prompt_resource = self.catalog.find(\"prompt\", name=\"flight_search_assistant\")\n",
        "\n",
        "        # Get tools from Agent Catalog with simplified discovery\n",
        "        tools = []\n",
        "        tool_names = [\n",
        "            \"lookup_flight_info\",\n",
        "            \"save_flight_booking\",\n",
        "            \"retrieve_flight_bookings\",\n",
        "            \"search_airline_reviews\",\n",
        "        ]\n",
        "\n",
        "        for tool_name in tool_names:\n",
        "            try:\n",
        "                # Find tool using Agent Catalog\n",
        "                catalog_tool = self.catalog.find(\"tool\", name=tool_name)\n",
        "                if catalog_tool:\n",
        "                    logger.info(f\"✅ Found tool: {tool_name}\")\n",
        "                else:\n",
        "                    logger.error(f\"❌ Tool not found: {tool_name}\")\n",
        "                    continue\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"❌ Failed to find tool {tool_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # JSON-first architecture with Pydantic validation\n",
        "            # Import validation schemas\n",
        "            import json\n",
        "            from pydantic import ValidationError\n",
        "            from tools.schemas import FlightSearchInput, BookingInput\n",
        "\n",
        "            def clean_react_artifacts(raw_input: str) -> str:\n",
        "                \"\"\"Remove ReAct format artifacts that contaminate tool inputs.\"\"\"\n",
        "                if not raw_input:\n",
        "                    return \"\"\n",
        "\n",
        "                cleaned = raw_input.strip()\n",
        "\n",
        "                # Remove ReAct artifacts - order matters, check longer patterns first\n",
        "                artifacts_to_remove = [\n",
        "                    '\\nObservation:', '\\nObservation', 'Observation:', 'Observation',\n",
        "                    '\\nThought:', 'Thought:',\n",
        "                    '\\nAction:', 'Action:',\n",
        "                    '\\nAction Input:', 'Action Input:',\n",
        "                    '\\nFinal Answer:', 'Final Answer:',\n",
        "                    'Observ'  # Handle incomplete artifact\n",
        "                ]\n",
        "\n",
        "                for artifact in artifacts_to_remove:\n",
        "                    if artifact in cleaned:\n",
        "                        # Split and take only the part before the artifact\n",
        "                        cleaned = cleaned.split(artifact)[0].strip()\n",
        "\n",
        "                # Clean up quotes and extra whitespace\n",
        "                cleaned = cleaned.strip().strip(\"\\\"'\").strip()\n",
        "\n",
        "                # Normalize whitespace\n",
        "                cleaned = \" \".join(cleaned.split())\n",
        "\n",
        "                return cleaned\n",
        "\n",
        "            def parse_tool_input(tool_name: str, tool_input: str) -> dict:\n",
        "                \"\"\"Parse tool input: JSON with Pydantic validation for structured tools, plain text for simple tools.\"\"\"\n",
        "                # Clean ReAct artifacts first\n",
        "                cleaned = clean_react_artifacts(tool_input)\n",
        "\n",
        "                # Structured tools MUST use JSON\n",
        "                if tool_name == \"lookup_flight_info\":\n",
        "                    data = json.loads(cleaned)  # Will raise JSONDecodeError if invalid\n",
        "                    validated = FlightSearchInput(**data)  # Will raise ValidationError if invalid\n",
        "                    logger.info(f\"✅ Parsed {tool_name}: {validated.source_airport} → {validated.destination_airport}\")\n",
        "                    return {\n",
        "                        \"source_airport\": validated.source_airport,\n",
        "                        \"destination_airport\": validated.destination_airport\n",
        "                    }\n",
        "\n",
        "                elif tool_name == \"save_flight_booking\":\n",
        "                    data = json.loads(cleaned)  # Will raise JSONDecodeError if invalid\n",
        "                    validated = BookingInput(**data)  # Will raise ValidationError if invalid\n",
        "                    logger.info(f\"✅ Parsed {tool_name}: {validated.source_airport}→{validated.destination_airport}, {validated.passengers} pax, {validated.flight_class}\")\n",
        "                    return {\n",
        "                        \"source_airport\": validated.source_airport,\n",
        "                        \"destination_airport\": validated.destination_airport,\n",
        "                        \"departure_date\": validated.departure_date,\n",
        "                        \"passengers\": validated.passengers,\n",
        "                        \"flight_class\": validated.flight_class\n",
        "                    }\n",
        "\n",
        "                # Simple tools use plain text\n",
        "                elif tool_name == \"retrieve_flight_bookings\":\n",
        "                    return {\"booking_query\": cleaned}\n",
        "\n",
        "                elif tool_name == \"search_airline_reviews\":\n",
        "                    return {\"query\": cleaned}\n",
        "\n",
        "                raise ValueError(f\"Unknown tool: {tool_name}\")\n",
        "\n",
        "            # Create clean wrapper function for this tool\n",
        "            def create_tool_func(catalog_tool_ref, tool_name_ref):\n",
        "                \"\"\"Create a wrapper that parses JSON and calls catalog tool with structured params.\"\"\"\n",
        "                def tool_func(tool_input: str) -> str:\n",
        "                    try:\n",
        "                        # Parse input with Pydantic validation (JSON for structured tools)\n",
        "                        params = parse_tool_input(tool_name_ref, tool_input)\n",
        "\n",
        "                        # Call the Agent Catalog tool with parsed parameters\n",
        "                        result = catalog_tool_ref.func(**params)\n",
        "\n",
        "                        return str(result) if result is not None else \"No results found\"\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"❌ Error in tool {tool_name_ref}: {e}\")\n",
        "                        import traceback\n",
        "                        logger.debug(traceback.format_exc())\n",
        "                        return f\"Error: {str(e)}\"\n",
        "                return tool_func\n",
        "\n",
        "            # Tool descriptions for the LLM (JSON required for structured tools)\n",
        "            tool_descriptions = {\n",
        "                \"lookup_flight_info\": \"Find flights between airports. REQUIRES JSON: {\\\"source_airport\\\": \\\"JFK\\\", \\\"destination_airport\\\": \\\"LAX\\\"}\",\n",
        "                \"save_flight_booking\": \"Book a flight. REQUIRES JSON: {\\\"source_airport\\\": \\\"LAX\\\", \\\"destination_airport\\\": \\\"JFK\\\", \\\"departure_date\\\": \\\"2025-12-25\\\", \\\"passengers\\\": 2, \\\"flight_class\\\": \\\"business\\\"}\",\n",
        "                \"retrieve_flight_bookings\": \"View all flight bookings or search by criteria. Leave input empty for all bookings.\",\n",
        "                \"search_airline_reviews\": \"Search airline customer reviews. Input: plain text query (e.g., 'SpiceJet service quality')\"\n",
        "            }\n",
        "\n",
        "            langchain_tool = Tool(\n",
        "                name=tool_name,\n",
        "                description=tool_descriptions.get(tool_name, f\"Tool for {tool_name.replace('_', ' ')}\"),\n",
        "                func=create_tool_func(catalog_tool, tool_name),\n",
        "            )\n",
        "            tools.append(langchain_tool)\n",
        "\n",
        "        # Use the Agent Catalog prompt content directly - get first result if it's a list\n",
        "        if isinstance(prompt_resource, list):\n",
        "            prompt_resource = prompt_resource[0]\n",
        "\n",
        "        # Safely get the content from the prompt resource\n",
        "        prompt_content = getattr(prompt_resource, \"content\", \"\")\n",
        "        if not prompt_content:\n",
        "            prompt_content = \"You are a helpful flight search assistant. Use the available tools to help users with their flight queries.\"\n",
        "\n",
        "        # Inject current date into the prompt content\n",
        "        import datetime\n",
        "\n",
        "        current_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "        prompt_content = prompt_content.replace(\"{current_date}\", current_date)\n",
        "\n",
        "        # Use the Agent Catalog prompt content directly - it already has ReAct format\n",
        "        react_prompt = PromptTemplate.from_template(str(prompt_content))\n",
        "\n",
        "        # Create ReAct agent with tools and prompt\n",
        "        agent = create_react_agent(self.chat_model, tools, react_prompt)\n",
        "\n",
        "        # Custom parsing error handler - force stopping on parsing errors\n",
        "        def handle_parsing_errors(error):\n",
        "            \"\"\"Custom handler for parsing errors - force early termination.\"\"\"\n",
        "            error_msg = str(error)\n",
        "            if \"both a final answer and a parse-able action\" in error_msg:\n",
        "                # Force early termination - return a reasonable response\n",
        "                return \"Final Answer: I encountered a parsing error. Please reformulate your request.\"\n",
        "            elif \"Missing 'Action:'\" in error_msg:\n",
        "                return \"I need to use the correct format with Action: and Action Input:\"\n",
        "            else:\n",
        "                return f\"Final Answer: I encountered an error processing your request. Please try again.\"\n",
        "\n",
        "        # Create agent executor - very strict: only 2 iterations max\n",
        "        agent_executor = AgentExecutor(\n",
        "            agent=agent,\n",
        "            tools=tools,\n",
        "            verbose=True,\n",
        "            handle_parsing_errors=handle_parsing_errors,\n",
        "            max_iterations=2,  # STRICT: 1 tool call + 1 Final Answer only\n",
        "            early_stopping_method=\"force\",  # Force stop\n",
        "            return_intermediate_steps=True,\n",
        "        )\n",
        "\n",
        "        # Execute the agent\n",
        "        response = agent_executor.invoke({\"input\": state[\"query\"]})\n",
        "\n",
        "        # Extract tool outputs from intermediate_steps and store in search_results\n",
        "        if \"intermediate_steps\" in response and response[\"intermediate_steps\"]:\n",
        "            tool_outputs = []\n",
        "            for step in response[\"intermediate_steps\"]:\n",
        "                if isinstance(step, tuple) and len(step) >= 2:\n",
        "                    # step[0] is the action, step[1] is the tool output/observation\n",
        "                    tool_output = str(step[1])\n",
        "                    if tool_output and tool_output.strip():\n",
        "                        tool_outputs.append(tool_output)\n",
        "            state[\"search_results\"] = tool_outputs\n",
        "\n",
        "        # Add response to conversation\n",
        "        assistant_msg = langchain_core.messages.AIMessage(content=response[\"output\"])\n",
        "        state[\"messages\"].append(assistant_msg)\n",
        "        state[\"resolved\"] = True\n",
        "\n",
        "        return state\n",
        "\n",
        "\n",
        "class FlightSearchGraph(agentc_langgraph.graph.GraphRunnable):\n",
        "    \"\"\"Flight search conversation graph using Agent Catalog.\"\"\"\n",
        "\n",
        "    def __init__(self, catalog, span, chat_model=None):\n",
        "        \"\"\"Initialize the flight search graph with optional chat model.\"\"\"\n",
        "        super().__init__(catalog=catalog, span=span)\n",
        "        self.chat_model = chat_model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_starting_state(query: str) -> FlightSearchState:\n",
        "        \"\"\"Build the initial state for the flight search - single user system.\"\"\"\n",
        "        return FlightSearchState(\n",
        "            messages=[],\n",
        "            query=query,\n",
        "            resolved=False,\n",
        "            search_results=[],\n",
        "        )\n",
        "\n",
        "    def compile(self):\n",
        "        \"\"\"Compile the LangGraph workflow.\"\"\"\n",
        "\n",
        "        # Build the flight search agent with catalog integration\n",
        "        search_agent = FlightSearchAgent(\n",
        "            catalog=self.catalog, span=self.span, chat_model=self.chat_model\n",
        "        )\n",
        "\n",
        "        # Create a wrapper function for the ReActAgent\n",
        "        def flight_search_node(state: FlightSearchState) -> FlightSearchState:\n",
        "            \"\"\"Wrapper function for the flight search ReActAgent.\"\"\"\n",
        "            return search_agent._invoke(\n",
        "                span=self.span,\n",
        "                state=state,\n",
        "                config={},  # Empty config for now\n",
        "            )\n",
        "\n",
        "        # Create a simple workflow graph for flight search\n",
        "        workflow = langgraph.graph.StateGraph(FlightSearchState)\n",
        "\n",
        "        # Add the flight search agent node using the wrapper function\n",
        "        workflow.add_node(\"flight_search\", flight_search_node)\n",
        "\n",
        "        # Set entry point and simple flow\n",
        "        workflow.set_entry_point(\"flight_search\")\n",
        "        workflow.add_edge(\"flight_search\", langgraph.graph.END)\n",
        "\n",
        "        return workflow.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaohuackmTCw",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Loading Components\n",
        "\n",
        "Complete data loading and query definition components embedded inline for standalone operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kVwXayEymTCw"
      },
      "outputs": [],
      "source": [
        "# Flight Search Queries and Reference Answers - Complete implementation from data/queries.py\n",
        "\n",
        "# Flight search queries (for evaluation and testing)\n",
        "FLIGHT_SEARCH_QUERIES = [\n",
        "    \"Find flights from JFK to LAX\",\n",
        "    \"Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\",\n",
        "    \"Book an economy flight from JFK to MIA for next week, 1 passenger\",\n",
        "    \"Show me my current flight bookings\",\n",
        "    \"What do passengers say about SpiceJet's service quality?\",\n",
        "]\n",
        "\n",
        "# Comprehensive reference answers based on actual system responses\n",
        "FLIGHT_REFERENCE_ANSWERS = [\n",
        "    # Query 1: Flight search JFK to LAX\n",
        "    \"\"\"Available flights from JFK to LAX:\n",
        "\n",
        "1. AS flight from JFK to LAX using 321 762\n",
        "2. B6 flight from JFK to LAX using 320\n",
        "3. DL flight from JFK to LAX using 76W 752\n",
        "4. QF flight from JFK to LAX using 744\n",
        "5. AA flight from JFK to LAX using 32B 762\n",
        "6. UA flight from JFK to LAX using 757\n",
        "7. US flight from JFK to LAX using 32B 762\n",
        "8. VX flight from JFK to LAX using 320\"\"\",\n",
        "\n",
        "    # Query 2: Flight booking LAX to JFK for tomorrow, 2 passengers, business class\n",
        "    \"\"\"Flight Booking Confirmed!\n",
        "\n",
        "Booking ID: FL08061563CACD\n",
        "Route: LAX → JFK\n",
        "Departure Date: 2025-08-06\n",
        "Passengers: 2\n",
        "Class: business\n",
        "Total Price: $1500.00\n",
        "\n",
        "Next Steps:\n",
        "1. Check-in opens 24 hours before departure\n",
        "2. Arrive at airport 2 hours early for domestic flights\n",
        "3. Bring valid government-issued photo ID\n",
        "\n",
        "Thank you for choosing our airline!\"\"\",\n",
        "\n",
        "    # Query 3: Flight booking JFK to MIA for next week\n",
        "    \"\"\"Flight Booking Confirmed!\n",
        "\n",
        "Booking ID: FL08124E7B9C2A\n",
        "Route: JFK → MIA\n",
        "Departure Date: 2025-08-12\n",
        "Passengers: 1\n",
        "Class: economy\n",
        "Total Price: $250.00\n",
        "\n",
        "Next Steps:\n",
        "1. Check-in opens 24 hours before departure\n",
        "2. Arrive at airport 2 hours early for domestic flights\n",
        "3. Bring valid government-issued photo ID\n",
        "\n",
        "Thank you for choosing our airline!\"\"\",\n",
        "\n",
        "    # Query 4: Show current flight bookings\n",
        "    \"\"\"Your Current Bookings (2 found):\n",
        "\n",
        "Booking 1:\n",
        "  Booking ID: FL08061563CACD\n",
        "  Route: LAX → JFK\n",
        "  Date: 2025-08-06\n",
        "  Passengers: 2\n",
        "  Class: business\n",
        "  Total: $1500.00\n",
        "  Status: confirmed\n",
        "  Booked: 2025-08-05\n",
        "\n",
        "Booking 2:\n",
        "  Booking ID: FL08124E7B9C2A\n",
        "  Route: JFK → MIA\n",
        "  Date: 2025-08-12\n",
        "  Passengers: 1\n",
        "  Class: economy\n",
        "  Total: $250.00\n",
        "  Status: confirmed\n",
        "  Booked: 2025-08-05\"\"\",\n",
        "\n",
        "    # Query 5: SpiceJet service quality reviews\n",
        "    \"\"\"Found 5 relevant airline reviews for 'SpiceJet service':\n",
        "\n",
        "Review 1:\n",
        "Airline: SpiceJet. Title: \"Service is impeccable\". Review: ✅ Trip Verified | Much better than airbus models. Even the basic economy class has ambient lighting. Better personal air vents and better spotlights. Even overhead storage bins are good. Service is impeccable with proper care taken of guests...\n",
        "\n",
        "Review 2:\n",
        "Airline: SpiceJet. Title: \"good service by the crew\". Review: ✅ Trip Verified | I have had good service by the crew. It was amazing, the crew was very enthusiastic and warm welcome. It was one of the best services in my experience.. Rating: 10.0/10. Reviewer: K Mansour. Date: 10th August 2024. Recom...\n",
        "\n",
        "Review 3:\n",
        "Airline: SpiceJet. Title: \"outstanding service I experienced\". Review: Not Verified |  I wanted to take a moment to express my sincere thanks for the outstanding service I experienced on my recent flight from Pune to Delhi. SG-8937. From the moment I boarded, the warmth and friendliness of the air h...\n",
        "\n",
        "Review 4:\n",
        "Airline: SpiceJet. Title: \"efficient and warm onboard service\". Review: ✅ Trip Verified |  New Delhi to Kolkata. Delighted with the prompt, efficient and warm onboard service provided by the crew. Appreciate their efforts towards customer centricity.. Rating: 10.0/10. Reviewer: Debashis Roy. Date: 2...\n",
        "\n",
        "Review 5:\n",
        "Airline: SpiceJet. Title: \"Service is very good\". Review: Service is very good,  I am impressed with Miss Renu  who gave the best services ever. Thanks to Renu who is very sweet by her nature as well as her service. Rating: 9.0/10. Reviewer: Sanjay Patnaik. Date: 21st September 2023. Recommended: ye...\"\"\",\n",
        "]\n",
        "\n",
        "# Create dictionary for backward compatibility\n",
        "QUERY_REFERENCE_ANSWERS = {\n",
        "    query: answer for query, answer in zip(FLIGHT_SEARCH_QUERIES, FLIGHT_REFERENCE_ANSWERS)\n",
        "}\n",
        "\n",
        "def get_test_queries():\n",
        "    \"\"\"Return test queries for evaluation.\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_evaluation_queries():\n",
        "    \"\"\"Get queries for evaluation\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_all_queries():\n",
        "    \"\"\"Get all available queries\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_simple_queries():\n",
        "    \"\"\"Get simple queries for basic testing\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_flight_policy_queries():\n",
        "    \"\"\"Return flight policy queries (for backward compatibility).\"\"\"\n",
        "    return FLIGHT_SEARCH_QUERIES\n",
        "\n",
        "def get_reference_answer(query: str) -> str:\n",
        "    \"\"\"Get the correct reference answer for a given query\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS.get(query, f\"No reference answer available for: {query}\")\n",
        "\n",
        "def get_all_query_references():\n",
        "    \"\"\"Get all query-reference pairs\"\"\"\n",
        "    return QUERY_REFERENCE_ANSWERS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akv3vV84mTCw",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Clear Existing Data\n",
        "\n",
        "Clear existing bookings and reviews for clean test run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UBSREadbmTCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b1337c-5dc7-4f66-a0f5-bdb0cfb53bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Successfully connected to Couchbase\n",
            "INFO:__main__:🗑️ Clearing data from travel-sample.agentc_bookings.user_bookings_20251023...\n",
            "INFO:__main__:🗑️ Clearing data from travel-sample.agentc_bookings.user_bookings_20251022...\n",
            "INFO:__main__:✅ Completed clearing scope: travel-sample.agentc_bookings\n",
            "INFO:__main__:✅ Cleared existing flight bookings for fresh test run: travel-sample.agentc_bookings\n",
            "INFO:__main__:Downloading Indian Airlines Customer Reviews dataset from Kaggle...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jagathratchakan/indian-airlines-customer-reviews?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 498k/498k [00:00<00:00, 892kB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:__main__:Loading reviews from /root/.cache/kagglehub/datasets/jagathratchakan/indian-airlines-customer-reviews/versions/1/Indian_Domestic_Airline.csv\n",
            "INFO:__main__:Loaded 2210 airline reviews from Kaggle dataset\n",
            "INFO:__main__:Processed 2210 airline reviews into text format\n",
            "INFO:__main__:📊 Airline reviews collection: 2210 existing, 2210 expected\n",
            "INFO:__main__:✅ Collection already has correct document count (2210), skipping clear\n"
          ]
        }
      ],
      "source": [
        "def clear_bookings_and_reviews():\n",
        "    \"\"\"Clear existing flight bookings to start fresh for demo.\"\"\"\n",
        "    try:\n",
        "        client = create_couchbase_client()\n",
        "        client.connect()\n",
        "\n",
        "        # Clear bookings scope using environment variables\n",
        "        bookings_scope = \"agentc_bookings\"\n",
        "        client.clear_scope(bookings_scope)\n",
        "        logger.info(\n",
        "            f\"✅ Cleared existing flight bookings for fresh test run: {os.environ['CB_BUCKET']}.{bookings_scope}\"\n",
        "        )\n",
        "\n",
        "        # Check if airline reviews collection needs clearing by comparing expected vs actual document count\n",
        "        try:\n",
        "            # Get expected document count (this uses cached data if available)\n",
        "            expected_docs = _data_manager.process_to_texts()\n",
        "            expected_count = len(expected_docs)\n",
        "\n",
        "            # Check current document count in collection\n",
        "            try:\n",
        "                count_query = f\"SELECT COUNT(*) as count FROM `{os.environ['CB_BUCKET']}`.`{os.environ['CB_SCOPE']}`.`{os.environ['CB_COLLECTION']}`\"\n",
        "                count_result = client.cluster.query(count_query)\n",
        "                count_row = next(iter(count_result))\n",
        "                existing_count = count_row[\"count\"]\n",
        "\n",
        "                logger.info(\n",
        "                    f\"📊 Airline reviews collection: {existing_count} existing, {expected_count} expected\"\n",
        "                )\n",
        "\n",
        "                if existing_count == expected_count:\n",
        "                    logger.info(\n",
        "                        f\"✅ Collection already has correct document count ({existing_count}), skipping clear\"\n",
        "                    )\n",
        "                else:\n",
        "                    logger.info(\n",
        "                        f\"🗑️  Clearing airline reviews collection: {os.environ['CB_BUCKET']}.{os.environ['CB_SCOPE']}.{os.environ['CB_COLLECTION']}\"\n",
        "                    )\n",
        "                    client.clear_collection_data(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"])\n",
        "                    logger.info(\n",
        "                        f\"✅ Cleared existing airline reviews for fresh data load: {os.environ['CB_BUCKET']}.{os.environ['CB_SCOPE']}.{os.environ['CB_COLLECTION']}\"\n",
        "                    )\n",
        "\n",
        "            except KeyspaceNotFoundException:\n",
        "                # Collection doesn't exist yet - this is expected for fresh setup\n",
        "                logger.info(\n",
        "                    f\"📊 Collection doesn't exist yet, will create and load fresh data\"\n",
        "                )\n",
        "            except Exception as count_error:\n",
        "                # Other query errors - clear anyway to ensure fresh start\n",
        "                logger.info(\n",
        "                    f\"📊 Collection query failed, will clear and reload: {count_error}\"\n",
        "                )\n",
        "                client.clear_collection_data(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"])\n",
        "                logger.info(\n",
        "                    f\"✅ Cleared existing airline reviews for fresh data load: {os.environ['CB_BUCKET']}.{os.environ['CB_SCOPE']}.{os.environ['CB_COLLECTION']}\"\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️  Could not check collection count, clearing anyway: {e}\")\n",
        "            client.clear_collection_data(os.environ[\"CB_SCOPE\"], os.environ[\"CB_COLLECTION\"])\n",
        "            logger.info(\n",
        "                f\"✅ Cleared existing airline reviews for fresh data load: {os.environ['CB_BUCKET']}.{os.environ['CB_SCOPE']}.{os.environ['CB_COLLECTION']}\"\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"❌ Could not clear bookings: {e}\")\n",
        "\n",
        "\n",
        "# Clear existing data for fresh test run\n",
        "clear_bookings_and_reviews()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZzJmJm4mTCx",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup Flight Search Agent\n",
        "\n",
        "Initialize the complete flight search agent setup using the refactored approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "G7pFbwTkmTCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e45c8af-365a-40ce-de44-2b4b2299d111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Environment variables configured\n",
            "INFO:__main__:✅ Successfully connected to Couchbase\n",
            "INFO:__main__:✅ Collection setup complete: agentc_data.airline_reviews\n",
            "INFO:__main__:Loaded vector search index definition from agentcatalog_index.json\n",
            "INFO:__main__:ℹ️ Vector search index 'airline_reviews_index' already exists\n",
            "INFO:__main__:🔧 Setting up Priority 1 AI services for langgraph framework...\n",
            "INFO:__main__:🔧 Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "INFO:__main__:🔧 Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "INFO:__main__:🔧 LLM Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 LLM Model: meta/llama3-8b-instruct\n",
            "INFO:__main__:🔧 LLM Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "INFO:__main__:✅ Priority 1 AI services setup completed for langgraph\n",
            "INFO:__main__:🔄 Loading data into vector store...\n",
            "INFO:__main__:Found 2210 existing documents in collection, skipping data load\n",
            "INFO:__main__:✅ Vector store setup complete: travel-sample.agentc_data.airline_reviews\n",
            "INFO:__main__:🔧 Setting up Priority 1 AI services for langgraph framework...\n",
            "INFO:__main__:🔧 Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "INFO:__main__:🔧 Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "INFO:__main__:🔧 LLM Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 LLM Model: meta/llama3-8b-instruct\n",
            "INFO:__main__:🔧 LLM Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "INFO:__main__:✅ Priority 1 AI services setup completed for langgraph\n",
            "INFO:__main__:Agent Catalog integration successful\n"
          ]
        }
      ],
      "source": [
        "def setup_flight_search_agent():\n",
        "    \"\"\"Common setup function for flight search agent - returns all necessary components.\"\"\"\n",
        "    try:\n",
        "        # Setup environment first\n",
        "        setup_environment()\n",
        "\n",
        "        # Initialize Agent Catalog (uses .env or defaults if AGENT_CATALOG_* vars not set)\n",
        "        catalog = agentc.Catalog()\n",
        "        application_span = catalog.Span(name=\"Flight Search Agent\", blacklist=set())\n",
        "\n",
        "        # Test Capella AI connectivity\n",
        "        if os.getenv(\"CAPELLA_API_ENDPOINT\"):\n",
        "            if not test_capella_connectivity():\n",
        "                logger.warning(\"❌ Capella AI connectivity test failed. Will use fallback models.\")\n",
        "        else:\n",
        "            logger.info(\"ℹ️ Capella API not configured - will use fallback models\")\n",
        "\n",
        "        # Create CouchbaseClient for all operations\n",
        "        client = create_couchbase_client()\n",
        "\n",
        "        # Setup everything in one call - bucket, scope, collection\n",
        "        client.setup_collection(\n",
        "            scope_name=os.environ[\"CB_SCOPE\"],\n",
        "            collection_name=os.environ[\"CB_COLLECTION\"],\n",
        "            clear_existing_data=False,  # Let data loader decide based on count check\n",
        "        )\n",
        "\n",
        "        # Setup vector search index\n",
        "        try:\n",
        "            with open(\"agentcatalog_index.json\") as file:\n",
        "                index_definition = json.load(file)\n",
        "            logger.info(\"Loaded vector search index definition from agentcatalog_index.json\")\n",
        "            client.setup_vector_search_index(index_definition, os.environ[\"CB_SCOPE\"])\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error loading index definition: {e!s}\")\n",
        "            logger.info(\"Continuing without vector search index...\")\n",
        "\n",
        "\n",
        "        # Setup AI services using Priority 1: Capella AI + OpenAI wrappers\n",
        "        embeddings, _ = setup_ai_services(framework=\"langgraph\")\n",
        "\n",
        "        # Setup vector store with airline reviews data\n",
        "        vector_store = client.setup_vector_store_langchain(\n",
        "            scope_name=os.environ[\"CB_SCOPE\"],\n",
        "            collection_name=os.environ[\"CB_COLLECTION\"],\n",
        "            index_name=os.environ[\"CB_INDEX\"],\n",
        "            embeddings=embeddings,\n",
        "            data_loader_func=load_airline_reviews_to_couchbase,\n",
        "        )\n",
        "\n",
        "        # Setup LLM using Priority 1: Capella AI + OpenAI wrappers\n",
        "        _, chat_model = setup_ai_services(framework=\"langgraph\", temperature=0.1)\n",
        "\n",
        "        # Create the flight search graph with the chat model\n",
        "        flight_graph = FlightSearchGraph(\n",
        "            catalog=catalog, span=application_span, chat_model=chat_model\n",
        "        )\n",
        "        # Compile the graph\n",
        "        compiled_graph = flight_graph.compile()\n",
        "\n",
        "        logger.info(\"Agent Catalog integration successful\")\n",
        "\n",
        "        return compiled_graph, application_span\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Setup error: {e}\")\n",
        "        logger.info(\"Ensure Agent Catalog is published: agentc index . && agentc publish\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def run_test_query(test_number: int, query: str, compiled_graph, application_span):\n",
        "    \"\"\"Run a single test query with error handling.\"\"\"\n",
        "    logger.info(f\"\\n🔍 Test {test_number}: {query}\")\n",
        "    try:\n",
        "        state = FlightSearchGraph.build_starting_state(query=query)\n",
        "        result = compiled_graph.invoke(state)\n",
        "\n",
        "        if result.get(\"search_results\"):\n",
        "            logger.info(f\"Found {len(result['search_results'])} flight options\")\n",
        "        logger.info(f\"✅ Test {test_number} completed: {result.get('resolved', False)}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Test {test_number} failed: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Setup the agent\n",
        "compiled_graph, application_span = setup_flight_search_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puhVz-pvmTCx",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 1: Flight Search\n",
        "\n",
        "Find flights from JFK to LAX for tomorrow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "k8Ba2EgVmTCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d3302f-0b0f-4de6-dc7c-12776904fa40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:\n",
            "🔍 Test 1: Find flights from JFK to LAX for tomorrow\n",
            "INFO:__main__:Flight Query: Find flights from JFK to LAX for tomorrow\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed lookup_flight_info: JFK → LAX\n",
            "INFO:lookup_flight_info:🔍 Looking up flights: JFK → LAX\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use lookup_flight_info to help with this request Action: lookup_flight_info Action Input: {\"source_airport\": \"JFK\", \"destination_airport\": \"LAX\"}\u001b[0m\u001b[36;1m\u001b[1;3mAvailable flights from JFK to LAX:\n",
            "\n",
            "1. AS flight from JFK to LAX using 321 762\n",
            "2. B6 flight from JFK to LAX using 320\n",
            "3. DL flight from JFK to LAX using 76W 752\n",
            "4. QF flight from JFK to LAX using 744\n",
            "5. AA flight from JFK to LAX using 32B 762\n",
            "6. UA flight from JFK to LAX using 757\n",
            "7. US flight from JFK to LAX using 32B 762\n",
            "8. VX flight from JFK to LAX using 320\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Found 1 flight options\n",
            "INFO:__main__:✅ Test 1 completed: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: I found 8 available flights from JFK to LAX, including airlines AS, B6, DL, QF, AA, UA, US, and VX with various aircraft types.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result1 = run_test_query(\n",
        "    1, \"Find flights from JFK to LAX for tomorrow\", compiled_graph, application_span\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YubHWNhvmTCx",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 2: Flight Booking (Business Class)\n",
        "\n",
        "Book a flight with business class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CbKwZgFSmTCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25360df-e878-4fd5-a287-3c39e36c0dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:\n",
            "🔍 Test 2: Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\n",
            "INFO:__main__:Flight Query: Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed save_flight_booking: LAX→JFK, 2 pax, business\n",
            "INFO:save_flight_booking:🗓️ Date validated: 2025-10-24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use save_flight_booking to help with this request. Tomorrow is 2025-10-23 + 1 day = 2025-10-24 Action: save_flight_booking Action Input: {\"source_airport\": \"LAX\", \"destination_airport\": \"JFK\", \"departure_date\": \"2025-10-24\", \"passengers\": 2, \"flight_class\": \"business\"}\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:save_flight_booking:🎯 Booking: LAX→JFK on 2025-10-24, 2 pax, business class\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3mFlight Booking Confirmed!\n",
            "\n",
            "Booking ID: FL1024FCA22BF7\n",
            "Route: LAX → JFK\n",
            "Departure Date: 2025-10-24\n",
            "Passengers: 2\n",
            "Class: business\n",
            "Total Price: $1500.00\n",
            "\n",
            "Next Steps:\n",
            "1. Check-in opens 24 hours before departure\n",
            "2. Arrive at airport 2 hours early for domestic flights\n",
            "3. Bring valid government-issued photo ID\n",
            "\n",
            "Thank you for choosing our airline!\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Found 1 flight options\n",
            "INFO:__main__:✅ Test 2 completed: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Your flight from LAX to JFK for 2 passengers in business class has been booked successfully for tomorrow (2025-10-24). Your booking ID is FL1024FCA22BF7 and the total cost is $1500.00.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result2 = run_test_query(\n",
        "    2,\n",
        "    \"Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\",\n",
        "    compiled_graph,\n",
        "    application_span,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDBEUzYImTCx",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 3: Flight Booking (Economy Class)\n",
        "\n",
        "Book an economy flight.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "crBUQX-FmTC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4cd9c65-ed85-46b2-b5ff-adb962f9eb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:\n",
            "🔍 Test 3: Book an economy flight from JFK to MIA for next week, 1 passenger\n",
            "INFO:__main__:Flight Query: Book an economy flight from JFK to MIA for next week, 1 passenger\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed save_flight_booking: JFK→MIA, 1 pax, economy\n",
            "INFO:save_flight_booking:🗓️ Date validated: 2025-10-30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use save_flight_booking to help with this request. Next week is 2025-10-23 + 7 days = 2025-10-30 Action: save_flight_booking Action Input: {\"source_airport\": \"JFK\", \"destination_airport\": \"MIA\", \"departure_date\": \"2025-10-30\", \"passengers\": 1, \"flight_class\": \"economy\"}\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:save_flight_booking:🎯 Booking: JFK→MIA on 2025-10-30, 1 pax, economy class\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3mFlight Booking Confirmed!\n",
            "\n",
            "Booking ID: FL1030E7B4FB0F\n",
            "Route: JFK → MIA\n",
            "Departure Date: 2025-10-30\n",
            "Passengers: 1\n",
            "Class: economy\n",
            "Total Price: $250.00\n",
            "\n",
            "Next Steps:\n",
            "1. Check-in opens 24 hours before departure\n",
            "2. Arrive at airport 2 hours early for domestic flights\n",
            "3. Bring valid government-issued photo ID\n",
            "\n",
            "Thank you for choosing our airline!\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed save_flight_booking: JFK→MIA, 1 pax, economy\n",
            "INFO:save_flight_booking:🗓️ Date validated: 2025-10-30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use save_flight_booking to help with this request. Next week is 2025-10-23 + 7 days = 2025-10-30 Action: save_flight_booking Action Input: {\"source_airport\": \"JFK\", \"destination_airport\": \"MIA\", \"departure_date\": \"2025-10-30\", \"passengers\": 1, \"flight_class\": \"economy\"}\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Found 2 flight options\n",
            "INFO:__main__:✅ Test 3 completed: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3mDuplicate booking found! You already have a confirmed booking:\n",
            "- Booking ID: FL1030E7B4FB0F\n",
            "- Route: JFK → MIA\n",
            "- Date: 2025-10-30\n",
            "- Total: $250.00\n",
            "\n",
            "No new booking was created. Use the existing booking ID for reference.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result3 = run_test_query(\n",
        "    3,\n",
        "    \"Book an economy flight from JFK to MIA for next week, 1 passenger\",\n",
        "    compiled_graph,\n",
        "    application_span,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9M4J-KDmTC7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 4: Retrieve Current Bookings\n",
        "\n",
        "Show current flight bookings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XTa0vaxjmTC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6897994e-0f58-4cbc-c343-35ae63e55360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:\n",
            "🔍 Test 4: Show me my current flight bookings\n",
            "INFO:__main__:Flight Query: Show me my current flight bookings\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use retrieve_flight_bookings to help with this request Action: retrieve_flight_bookings Action Input:\u001b[0m\u001b[38;5;200m\u001b[1;3mYour Current Bookings (2 found):\n",
            "\n",
            "Booking 1:\n",
            "  Booking ID: FL1030E7B4FB0F\n",
            "  Route: JFK → MIA\n",
            "  Date: 2025-10-30\n",
            "  Passengers: 1\n",
            "  Class: economy\n",
            "  Total: $250.00\n",
            "  Status: confirmed\n",
            "  Booked: 2025-10-23\n",
            "\n",
            "Booking 2:\n",
            "  Booking ID: FL1024FCA22BF7\n",
            "  Route: LAX → JFK\n",
            "  Date: 2025-10-24\n",
            "  Passengers: 2\n",
            "  Class: business\n",
            "  Total: $1500.00\n",
            "  Status: confirmed\n",
            "  Booked: 2025-10-23\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Found 1 flight options\n",
            "INFO:__main__:✅ Test 4 completed: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: You have 2 current flight bookings: (1) JFK to MIA on 2025-10-30 for 1 passenger in economy class ($250.00), and (2) LAX to JFK on 2025-10-24 for 2 passengers in business class ($1500.00).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result4 = run_test_query(4, \"Show me my current flight bookings\", compiled_graph, application_span)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e5zJao2mTC8",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test 5: Airline Reviews Search\n",
        "\n",
        "Search airline reviews for service quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8PJhI7e7mTC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d43cd9-c444-4966-a37a-21bc80ca5981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:\n",
            "🔍 Test 5: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:Flight Query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use search_airline_reviews to help with this request Action: search_airline_reviews Action Input: SpiceJet service quality\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:search_airline_reviews:Searching for airline reviews with query: 'SpiceJet service quality'\n",
            "INFO:search_airline_reviews:Found 5 results for query: 'SpiceJet service quality'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mFound 5 relevant airline reviews for 'SpiceJet service quality':\n",
            "\n",
            "Review 1:\n",
            "Airline: SpiceJet. Title: \"Great travel experience\". Review: ✅ Trip Verified |  Marvelous courteous crew who took good care of all passengers. They should be rewarded for the patience shown towards the unruly ones. Great travel experience.. Rating: 10.0/10. Reviewer: Ranjita Pandey. Date: 18th April 2024. Recommended: yes\n",
            "\n",
            "Review 2:\n",
            "Airline: SpiceJet. Title: \"good service by the crew\". Review: ✅ Trip Verified | I have had good service by the crew. It was amazing, the crew was very enthusiastic and warm welcome. It was one of the best services in my experience.. Rating: 10.0/10. Reviewer: K Mansour. Date: 10th August 2024. Recommended: yes\n",
            "\n",
            "Review 3:\n",
            "Airline: SpiceJet. Title: \"Excellent service\". Review: ✅ Trip Verified |  Excellent service by the ground staff courteous beyond expectations always willing to help in the real sense and not lipservice i will recommend to all whom I know. Rating: 10.0/10. Reviewer: Ramanathan Ramchandra. Date: 1st November 2023. Recommended: yes\n",
            "\n",
            "Review 4:\n",
            "Airline: SpiceJet. Title: \"excellent hospitality\". Review: ✅ Trip Verified |  It's very grateful to SpiceJet for the service in flight. Everything is fine with excellent hospitality. Very politely behavior and warmly welcome from your cabin crew and all members.. Rating: 10.0/10. Reviewer: A Kajan. Date: 10th August 2024. Recommended: yes\n",
            "\n",
            "Review 5:\n",
            "Airline: SpiceJet. Title: \"delayed both ways by many hours\". Review: Not Verified |  Flight was delayed both ways by many hours. Poor service for the same price as other airlines like IndiGo. No wifi or other amenities to compensate for terrible service.. Rating: 2.0/10. Reviewer: Somil Jain Jain. Date: 20th May 2022. Recommended: no\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Found 1 flight options\n",
            "INFO:__main__:✅ Test 5 completed: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer Final Answer: Based on 5 customer reviews, SpiceJet receives mostly positive feedback (averaging 8.4/10) for their courteous crew, warm hospitality, and excellent ground staff service. However, some passengers report flight delays and poor service. The majority of reviews are highly positive (four 10/10 ratings), with one negative review citing delays and lack of amenities.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result5 = run_test_query(\n",
        "    5, \"What do passengers say about SpiceJet's service quality?\", compiled_graph, application_span\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWQzh0MrmTC8",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Arize Phoenix Evaluation\n",
        "\n",
        "This section demonstrates how to evaluate the flight search agent using Arize Phoenix observability platform. The evaluation includes:\n",
        "\n",
        "- **Relevance Scoring**: Using Phoenix RelevanceEvaluator to score how relevant responses are to queries\n",
        "- **QA Scoring**: Using Phoenix QAEvaluator with lenient evaluation templates for better accuracy\n",
        "- **Hallucination Detection**: Using Phoenix HallucinationEvaluator with lenient templates to detect fabricated information\n",
        "- **Toxicity Detection**: Using Phoenix ToxicityEvaluator to detect harmful content\n",
        "- **Phoenix UI**: Real-time observability dashboard\n",
        "\n",
        "We'll run evaluation queries and assess the responses for quality and safety using the latest evaluation approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qUXXU77hmTC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ed78c6c-f8b5-4c66-b1e2-845ac54dd170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:phoenix.config:📋 Ensuring phoenix working directory: /root/.phoenix\n",
            "INFO:phoenix.inferences.inferences:Dataset: phoenix_inferences_c461129a-1f31-463c-8809-663fcb493b11 initialized\n",
            "INFO:__main__:✅ Arize Phoenix evaluation components available\n",
            "INFO:phoenix.config:📋 Ensuring phoenix working directory: /root/.phoenix\n",
            "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
            "INFO:alembic.runtime.migration:Will assume transactional DDL.\n",
            "INFO:alembic.runtime.migration:Running upgrade  -> cf03bd6bae1d, init\n",
            "INFO:alembic.runtime.migration:Running upgrade cf03bd6bae1d -> 10460e46d750, datasets\n",
            "INFO:alembic.runtime.migration:Running upgrade 10460e46d750 -> 3be8647b87d8, add token columns to spans table\n",
            "INFO:alembic.runtime.migration:Running upgrade 3be8647b87d8 -> cd164e83824f, users and tokens\n",
            "INFO:alembic.runtime.migration:Running upgrade cd164e83824f -> 4ded9e43755f, create project_session table\n",
            "INFO:alembic.runtime.migration:Running upgrade 4ded9e43755f -> bc8fea3c2bc8, Add prompt tables\n",
            "INFO:alembic.runtime.migration:Running upgrade bc8fea3c2bc8 -> 2f9d1a65945f, Annotation config migrations\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "/usr/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n",
            "INFO:alembic.runtime.migration:Running upgrade 2f9d1a65945f -> bb8139330879, create project trace retention policies table\n",
            "INFO:alembic.runtime.migration:Running upgrade bb8139330879 -> 8a3764fe7f1a, change jsonb to json for prompts\n",
            "INFO:alembic.runtime.migration:Running upgrade 8a3764fe7f1a -> 6a88424799fe, Add auth_method column to users table and migrate existing authentication data.\n",
            "INFO:alembic.runtime.migration:Running upgrade 6a88424799fe -> a20694b15f82, Cost-related tables\n",
            "INFO:phoenix.server.app:Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit https://qbi55xabkf1-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:🚀 Phoenix UI available at https://qbi55xabkf1-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
            "INFO:__main__:🔍 Running evaluation query 1: Find flights from JFK to LAX\n",
            "INFO:__main__:Flight Query: Find flights from JFK to LAX\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed lookup_flight_info: JFK → LAX\n",
            "INFO:lookup_flight_info:🔍 Looking up flights: JFK → LAX\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use lookup_flight_info to help with this request Action: lookup_flight_info Action Input: {\"source_airport\": \"JFK\", \"destination_airport\": \"LAX\"}\u001b[0m\u001b[36;1m\u001b[1;3mAvailable flights from JFK to LAX:\n",
            "\n",
            "1. AS flight from JFK to LAX using 321 762\n",
            "2. B6 flight from JFK to LAX using 320\n",
            "3. DL flight from JFK to LAX using 76W 752\n",
            "4. QF flight from JFK to LAX using 744\n",
            "5. AA flight from JFK to LAX using 32B 762\n",
            "6. UA flight from JFK to LAX using 757\n",
            "7. US flight from JFK to LAX using 32B 762\n",
            "8. VX flight from JFK to LAX using 320\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query 1 completed successfully\n",
            "INFO:__main__:🔍 Running evaluation query 2: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:Flight Query: What do passengers say about SpiceJet's service quality?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: I found 8 available flights from JFK to LAX, including airlines AS, B6, DL, QF, AA, UA, US, and VX with various aircraft types.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use search_airline_reviews to help with this request Action: search_airline_reviews Action Input: SpiceJet service quality\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:search_airline_reviews:Searching for airline reviews with query: 'SpiceJet service quality'\n",
            "INFO:search_airline_reviews:Found 5 results for query: 'SpiceJet service quality'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mFound 5 relevant airline reviews for 'SpiceJet service quality':\n",
            "\n",
            "Review 1:\n",
            "Airline: SpiceJet. Title: \"Great travel experience\". Review: ✅ Trip Verified |  Marvelous courteous crew who took good care of all passengers. They should be rewarded for the patience shown towards the unruly ones. Great travel experience.. Rating: 10.0/10. Reviewer: Ranjita Pandey. Date: 18th April 2024. Recommended: yes\n",
            "\n",
            "Review 2:\n",
            "Airline: SpiceJet. Title: \"good service by the crew\". Review: ✅ Trip Verified | I have had good service by the crew. It was amazing, the crew was very enthusiastic and warm welcome. It was one of the best services in my experience.. Rating: 10.0/10. Reviewer: K Mansour. Date: 10th August 2024. Recommended: yes\n",
            "\n",
            "Review 3:\n",
            "Airline: SpiceJet. Title: \"Excellent service\". Review: ✅ Trip Verified |  Excellent service by the ground staff courteous beyond expectations always willing to help in the real sense and not lipservice i will recommend to all whom I know. Rating: 10.0/10. Reviewer: Ramanathan Ramchandra. Date: 1st November 2023. Recommended: yes\n",
            "\n",
            "Review 4:\n",
            "Airline: SpiceJet. Title: \"excellent hospitality\". Review: ✅ Trip Verified |  It's very grateful to SpiceJet for the service in flight. Everything is fine with excellent hospitality. Very politely behavior and warmly welcome from your cabin crew and all members.. Rating: 10.0/10. Reviewer: A Kajan. Date: 10th August 2024. Recommended: yes\n",
            "\n",
            "Review 5:\n",
            "Airline: SpiceJet. Title: \"delayed both ways by many hours\". Review: Not Verified |  Flight was delayed both ways by many hours. Poor service for the same price as other airlines like IndiGo. No wifi or other amenities to compensate for terrible service.. Rating: 2.0/10. Reviewer: Somil Jain Jain. Date: 20th May 2022. Recommended: no\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query 2 completed successfully\n",
            "INFO:__main__:📊 Collected 2 responses for evaluation\n",
            "INFO:__main__:Query: Find flights from JFK to LAX\n",
            "INFO:__main__:Response: ['Available flights from JFK to LAX:\\n\\n1. AS flight from JFK to LAX using 321 762\\n2. B6 flight from JFK to LAX using 320\\n3. DL flight from JFK to LAX using 76W 752\\n4. QF flight from JFK to LAX usi...\n",
            "INFO:__main__:Success: True\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:Response: ['Found 5 relevant airline reviews for \\'SpiceJet service quality\\':\\n\\nReview 1:\\nAirline: SpiceJet. Title: \"Great travel experience\". Review: ✅ Trip Verified |  Marvelous courteous crew who took goo...\n",
            "INFO:__main__:Success: True\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:💡 Visit Phoenix UI to see detailed traces and evaluations\n",
            "INFO:__main__:💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer Final Answer: Based on 5 customer reviews, SpiceJet receives mostly positive feedback (averaging 8.4/10) for their courteous crew, warm hospitality, and excellent ground staff service. However, some passengers report flight delays and poor service. The majority of reviews are highly positive (four 10/10 ratings), with one negative review citing delays and lack of amenities.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import Phoenix evaluation components and nest_asyncio for better notebook performance\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    import pandas as pd\n",
        "    import phoenix as px\n",
        "    from phoenix.evals import (\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        OpenAIModel,\n",
        "        llm_classify,\n",
        "    )\n",
        "\n",
        "    # Apply the patch to allow nested asyncio event loops\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    # Define lenient evaluation templates inline for self-contained notebook\n",
        "    LENIENT_QA_PROMPT_TEMPLATE = \"\"\"\n",
        "You are evaluating whether an AI agent's response correctly addresses a user's question.\n",
        "\n",
        "FOCUS ON FUNCTIONAL SUCCESS, NOT EXACT MATCHING:\n",
        "1. Did the agent provide the requested information (flights, bookings, reviews)?\n",
        "2. Is the core information accurate and helpful to the user?\n",
        "3. Would the user be satisfied with what they received?\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND CORRECT:\n",
        "- Booking IDs will be DIFFERENT each time (dynamically generated - this is correct!)\n",
        "- Dates like \"tomorrow\" are calculated dynamically (may differ from reference)\n",
        "- Booking lists reflect ACTUAL session bookings (may differ from reference)\n",
        "- Route sequences depend on actual booking order in this session\n",
        "\n",
        "IGNORE THESE DIFFERENCES:\n",
        "- Different booking IDs, dates, or sequences (these are dynamic!)\n",
        "- Format differences, duplicate calls, system messages\n",
        "- Reference mismatches due to dynamic data\n",
        "\n",
        "MARK AS CORRECT IF:\n",
        "- Agent successfully completed the action (found flights, made booking, retrieved bookings, got reviews)\n",
        "- User received useful, accurate information\n",
        "- Core functionality worked as expected\n",
        "\n",
        "Question: {input}\n",
        "Reference Answer: {reference}\n",
        "Agent Response: {output}\n",
        "\n",
        "Did the agent successfully provide what the user requested, regardless of exact reference matching?\n",
        "Respond with just \"correct\" or \"incorrect\".\n",
        "\"\"\"\n",
        "\n",
        "    LENIENT_HALLUCINATION_PROMPT_TEMPLATE = \"\"\"\n",
        "You are checking if an AI agent's response contains hallucinated information.\n",
        "\n",
        "DYNAMIC DATA IS EXPECTED AND FACTUAL:\n",
        "- Booking IDs are dynamically generated (will ALWAYS be different from reference - this is correct!)\n",
        "- Dates are calculated dynamically (\"tomorrow\", \"next week\" based on current date)\n",
        "- Booking sequences reflect actual session bookings (not static reference data)\n",
        "- Tool outputs contain real system data\n",
        "\n",
        "MARK AS FACTUAL IF:\n",
        "- Response contains \"iteration limit\" or \"time limit\" (system issue, not hallucination)\n",
        "- Dynamic data differs from reference (booking IDs, dates, booking sequences)\n",
        "- Agent provides plausible flight data, booking confirmations, or reviews\n",
        "- Information is consistent with system capabilities\n",
        "\n",
        "ONLY MARK AS HALLUCINATED IF:\n",
        "- Response contains clearly impossible information (fake airlines, impossible routes)\n",
        "- Agent makes up data it cannot access\n",
        "- Response contradicts fundamental system facts\n",
        "\n",
        "REMEMBER: Different booking IDs, dates, and sequences are EXPECTED dynamic behavior!\n",
        "\n",
        "Question: {input}\n",
        "Reference Text: {reference}\n",
        "Agent Response: {output}\n",
        "\n",
        "Does the response contain clearly false information, ignoring expected dynamic data differences?\n",
        "Respond with just \"factual\" or \"hallucinated\".\n",
        "\"\"\"\n",
        "\n",
        "    # Custom Rails\n",
        "    LENIENT_QA_RAILS = [\"correct\", \"incorrect\"]\n",
        "    LENIENT_HALLUCINATION_RAILS = [\"factual\", \"hallucinated\"]\n",
        "\n",
        "    ARIZE_AVAILABLE = True\n",
        "    logger.info(\"✅ Arize Phoenix evaluation components available\")\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Arize dependencies not available: {e}\")\n",
        "    logger.warning(\"Skipping evaluation section...\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "if ARIZE_AVAILABLE:\n",
        "    # Start Phoenix session for observability\n",
        "    try:\n",
        "        session = px.launch_app()\n",
        "        if session:\n",
        "            logger.info(f\"🚀 Phoenix UI available at {session.url}\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not start Phoenix UI: {e}\")\n",
        "\n",
        "    # Demo queries for evaluation\n",
        "    flight_demo_queries = [\n",
        "        \"Find flights from JFK to LAX\",\n",
        "        \"What do passengers say about SpiceJet's service quality?\",\n",
        "    ]\n",
        "\n",
        "    # Run demo queries and collect responses for evaluation\n",
        "    flight_demo_results = []\n",
        "\n",
        "    for i, query in enumerate(flight_demo_queries, 1):\n",
        "        try:\n",
        "            logger.info(f\"🔍 Running evaluation query {i}: {query}\")\n",
        "\n",
        "            # Create initial state and run the compiled graph\n",
        "            state = FlightSearchGraph.build_starting_state(query=query)\n",
        "            result = compiled_graph.invoke(state)\n",
        "\n",
        "            # Extract the response content including tool results\n",
        "            response_parts = []\n",
        "\n",
        "            # Critical Fix: Extract tool outputs from search_results first\n",
        "            if isinstance(result, dict) and \"search_results\" in result:\n",
        "                search_results = result[\"search_results\"]\n",
        "                if search_results:\n",
        "                    response_parts.append(str(search_results))\n",
        "\n",
        "            # Check for messages from final response\n",
        "            if result.get(\"messages\") and len(result[\"messages\"]) > 1:\n",
        "                final_response = result[\"messages\"][-1].content\n",
        "                if final_response:\n",
        "                    response_parts.append(final_response)\n",
        "\n",
        "            # Join all response parts\n",
        "            output = \"\\n\\n\".join(response_parts) if response_parts else \"No response generated\"\n",
        "\n",
        "            flight_demo_results.append(\n",
        "                {\n",
        "                    \"query\": query,\n",
        "                    \"response\": output,\n",
        "                    \"success\": result.get(\"resolved\", False),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            logger.info(f\"✅ Query {i} completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query {i} failed: {e}\")\n",
        "            flight_demo_results.append(\n",
        "                {\n",
        "                    \"query\": query,\n",
        "                    \"response\": f\"Error: {e!s}\",\n",
        "                    \"success\": False,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # Convert to DataFrame for evaluation\n",
        "    flight_results_df = pd.DataFrame(flight_demo_results)\n",
        "    logger.info(f\"📊 Collected {len(flight_results_df)} responses for evaluation\")\n",
        "\n",
        "    # Display results summary\n",
        "    for _, row in flight_results_df.iterrows():\n",
        "        logger.info(f\"Query: {row['query']}\")\n",
        "        logger.info(f\"Response: {row['response'][:200]}...\")\n",
        "        logger.info(f\"Success: {row['success']}\")\n",
        "        logger.info(\"-\" * 50)\n",
        "\n",
        "    logger.info(\"💡 Visit Phoenix UI to see detailed traces and evaluations\")\n",
        "    logger.info(\"💡 Use the evaluation script at evals/eval_arize.py for comprehensive evaluation\")\n",
        "\n",
        "else:\n",
        "    logger.info(\"Arize evaluation not available - install phoenix-evals to enable evaluation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bEgPxq8PmTC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ea47f2814fa346fd866e050dfb890c1e",
            "dc1bd74295444d9296401517d6d64b2a",
            "d5a3c0210f4243b8ac64f04e2f6b0e37",
            "216dbc504fd740589cbe990002dfda42",
            "0d17e37081dd4b068d01fae37e0eb5a8",
            "62826e09faa34f40b6f80aeaea02eae1",
            "7f4e86d45d18492e90c9082d47c750dc",
            "b8b2acc6fe1e411aadfd7e0e13bfc0c3",
            "bf6faa8c8f534cbb99d66ebb110e74e8",
            "812cff3e825e4d50b6827c380da3a56b",
            "5f2a7f2bb0b34a8383ab254f1eabc13c",
            "3f393e7ad9c64be2acd6efab16c2fea3",
            "20fa0c59efaf44f4b387f58ed0ac0a5a",
            "9229afeaf5024bb495586a02b13fd5dc",
            "89f1a69b47694e5eaa4dde74145ffc04",
            "a5a86afc2c6d4847a7aee2ccedaf7c05",
            "418c67d7f36e4dbda10e4b7e690b5b44",
            "f3d0be30a41f422395c5147d014c7ea2",
            "a3edd1f139304386beb29a76dac021b5",
            "00f3211eb49d4cc6b20f0ff2add367fe",
            "577f0ef3ef2a49f2812e9500e4a5c139",
            "f3fe1d3f8e764c6e8601d292c0857e17",
            "931c24a958aa4fcfbd9825640cebcc3f",
            "1ade51ac63b148f69ff02faaacfb980c",
            "cc379b4ab20b452f920b4c05f1250cba",
            "8e2bfac2301c41eeac858121a81071ad",
            "8ec9c2f0ee1c40e0a5d6c74975dd8aea",
            "c31ca10656624e938a5d2662660782d0",
            "6840c60d724b407b9a12535dd153860b",
            "45b24e8f306e4d019599d314192718ba",
            "b5edccebc9124c28b6127fa342b219b0",
            "e5eceb1fc35f4fdd81320e9bd30e504d",
            "52965b2bffa44706ac6d63202f3c14cf",
            "bb60e7ce21ff4924983752dd309ecce8",
            "122484e75a8c499a9742ab8369d4ba49",
            "8b51029fa0c8465d8d98247733f872cb",
            "ef635829436c4e9098ccbb73a891da12",
            "7b3e06acf65e4f99a04d7f191a962e3b",
            "e419ee3541b74c50852067af704e12fd",
            "4c6254e9a1994972b954c2e2f372b98a",
            "9c85f0295de24534ac14152c8291b5d4",
            "dec58c834aa84b7da2afeb02f8f4d23a",
            "c8fad9391c384cf482d68b65cf3daf54",
            "4b8d4c3319db4defb78848a0844b2e21"
          ]
        },
        "outputId": "0da2cf1e-92fa-4011-f0e6-1e730a31a99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:🔍 Running comprehensive Phoenix evaluations with lenient templates...\n",
            "INFO:__main__:🔍 Running Relevance Evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea47f2814fa346fd866e050dfb890c1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Relevance Evaluation Results:\n",
            "INFO:__main__:   Query: Find flights from JFK to LAX\n",
            "INFO:__main__:   Relevance: relevant\n",
            "INFO:__main__:   Explanation: The question asks for flights from JFK to LAX. The reference text provides a list of available flights from JFK to LAX, including the airline codes and aircraft types. This information directly answers the question by listing the flights that are available for the specified route. Therefore, the reference text is relevant to the question.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:   Query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:   Relevance: relevant\n",
            "INFO:__main__:   Explanation: The question asks about passengers' opinions on SpiceJet's service quality. The reference text provides multiple reviews from passengers specifically discussing their experiences with SpiceJet's service. Each review highlights aspects of the service quality, such as the crew's enthusiasm, warmth, efficiency, and professionalism, as well as the overall experience with the airline. These reviews directly address the question by providing firsthand accounts of the service quality from passengers' perspectives.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:🔍 Running QA Evaluation with Lenient Templates...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f393e7ad9c64be2acd6efab16c2fea3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ QA Evaluation Results:\n",
            "INFO:__main__:   Query: Find flights from JFK to LAX\n",
            "INFO:__main__:   QA Score: correct\n",
            "INFO:__main__:   Explanation: The agent successfully provided the user with a list of available flights from JFK to LAX, including the airlines and aircraft types. The response matches the core information requested by the user, and the dynamic nature of the data (such as booking IDs or sequences) is not relevant here. The user would be satisfied with the information provided.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:   Query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:   QA Score: correct\n",
            "INFO:__main__:   Explanation: The agent provided 5 reviews about SpiceJet's service quality, which is what the user requested. The reviews cover both positive and negative aspects, giving a balanced view of the service quality. The core information is accurate and helpful, as it includes specific feedback on the crew, hospitality, and service issues like delays. Therefore, the user would likely be satisfied with this response.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:🔍 Running Hallucination Evaluation with Lenient Templates...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931c24a958aa4fcfbd9825640cebcc3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Hallucination Evaluation Results:\n",
            "INFO:__main__:   Query: Find flights from JFK to LAX\n",
            "INFO:__main__:   Hallucination: factual\n",
            "INFO:__main__:   Explanation: The agent's response matches the reference text exactly, listing the same airlines and aircraft types for flights from JFK to LAX. There is no indication of impossible information or made-up data. The response is consistent with the system's capabilities and does not contradict any fundamental facts.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:   Query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:   Hallucination: hallucinated\n",
            "INFO:__main__:   Explanation: The agent's response contains reviews that are not present in the reference text. The titles and content of the reviews in the agent's response do not match those in the reference text, indicating that the agent has generated or retrieved different reviews. This is a case of hallucination as the reviews are not consistent with the provided reference data.\n",
            "WARNING:__main__:⚠️  HALLUCINATION DETECTED in response to: What do passengers say about SpiceJet's service quality?\n",
            "WARNING:__main__:   Response may contain fabricated information!\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:🔍 Running Toxicity Evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb60e7ce21ff4924983752dd309ecce8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Toxicity Evaluation Results:\n",
            "INFO:__main__:   Query: Find flights from JFK to LAX\n",
            "INFO:__main__:   Toxicity: non-toxic\n",
            "INFO:__main__:   Explanation: To determine whether the text is toxic, we need to analyze the content for any signs of hateful language, demeaning comments, inappropriate language, or threats of violence. The text in question is: \"Find flights from JFK to LAX.\" This text is a straightforward request or command to search for flights between two airports, JFK (John F. Kennedy International Airport) and LAX (Los Angeles International Airport). \n",
            "\n",
            "1. **Hateful Statements**: The text does not contain any language that could be interpreted as hateful towards any individual or group.\n",
            "\n",
            "2. **Demeaning or Disparaging Language**: There is no language that demeans or disparages anyone. It is a neutral statement focused on a travel-related task.\n",
            "\n",
            "3. **Inappropriate Language**: The text uses standard, appropriate language without any profanity or vulgarity.\n",
            "\n",
            "4. **Threats of Violence**: There are no threats, either physical or emotional, present in the text.\n",
            "\n",
            "Given these observations, the text does not meet any criteria for toxicity. It is a simple, non-offensive request related to travel.\n",
            "\n",
            "Therefore, the text is non-toxic.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:   Query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:   Toxicity: non-toxic\n",
            "INFO:__main__:   Explanation: To determine whether the text is toxic, we need to evaluate it against the criteria for toxicity: hateful statements, demeaning or disparaging language, inappropriate language, or threats of violence.\n",
            "\n",
            "1. The text is a question asking about passengers' opinions on SpiceJet's service quality. It does not contain any statements or opinions itself.\n",
            "2. There are no hateful statements present in the text. It is a neutral question.\n",
            "3. The text does not demean or disparage any individual or group. It simply inquires about service quality.\n",
            "4. There is no inappropriate language used in the text. The language is formal and neutral.\n",
            "5. There are no threats of physical or emotional violence in the text.\n",
            "\n",
            "Given these observations, the text does not meet any of the criteria for toxicity. It is a straightforward question without any negative or harmful language.\n",
            "INFO:__main__:   ------------------------------\n",
            "INFO:__main__:📊 EVALUATION SUMMARY\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:Query 1: Find flights from JFK to LAX\n",
            "INFO:__main__:  Relevance: relevant\n",
            "INFO:__main__:  QA Score: correct\n",
            "INFO:__main__:  Hallucination: factual\n",
            "INFO:__main__:  Toxicity: non-toxic\n",
            "INFO:__main__:  --------------------------------------------------\n",
            "INFO:__main__:Query 2: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:  Relevance: relevant\n",
            "INFO:__main__:  QA Score: correct\n",
            "INFO:__main__:  Hallucination: hallucinated\n",
            "INFO:__main__:  Toxicity: non-toxic\n",
            "WARNING:__main__:  🚨 FACTUAL ISSUE DETECTED!\n",
            "INFO:__main__:  --------------------------------------------------\n",
            "INFO:__main__:\n",
            "🎯 FACTUAL QUALITY ASSESSMENT\n",
            "INFO:__main__:========================================\n",
            "INFO:__main__:Total Queries: 2\n",
            "INFO:__main__:Factual Issues: 1\n",
            "INFO:__main__:Factual Accuracy: 50.0%\n",
            "ERROR:__main__:❌ POOR FACTUAL ACCURACY - Need immediate attention!\n",
            "INFO:__main__:✅ All Phoenix evaluations completed successfully!\n"
          ]
        }
      ],
      "source": [
        "if ARIZE_AVAILABLE and len(flight_demo_results) > 0:\n",
        "    logger.info(\"🔍 Running comprehensive Phoenix evaluations with lenient templates...\")\n",
        "\n",
        "    # Setup evaluator LLM (using OpenAI for consistency)\n",
        "    evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.1)\n",
        "\n",
        "    # Reference answers copied from data/queries.py (proper copy-paste as requested)\n",
        "    FLIGHT_REFERENCE_ANSWERS = [\n",
        "        # Query 1: Flight search JFK to LAX\n",
        "        \"\"\"Available flights from JFK to LAX:\n",
        "\n",
        "1. AS flight from JFK to LAX using 321 762\n",
        "2. B6 flight from JFK to LAX using 320\n",
        "3. DL flight from JFK to LAX using 76W 752\n",
        "4. QF flight from JFK to LAX using 744\n",
        "5. AA flight from JFK to LAX using 32B 762\n",
        "6. UA flight from JFK to LAX using 757\n",
        "7. US flight from JFK to LAX using 32B 762\n",
        "8. VX flight from JFK to LAX using 320\"\"\",\n",
        "\n",
        "        # Query 2: Flight booking LAX to JFK for tomorrow, 2 passengers, business class\n",
        "        \"\"\"Flight Booking Confirmed!\n",
        "\n",
        "Booking ID: FL08061563CACD\n",
        "Route: LAX → JFK\n",
        "Departure Date: 2025-08-06\n",
        "Passengers: 2\n",
        "Class: business\n",
        "Total Price: $1500.00\n",
        "\n",
        "Next Steps:\n",
        "1. Check-in opens 24 hours before departure\n",
        "2. Arrive at airport 2 hours early for domestic flights\n",
        "3. Bring valid government-issued photo ID\n",
        "\n",
        "Thank you for choosing our airline!\"\"\",\n",
        "\n",
        "        # Query 3: Flight booking JFK to MIA for next week\n",
        "        \"\"\"Flight Booking Confirmed!\n",
        "\n",
        "Booking ID: FL08124E7B9C2A\n",
        "Route: JFK → MIA\n",
        "Departure Date: 2025-08-12\n",
        "Passengers: 1\n",
        "Class: economy\n",
        "Total Price: $250.00\n",
        "\n",
        "Next Steps:\n",
        "1. Check-in opens 24 hours before departure\n",
        "2. Arrive at airport 2 hours early for domestic flights\n",
        "3. Bring valid government-issued photo ID\n",
        "\n",
        "Thank you for choosing our airline!\"\"\",\n",
        "\n",
        "        # Query 4: Show current flight bookings\n",
        "        \"\"\"Your Current Bookings (2 found):\n",
        "\n",
        "Booking 1:\n",
        "  Booking ID: FL08061563CACD\n",
        "  Route: LAX → JFK\n",
        "  Date: 2025-08-06\n",
        "  Passengers: 2\n",
        "  Class: business\n",
        "  Total: $1500.00\n",
        "  Status: confirmed\n",
        "  Booked: 2025-08-05\n",
        "\n",
        "Booking 2:\n",
        "  Booking ID: FL08124E7B9C2A\n",
        "  Route: JFK → MIA\n",
        "  Date: 2025-08-12\n",
        "  Passengers: 1\n",
        "  Class: economy\n",
        "  Total: $250.00\n",
        "  Status: confirmed\n",
        "  Booked: 2025-08-05\"\"\",\n",
        "\n",
        "        # Query 5: SpiceJet service quality reviews\n",
        "        \"\"\"Found 5 relevant airline reviews for 'SpiceJet service':\n",
        "\n",
        "Review 1:\n",
        "Airline: SpiceJet. Title: \"Service is impeccable\". Review: ✅ Trip Verified | Much better than airbus models. Even the basic economy class has ambient lighting. Better personal air vents and better spotlights. Even overhead storage bins are good. Service is impeccable with proper care taken of guests...\n",
        "\n",
        "Review 2:\n",
        "Airline: SpiceJet. Title: \"good service by the crew\". Review: ✅ Trip Verified | I have had good service by the crew. It was amazing, the crew was very enthusiastic and warm welcome. It was one of the best services in my experience.. Rating: 10.0/10. Reviewer: K Mansour. Date: 10th August 2024. Recom...\n",
        "\n",
        "Review 3:\n",
        "Airline: SpiceJet. Title: \"outstanding service I experienced\". Review: Not Verified |  I wanted to take a moment to express my sincere thanks for the outstanding service I experienced on my recent flight from Pune to Delhi. SG-8937. From the moment I boarded, the warmth and friendliness of the air h...\n",
        "\n",
        "Review 4:\n",
        "Airline: SpiceJet. Title: \"efficient and warm onboard service\". Review: ✅ Trip Verified |  New Delhi to Kolkata. Delighted with the prompt, efficient and warm onboard service provided by the crew. Appreciate their efforts towards customer centricity.. Rating: 10.0/10. Reviewer: Debashis Roy. Date: 2...\n",
        "\n",
        "Review 5:\n",
        "Airline: SpiceJet. Title: \"Outstanding service from SpiceJet\". Review: ✅ Trip Verified | I recently flew with SpiceJet from Mumbai to Delhi and was thoroughly impressed with the level of service provided. The check-in process was smooth and efficient, and the staff at the counter were courteous and helpful. The aircraft was clean and well-maintained, and the seats were comfortable for the duration of the flight. The in-flight service was exceptional, with the cabin crew being attentive and professional throughout the journey. The meal served was tasty and well-presented, and the entertainment system kept me engaged during the flight. Overall, I had a fantastic experience with SpiceJet and would definitely recommend them to other travelers. Rating: 9.5/10. Reviewer: Priya Sharma. Date: 15th July 2024.\"\"\",\n",
        "    ]\n",
        "\n",
        "    # Queries copied from data/queries.py\n",
        "    FLIGHT_SEARCH_QUERIES = [\n",
        "        \"Find flights from JFK to LAX\",\n",
        "        \"Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\",\n",
        "        \"Book an economy flight from JFK to MIA for next week, 1 passenger\",\n",
        "        \"Show me my current flight bookings\",\n",
        "        \"What do passengers say about SpiceJet's service quality?\",\n",
        "    ]\n",
        "\n",
        "    # Create mapping dictionary like the working source files\n",
        "    QUERY_REFERENCE_ANSWERS = {\n",
        "        query: answer for query, answer in zip(FLIGHT_SEARCH_QUERIES, FLIGHT_REFERENCE_ANSWERS)\n",
        "    }\n",
        "\n",
        "    # Prepare evaluation data with proper column names for Phoenix evaluators\n",
        "    flight_eval_data = []\n",
        "    for _, row in flight_results_df.iterrows():\n",
        "        flight_eval_data.append(\n",
        "            {\n",
        "                \"input\": row[\"query\"],\n",
        "                \"output\": row[\"response\"],\n",
        "                \"reference\": QUERY_REFERENCE_ANSWERS.get(row[\"query\"], \"Reference answer not found\"),\n",
        "                \"text\": row[\"response\"],  # For toxicity evaluation\n",
        "            }\n",
        "        )\n",
        "\n",
        "    flight_eval_df = pd.DataFrame(flight_eval_data)\n",
        "\n",
        "    try:\n",
        "        # 1. Relevance Evaluation\n",
        "        logger.info(\"🔍 Running Relevance Evaluation...\")\n",
        "        flight_relevance_results = llm_classify(\n",
        "            data=flight_eval_df[[\"input\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "            rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "\n",
        "        logger.info(\"✅ Relevance Evaluation Results:\")\n",
        "        for i, row in flight_relevance_results.iterrows():\n",
        "            query = flight_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Relevance: {row.get('label', row.get('classification', 'unknown'))}\")\n",
        "            logger.info(f\"   Explanation: {row.get('explanation', 'No explanation')}\")\n",
        "            logger.info(\"   \" + \"-\" * 30)\n",
        "\n",
        "        # 2. QA Evaluation with Lenient Templates\n",
        "        logger.info(\"🔍 Running QA Evaluation with Lenient Templates...\")\n",
        "        flight_qa_results = llm_classify(\n",
        "            data=flight_eval_df[[\"input\", \"output\", \"reference\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=LENIENT_QA_PROMPT_TEMPLATE,\n",
        "            rails=LENIENT_QA_RAILS,\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "\n",
        "        logger.info(\"✅ QA Evaluation Results:\")\n",
        "        for i, row in flight_qa_results.iterrows():\n",
        "            query = flight_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   QA Score: {row.get('label', row.get('classification', 'unknown'))}\")\n",
        "            logger.info(f\"   Explanation: {row.get('explanation', 'No explanation')}\")\n",
        "            logger.info(\"   \" + \"-\" * 30)\n",
        "\n",
        "        # 3. Hallucination Evaluation with Lenient Templates\n",
        "        logger.info(\"🔍 Running Hallucination Evaluation with Lenient Templates...\")\n",
        "        flight_hallucination_results = llm_classify(\n",
        "            data=flight_eval_df[[\"input\", \"reference\", \"output\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=LENIENT_HALLUCINATION_PROMPT_TEMPLATE,\n",
        "            rails=LENIENT_HALLUCINATION_RAILS,\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "\n",
        "        logger.info(\"✅ Hallucination Evaluation Results:\")\n",
        "        for i, row in flight_hallucination_results.iterrows():\n",
        "            query = flight_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            hallucination_result = row.get(\"label\", row.get(\"classification\", \"unknown\"))\n",
        "            logger.info(f\"   Hallucination: {hallucination_result}\")\n",
        "            logger.info(f\"   Explanation: {row.get('explanation', 'No explanation')}\")\n",
        "\n",
        "            # Add warning for hallucinated responses\n",
        "            if hallucination_result.lower() in [\"hallucinated\", \"hallucination\", \"yes\"]:\n",
        "                logger.warning(f\"⚠️  HALLUCINATION DETECTED in response to: {query}\")\n",
        "                logger.warning(f\"   Response may contain fabricated information!\")\n",
        "\n",
        "            logger.info(\"   \" + \"-\" * 30)\n",
        "\n",
        "        # 4. Toxicity Evaluation\n",
        "        logger.info(\"🔍 Running Toxicity Evaluation...\")\n",
        "        flight_toxicity_results = llm_classify(\n",
        "            data=flight_eval_df[[\"input\"]],\n",
        "            model=evaluator_llm,\n",
        "            template=TOXICITY_PROMPT_TEMPLATE,\n",
        "            rails=list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "            provide_explanation=True,\n",
        "        )\n",
        "\n",
        "        logger.info(\"✅ Toxicity Evaluation Results:\")\n",
        "        for i, row in flight_toxicity_results.iterrows():\n",
        "            query = flight_eval_data[i][\"input\"]\n",
        "            logger.info(f\"   Query: {query}\")\n",
        "            logger.info(f\"   Toxicity: {row.get('label', row.get('classification', 'unknown'))}\")\n",
        "            logger.info(f\"   Explanation: {row.get('explanation', 'No explanation')}\")\n",
        "            logger.info(\"   \" + \"-\" * 30)\n",
        "\n",
        "        # Summary with improved factual validation\n",
        "        logger.info(\"📊 EVALUATION SUMMARY\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "        factual_issues = 0\n",
        "        for i, query in enumerate([item[\"input\"] for item in flight_eval_data]):\n",
        "            relevance = flight_relevance_results.iloc[i].get(\"label\", \"unknown\")\n",
        "            qa_score = flight_qa_results.iloc[i].get(\"label\", \"unknown\")\n",
        "            hallucination = flight_hallucination_results.iloc[i].get(\"label\", \"unknown\")\n",
        "            toxicity = flight_toxicity_results.iloc[i].get(\"label\", \"unknown\")\n",
        "\n",
        "            logger.info(f\"Query {i + 1}: {query}\")\n",
        "            logger.info(f\"  Relevance: {relevance}\")\n",
        "            logger.info(f\"  QA Score: {qa_score}\")\n",
        "            logger.info(f\"  Hallucination: {hallucination}\")\n",
        "            logger.info(f\"  Toxicity: {toxicity}\")\n",
        "\n",
        "            # Check for factual issues\n",
        "            if hallucination.lower() in [\n",
        "                \"hallucinated\",\n",
        "                \"hallucination\",\n",
        "            ] or qa_score.lower() in [\"incorrect\"]:\n",
        "                factual_issues += 1\n",
        "                logger.warning(f\"  🚨 FACTUAL ISSUE DETECTED!\")\n",
        "\n",
        "            logger.info(\"  \" + \"-\" * 50)\n",
        "\n",
        "        # Overall factual quality assessment\n",
        "        logger.info(\"\\n🎯 FACTUAL QUALITY ASSESSMENT\")\n",
        "        logger.info(\"=\" * 40)\n",
        "        total_queries = len(flight_eval_data)\n",
        "        factual_accuracy = ((total_queries - factual_issues) / total_queries) * 100\n",
        "\n",
        "        logger.info(f\"Total Queries: {total_queries}\")\n",
        "        logger.info(f\"Factual Issues: {factual_issues}\")\n",
        "        logger.info(f\"Factual Accuracy: {factual_accuracy:.1f}%\")\n",
        "\n",
        "        if factual_accuracy < 80:\n",
        "            logger.error(\"❌ POOR FACTUAL ACCURACY - Need immediate attention!\")\n",
        "        elif factual_accuracy < 90:\n",
        "            logger.warning(\"⚠️  MODERATE FACTUAL ACCURACY - Review needed\")\n",
        "        else:\n",
        "            logger.info(\"✅ GOOD FACTUAL ACCURACY\")\n",
        "\n",
        "        logger.info(\"✅ All Phoenix evaluations completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"❌ Phoenix evaluation failed: {e}\")\n",
        "        logger.info(\"💡 This might be due to API rate limits or model availability\")\n",
        "        logger.info(\"💡 Try again with a different model or check your API keys\")\n",
        "\n",
        "else:\n",
        "    if not ARIZE_AVAILABLE:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - Arize dependencies not available\")\n",
        "    else:\n",
        "        logger.info(\"❌ Phoenix evaluations skipped - No demo results to evaluate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4WANBV3mTC8",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Evaluation Configuration\n",
        "\n",
        "Configuration class for the evaluation system with all parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VtGx7JSvmTC8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nest_asyncio\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "\n",
        "# Apply the patch to allow nested asyncio event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Try to import Arize dependencies with fallback\n",
        "try:\n",
        "    import phoenix as px\n",
        "    from arize.experimental.datasets import ArizeDatasetsClient\n",
        "    from arize.experimental.datasets.utils.constants import GENERATIVE\n",
        "    from openinference.instrumentation.langchain import LangChainInstrumentor\n",
        "    from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "    from phoenix.evals import (\n",
        "        RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
        "        RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "        TOXICITY_PROMPT_RAILS_MAP,\n",
        "        TOXICITY_PROMPT_TEMPLATE,\n",
        "        HallucinationEvaluator,\n",
        "        OpenAIModel,\n",
        "        QAEvaluator,\n",
        "        RelevanceEvaluator,\n",
        "        ToxicityEvaluator,\n",
        "        llm_classify,\n",
        "    )\n",
        "    from phoenix.otel import register\n",
        "\n",
        "    ARIZE_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    logger.warning(f\"Arize dependencies not available: {e}\")\n",
        "    logger.warning(\"Running in local evaluation mode only...\")\n",
        "    ARIZE_AVAILABLE = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EvaluationConfig:\n",
        "    \"\"\"Configuration for the evaluation system.\"\"\"\n",
        "\n",
        "    # Arize Configuration\n",
        "    arize_space_id: str = os.getenv(\"ARIZE_SPACE_ID\", \"your-space-id\")\n",
        "    arize_api_key: str = os.getenv(\"ARIZE_API_KEY\", \"your-api-key\")\n",
        "    project_name: str = \"flight-search-agent-evaluation\"\n",
        "\n",
        "    # Phoenix Configuration\n",
        "    phoenix_base_port: int = 6006\n",
        "    phoenix_grpc_base_port: int = 4317\n",
        "    phoenix_max_port_attempts: int = 5\n",
        "    phoenix_startup_timeout: int = 30\n",
        "\n",
        "    # Evaluation Configuration\n",
        "    evaluator_model: str = \"gpt-4o\"\n",
        "    batch_size: int = 10\n",
        "    max_retries: int = 3\n",
        "    evaluation_timeout: int = 300\n",
        "\n",
        "    # Logging Configuration\n",
        "    log_level: str = \"INFO\"\n",
        "    detailed_logging: bool = True\n",
        "\n",
        "    # Dataset Configuration\n",
        "    dataset_name: str = \"flight-search-evaluation-queries\"\n",
        "    dataset_description: str = \"Flight search agent evaluation queries with expected responses\"\n",
        "\n",
        "    # Output Configuration\n",
        "    save_results: bool = True\n",
        "    results_format: str = \"csv\"  # csv, json, both\n",
        "    output_dir: str = \"output\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration after initialization.\"\"\"\n",
        "        if self.phoenix_base_port < 1024 or self.phoenix_base_port > 65535:\n",
        "            raise ValueError(\"Phoenix base port must be between 1024 and 65535\")\n",
        "\n",
        "        if self.batch_size < 1 or self.batch_size > 100:\n",
        "            raise ValueError(\"Batch size must be between 1 and 100\")\n",
        "\n",
        "        if self.evaluation_timeout < 30:\n",
        "            raise ValueError(\"Evaluation timeout must be at least 30 seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB9KfoEBmTC9",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Phoenix Manager\n",
        "\n",
        "Manages Phoenix server lifecycle and port management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "W-eWQOiSmTC9"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "class PhoenixManager:\n",
        "    \"\"\"Manages Phoenix server lifecycle and port management.\"\"\"\n",
        "\n",
        "    def __init__(self, config: EvaluationConfig):\n",
        "        self.config = config\n",
        "        self.session = None\n",
        "        self.active_port = None\n",
        "        self.tracer_provider = None\n",
        "\n",
        "    def _is_port_in_use(self, port: int) -> bool:\n",
        "        \"\"\"Check if a port is in use.\"\"\"\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "            return s.connect_ex((\"localhost\", port)) == 0\n",
        "\n",
        "    def _kill_existing_phoenix_processes(self) -> None:\n",
        "        \"\"\"Kill any existing Phoenix processes.\"\"\"\n",
        "        try:\n",
        "            subprocess.run([\"pkill\", \"-f\", \"phoenix\"], check=False, capture_output=True)\n",
        "            time.sleep(2)  # Wait for processes to terminate\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"Error killing Phoenix processes: {e}\")\n",
        "\n",
        "    def _find_available_port(self) -> Tuple[int, int]:\n",
        "        \"\"\"Find available ports for Phoenix.\"\"\"\n",
        "        phoenix_port = self.config.phoenix_base_port\n",
        "        grpc_port = self.config.phoenix_grpc_base_port\n",
        "\n",
        "        for _ in range(self.config.phoenix_max_port_attempts):\n",
        "            if not self._is_port_in_use(phoenix_port):\n",
        "                return phoenix_port, grpc_port\n",
        "            phoenix_port += 1\n",
        "            grpc_port += 1\n",
        "\n",
        "        raise RuntimeError(\n",
        "            f\"Could not find available ports after {self.config.phoenix_max_port_attempts} attempts\"\n",
        "        )\n",
        "\n",
        "    def start_phoenix(self) -> bool:\n",
        "        \"\"\"Start Phoenix server and return success status.\"\"\"\n",
        "        if not ARIZE_AVAILABLE:\n",
        "            logger.warning(\"⚠️ Phoenix dependencies not available\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            logger.info(\"🔧 Setting up Phoenix observability...\")\n",
        "\n",
        "            # Clean up existing processes\n",
        "            self._kill_existing_phoenix_processes()\n",
        "\n",
        "            # Find available ports\n",
        "            phoenix_port, grpc_port = self._find_available_port()\n",
        "\n",
        "            # Set environment variables\n",
        "            os.environ[\"PHOENIX_PORT\"] = str(phoenix_port)\n",
        "            os.environ[\"PHOENIX_GRPC_PORT\"] = str(grpc_port)\n",
        "\n",
        "            # Start Phoenix session\n",
        "            self.session = px.launch_app()\n",
        "            self.active_port = phoenix_port\n",
        "\n",
        "            if self.session:\n",
        "                logger.info(f\"🌐 Phoenix UI: {self.session.url}\")\n",
        "\n",
        "            # Register Phoenix OTEL\n",
        "            self.tracer_provider = register(\n",
        "                project_name=self.config.project_name,\n",
        "                endpoint=f\"http://localhost:{phoenix_port}/v1/traces\",\n",
        "            )\n",
        "\n",
        "            logger.info(\"✅ Phoenix setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Phoenix setup failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def setup_instrumentation(self) -> bool:\n",
        "        \"\"\"Setup OpenTelemetry instrumentation.\"\"\"\n",
        "        if not self.tracer_provider or not ARIZE_AVAILABLE:\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            instrumentors = [\n",
        "                (\"LangChain\", LangChainInstrumentor),\n",
        "                (\"OpenAI\", OpenAIInstrumentor),\n",
        "            ]\n",
        "\n",
        "            for name, instrumentor_class in instrumentors:\n",
        "                try:\n",
        "                    instrumentor = instrumentor_class()\n",
        "                    instrumentor.instrument(tracer_provider=self.tracer_provider)\n",
        "                    logger.info(f\"✅ {name} instrumentation enabled\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"⚠️ {name} instrumentation failed: {e}\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Instrumentation setup failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"Clean up Phoenix resources.\"\"\"\n",
        "        try:\n",
        "            # Clean up environment variables\n",
        "            for var in [\"PHOENIX_PORT\", \"PHOENIX_GRPC_PORT\"]:\n",
        "                if var in os.environ:\n",
        "                    del os.environ[var]\n",
        "\n",
        "            logger.info(\"🔒 Phoenix cleanup completed\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error during Phoenix cleanup: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mjlAzXBmTC9",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Arize Dataset Manager\n",
        "\n",
        "Manages Arize dataset creation and management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "T_MM1xe-mTC9"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class ArizeDatasetManager:\n",
        "    \"\"\"Manages Arize dataset creation and management.\"\"\"\n",
        "\n",
        "    def __init__(self, config: EvaluationConfig):\n",
        "        self.config = config\n",
        "        self.client = None\n",
        "        self._setup_client()\n",
        "\n",
        "    def _setup_client(self) -> None:\n",
        "        \"\"\"Setup Arize datasets client.\"\"\"\n",
        "        if not ARIZE_AVAILABLE:\n",
        "            return\n",
        "\n",
        "        if (\n",
        "            self.config.arize_api_key != \"your-api-key\"\n",
        "            and self.config.arize_space_id != \"your-space-id\"\n",
        "        ):\n",
        "            try:\n",
        "                # Initialize with correct parameters - no space_id needed for datasets client\n",
        "                self.client = ArizeDatasetsClient(\n",
        "                    api_key=self.config.arize_api_key\n",
        "                )\n",
        "                logger.info(\"✅ Arize datasets client initialized successfully\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ Could not initialize Arize datasets client: {e}\")\n",
        "                self.client = None\n",
        "        else:\n",
        "            logger.warning(\"⚠️ Arize API credentials not configured\")\n",
        "            self.client = None\n",
        "\n",
        "    def create_dataset(self, results_df: pd.DataFrame) -> Optional[str]:\n",
        "        \"\"\"Create Arize dataset from evaluation results.\"\"\"\n",
        "        if not self.client:\n",
        "            logger.warning(\"⚠️ Arize client not available - skipping dataset creation\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            dataset_name = f\"flight-search-evaluation-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "            logger.info(\"📊 Creating Arize dataset...\")\n",
        "            dataset_id = self.client.create_dataset(\n",
        "                space_id=self.config.arize_space_id,\n",
        "                dataset_name=dataset_name,\n",
        "                dataset_type=GENERATIVE,\n",
        "                data=results_df,\n",
        "                convert_dict_to_json=True\n",
        "            )\n",
        "\n",
        "            if dataset_id:\n",
        "                logger.info(f\"✅ Arize dataset created successfully: {dataset_id}\")\n",
        "                return dataset_id\n",
        "            else:\n",
        "                logger.warning(\"⚠️ Dataset creation returned None\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Error creating Arize dataset: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZYhP6E3mTC9",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Arize Flight Search Evaluator\n",
        "\n",
        "Main evaluator class for comprehensive flight search agent evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7OmaB3d-mTC9"
      },
      "outputs": [],
      "source": [
        "class ArizeFlightSearchEvaluator:\n",
        "    \"\"\"\n",
        "    Streamlined flight search agent evaluator using only Arize Phoenix evaluators.\n",
        "\n",
        "    This class provides comprehensive evaluation capabilities using:\n",
        "    - Phoenix RelevanceEvaluator for response relevance\n",
        "    - Phoenix QAEvaluator for correctness assessment\n",
        "    - Phoenix HallucinationEvaluator for factual accuracy\n",
        "    - Phoenix ToxicityEvaluator for safety assessment\n",
        "    - No manual validation - Phoenix evaluators only\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Optional[EvaluationConfig] = None):\n",
        "        \"\"\"Initialize the evaluator with configuration.\"\"\"\n",
        "        self.config = config or EvaluationConfig()\n",
        "        self._setup_logging()\n",
        "\n",
        "        # Initialize components\n",
        "        self.phoenix_manager = PhoenixManager(self.config)\n",
        "        self.dataset_manager = ArizeDatasetManager(self.config)\n",
        "\n",
        "        # Agent components\n",
        "        self.agent = None\n",
        "        self.span = None\n",
        "\n",
        "        # Phoenix evaluators\n",
        "        self.evaluators = {}\n",
        "        self.evaluator_llm = None\n",
        "\n",
        "        if ARIZE_AVAILABLE:\n",
        "            self._setup_phoenix_evaluators()\n",
        "\n",
        "    def _setup_logging(self) -> None:\n",
        "        \"\"\"Configure logging to suppress verbose modules.\"\"\"\n",
        "        verbose_modules = [\"openai\", \"httpx\", \"httpcore\", \"agentc_core\"]\n",
        "        for module in verbose_modules:\n",
        "            logging.getLogger(module).setLevel(logging.WARNING)\n",
        "\n",
        "    def _setup_phoenix_evaluators(self) -> None:\n",
        "        \"\"\"Setup Phoenix evaluators with robust error handling.\"\"\"\n",
        "        if not ARIZE_AVAILABLE:\n",
        "            logger.warning(\"⚠️ Phoenix dependencies not available - evaluations will be limited\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            self.evaluator_llm = OpenAIModel(model=self.config.evaluator_model)\n",
        "\n",
        "            # Initialize all Phoenix evaluators\n",
        "            self.evaluators = {\n",
        "                \"relevance\": RelevanceEvaluator(self.evaluator_llm),\n",
        "                \"qa_correctness\": QAEvaluator(self.evaluator_llm),\n",
        "                \"hallucination\": HallucinationEvaluator(self.evaluator_llm),\n",
        "                \"toxicity\": ToxicityEvaluator(self.evaluator_llm),\n",
        "            }\n",
        "\n",
        "            logger.info(\"✅ Phoenix evaluators initialized successfully\")\n",
        "            logger.info(f\"   🤖 Using evaluator model: {self.config.evaluator_model}\")\n",
        "            logger.info(f\"   📊 Available evaluators: {list(self.evaluators.keys())}\")\n",
        "\n",
        "            # Setup Phoenix if available\n",
        "            if self.phoenix_manager.start_phoenix():\n",
        "                self.phoenix_manager.setup_instrumentation()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Phoenix evaluators setup failed: {e}\")\n",
        "            logger.info(\"Continuing with basic evaluation metrics only...\")\n",
        "            self.evaluators = {}\n",
        "\n",
        "    def setup_agent(self) -> bool:\n",
        "        \"\"\"Setup flight search agent using refactored main.py setup.\"\"\"\n",
        "        try:\n",
        "            logger.info(\"🔧 Setting up flight search agent...\")\n",
        "\n",
        "            # Use the refactored setup function from main.py\n",
        "            compiled_graph, application_span = setup_flight_search_agent()\n",
        "\n",
        "            self.agent = compiled_graph\n",
        "            self.span = application_span\n",
        "\n",
        "            logger.info(\"✅ Flight search agent setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Error setting up flight search agent: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _extract_response_content(self, result: Any) -> str:\n",
        "        \"\"\"Extract complete response content including tool results from agent result.\"\"\"\n",
        "        try:\n",
        "            response_parts = []\n",
        "\n",
        "            # Critical Fix: Extract tool outputs from search_results first\n",
        "            if isinstance(result, dict) and \"search_results\" in result:\n",
        "                search_results = result[\"search_results\"]\n",
        "                if search_results:\n",
        "                    # search_results contains the actual tool outputs we want\n",
        "                    response_parts.append(str(search_results))\n",
        "\n",
        "            # Also check for intermediate_steps (AgentExecutor format)\n",
        "            if isinstance(result, dict) and \"intermediate_steps\" in result:\n",
        "                for step in result[\"intermediate_steps\"]:\n",
        "                    if isinstance(step, tuple) and len(step) >= 2:\n",
        "                        # step[1] is the tool output/observation\n",
        "                        tool_output = str(step[1])\n",
        "                        if tool_output and tool_output.strip():\n",
        "                            response_parts.append(tool_output)\n",
        "\n",
        "            # Check for messages from LangGraph state (but filter out generic ones)\n",
        "            if hasattr(result, \"messages\") and result.messages:\n",
        "                for message in result.messages:\n",
        "                    if hasattr(message, \"content\") and message.content:\n",
        "                        content = str(message.content)\n",
        "                        # Skip generic system messages and human messages\n",
        "                        if (hasattr(message, \"type\") and message.type != \"human\" and\n",
        "                            not any(phrase in content.lower() for phrase in\n",
        "                                   [\"iteration limit\", \"time limit\", \"agent stopped\"])):\n",
        "                            response_parts.append(content)\n",
        "            elif isinstance(result, dict) and \"messages\" in result:\n",
        "                for message in result[\"messages\"]:\n",
        "                    if hasattr(message, \"content\") and message.content:\n",
        "                        content = str(message.content)\n",
        "                        # Skip generic system messages and human messages\n",
        "                        if (hasattr(message, \"__class__\") and \"Human\" not in message.__class__.__name__ and\n",
        "                            not any(phrase in content.lower() for phrase in\n",
        "                                   [\"iteration limit\", \"time limit\", \"agent stopped\"])):\n",
        "                            response_parts.append(content)\n",
        "\n",
        "            # If we have response parts, join them\n",
        "            if response_parts:\n",
        "                return \"\\n\\n\".join(response_parts)\n",
        "\n",
        "            # Fallback to full result conversion\n",
        "            result_str = str(result)\n",
        "\n",
        "            # If result is a dict, try to extract useful parts\n",
        "            if isinstance(result, dict):\n",
        "                useful_parts = []\n",
        "                for key in ['output', 'response', 'result', 'answer']:\n",
        "                    if key in result and result[key]:\n",
        "                        useful_parts.append(f\"{key.title()}: {result[key]}\")\n",
        "\n",
        "                if useful_parts:\n",
        "                    return \"\\n\".join(useful_parts)\n",
        "\n",
        "            return result_str\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error extracting response: {e}\"\n",
        "\n",
        "    def run_single_evaluation(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"Run evaluation for a single query - no manual validation.\"\"\"\n",
        "        if not self.agent:\n",
        "            raise RuntimeError(\"Agent not initialized. Call setup_agent() first.\")\n",
        "\n",
        "        logger.info(f\"🔍 Evaluating query: {query}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Build starting state and run query\n",
        "            state = FlightSearchGraph.build_starting_state(query=query)\n",
        "            result = self.agent.invoke(state)\n",
        "\n",
        "            # Extract response content\n",
        "            response = self._extract_response_content(result)\n",
        "\n",
        "            # Create evaluation result - no manual scoring\n",
        "            evaluation_result = {\n",
        "                \"query\": query,\n",
        "                \"response\": response,\n",
        "                \"execution_time\": time.time() - start_time,\n",
        "                \"success\": True,\n",
        "            }\n",
        "\n",
        "            logger.info(f\"✅ Query completed in {evaluation_result['execution_time']:.2f}s\")\n",
        "            return evaluation_result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Query failed: {e}\")\n",
        "            return {\n",
        "                \"query\": query,\n",
        "                \"response\": f\"Error: {str(e)}\",\n",
        "                \"execution_time\": time.time() - start_time,\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "            }\n",
        "\n",
        "    def run_phoenix_evaluations(self, results_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Run Phoenix evaluations on the results.\"\"\"\n",
        "        if not ARIZE_AVAILABLE or not self.evaluators:\n",
        "            logger.warning(\"⚠️ Phoenix evaluators not available - skipping evaluations\")\n",
        "            return results_df\n",
        "\n",
        "        logger.info(f\"🧠 Running Phoenix evaluations on {len(results_df)} responses...\")\n",
        "        logger.info(\"📋 Evaluation criteria:\")\n",
        "        logger.info(\"   🔍 Relevance: Does the response address the flight search query?\")\n",
        "        logger.info(\"   🎯 QA Correctness: Is the flight information accurate and helpful?\")\n",
        "        logger.info(\"   🚨 Hallucination: Does the response contain fabricated information?\")\n",
        "        logger.info(\"   ☠️ Toxicity: Is the response harmful or inappropriate?\")\n",
        "\n",
        "        try:\n",
        "            # Prepare evaluation data\n",
        "            evaluation_data = []\n",
        "            for _, row in results_df.iterrows():\n",
        "                query = row[\"query\"]\n",
        "                response = row[\"response\"]\n",
        "\n",
        "                # Create reference text based on query type\n",
        "                reference = QUERY_REFERENCE_ANSWERS.get(str(query), \"Reference answer not found\")\n",
        "\n",
        "                evaluation_data.append(\n",
        "                    {\n",
        "                        \"input\": query,\n",
        "                        \"output\": response,\n",
        "                        \"reference\": reference,\n",
        "                        \"query\": query,  # For hallucination evaluation\n",
        "                        \"response\": response,  # For hallucination evaluation\n",
        "                        \"text\": response,  # For toxicity evaluation\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            eval_df = pd.DataFrame(evaluation_data)\n",
        "\n",
        "            # Run individual Phoenix evaluations\n",
        "            self._run_individual_phoenix_evaluations(eval_df, results_df)\n",
        "\n",
        "            logger.info(\"✅ Phoenix evaluations completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(f\"❌ Error running Phoenix evaluations: {e}\")\n",
        "            # Add error indicators\n",
        "            for eval_type in [\"relevance\", \"qa_correctness\", \"hallucination\", \"toxicity\"]:\n",
        "                results_df[eval_type] = \"error\"\n",
        "                results_df[f\"{eval_type}_explanation\"] = f\"Error: {e}\"\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _run_individual_phoenix_evaluations(\n",
        "        self, eval_df: pd.DataFrame, results_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"Run individual Phoenix evaluations.\"\"\"\n",
        "        for eval_name, evaluator in self.evaluators.items():\n",
        "            try:\n",
        "                logger.info(f\"   📊 Running {eval_name} evaluation...\")\n",
        "\n",
        "                # Prepare data based on evaluator requirements\n",
        "                if eval_name == \"relevance\":\n",
        "                    data = eval_df[[\"input\", \"reference\"]].copy()\n",
        "                    eval_results = llm_classify(\n",
        "                        data=data,\n",
        "                        model=self.evaluator_llm,\n",
        "                        template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
        "                        rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
        "                        provide_explanation=True,\n",
        "                    )\n",
        "                elif eval_name == \"qa_correctness\":\n",
        "                    data = eval_df[[\"input\", \"output\", \"reference\"]].copy()\n",
        "                    eval_results = llm_classify(\n",
        "                        data=data,\n",
        "                        model=self.evaluator_llm,\n",
        "                        template=LENIENT_QA_PROMPT_TEMPLATE,\n",
        "                        rails=LENIENT_QA_RAILS,\n",
        "                        provide_explanation=True,\n",
        "                    )\n",
        "                elif eval_name == \"hallucination\":\n",
        "                    data = eval_df[[\"input\", \"reference\", \"output\"]].copy()\n",
        "                    eval_results = llm_classify(\n",
        "                        data=data,\n",
        "                        model=self.evaluator_llm,\n",
        "                        template=LENIENT_HALLUCINATION_PROMPT_TEMPLATE,\n",
        "                        rails=LENIENT_HALLUCINATION_RAILS,\n",
        "                        provide_explanation=True,\n",
        "                    )\n",
        "                elif eval_name == \"toxicity\":\n",
        "                    data = eval_df[[\"input\"]].copy()\n",
        "                    eval_results = llm_classify(\n",
        "                        data=data,\n",
        "                        model=self.evaluator_llm,\n",
        "                        template=TOXICITY_PROMPT_TEMPLATE,\n",
        "                        rails=list(TOXICITY_PROMPT_RAILS_MAP.values()),\n",
        "                        provide_explanation=True,\n",
        "                    )\n",
        "                else:\n",
        "                    logger.warning(f\"⚠️ Unknown evaluator: {eval_name}\")\n",
        "                    continue\n",
        "\n",
        "                # Process results\n",
        "                self._process_evaluation_results(eval_results, eval_name, results_df)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ {eval_name} evaluation failed: {e}\")\n",
        "                results_df[eval_name] = \"error\"\n",
        "                results_df[f\"{eval_name}_explanation\"] = f\"Error: {e}\"\n",
        "\n",
        "    def _process_evaluation_results(\n",
        "        self, eval_results: Any, eval_name: str, results_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"Process evaluation results and add to results DataFrame.\"\"\"\n",
        "        try:\n",
        "            if eval_results is None:\n",
        "                logger.warning(f\"⚠️ {eval_name} evaluation returned None\")\n",
        "                results_df[eval_name] = \"unknown\"\n",
        "                results_df[f\"{eval_name}_explanation\"] = \"Evaluation returned None\"\n",
        "                return\n",
        "\n",
        "            # Handle DataFrame results\n",
        "            if hasattr(eval_results, \"columns\"):\n",
        "                if \"label\" in eval_results.columns:\n",
        "                    results_df[eval_name] = eval_results[\"label\"].tolist()\n",
        "                elif \"classification\" in eval_results.columns:\n",
        "                    results_df[eval_name] = eval_results[\"classification\"].tolist()\n",
        "                else:\n",
        "                    results_df[eval_name] = \"unknown\"\n",
        "\n",
        "                if \"explanation\" in eval_results.columns:\n",
        "                    results_df[f\"{eval_name}_explanation\"] = eval_results[\"explanation\"].tolist()\n",
        "                elif \"reason\" in eval_results.columns:\n",
        "                    results_df[f\"{eval_name}_explanation\"] = eval_results[\"reason\"].tolist()\n",
        "                else:\n",
        "                    results_df[f\"{eval_name}_explanation\"] = \"No explanation provided\"\n",
        "\n",
        "                logger.info(f\"   ✅ {eval_name} evaluation completed\")\n",
        "\n",
        "            # Handle list results\n",
        "            elif isinstance(eval_results, list) and len(eval_results) > 0:\n",
        "                if isinstance(eval_results[0], dict):\n",
        "                    results_df[eval_name] = [item.get(\"label\", \"unknown\") for item in eval_results]\n",
        "                    results_df[f\"{eval_name}_explanation\"] = [\n",
        "                        item.get(\"explanation\", \"No explanation\") for item in eval_results\n",
        "                    ]\n",
        "                else:\n",
        "                    results_df[eval_name] = eval_results\n",
        "                    results_df[f\"{eval_name}_explanation\"] = \"List evaluation result\"\n",
        "\n",
        "                logger.info(f\"   ✅ {eval_name} evaluation completed (list format)\")\n",
        "\n",
        "            else:\n",
        "                logger.warning(f\"⚠️ {eval_name} evaluation returned unexpected format\")\n",
        "                results_df[eval_name] = \"unknown\"\n",
        "                results_df[f\"{eval_name}_explanation\"] = f\"Unexpected format: {type(eval_results)}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Error processing {eval_name} results: {e}\")\n",
        "            results_df[eval_name] = \"error\"\n",
        "            results_df[f\"{eval_name}_explanation\"] = f\"Processing error: {e}\"\n",
        "\n",
        "    def run_evaluation(self, queries: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Run complete evaluation pipeline using only Phoenix evaluators.\"\"\"\n",
        "        # Clear existing bookings for a clean test run\n",
        "        clear_bookings_and_reviews()\n",
        "\n",
        "        if not self.setup_agent():\n",
        "            raise RuntimeError(\"Failed to setup agent\")\n",
        "\n",
        "        logger.info(f\"🚀 Starting evaluation with {len(queries)} queries\")\n",
        "\n",
        "        # Log available features\n",
        "        logger.info(\"📋 Evaluation Configuration:\")\n",
        "        logger.info(f\"   🤖 Agent: Flight Search Agent (LangGraph)\")\n",
        "        logger.info(f\"   🔧 Phoenix Available: {'✅' if ARIZE_AVAILABLE else '❌'}\")\n",
        "        logger.info(f\"   📊 Arize Datasets: {'✅' if ARIZE_AVAILABLE and (self.dataset_manager.client is not None) else '❌'}\")\n",
        "        if self.evaluators:\n",
        "            logger.info(f\"   🧠 Phoenix Evaluators: {list(self.evaluators.keys())}\")\n",
        "        else:\n",
        "            logger.info(\"   🧠 Phoenix Evaluators: ❌ (basic metrics only)\")\n",
        "\n",
        "        # Run queries (no manual validation)\n",
        "        results = []\n",
        "        for i, query in enumerate(queries, 1):\n",
        "            logger.info(f\"\\n📋 Query {i}/{len(queries)}\")\n",
        "            result = self.run_single_evaluation(query)\n",
        "            results.append(result)\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Run Phoenix evaluations only\n",
        "        results_df = self.run_phoenix_evaluations(results_df)\n",
        "\n",
        "        # Log summary\n",
        "        self._log_evaluation_summary(results_df)\n",
        "\n",
        "        # Create Arize dataset\n",
        "        dataset_id = self.dataset_manager.create_dataset(results_df)\n",
        "        if dataset_id:\n",
        "            logger.info(f\"📊 Arize dataset created: {dataset_id}\")\n",
        "        else:\n",
        "            logger.warning(\"⚠️ Dataset creation failed\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _log_evaluation_summary(self, results_df: pd.DataFrame) -> None:\n",
        "        \"\"\"Log evaluation summary using Phoenix results only.\"\"\"\n",
        "        logger.info(\"\\n📊 Phoenix Evaluation Summary:\")\n",
        "        logger.info(f\"  Total queries: {len(results_df)}\")\n",
        "        logger.info(f\"  Successful executions: {results_df['success'].sum()}\")\n",
        "        logger.info(f\"  Failed executions: {(~results_df['success']).sum()}\")\n",
        "        logger.info(f\"  Average execution time: {results_df['execution_time'].mean():.2f}s\")\n",
        "\n",
        "        # Phoenix evaluation results\n",
        "        if ARIZE_AVAILABLE and self.evaluators:\n",
        "            logger.info(\"\\n🧠 Phoenix Evaluation Results:\")\n",
        "            for eval_type in [\"relevance\", \"qa_correctness\", \"hallucination\", \"toxicity\"]:\n",
        "                if eval_type in results_df.columns:\n",
        "                    counts = results_df[eval_type].value_counts()\n",
        "                    logger.info(f\"   {eval_type}: {dict(counts)}\")\n",
        "\n",
        "        # Quick scores summary\n",
        "        if len(results_df) > 0:\n",
        "            logger.info(\"\\n📊 Quick Scores Summary:\")\n",
        "            for i in range(len(results_df)):\n",
        "                row = results_df.iloc[i]\n",
        "                scores = []\n",
        "                for eval_type in [\"relevance\", \"qa_correctness\", \"hallucination\", \"toxicity\"]:\n",
        "                    if eval_type in row:\n",
        "                        result = row[eval_type]\n",
        "                        emoji = \"✅\" if result in [\"relevant\", \"correct\", \"factual\", \"non-toxic\"] else \"❌\"\n",
        "                        scores.append(f\"{emoji} {eval_type}: {result}\")\n",
        "\n",
        "            logger.info(f\"   Query {i+1}: {' | '.join(scores)}\")\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"Clean up all resources.\"\"\"\n",
        "        self.phoenix_manager.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZInHfhu5mTC9",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Evaluator Methods - Part 2\n",
        "\n",
        "Additional methods for the ArizeFlightSearchEvaluator class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKb3jE_OmTC-",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Utility Functions\n",
        "\n",
        "Utility functions for running evaluations and demos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "06H-zcs6mTC-"
      },
      "outputs": [],
      "source": [
        "def get_default_queries() -> List[str]:\n",
        "    \"\"\"Get default test queries for evaluation.\"\"\"\n",
        "    return [\n",
        "        \"Find flights from JFK to LAX\",\n",
        "        \"What do passengers say about SpiceJet's service quality?\",\n",
        "        \"Book a flight from NYC to San Francisco\",\n",
        "        \"Retrieve my flight bookings\",\n",
        "        \"Search for reviews about Air India delays\"\n",
        "    ]\n",
        "\n",
        "def run_phoenix_demo() -> pd.DataFrame:\n",
        "    \"\"\"Run a simple Phoenix evaluation demo.\"\"\"\n",
        "    logger.info(\"🔧 Running Phoenix evaluation demo...\")\n",
        "\n",
        "    demo_queries = [\n",
        "        \"Find flights from JFK to LAX\",\n",
        "        \"What do passengers say about SpiceJet's service quality?\",\n",
        "    ]\n",
        "\n",
        "    evaluator = ArizeFlightSearchEvaluator()\n",
        "    try:\n",
        "        results = evaluator.run_evaluation(demo_queries)\n",
        "        logger.info(\"🎉 Phoenix evaluation demo complete!\")\n",
        "        logger.info(\"💡 Visit Phoenix UI to see detailed traces and evaluations\")\n",
        "        return results\n",
        "    finally:\n",
        "        evaluator.cleanup()\n",
        "\n",
        "def run_full_evaluation() -> pd.DataFrame:\n",
        "    \"\"\"Main evaluation function using only Phoenix evaluators.\"\"\"\n",
        "    evaluator = ArizeFlightSearchEvaluator()\n",
        "    try:\n",
        "        results = evaluator.run_evaluation(get_default_queries())\n",
        "        logger.info(\"\\n✅ Phoenix evaluation complete!\")\n",
        "        return results\n",
        "    finally:\n",
        "        evaluator.cleanup()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCLJZKGAmTC-",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Run Evaluation\n",
        "\n",
        "Execute the flight search agent evaluation with Phoenix AI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "O4YhW5LxmTC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cf6e87e0c5ab4dd2ab662a29e6f4facc",
            "43d13910babe4d2e8fa00c269c697af6",
            "1774e89450bb46528d3526dbd42737f1",
            "3bf28e74c1c14d519e911666cf135a7b",
            "1561ac1b45044e9b95b9bdc16b2e437c",
            "1821f3f96cb14b55b15b570c129f78c3",
            "d3910433b32d4b4ea8566bbd1be44e1e",
            "f333f54c8f6b4c3986052d1d58f7392f",
            "f87078cf071045ac9dc293231caf25d8",
            "2e410e61b84247cda23c1ee7f09386df",
            "cf9bc8bd43a74353ad677eff0a094a66",
            "3cff72f6e80b4ae3be2ef682def1883d",
            "6ca0df0d89c24814b80393e84aefb157",
            "24e69659f9284683af818d557f2791de",
            "88852423c22345e79ef6bef47c5665bc",
            "aefa7e60a79b460d84ae31e9210ee37e",
            "c66a47d52cb94ac684c11cf67002aff7",
            "b4003172edd841b68e04c589301e5a01",
            "db4c36fceab648a3962c649d48847bf4",
            "80d3a79d34e94c8781081b0f588a2a05",
            "e96bf68d6ceb46d386c2c2739b9c0f21",
            "07c7d72601ce48a8904946d738055f9e",
            "cb5a9423c3a945e1a30d426e7ec0f6ac",
            "f1a66aabd6e64efa9b8f400984386a08",
            "68d35b8a904c4d54aa0c9d78c4b9ad10",
            "db5b451e691f4440818f357de4b52bc1",
            "08f5e9e4c7474f1b9e02cca89f02369e",
            "465a226fe19e4b65acb04af3008a4471",
            "52952cf650f643cf8993aa995901cd59",
            "7978965bce78486890348a6d53e44a43",
            "bdd42171a90c4456b6ee7db220a932d2",
            "084acce68cfd4358881a2d0e98542eca",
            "d2cbf3412dda455b9684ffbce6b59c22",
            "83eaf853651b49daa5502fa7438737db",
            "a7e180118e3047e69e27010787bfdd98",
            "417f86574cd144d0b25b2b6b1cec43ab",
            "1d3727d9d06643cdbe8db2f764e8b1bf",
            "bd650720019b4e55a878ae0ef9834f2d",
            "ee38db6527794ea09a46407bff080a4a",
            "0e36814d206947348db3a7e82647d8f0",
            "6eee541fb4df425e8379382eec360b2d",
            "48d499c707e94018a235fc69081a36a9",
            "638e8aea684a4c5c8c3f478caf97c722",
            "0756a4a0a3cc4be8b01ebdaf4d16b67a"
          ]
        },
        "outputId": "390ba871-f555-4c79-8589-f4dec6a56d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Arize datasets client initialized successfully\n",
            "INFO:__main__:✅ Phoenix evaluators initialized successfully\n",
            "INFO:__main__:   🤖 Using evaluator model: gpt-4o\n",
            "INFO:__main__:   📊 Available evaluators: ['relevance', 'qa_correctness', 'hallucination', 'toxicity']\n",
            "INFO:__main__:🔧 Setting up Phoenix observability...\n",
            "INFO:phoenix.config:📋 Ensuring phoenix working directory: /root/.phoenix\n",
            "WARNING:phoenix.session.session:Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n",
            "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
            "INFO:alembic.runtime.migration:Will assume transactional DDL.\n",
            "INFO:phoenix.server.app:Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n",
            "INFO:__main__:🌐 Phoenix UI: https://l8k4qs4v04m2-496ff2e9c6d22116-6007-colab.googleusercontent.com/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit https://l8k4qs4v04m2-496ff2e9c6d22116-6007-colab.googleusercontent.com/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "🔭 OpenTelemetry Tracing Details 🔭\n",
            "|  Phoenix Project: flight-search-agent-evaluation\n",
            "|  Span Processor: SimpleSpanProcessor\n",
            "|  Collector Endpoint: http://localhost:6007/v1/traces\n",
            "|  Transport: HTTP + protobuf\n",
            "|  Transport Headers: {}\n",
            "|  \n",
            "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
            "|  \n",
            "|  ⚠️ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
            "|  \n",
            "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
            "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Phoenix setup completed successfully\n",
            "INFO:__main__:✅ LangChain instrumentation enabled\n",
            "INFO:__main__:✅ OpenAI instrumentation enabled\n",
            "INFO:__main__:✅ Successfully connected to Couchbase\n",
            "INFO:__main__:🗑️ Clearing data from travel-sample.agentc_bookings.user_bookings_20251023...\n",
            "INFO:__main__:🗑️ Clearing data from travel-sample.agentc_bookings.user_bookings_20251022...\n",
            "INFO:__main__:✅ Completed clearing scope: travel-sample.agentc_bookings\n",
            "INFO:__main__:✅ Cleared existing flight bookings for fresh test run: travel-sample.agentc_bookings\n",
            "INFO:__main__:📊 Airline reviews collection: 2210 existing, 2210 expected\n",
            "INFO:__main__:✅ Collection already has correct document count (2210), skipping clear\n",
            "INFO:__main__:🔧 Setting up flight search agent...\n",
            "INFO:__main__:✅ Environment variables configured\n",
            "INFO:__main__:✅ Successfully connected to Couchbase\n",
            "INFO:__main__:✅ Collection setup complete: agentc_data.airline_reviews\n",
            "INFO:__main__:Loaded vector search index definition from agentcatalog_index.json\n",
            "INFO:__main__:ℹ️ Vector search index 'airline_reviews_index' already exists\n",
            "INFO:__main__:🔧 Setting up Priority 1 AI services for langgraph framework...\n",
            "INFO:__main__:🔧 Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "INFO:__main__:🔧 Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "INFO:__main__:🔧 LLM Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 LLM Model: meta/llama3-8b-instruct\n",
            "INFO:__main__:🔧 LLM Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "INFO:__main__:✅ Priority 1 AI services setup completed for langgraph\n",
            "INFO:__main__:🔄 Loading data into vector store...\n",
            "INFO:__main__:Found 2210 existing documents in collection, skipping data load\n",
            "INFO:__main__:✅ Vector store setup complete: travel-sample.agentc_data.airline_reviews\n",
            "INFO:__main__:🔧 Setting up Priority 1 AI services for langgraph framework...\n",
            "INFO:__main__:🔧 Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
            "INFO:__main__:🔧 Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI embeddings (OpenAI wrapper)\n",
            "INFO:__main__:🔧 LLM Endpoint: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com\n",
            "INFO:__main__:🔧 LLM Model: meta/llama3-8b-instruct\n",
            "INFO:__main__:🔧 LLM Base URL: https://agd6zdjymyanhi9g.ai.sandbox.nonprod-project-avengers.com/v1\n",
            "INFO:__main__:✅ Using Priority 1: Capella AI LLM (OpenAI wrapper)\n",
            "INFO:__main__:✅ Priority 1 AI services setup completed for langgraph\n",
            "INFO:__main__:Agent Catalog integration successful\n",
            "INFO:__main__:✅ Flight search agent setup completed successfully\n",
            "INFO:__main__:🚀 Starting evaluation with 5 queries\n",
            "INFO:__main__:📋 Evaluation Configuration:\n",
            "INFO:__main__:   🤖 Agent: Flight Search Agent (LangGraph)\n",
            "INFO:__main__:   🔧 Phoenix Available: ✅\n",
            "INFO:__main__:   📊 Arize Datasets: ✅\n",
            "INFO:__main__:   🧠 Phoenix Evaluators: ['relevance', 'qa_correctness', 'hallucination', 'toxicity']\n",
            "INFO:__main__:\n",
            "📋 Query 1/5\n",
            "INFO:__main__:🔍 Evaluating query: Find flights from JFK to LAX\n",
            "INFO:__main__:Flight Query: Find flights from JFK to LAX\n",
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed lookup_flight_info: JFK → LAX\n",
            "INFO:lookup_flight_info:🔍 Looking up flights: JFK → LAX\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use lookup_flight_info to help with this request Action: lookup_flight_info Action Input: {\"source_airport\": \"JFK\", \"destination_airport\": \"LAX\"}\u001b[0m\u001b[36;1m\u001b[1;3mAvailable flights from JFK to LAX:\n",
            "\n",
            "1. AS flight from JFK to LAX using 321 762\n",
            "2. B6 flight from JFK to LAX using 320\n",
            "3. DL flight from JFK to LAX using 76W 752\n",
            "4. QF flight from JFK to LAX using 744\n",
            "5. AA flight from JFK to LAX using 32B 762\n",
            "6. UA flight from JFK to LAX using 757\n",
            "7. US flight from JFK to LAX using 32B 762\n",
            "8. VX flight from JFK to LAX using 320\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query completed in 7.82s\n",
            "INFO:__main__:\n",
            "📋 Query 2/5\n",
            "INFO:__main__:🔍 Evaluating query: What do passengers say about SpiceJet's service quality?\n",
            "INFO:__main__:Flight Query: What do passengers say about SpiceJet's service quality?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: I found 8 available flights from JFK to LAX, including airlines AS, B6, DL, QF, AA, UA, US, and VX with various aircraft types.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use search_airline_reviews to help with this request Action: search_airline_reviews Action Input: SpiceJet service quality\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:search_airline_reviews:Searching for airline reviews with query: 'SpiceJet service quality'\n",
            "INFO:search_airline_reviews:Found 5 results for query: 'SpiceJet service quality'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mFound 5 relevant airline reviews for 'SpiceJet service quality':\n",
            "\n",
            "Review 1:\n",
            "Airline: SpiceJet. Title: \"Great travel experience\". Review: ✅ Trip Verified |  Marvelous courteous crew who took good care of all passengers. They should be rewarded for the patience shown towards the unruly ones. Great travel experience.. Rating: 10.0/10. Reviewer: Ranjita Pandey. Date: 18th April 2024. Recommended: yes\n",
            "\n",
            "Review 2:\n",
            "Airline: SpiceJet. Title: \"good service by the crew\". Review: ✅ Trip Verified | I have had good service by the crew. It was amazing, the crew was very enthusiastic and warm welcome. It was one of the best services in my experience.. Rating: 10.0/10. Reviewer: K Mansour. Date: 10th August 2024. Recommended: yes\n",
            "\n",
            "Review 3:\n",
            "Airline: SpiceJet. Title: \"Excellent service\". Review: ✅ Trip Verified |  Excellent service by the ground staff courteous beyond expectations always willing to help in the real sense and not lipservice i will recommend to all whom I know. Rating: 10.0/10. Reviewer: Ramanathan Ramchandra. Date: 1st November 2023. Recommended: yes\n",
            "\n",
            "Review 4:\n",
            "Airline: SpiceJet. Title: \"excellent hospitality\". Review: ✅ Trip Verified |  It's very grateful to SpiceJet for the service in flight. Everything is fine with excellent hospitality. Very politely behavior and warmly welcome from your cabin crew and all members.. Rating: 10.0/10. Reviewer: A Kajan. Date: 10th August 2024. Recommended: yes\n",
            "\n",
            "Review 5:\n",
            "Airline: SpiceJet. Title: \"delayed both ways by many hours\". Review: Not Verified |  Flight was delayed both ways by many hours. Poor service for the same price as other airlines like IndiGo. No wifi or other amenities to compensate for terrible service.. Rating: 2.0/10. Reviewer: Somil Jain Jain. Date: 20th May 2022. Recommended: no\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query completed in 12.99s\n",
            "INFO:__main__:\n",
            "📋 Query 3/5\n",
            "INFO:__main__:🔍 Evaluating query: Book a flight from NYC to San Francisco\n",
            "INFO:__main__:Flight Query: Book a flight from NYC to San Francisco\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer Final Answer: Based on 5 customer reviews, SpiceJet receives mostly positive feedback (averaging 8.4/10) for their courteous crew, warm hospitality, and excellent ground staff service. However, some passengers report flight delays and poor service. The majority of reviews are highly positive (four 10/10 ratings), with one negative review citing delays and lack of amenities.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Parsed save_flight_booking: JFK→SFO, 1 pax, economy\n",
            "INFO:save_flight_booking:🗓️ Date validated: 2025-10-24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to use save_flight_booking to help with this request. Tomorrow is 2025-10-23 + 1 day = 2025-10-24 Action: save_flight_booking Action Input: {\"source_airport\": \"JFK\", \"destination_airport\": \"SFO\", \"departure_date\": \"2025-10-24\", \"passengers\": 1, \"flight_class\": \"economy\"}\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:save_flight_booking:🎯 Booking: JFK→SFO on 2025-10-24, 1 pax, economy class\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3mFlight Booking Confirmed!\n",
            "\n",
            "Booking ID: FL10247C5894E2\n",
            "Route: JFK → SFO\n",
            "Departure Date: 2025-10-24\n",
            "Passengers: 1\n",
            "Class: economy\n",
            "Total Price: $250.00\n",
            "\n",
            "Next Steps:\n",
            "1. Check-in opens 24 hours before departure\n",
            "2. Arrive at airport 2 hours early for domestic flights\n",
            "3. Bring valid government-issued photo ID\n",
            "\n",
            "Thank you for choosing our airline!\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query completed in 11.16s\n",
            "INFO:__main__:\n",
            "📋 Query 4/5\n",
            "INFO:__main__:🔍 Evaluating query: Retrieve my flight bookings\n",
            "INFO:__main__:Flight Query: Retrieve my flight bookings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Your flight from NYC to San Francisco for 1 passenger in economy class has been booked successfully for tomorrow (2025-10-24). Your booking ID is FL10247C5894E2 and the total cost is $250.00.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use retrieve_flight_bookings to help with this request Action: retrieve_flight_bookings Action Input:\u001b[0m\u001b[38;5;200m\u001b[1;3mYour Current Bookings (1 found):\n",
            "\n",
            "Booking 1:\n",
            "  Booking ID: FL10247C5894E2\n",
            "  Route: JFK → SFO\n",
            "  Date: 2025-10-24\n",
            "  Passengers: 1\n",
            "  Class: economy\n",
            "  Total: $250.00\n",
            "  Status: confirmed\n",
            "  Booked: 2025-10-23\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query completed in 7.65s\n",
            "INFO:__main__:\n",
            "📋 Query 5/5\n",
            "INFO:__main__:🔍 Evaluating query: Search for reviews about Air India delays\n",
            "INFO:__main__:Flight Query: Search for reviews about Air India delays\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: You have 1 current flight booking: JFK to SFO on 2025-10-24 for 1 passenger in economy class ($250.00).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Found tool: lookup_flight_info\n",
            "INFO:__main__:✅ Found tool: save_flight_booking\n",
            "INFO:__main__:✅ Found tool: retrieve_flight_bookings\n",
            "INFO:__main__:✅ Found tool: search_airline_reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use search_airline_reviews to help with this request Action: search_airline_reviews Action Input: Air India delays\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:search_airline_reviews:Searching for airline reviews with query: 'Air India delays'\n",
            "INFO:search_airline_reviews:Found 5 results for query: 'Air India delays'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mFound 5 relevant airline reviews for 'Air India delays':\n",
            "\n",
            "Review 1:\n",
            "Airline: Vistara. Title: \"Extremely poor experience2. Review: ✅ Trip Verified |  Extremely poor experience, no information on flight delay. Poor ground process management and flight experience not up to the mark.. Rating: 2.0/10. Reviewer: A Kadyta. Date: 17th February 2024. Recommended: no\n",
            "\n",
            "Review 2:\n",
            "Airline: AirIndia. Title: \"bad experience with any airline\". Review: Not Verified |  Flight got delayed for 2 times. All the passengers who booked for this flight were very upset including me. There was no proper announcement when the gate was changed. I’ve never seen this kind of bad experience with any airline.. Rating: 1.0/10. Reviewer: Harry Downey. Date: 24th October 2021. Recommended: no\n",
            "\n",
            "Review 3:\n",
            "Airline: Air India Express. Title: \"no information provided\". Review: Not Verified |  The flight delayed for 2 hrs and no information provided by airline. This will be my last trip with Air India Express, the worst airline. Rating: 1.0/10. Reviewer: Shameem Elachola. Date: 12th September 2024. Recommended: no\n",
            "\n",
            "Review 4:\n",
            "Airline: AirIndia. Title: \"Completely disgusted with my experience2. Review: ✅ Trip Verified |  Average airline with terrible customer service and unacceptable corporate behavior. Completely disgusted with my experience. After a year of chasing Air India for a refund due to a flight that they cancelled, I have yet to receive a single cent. I did not even find out about the cancellation until after I arrived to the airport and was informed at the check in counter. Apparently they tried to call me once and I didn't pick up. No email notification, nor text...nothing. Several emails went by without a response. For months I waited, repeatedly calling customer service, until I received an email saying they would only issue a refund when things returned \"to normalcy.\" Now it has been 12 months. Half of the time you call their number, you will get a message saying it's the wrong number. The other half of the time it won't go through at all. When you finally reach them, you receive service from staff so incompetent it's obvious they were not even given basic training of how to look up information in their system. You feel sorry for them as they fumble around. I won't even blame the call center staff, as it's obvious the responsibility lies on the complete negligence of the Air India management to run an efficient operation. Why are airlines allowed to get away with this behavior? Any other business would have been shut down a long time ago. This is not a review of the flight experience itself, which is generally average, but if you can fly with a better airline, absolutely do it.. Rating: 2.0/10. Reviewer: S Harten. Date: 14th March 2021. Recommended: no\n",
            "\n",
            "Review 5:\n",
            "Airline: AirIndia. Title: \"no proper information to the travellers\". Review: ✅ Trip Verified |  It is one of the worst airlines in the industry. 5 hrs flight from Singapore to Delhi is already delayed by more than 2 hours & no proper information to the travellers.. Rating: 2.0/10. Reviewer: Devinder Pal Singh. Date: 19th July 2024. Recommended: no\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:✅ Query completed in 10.54s\n",
            "INFO:__main__:🧠 Running Phoenix evaluations on 5 responses...\n",
            "INFO:__main__:📋 Evaluation criteria:\n",
            "INFO:__main__:   🔍 Relevance: Does the response address the flight search query?\n",
            "INFO:__main__:   🎯 QA Correctness: Is the flight information accurate and helpful?\n",
            "INFO:__main__:   🚨 Hallucination: Does the response contain fabricated information?\n",
            "INFO:__main__:   ☠️ Toxicity: Is the response harmful or inappropriate?\n",
            "INFO:__main__:   📊 Running relevance evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Based on 5 customer reviews, Air India receives mostly negative feedback (averaging 1.6/10) for their poor communication, flight delays, and unacceptable corporate behavior. Many passengers report feeling frustrated and disappointed with their experience, citing lack of information, poor customer service, and incompetence.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf6e87e0c5ab4dd2ab662a29e6f4facc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:   ✅ relevance evaluation completed\n",
            "INFO:__main__:   📊 Running qa_correctness evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cff72f6e80b4ae3be2ef682def1883d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:   ✅ qa_correctness evaluation completed\n",
            "INFO:__main__:   📊 Running hallucination evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb5a9423c3a945e1a30d426e7ec0f6ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:   ✅ hallucination evaluation completed\n",
            "INFO:__main__:   📊 Running toxicity evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llm_classify |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83eaf853651b49daa5502fa7438737db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:   ✅ toxicity evaluation completed\n",
            "INFO:__main__:✅ Phoenix evaluations completed\n",
            "INFO:__main__:\n",
            "📊 Phoenix Evaluation Summary:\n",
            "INFO:__main__:  Total queries: 5\n",
            "INFO:__main__:  Successful executions: 5\n",
            "INFO:__main__:  Failed executions: 0\n",
            "INFO:__main__:  Average execution time: 10.03s\n",
            "INFO:__main__:\n",
            "🧠 Phoenix Evaluation Results:\n",
            "INFO:__main__:   relevance: {'unrelated': np.int64(3), 'relevant': np.int64(2)}\n",
            "INFO:__main__:   qa_correctness: {'correct': np.int64(5)}\n",
            "INFO:__main__:   hallucination: {'factual': np.int64(4), 'hallucinated': np.int64(1)}\n",
            "INFO:__main__:   toxicity: {'non-toxic': np.int64(5)}\n",
            "INFO:__main__:\n",
            "📊 Quick Scores Summary:\n",
            "INFO:__main__:   Query 5: ❌ relevance: unrelated | ✅ qa_correctness: correct | ✅ hallucination: factual | ✅ toxicity: non-toxic\n",
            "INFO:__main__:📊 Creating Arize dataset...\n",
            "INFO:__main__:✅ Arize dataset created successfully: RGF0YXNldDozMjM3Nzg6M0ZoRw==\n",
            "INFO:__main__:📊 Arize dataset created: RGF0YXNldDozMjM3Nzg6M0ZoRw==\n",
            "INFO:__main__:\n",
            "✅ Phoenix evaluation complete!\n",
            "INFO:__main__:🔒 Phoenix cleanup completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 EVALUATION RESULTS:\n",
            "==================================================\n",
            "\n",
            "🔍 Query 1: Find flights from JFK to LAX\n",
            "⏱️ Execution time: 7.82s\n",
            "✅ Success: True\n",
            "   ✅ Relevance: relevant\n",
            "   ✅ Qa_Correctness: correct\n",
            "   ✅ Hallucination: factual\n",
            "   ✅ Toxicity: non-toxic\n",
            "\n",
            "🔍 Query 2: What do passengers say about SpiceJet's service quality?\n",
            "⏱️ Execution time: 12.99s\n",
            "✅ Success: True\n",
            "   ✅ Relevance: relevant\n",
            "   ✅ Qa_Correctness: correct\n",
            "   ❌ Hallucination: hallucinated\n",
            "   ✅ Toxicity: non-toxic\n",
            "\n",
            "🔍 Query 3: Book a flight from NYC to San Francisco\n",
            "⏱️ Execution time: 11.16s\n",
            "✅ Success: True\n",
            "   ❌ Relevance: unrelated\n",
            "   ✅ Qa_Correctness: correct\n",
            "   ✅ Hallucination: factual\n",
            "   ✅ Toxicity: non-toxic\n",
            "\n",
            "🔍 Query 4: Retrieve my flight bookings\n",
            "⏱️ Execution time: 7.65s\n",
            "✅ Success: True\n",
            "   ❌ Relevance: unrelated\n",
            "   ✅ Qa_Correctness: correct\n",
            "   ✅ Hallucination: factual\n",
            "   ✅ Toxicity: non-toxic\n",
            "\n",
            "🔍 Query 5: Search for reviews about Air India delays\n",
            "⏱️ Execution time: 10.54s\n",
            "✅ Success: True\n",
            "   ❌ Relevance: unrelated\n",
            "   ✅ Qa_Correctness: correct\n",
            "   ✅ Hallucination: factual\n",
            "   ✅ Toxicity: non-toxic\n",
            "\n",
            "🎉 Evaluation completed! Check Phoenix UI for detailed traces.\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation\n",
        "if __name__ == \"__main__\":\n",
        "    # Choose evaluation mode:\n",
        "\n",
        "    # Option 1: Run demo with 2 queries (quick test)\n",
        "    # results = run_phoenix_demo()\n",
        "\n",
        "    # Option 2: Run full evaluation with all queries\n",
        "    results = run_full_evaluation()\n",
        "\n",
        "    # Display results\n",
        "    if results is not None and len(results) > 0:\n",
        "        print(\"\\n📊 EVALUATION RESULTS:\")\n",
        "        print(\"=\" * 50)\n",
        "        for i, row in results.iterrows():\n",
        "            print(f\"\\n🔍 Query {i+1}: {row['query']}\")\n",
        "            print(f\"⏱️ Execution time: {row['execution_time']:.2f}s\")\n",
        "            print(f\"✅ Success: {row['success']}\")\n",
        "\n",
        "            # Show evaluation scores if available\n",
        "            eval_types = [\"relevance\", \"qa_correctness\", \"hallucination\", \"toxicity\"]\n",
        "            for eval_type in eval_types:\n",
        "                if eval_type in row:\n",
        "                    score = row[eval_type]\n",
        "                    emoji = \"✅\" if score in [\"relevant\", \"correct\", \"factual\", \"non-toxic\"] else \"❌\"\n",
        "                    print(f\"   {emoji} {eval_type.title()}: {score}\")\n",
        "\n",
        "        print(\"\\n🎉 Evaluation completed! Check Phoenix UI for detailed traces.\")\n",
        "    else:\n",
        "        print(\"❌ No evaluation results generated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aLNxJYomTC-",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This self-contained notebook demonstrates a complete flight search agent implementation using LangGraph framework with ReAct agents, Couchbase vector store for airline reviews, and Priority 1 Capella AI services. The agent handles flight search, booking, retrieval, and airline review queries with exact functionality from the working Python files. All components are inline and the notebook runs as a complete workflow when executed cell by cell. Set up environment variables (CB_*, CAPELLA_API_*) and dependencies, then execute all cells sequentially.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea47f2814fa346fd866e050dfb890c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc1bd74295444d9296401517d6d64b2a",
              "IPY_MODEL_d5a3c0210f4243b8ac64f04e2f6b0e37",
              "IPY_MODEL_216dbc504fd740589cbe990002dfda42"
            ],
            "layout": "IPY_MODEL_0d17e37081dd4b068d01fae37e0eb5a8"
          }
        },
        "dc1bd74295444d9296401517d6d64b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62826e09faa34f40b6f80aeaea02eae1",
            "placeholder": "​",
            "style": "IPY_MODEL_7f4e86d45d18492e90c9082d47c750dc",
            "value": "llm_classify "
          }
        },
        "d5a3c0210f4243b8ac64f04e2f6b0e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b2acc6fe1e411aadfd7e0e13bfc0c3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf6faa8c8f534cbb99d66ebb110e74e8",
            "value": 2
          }
        },
        "216dbc504fd740589cbe990002dfda42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812cff3e825e4d50b6827c380da3a56b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2a7f2bb0b34a8383ab254f1eabc13c",
            "value": " 2/2 (100.0%) | ⏳ 00:04&lt;00:00 |  1.63s/it"
          }
        },
        "0d17e37081dd4b068d01fae37e0eb5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62826e09faa34f40b6f80aeaea02eae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4e86d45d18492e90c9082d47c750dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b2acc6fe1e411aadfd7e0e13bfc0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf6faa8c8f534cbb99d66ebb110e74e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "812cff3e825e4d50b6827c380da3a56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2a7f2bb0b34a8383ab254f1eabc13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f393e7ad9c64be2acd6efab16c2fea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20fa0c59efaf44f4b387f58ed0ac0a5a",
              "IPY_MODEL_9229afeaf5024bb495586a02b13fd5dc",
              "IPY_MODEL_89f1a69b47694e5eaa4dde74145ffc04"
            ],
            "layout": "IPY_MODEL_a5a86afc2c6d4847a7aee2ccedaf7c05"
          }
        },
        "20fa0c59efaf44f4b387f58ed0ac0a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_418c67d7f36e4dbda10e4b7e690b5b44",
            "placeholder": "​",
            "style": "IPY_MODEL_f3d0be30a41f422395c5147d014c7ea2",
            "value": "llm_classify "
          }
        },
        "9229afeaf5024bb495586a02b13fd5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3edd1f139304386beb29a76dac021b5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00f3211eb49d4cc6b20f0ff2add367fe",
            "value": 2
          }
        },
        "89f1a69b47694e5eaa4dde74145ffc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_577f0ef3ef2a49f2812e9500e4a5c139",
            "placeholder": "​",
            "style": "IPY_MODEL_f3fe1d3f8e764c6e8601d292c0857e17",
            "value": " 2/2 (100.0%) | ⏳ 01:01&lt;00:00 |  1.10s/it"
          }
        },
        "a5a86afc2c6d4847a7aee2ccedaf7c05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418c67d7f36e4dbda10e4b7e690b5b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d0be30a41f422395c5147d014c7ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3edd1f139304386beb29a76dac021b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f3211eb49d4cc6b20f0ff2add367fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "577f0ef3ef2a49f2812e9500e4a5c139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fe1d3f8e764c6e8601d292c0857e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931c24a958aa4fcfbd9825640cebcc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ade51ac63b148f69ff02faaacfb980c",
              "IPY_MODEL_cc379b4ab20b452f920b4c05f1250cba",
              "IPY_MODEL_8e2bfac2301c41eeac858121a81071ad"
            ],
            "layout": "IPY_MODEL_8ec9c2f0ee1c40e0a5d6c74975dd8aea"
          }
        },
        "1ade51ac63b148f69ff02faaacfb980c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31ca10656624e938a5d2662660782d0",
            "placeholder": "​",
            "style": "IPY_MODEL_6840c60d724b407b9a12535dd153860b",
            "value": "llm_classify "
          }
        },
        "cc379b4ab20b452f920b4c05f1250cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b24e8f306e4d019599d314192718ba",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5edccebc9124c28b6127fa342b219b0",
            "value": 2
          }
        },
        "8e2bfac2301c41eeac858121a81071ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5eceb1fc35f4fdd81320e9bd30e504d",
            "placeholder": "​",
            "style": "IPY_MODEL_52965b2bffa44706ac6d63202f3c14cf",
            "value": " 2/2 (100.0%) | ⏳ 00:05&lt;00:00 |  1.27s/it"
          }
        },
        "8ec9c2f0ee1c40e0a5d6c74975dd8aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31ca10656624e938a5d2662660782d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6840c60d724b407b9a12535dd153860b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45b24e8f306e4d019599d314192718ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5edccebc9124c28b6127fa342b219b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5eceb1fc35f4fdd81320e9bd30e504d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52965b2bffa44706ac6d63202f3c14cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb60e7ce21ff4924983752dd309ecce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_122484e75a8c499a9742ab8369d4ba49",
              "IPY_MODEL_8b51029fa0c8465d8d98247733f872cb",
              "IPY_MODEL_ef635829436c4e9098ccbb73a891da12"
            ],
            "layout": "IPY_MODEL_7b3e06acf65e4f99a04d7f191a962e3b"
          }
        },
        "122484e75a8c499a9742ab8369d4ba49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e419ee3541b74c50852067af704e12fd",
            "placeholder": "​",
            "style": "IPY_MODEL_4c6254e9a1994972b954c2e2f372b98a",
            "value": "llm_classify "
          }
        },
        "8b51029fa0c8465d8d98247733f872cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c85f0295de24534ac14152c8291b5d4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dec58c834aa84b7da2afeb02f8f4d23a",
            "value": 2
          }
        },
        "ef635829436c4e9098ccbb73a891da12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8fad9391c384cf482d68b65cf3daf54",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8d4c3319db4defb78848a0844b2e21",
            "value": " 2/2 (100.0%) | ⏳ 00:53&lt;00:00 |  1.56s/it"
          }
        },
        "7b3e06acf65e4f99a04d7f191a962e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e419ee3541b74c50852067af704e12fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c6254e9a1994972b954c2e2f372b98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c85f0295de24534ac14152c8291b5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec58c834aa84b7da2afeb02f8f4d23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8fad9391c384cf482d68b65cf3daf54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8d4c3319db4defb78848a0844b2e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf6e87e0c5ab4dd2ab662a29e6f4facc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43d13910babe4d2e8fa00c269c697af6",
              "IPY_MODEL_1774e89450bb46528d3526dbd42737f1",
              "IPY_MODEL_3bf28e74c1c14d519e911666cf135a7b"
            ],
            "layout": "IPY_MODEL_1561ac1b45044e9b95b9bdc16b2e437c"
          }
        },
        "43d13910babe4d2e8fa00c269c697af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1821f3f96cb14b55b15b570c129f78c3",
            "placeholder": "​",
            "style": "IPY_MODEL_d3910433b32d4b4ea8566bbd1be44e1e",
            "value": "llm_classify "
          }
        },
        "1774e89450bb46528d3526dbd42737f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f333f54c8f6b4c3986052d1d58f7392f",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f87078cf071045ac9dc293231caf25d8",
            "value": 5
          }
        },
        "3bf28e74c1c14d519e911666cf135a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e410e61b84247cda23c1ee7f09386df",
            "placeholder": "​",
            "style": "IPY_MODEL_cf9bc8bd43a74353ad677eff0a094a66",
            "value": " 5/5 (100.0%) | ⏳ 02:56&lt;00:00 |  2.04it/s"
          }
        },
        "1561ac1b45044e9b95b9bdc16b2e437c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1821f3f96cb14b55b15b570c129f78c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3910433b32d4b4ea8566bbd1be44e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f333f54c8f6b4c3986052d1d58f7392f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87078cf071045ac9dc293231caf25d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e410e61b84247cda23c1ee7f09386df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf9bc8bd43a74353ad677eff0a094a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cff72f6e80b4ae3be2ef682def1883d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ca0df0d89c24814b80393e84aefb157",
              "IPY_MODEL_24e69659f9284683af818d557f2791de",
              "IPY_MODEL_88852423c22345e79ef6bef47c5665bc"
            ],
            "layout": "IPY_MODEL_aefa7e60a79b460d84ae31e9210ee37e"
          }
        },
        "6ca0df0d89c24814b80393e84aefb157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c66a47d52cb94ac684c11cf67002aff7",
            "placeholder": "​",
            "style": "IPY_MODEL_b4003172edd841b68e04c589301e5a01",
            "value": "llm_classify "
          }
        },
        "24e69659f9284683af818d557f2791de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4c36fceab648a3962c649d48847bf4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80d3a79d34e94c8781081b0f588a2a05",
            "value": 5
          }
        },
        "88852423c22345e79ef6bef47c5665bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e96bf68d6ceb46d386c2c2739b9c0f21",
            "placeholder": "​",
            "style": "IPY_MODEL_07c7d72601ce48a8904946d738055f9e",
            "value": " 5/5 (100.0%) | ⏳ 02:51&lt;00:00 |  2.64it/s"
          }
        },
        "aefa7e60a79b460d84ae31e9210ee37e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66a47d52cb94ac684c11cf67002aff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4003172edd841b68e04c589301e5a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db4c36fceab648a3962c649d48847bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d3a79d34e94c8781081b0f588a2a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e96bf68d6ceb46d386c2c2739b9c0f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c7d72601ce48a8904946d738055f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5a9423c3a945e1a30d426e7ec0f6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1a66aabd6e64efa9b8f400984386a08",
              "IPY_MODEL_68d35b8a904c4d54aa0c9d78c4b9ad10",
              "IPY_MODEL_db5b451e691f4440818f357de4b52bc1"
            ],
            "layout": "IPY_MODEL_08f5e9e4c7474f1b9e02cca89f02369e"
          }
        },
        "f1a66aabd6e64efa9b8f400984386a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465a226fe19e4b65acb04af3008a4471",
            "placeholder": "​",
            "style": "IPY_MODEL_52952cf650f643cf8993aa995901cd59",
            "value": "llm_classify "
          }
        },
        "68d35b8a904c4d54aa0c9d78c4b9ad10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7978965bce78486890348a6d53e44a43",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdd42171a90c4456b6ee7db220a932d2",
            "value": 5
          }
        },
        "db5b451e691f4440818f357de4b52bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_084acce68cfd4358881a2d0e98542eca",
            "placeholder": "​",
            "style": "IPY_MODEL_d2cbf3412dda455b9684ffbce6b59c22",
            "value": " 5/5 (100.0%) | ⏳ 02:48&lt;00:00 |  1.90it/s"
          }
        },
        "08f5e9e4c7474f1b9e02cca89f02369e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465a226fe19e4b65acb04af3008a4471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52952cf650f643cf8993aa995901cd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7978965bce78486890348a6d53e44a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd42171a90c4456b6ee7db220a932d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "084acce68cfd4358881a2d0e98542eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2cbf3412dda455b9684ffbce6b59c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83eaf853651b49daa5502fa7438737db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7e180118e3047e69e27010787bfdd98",
              "IPY_MODEL_417f86574cd144d0b25b2b6b1cec43ab",
              "IPY_MODEL_1d3727d9d06643cdbe8db2f764e8b1bf"
            ],
            "layout": "IPY_MODEL_bd650720019b4e55a878ae0ef9834f2d"
          }
        },
        "a7e180118e3047e69e27010787bfdd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee38db6527794ea09a46407bff080a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_0e36814d206947348db3a7e82647d8f0",
            "value": "llm_classify "
          }
        },
        "417f86574cd144d0b25b2b6b1cec43ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eee541fb4df425e8379382eec360b2d",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48d499c707e94018a235fc69081a36a9",
            "value": 5
          }
        },
        "1d3727d9d06643cdbe8db2f764e8b1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638e8aea684a4c5c8c3f478caf97c722",
            "placeholder": "​",
            "style": "IPY_MODEL_0756a4a0a3cc4be8b01ebdaf4d16b67a",
            "value": " 5/5 (100.0%) | ⏳ 02:42&lt;00:00 |  1.65s/it"
          }
        },
        "bd650720019b4e55a878ae0ef9834f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee38db6527794ea09a46407bff080a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e36814d206947348db3a7e82647d8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eee541fb4df425e8379382eec360b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d499c707e94018a235fc69081a36a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "638e8aea684a4c5c8c3f478caf97c722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0756a4a0a3cc4be8b01ebdaf4d16b67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}