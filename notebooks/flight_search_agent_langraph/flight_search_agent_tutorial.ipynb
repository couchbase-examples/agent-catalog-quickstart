{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Search Agent Tutorial\n",
    "\n",
    "This notebook demonstrates the Agent Catalog flight search agent with fixed parameter mapping and robust ReAct artifact cleaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import all necessary modules with parameter mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports completed!\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import getpass\n",
    "import inspect\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from typing import Any\n",
    "\n",
    "import agentc\n",
    "import agentc_langgraph.agent\n",
    "import agentc_langgraph.graph\n",
    "import dotenv\n",
    "import langchain_core.messages\n",
    "import langchain_core.runnables\n",
    "import langchain_openai.chat_models\n",
    "import langgraph.graph\n",
    "import openai\n",
    "import requests\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress verbose logging\n",
    "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"agentc_core\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Setup environment variables and initialization functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:42:18,497 - __main__ - INFO - Testing Capella AI connectivity...\n",
      "2025-07-13 12:42:21,145 - __main__ - INFO - ✅ Capella AI embedding test successful - dimensions: 4096\n",
      "2025-07-13 12:42:22,529 - __main__ - INFO - ✅ Capella AI LLM test successful\n",
      "2025-07-13 12:42:22,544 - __main__ - INFO - ✅ Capella AI connectivity tests completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured\n"
     ]
    }
   ],
   "source": [
    "def setup_capella_ai_config():\n",
    "    \"\"\"Setup Capella AI configuration - requires environment variables to be set.\"\"\"\n",
    "    # Verify required environment variables are set (no defaults)\n",
    "    required_capella_vars = [\n",
    "        \"CB_USERNAME\",\n",
    "        \"CB_PASSWORD\",\n",
    "        \"CAPELLA_API_ENDPOINT\",\n",
    "        \"CAPELLA_API_EMBEDDING_MODEL\",\n",
    "        \"CAPELLA_API_LLM_MODEL\",\n",
    "    ]\n",
    "    missing_vars = [var for var in required_capella_vars if not os.getenv(var)]\n",
    "    if missing_vars:\n",
    "        msg = f\"Missing required Capella AI environment variables: {missing_vars}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    return {\n",
    "        \"endpoint\": os.getenv(\"CAPELLA_API_ENDPOINT\"),\n",
    "        \"embedding_model\": os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\"),\n",
    "        \"llm_model\": os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
    "        \"dimensions\": 4096,\n",
    "    }\n",
    "\n",
    "\n",
    "def test_capella_connectivity():\n",
    "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
    "    try:\n",
    "        endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
    "        if not endpoint:\n",
    "            logger.warning(\"CAPELLA_API_ENDPOINT not configured\")\n",
    "            return False\n",
    "\n",
    "        # Test basic HTTP connectivity\n",
    "        logger.info(\"Testing Capella AI connectivity...\")\n",
    "        response = requests.get(f\"{endpoint}/health\", timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            logger.warning(f\"Capella AI health check failed: {response.status_code}\")\n",
    "\n",
    "        # Test embedding model (requires API key)\n",
    "        if os.getenv(\"CB_USERNAME\") and os.getenv(\"CB_PASSWORD\"):\n",
    "            api_key = base64.b64encode(\n",
    "                f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
    "            ).decode()\n",
    "\n",
    "            headers = {\"Authorization\": f\"Basic {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "            # Test embedding\n",
    "            embedding_data = {\n",
    "                \"model\": os.getenv(\n",
    "                    \"CAPELLA_API_EMBEDDING_MODEL\", \"intfloat/e5-mistral-7b-instruct\"\n",
    "                ),\n",
    "                \"input\": \"test connectivity\",\n",
    "            }\n",
    "\n",
    "            embedding_response = requests.post(\n",
    "                f\"{endpoint}/v1/embeddings\", headers=headers, json=embedding_data, timeout=30\n",
    "            )\n",
    "\n",
    "            if embedding_response.status_code == 200:\n",
    "                embed_result = embedding_response.json()\n",
    "                embed_dims = len(embed_result[\"data\"][0][\"embedding\"])\n",
    "                logger.info(f\"✅ Capella AI embedding test successful - dimensions: {embed_dims}\")\n",
    "\n",
    "                if embed_dims != 4096:\n",
    "                    logger.warning(f\"Expected 4096 dimensions, got {embed_dims}\")\n",
    "                    return False\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"Capella AI embedding test failed: {embedding_response.status_code}\"\n",
    "                )\n",
    "                return False\n",
    "\n",
    "            # Test LLM\n",
    "            llm_data = {\n",
    "                \"model\": os.getenv(\"CAPELLA_API_LLM_MODEL\", \"meta-llama/Llama-3.1-8B-Instruct\"),\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                \"max_tokens\": 10,\n",
    "            }\n",
    "\n",
    "            llm_response = requests.post(\n",
    "                f\"{endpoint}/v1/chat/completions\", headers=headers, json=llm_data, timeout=30\n",
    "            )\n",
    "\n",
    "            if llm_response.status_code == 200:\n",
    "                logger.info(\"✅ Capella AI LLM test successful\")\n",
    "            else:\n",
    "                logger.warning(f\"Capella AI LLM test failed: {llm_response.status_code}\")\n",
    "                return False\n",
    "\n",
    "        logger.info(\"✅ Capella AI connectivity tests completed successfully\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Capella AI connectivity test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if os.environ.get(var) is None:\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}: \")\n",
    "\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup required environment variables with defaults.\"\"\"\n",
    "    # Setup Capella AI configuration first\n",
    "    setup_capella_ai_config()\n",
    "\n",
    "    # Required variables\n",
    "    required_vars = [\"OPENAI_API_KEY\", \"CB_CONN_STRING\", \"CB_USERNAME\", \"CB_PASSWORD\", \"CB_BUCKET\"]\n",
    "    for var in required_vars:\n",
    "        _set_if_undefined(var)\n",
    "\n",
    "    defaults = {\n",
    "        \"CB_CONN_STRING\": \"couchbase://localhost\",\n",
    "        \"CB_USERNAME\": \"Administrator\",\n",
    "        \"CB_PASSWORD\": \"password\",\n",
    "        \"CB_BUCKET\": \"travel-sample\",\n",
    "    }\n",
    "\n",
    "    for key, default_value in defaults.items():\n",
    "        if not os.environ.get(key):\n",
    "            os.environ[key] = input(f\"Enter {key} (default: {default_value}): \") or default_value\n",
    "\n",
    "    os.environ[\"CB_INDEX\"] = os.getenv(\"CB_INDEX\", \"flight_policies_index\")\n",
    "    os.environ[\"CB_SCOPE\"] = os.getenv(\"CB_SCOPE\", \"agentc_data\")\n",
    "    os.environ[\"CB_COLLECTION\"] = os.getenv(\"CB_COLLECTION\", \"flight_policies\")\n",
    "\n",
    "    # Test Capella AI connectivity\n",
    "    test_capella_connectivity()\n",
    "\n",
    "\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CouchbaseClient Class\n",
    "\n",
    "Define the CouchbaseClient for all database operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CouchbaseClient defined\n"
     ]
    }
   ],
   "source": [
    "class CouchbaseClient:\n",
    "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
    "\n",
    "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
    "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
    "        self.conn_string = conn_string\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.bucket_name = bucket_name\n",
    "        self.cluster = None\n",
    "        self.bucket = None\n",
    "        self._collections = {}\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
    "        try:\n",
    "            auth = PasswordAuthenticator(self.username, self.password)\n",
    "            options = ClusterOptions(auth)\n",
    "            # Use WAN profile for better timeout handling with remote clusters\n",
    "            options.apply_profile(\"wan_development\")\n",
    "            self.cluster = Cluster(self.conn_string, options)\n",
    "            self.cluster.wait_until_ready(timedelta(seconds=10))\n",
    "            logger.info(\"Successfully connected to Couchbase\")\n",
    "            return self.cluster\n",
    "        except Exception as e:\n",
    "            msg = f\"Failed to connect to Couchbase: {e!s}\"\n",
    "            raise ConnectionError(msg)\n",
    "\n",
    "    def setup_collection(self, scope_name: str, collection_name: str):\n",
    "        \"\"\"Setup bucket, scope and collection all in one function.\"\"\"\n",
    "        try:\n",
    "            if not self.cluster:\n",
    "                self.connect()\n",
    "\n",
    "            if not self.bucket:\n",
    "                try:\n",
    "                    self.bucket = self.cluster.bucket(self.bucket_name)\n",
    "                    logger.info(f\"Bucket '{self.bucket_name}' exists\")\n",
    "                except Exception:\n",
    "                    logger.info(f\"Creating bucket '{self.bucket_name}'...\")\n",
    "                    bucket_settings = CreateBucketSettings(\n",
    "                        name=self.bucket_name,\n",
    "                        bucket_type=\"couchbase\",\n",
    "                        ram_quota_mb=1024,\n",
    "                        flush_enabled=True,\n",
    "                        num_replicas=0,\n",
    "                    )\n",
    "                    self.cluster.buckets().create_bucket(bucket_settings)\n",
    "                    time.sleep(5)\n",
    "                    self.bucket = self.cluster.bucket(self.bucket_name)\n",
    "                    logger.info(f\"Bucket '{self.bucket_name}' created successfully\")\n",
    "\n",
    "            bucket_manager = self.bucket.collections()\n",
    "            scopes = bucket_manager.get_all_scopes()\n",
    "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
    "\n",
    "            if not scope_exists and scope_name != \"_default\":\n",
    "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
    "                bucket_manager.create_scope(scope_name)\n",
    "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
    "\n",
    "            collections = bucket_manager.get_all_scopes()\n",
    "            collection_exists = any(\n",
    "                scope.name == scope_name\n",
    "                and collection_name in [col.name for col in scope.collections]\n",
    "                for scope in collections\n",
    "            )\n",
    "\n",
    "            if not collection_exists:\n",
    "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
    "                bucket_manager.create_collection(scope_name, collection_name)\n",
    "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
    "\n",
    "            collection = self.bucket.scope(scope_name).collection(collection_name)\n",
    "            time.sleep(3)\n",
    "\n",
    "            try:\n",
    "                self.cluster.query(\n",
    "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "                ).execute()\n",
    "                logger.info(\"Primary index created successfully\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error creating primary index: {e!s}\")\n",
    "\n",
    "            collection_key = f\"{scope_name}.{collection_name}\"\n",
    "            self._collections[collection_key] = collection\n",
    "\n",
    "            logger.info(f\"Collection setup complete for {scope_name}.{collection_name}\")\n",
    "            return collection\n",
    "\n",
    "        except Exception as e:\n",
    "            msg = f\"Error setting up collection: {e!s}\"\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "    def get_collection(self, scope_name: str, collection_name: str):\n",
    "        \"\"\"Get a collection, creating it if it doesn't exist.\"\"\"\n",
    "        collection_key = f\"{scope_name}.{collection_name}\"\n",
    "        if collection_key not in self._collections:\n",
    "            self.setup_collection(scope_name, collection_name)\n",
    "        return self._collections[collection_key]\n",
    "\n",
    "    def clear_scope(self, scope_name: str):\n",
    "        \"\"\"Clear all collections in the specified scope.\"\"\"\n",
    "        try:\n",
    "            if not self.bucket:\n",
    "                if not self.cluster:\n",
    "                    self.connect()\n",
    "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
    "\n",
    "            bucket_manager = self.bucket.collections()\n",
    "            scopes = bucket_manager.get_all_scopes()\n",
    "\n",
    "            target_scope = None\n",
    "            for scope in scopes:\n",
    "                if scope.name == scope_name:\n",
    "                    target_scope = scope\n",
    "                    break\n",
    "\n",
    "            if not target_scope:\n",
    "                logger.info(f\"Scope '{scope_name}' does not exist, nothing to clear\")\n",
    "                return\n",
    "\n",
    "            for collection in target_scope.collections:\n",
    "                try:\n",
    "                    delete_query = (\n",
    "                        f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection.name}`\"\n",
    "                    )\n",
    "                    self.cluster.query(delete_query).execute()\n",
    "                    logger.info(f\"Cleared collection '{collection.name}' in scope '{scope_name}'\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not clear collection '{collection.name}': {e}\")\n",
    "\n",
    "            logger.info(f\"Cleared all collections in scope '{scope_name}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not clear scope '{scope_name}': {e}\")\n",
    "\n",
    "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
    "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
    "        try:\n",
    "            if not self.bucket:\n",
    "                msg = \"Bucket not initialized. Call setup_collection first.\"\n",
    "                raise RuntimeError(msg)\n",
    "\n",
    "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
    "            existing_indexes = scope_index_manager.get_all_indexes()\n",
    "            index_name = index_definition[\"name\"]\n",
    "\n",
    "            if index_name not in [index.name for index in existing_indexes]:\n",
    "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
    "                search_index = SearchIndex.from_json(index_definition)\n",
    "                scope_index_manager.upsert_index(search_index)\n",
    "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
    "            else:\n",
    "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
    "        except Exception as e:\n",
    "            msg = f\"Error setting up vector search index: {e!s}\"\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "    def load_flight_data(self):\n",
    "        \"\"\"Load flight data from the enhanced flight_data.py file.\"\"\"\n",
    "        try:\n",
    "            # Import flight data\n",
    "            sys.path.append(os.path.join(os.path.dirname(__file__), \"data\"))\n",
    "            from flight_data import get_all_flight_data\n",
    "\n",
    "            flight_data = get_all_flight_data()\n",
    "\n",
    "            # Convert to text format for vector store\n",
    "            flight_texts = []\n",
    "            for item in flight_data:\n",
    "                text = f\"{item['title']} - {item['content']}\"\n",
    "                flight_texts.append(text)\n",
    "\n",
    "            return flight_texts\n",
    "        except Exception as e:\n",
    "            msg = f\"Error loading flight data: {e!s}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "    def setup_vector_store(\n",
    "        self, scope_name: str, collection_name: str, index_name: str, embeddings\n",
    "    ):\n",
    "        \"\"\"Setup vector store with flight data.\"\"\"\n",
    "        try:\n",
    "            if not self.cluster:\n",
    "                msg = \"Cluster not connected. Call connect first.\"\n",
    "                raise RuntimeError(msg)\n",
    "\n",
    "            vector_store = CouchbaseVectorStore(\n",
    "                cluster=self.cluster,\n",
    "                bucket_name=self.bucket_name,\n",
    "                scope_name=scope_name,\n",
    "                collection_name=collection_name,\n",
    "                embedding=embeddings,\n",
    "                index_name=index_name,\n",
    "            )\n",
    "\n",
    "            # Load flight data - single attempt\n",
    "            try:\n",
    "                flight_data = self.load_flight_data()\n",
    "                vector_store.add_texts(texts=flight_data, batch_size=10)\n",
    "                logger.info(\"Flight data loaded into vector store successfully\")\n",
    "            except Exception as e:\n",
    "                logger.exception(f\"Failed to load flight data: {e}\")\n",
    "                logger.warning(\"Vector store created but data not loaded.\")\n",
    "\n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            msg = f\"Error setting up vector store: {e!s}\"\n",
    "            raise ValueError(msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Mapper\n",
    "\n",
    "Define the ParameterMapper class with ReAct artifact cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterMapper:\n",
    "    \"\"\"Intelligent parameter mapper using LLM with guardrail-safe prompts.\"\"\"\n",
    "\n",
    "    def __init__(self, chat_model: ChatOpenAI):\n",
    "        self.chat_model = chat_model\n",
    "\n",
    "        # Common parameter synonyms for flight tools\n",
    "        self.parameter_synonyms = {\n",
    "            \"source_airport\": [\"departure_airport\", \"origin\", \"from\", \"origin_airport\", \"start\"],\n",
    "            \"destination_airport\": [\"arrival_airport\", \"destination\", \"to\", \"dest\", \"end\"],\n",
    "            \"departure_date\": [\"date\", \"travel_date\", \"dep_date\", \"when\"],\n",
    "            \"return_date\": [\"return\", \"return_date\", \"back_date\"],\n",
    "            \"passengers\": [\"pax\", \"travelers\", \"people\", \"passenger_count\"],\n",
    "            \"flight_class\": [\"class\", \"cabin\", \"service_class\", \"ticket_class\"],\n",
    "        }\n",
    "\n",
    "    def get_function_parameters(self, func) -> set[str]:\n",
    "        \"\"\"Extract parameter names from function signature.\"\"\"\n",
    "        try:\n",
    "            sig = inspect.signature(func)\n",
    "            return set(sig.parameters.keys())\n",
    "        except Exception:\n",
    "            logger.exception(\"Error getting function parameters\")\n",
    "            return set()\n",
    "\n",
    "    def map_parameters_smart(\n",
    "        self, tool_name: str, raw_args: dict[str, Any], func\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Smart parameter mapping using LLM to understand parameter intent.\n",
    "\n",
    "        Args:\n",
    "            tool_name: Name of the tool being called\n",
    "            raw_args: Raw arguments from LLM\n",
    "            func: Function object to get expected parameters\n",
    "\n",
    "        Returns:\n",
    "            Mapped parameters ready for function call\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get expected parameters from function signature\n",
    "            expected_params = self.get_function_parameters(func)\n",
    "\n",
    "            # If parameters already match, return as-is\n",
    "            if set(raw_args.keys()).issubset(expected_params):\n",
    "                return raw_args\n",
    "\n",
    "            # Use LLM to map parameters intelligently with guardrail-safe prompts\n",
    "            mapped_params = self._llm_parameter_mapping(tool_name, raw_args, expected_params)\n",
    "\n",
    "            # Add tool-specific defaults\n",
    "            mapped_params = self._add_tool_defaults(tool_name, mapped_params)\n",
    "\n",
    "            # Filter to only valid parameters\n",
    "            return {k: v for k, v in mapped_params.items() if k in expected_params}\n",
    "\n",
    "\n",
    "        except Exception:\n",
    "            logger.exception(\"Error in smart parameter mapping\")\n",
    "            # Fallback to synonym-based mapping\n",
    "            return self._fallback_synonym_mapping(raw_args, expected_params)\n",
    "\n",
    "    def _llm_parameter_mapping(\n",
    "        self, tool_name: str, raw_args: dict[str, Any], expected_params: set[str]\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Use LLM to map parameters with minimal, guardrail-safe prompts.\"\"\"\n",
    "\n",
    "        # Ultra-minimal prompt to avoid guardrail violations\n",
    "        system_prompt = f\"\"\"Map parameters to: {list(expected_params)}\n",
    "Output only valid JSON.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Input: {json.dumps(raw_args)}\n",
    "Tool: {tool_name}\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Primary LLM call with minimal prompt\n",
    "            mapped_params = self._safe_llm_call(system_prompt, user_prompt)\n",
    "            if mapped_params:\n",
    "                return mapped_params\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"LLM parameter mapping failed: {e}\")\n",
    "\n",
    "        # Fallback to synonym-based mapping\n",
    "        return self._fallback_synonym_mapping(raw_args, expected_params)\n",
    "\n",
    "    def _safe_llm_call(self, system_prompt: str, user_prompt: str) -> dict | None:\n",
    "        \"\"\"Make safe LLM call with robust JSON parsing.\"\"\"\n",
    "        try:\n",
    "            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)]\n",
    "\n",
    "            response = self.chat_model.invoke(messages)\n",
    "            content = response.content.strip()\n",
    "\n",
    "            # Try multiple JSON parsing methods\n",
    "            return self._parse_json_response(content)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Safe LLM call failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _parse_json_response(self, content: str) -> dict | None:\n",
    "        \"\"\"Parse JSON response with multiple fallback methods.\"\"\"\n",
    "\n",
    "        logger.debug(f\"Parsing JSON response: '{content[:200]}...' (length: {len(content)})\")\n",
    "\n",
    "        # Method 1: Direct JSON parsing\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.debug(f\"Direct JSON parsing failed: {e}\")\n",
    "\n",
    "        # Method 2: Extract from code blocks\n",
    "        try:\n",
    "            if \"```json\" in content:\n",
    "                json_content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                return json.loads(json_content)\n",
    "            if \"```\" in content:\n",
    "                json_content = content.split(\"```\")[1].strip()\n",
    "                return json.loads(json_content)\n",
    "        except (json.JSONDecodeError, IndexError):\n",
    "            pass\n",
    "\n",
    "        # Method 3: Find JSON-like patterns\n",
    "        try:\n",
    "            # Look for balanced {.*} patterns\n",
    "            json_pattern = r\"\\{[^{}]*\\}\"\n",
    "            matches = re.findall(json_pattern, content)\n",
    "            if matches:\n",
    "                return json.loads(matches[0])\n",
    "        except (json.JSONDecodeError, IndexError):\n",
    "            pass\n",
    "\n",
    "        # Method 3b: More complex JSON pattern with nested braces\n",
    "        try:\n",
    "            # Find JSON with proper brace matching\n",
    "            start = content.find(\"{\")\n",
    "            if start != -1:\n",
    "                brace_count = 0\n",
    "                for i, char in enumerate(content[start:], start):\n",
    "                    if char == \"{\":\n",
    "                        brace_count += 1\n",
    "                    elif char == \"}\":\n",
    "                        brace_count -= 1\n",
    "                        if brace_count == 0:\n",
    "                            json_content = content[start : i + 1]\n",
    "                            return json.loads(json_content)\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            pass\n",
    "\n",
    "        # Method 4: Handle truncated JSON (common at character 168)\n",
    "        try:\n",
    "            # If content appears truncated, try to find the last complete JSON object\n",
    "            if len(content) >= 160:  # Near the problematic character range\n",
    "                # Look for the last complete brace pair\n",
    "                last_close_brace = content.rfind(\"}\")\n",
    "                if last_close_brace > 0:\n",
    "                    # Find the matching opening brace\n",
    "                    brace_count = 0\n",
    "                    for i in range(last_close_brace, -1, -1):\n",
    "                        if content[i] == \"}\":\n",
    "                            brace_count += 1\n",
    "                        elif content[i] == \"{\":\n",
    "                            brace_count -= 1\n",
    "                            if brace_count == 0:\n",
    "                                truncated_json = content[i : last_close_brace + 1]\n",
    "                                logger.debug(f\"Trying truncated JSON: '{truncated_json}'\")\n",
    "                                return json.loads(truncated_json)\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            pass\n",
    "\n",
    "        # Method 5: Clean and retry\n",
    "        try:\n",
    "            # Remove extra whitespace and try again\n",
    "            cleaned = re.sub(r\"\\s+\", \" \", content.strip())\n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        # Method 6: Emergency fallback - try to construct basic JSON from visible patterns\n",
    "        try:\n",
    "            # Look for key-value pairs and construct basic JSON\n",
    "            if \"source_airport\" in content and \"destination_airport\" in content:\n",
    "                # Try to extract airport codes with regex\n",
    "                source_match = re.search(r'\"source_airport\"\\s*:\\s*\"([^\"]*)\"', content)\n",
    "                dest_match = re.search(r'\"destination_airport\"\\s*:\\s*\"([^\"]*)\"', content)\n",
    "\n",
    "                if source_match and dest_match:\n",
    "                    fallback_json = {\n",
    "                        \"source_airport\": source_match.group(1),\n",
    "                        \"destination_airport\": dest_match.group(1),\n",
    "                    }\n",
    "                    logger.debug(f\"Emergency fallback JSON: {fallback_json}\")\n",
    "                    return fallback_json\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        logger.warning(\n",
    "            f\"Failed to parse JSON response (length: {len(content)}): {content[:200]}...\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    def _fallback_synonym_mapping(\n",
    "        self, raw_args: dict[str, Any], expected_params: set[str]\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Fallback to synonym-based mapping if LLM fails.\"\"\"\n",
    "        mapped = {}\n",
    "\n",
    "        for expected_param in expected_params:\n",
    "            # Check if parameter exists directly\n",
    "            if expected_param in raw_args:\n",
    "                mapped[expected_param] = raw_args[expected_param]\n",
    "                continue\n",
    "\n",
    "            # Check synonyms\n",
    "            synonyms = self.parameter_synonyms.get(expected_param, [])\n",
    "            for synonym in synonyms:\n",
    "                if synonym in raw_args:\n",
    "                    mapped[expected_param] = raw_args[synonym]\n",
    "                    break\n",
    "\n",
    "        return mapped\n",
    "\n",
    "    def _add_tool_defaults(self, tool_name: str, params: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Add tool-specific defaults for single user system.\"\"\"\n",
    "\n",
    "        if tool_name == \"save_flight_booking\":\n",
    "            # Default departure date if missing\n",
    "            if \"departure_date\" not in params:\n",
    "                params[\"departure_date\"] = \"tomorrow\"\n",
    "\n",
    "            # Default passengers if missing\n",
    "            if \"passengers\" not in params:\n",
    "                params[\"passengers\"] = 1\n",
    "\n",
    "            # Default flight class if missing\n",
    "            if \"flight_class\" not in params:\n",
    "                params[\"flight_class\"] = \"economy\"\n",
    "\n",
    "        elif tool_name == \"retrieve_flight_bookings\":\n",
    "            # No customer_id needed for single user system\n",
    "            pass\n",
    "\n",
    "        return params\n",
    "\n",
    "    def extract_airports_from_text(self, text: str) -> dict[str, str | None]:\n",
    "        \"\"\"Extract airport codes from text using guardrail-safe LLM calls.\"\"\"\n",
    "\n",
    "        # Ultra-minimal prompt for location code extraction\n",
    "        system_prompt = (\n",
    "            \"Extract location codes. Return JSON with source_airport and destination_airport.\"\n",
    "        )\n",
    "        user_prompt = f\"Text: {text}\"\n",
    "\n",
    "        try:\n",
    "            # Try LLM extraction with minimal prompt\n",
    "            result = self._safe_llm_call(system_prompt, user_prompt)\n",
    "            if result and isinstance(result, dict):\n",
    "                # Validate and clean the result\n",
    "                cleaned_result = {}\n",
    "                for key in [\"source_airport\", \"destination_airport\"]:\n",
    "                    value = result.get(key)\n",
    "                    if value and isinstance(value, str) and len(value) == 3:\n",
    "                        cleaned_result[key] = value.upper()\n",
    "                    else:\n",
    "                        cleaned_result[key] = None\n",
    "                return cleaned_result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"LLM airport extraction failed: {e}\")\n",
    "\n",
    "        # Fallback to pattern matching\n",
    "        return self._fallback_airport_extraction(text)\n",
    "\n",
    "    def _fallback_airport_extraction(self, text: str) -> dict[str, str | None]:\n",
    "        \"\"\"Fallback airport extraction using regex patterns.\"\"\"\n",
    "        result = {\"source_airport\": None, \"destination_airport\": None}\n",
    "\n",
    "        # Find 3-letter codes\n",
    "        airport_codes = re.findall(r\"\\b[A-Z]{3}\\b\", text.upper())\n",
    "\n",
    "        if len(airport_codes) >= 2:\n",
    "            result[\"source_airport\"] = airport_codes[0]\n",
    "            result[\"destination_airport\"] = airport_codes[1]\n",
    "        elif len(airport_codes) == 1:\n",
    "            # Try to determine if it's source or destination\n",
    "            if any(word in text.lower() for word in [\"from\", \"origin\"]):\n",
    "                result[\"source_airport\"] = airport_codes[0]\n",
    "            elif any(word in text.lower() for word in [\"to\", \"destination\"]):\n",
    "                result[\"destination_airport\"] = airport_codes[0]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def map_positional_args(self, tool_name: str, args: tuple, func) -> dict[str, Any]:\n",
    "        \"\"\"Map positional arguments from ReAct agent to function parameters.\"\"\"\n",
    "        try:\n",
    "            expected_params = self.get_function_parameters(func)\n",
    "\n",
    "            # Map positional args to expected parameter names\n",
    "            mapped = {}\n",
    "\n",
    "            if tool_name == \"lookup_flight_info\":\n",
    "                # Expects source_airport, destination_airport\n",
    "                if len(args) >= 2:\n",
    "                    mapped[\"source_airport\"] = args[0]\n",
    "                    mapped[\"destination_airport\"] = args[1]\n",
    "                elif len(args) == 1:\n",
    "                    # Try to extract both from single string\n",
    "                    airports = self.extract_airports_from_text(args[0])\n",
    "                    mapped.update(airports)\n",
    "\n",
    "            elif tool_name == \"save_flight_booking\":\n",
    "                # Map based on position and add defaults\n",
    "                if len(args) >= 2:\n",
    "                    mapped[\"source_airport\"] = args[0]\n",
    "                    mapped[\"destination_airport\"] = args[1]\n",
    "                if len(args) >= 3:\n",
    "                    mapped[\"departure_date\"] = args[2]\n",
    "\n",
    "                # Add defaults for missing parameters\n",
    "                mapped = self._add_tool_defaults(tool_name, mapped)\n",
    "\n",
    "            elif tool_name == \"search_flight_policies\":\n",
    "                # Single query parameter\n",
    "                if len(args) >= 1:\n",
    "                    mapped[\"query\"] = \" \".join(args)\n",
    "\n",
    "            # Filter to only valid parameters\n",
    "            return {k: v for k, v in mapped.items() if k in expected_params}\n",
    "\n",
    "        except Exception:\n",
    "            logger.exception(\"Error mapping positional args for %s\", tool_name)\n",
    "            return {}\n",
    "\n",
    "    def map_string_input(self, tool_name: str, input_str: str, func) -> dict[str, Any]:\n",
    "        \"\"\"Map single string input to function parameters.\"\"\"\n",
    "        try:\n",
    "            expected_params = self.get_function_parameters(func)\n",
    "            mapped = {}\n",
    "\n",
    "            logger.debug(\n",
    "                f\"Parameter mapping for {tool_name}: input='{input_str}', expected={expected_params}\"\n",
    "            )\n",
    "\n",
    "            # Enhanced cleaning for ReAct parsing artifacts\n",
    "            clean_input = self._clean_react_artifacts(input_str)\n",
    "\n",
    "            # Debug logging for edge cases\n",
    "            if input_str != clean_input:\n",
    "                logger.debug(\n",
    "                    f\"Cleaned ReAct artifacts for {tool_name}: '{input_str}' -> '{clean_input}'\"\n",
    "                )\n",
    "\n",
    "            if tool_name == \"lookup_flight_info\":\n",
    "                # Handle comma-separated format: \"JFK,LAX,tomorrow\"\n",
    "                parts = [part.strip() for part in clean_input.split(\",\")]\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    # Direct airport codes\n",
    "                    mapped[\"source_airport\"] = parts[0].upper()\n",
    "                    mapped[\"destination_airport\"] = parts[1].upper()\n",
    "                else:\n",
    "                    # Try to extract airports from string\n",
    "                    airports = self.extract_airports_from_text(clean_input)\n",
    "                    mapped.update(airports)\n",
    "\n",
    "            elif tool_name == \"save_flight_booking\":\n",
    "                # Handle comma-separated format: \"SOURCE,DEST,DATE,PASSENGERS,CLASS\"\n",
    "                parts = [part.strip() for part in clean_input.split(\",\")]\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    mapped[\"source_airport\"] = parts[0].upper()\n",
    "                    mapped[\"destination_airport\"] = parts[1].upper()\n",
    "\n",
    "                    # Handle positional parameters\n",
    "                    if len(parts) >= 3:\n",
    "                        mapped[\"departure_date\"] = parts[2]\n",
    "                    if len(parts) >= 4:\n",
    "                        # Try to parse passengers as integer\n",
    "                        try:\n",
    "                            mapped[\"passengers\"] = int(parts[3])\n",
    "                        except ValueError:\n",
    "                            # If not integer, check if it contains a number\n",
    "                            numbers = re.findall(r\"\\d+\", parts[3])\n",
    "                            if numbers:\n",
    "                                mapped[\"passengers\"] = int(numbers[0])\n",
    "                    if len(parts) >= 5:\n",
    "                        # Enhanced cleaning for flight class with ReAct artifacts\n",
    "                        flight_class = self._clean_flight_class(parts[4])\n",
    "                        if flight_class:\n",
    "                            mapped[\"flight_class\"] = flight_class\n",
    "                else:\n",
    "                    # Try to extract flight info from text\n",
    "                    airports = self.extract_airports_from_text(clean_input)\n",
    "                    mapped.update(airports)\n",
    "\n",
    "                # Add defaults\n",
    "                mapped = self._add_tool_defaults(tool_name, mapped)\n",
    "\n",
    "            elif tool_name == \"search_flight_policies\":\n",
    "                # Use cleaned string as query\n",
    "                mapped[\"query\"] = clean_input\n",
    "\n",
    "            elif tool_name == \"retrieve_flight_bookings\":\n",
    "                # No parameters needed for single user system\n",
    "                pass\n",
    "\n",
    "            # Filter to only valid parameters\n",
    "            final_mapped = {\n",
    "                k: v for k, v in mapped.items() if k in expected_params and v is not None\n",
    "            }\n",
    "\n",
    "            logger.debug(f\"Parameter mapping result for {tool_name}: {final_mapped}\")\n",
    "\n",
    "            if not final_mapped:\n",
    "                logger.warning(\n",
    "                    f\"No valid parameters mapped for {tool_name} with input '{input_str}'\"\n",
    "                )\n",
    "\n",
    "            return final_mapped\n",
    "\n",
    "        except Exception:\n",
    "            logger.exception(\"Error mapping string input for %s\", tool_name)\n",
    "            return {}\n",
    "\n",
    "    def _clean_react_artifacts(self, input_str: str) -> str:\n",
    "        \"\"\"Clean ReAct parsing artifacts from input string.\"\"\"\n",
    "        if not input_str:\n",
    "            return \"\"\n",
    "\n",
    "        # Remove common ReAct artifacts\n",
    "        clean_str = input_str\n",
    "\n",
    "        # Enhanced cleaning for ReAct artifacts - handle multi-line patterns\n",
    "        # Remove trailing quotes and observation artifacts (case insensitive)\n",
    "        clean_str = re.sub(\n",
    "            r'[\"\\']?\\s*\\n?\\s*observation.*$', \"\", clean_str, flags=re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "\n",
    "        # Remove newlines followed by any text (common ReAct artifact)\n",
    "        clean_str = re.sub(r\"\\n.*$\", \"\", clean_str, flags=re.DOTALL)\n",
    "\n",
    "        # Remove leading/trailing quotes and whitespace\n",
    "        clean_str = clean_str.strip().strip(\"\\\"'\").strip()\n",
    "\n",
    "        # Handle specific ReAct patterns like \\\"None\\nObservation\\\"\n",
    "        if clean_str.lower().startswith(\"none\"):\n",
    "            # Extract just \\\"none\\\" if it starts with none followed by artifacts\n",
    "            clean_str = \"none\"\n",
    "\n",
    "        return clean_str\n",
    "\n",
    "    def _clean_flight_class(self, flight_class_str: str) -> str:\n",
    "        \"\"\"Clean flight class parameter with enhanced artifact removal.\"\"\"\n",
    "        if not flight_class_str:\n",
    "            return \"\"\n",
    "\n",
    "        # Start with basic cleaning\n",
    "        cleaned = flight_class_str.strip().lower()\n",
    "\n",
    "        # Remove quotes\n",
    "        cleaned = cleaned.strip(\"\\\"'\")\n",
    "\n",
    "        # Remove observation artifacts (case insensitive)\n",
    "        cleaned = re.sub(r'\\s*[\"\\']?\\s*observation.*$', \"\", cleaned, flags=re.IGNORECASE)\n",
    "\n",
    "        # Remove newlines and everything after\n",
    "        cleaned = re.sub(r\"\\n.*$\", \"\", cleaned)\n",
    "\n",
    "        # Remove any remaining special characters at the end\n",
    "        cleaned = re.sub(r\"[^a-zA-Z]+$\", \"\", cleaned)\n",
    "\n",
    "        # Final trim\n",
    "        cleaned = cleaned.strip()\n",
    "\n",
    "        # Validate against known flight classes\n",
    "        valid_classes = [\"economy\", \"business\", \"first\", \"premium\"]\n",
    "        if cleaned in valid_classes:\n",
    "            return cleaned\n",
    "\n",
    "        # If not exact match, try to find closest match\n",
    "        for valid_class in valid_classes:\n",
    "            if valid_class in cleaned:\n",
    "                return valid_class\n",
    "\n",
    "        return cleaned  # Return as-is if no match found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parameter Mapping\n",
    "\n",
    "Test the parameter mapping functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 'JFK,LAX,tomorrow,1,economy'\n",
      "Mapped parameters: {'source_airport': 'JFK', 'destination_airport': 'LAX', 'departure_date': 'tomorrow', 'passengers': 1, 'flight_class': 'economy'}\n",
      "Result: Booked 1 passengers from JFK to LAX on tomorrow in economy\n",
      "\n",
      "Testing: 'JFK,LAX,tomorrow,1,economy\"\n",
      "observation'\n",
      "Mapped parameters: {'source_airport': 'JFK', 'destination_airport': 'LAX', 'departure_date': 'tomorrow', 'passengers': 1, 'flight_class': 'economy'}\n",
      "Result: Booked 1 passengers from JFK to LAX on tomorrow in economy\n",
      "\n",
      "Testing: 'LAX,JFK,next week,2,business'\n",
      "Mapped parameters: {'source_airport': 'LAX', 'destination_airport': 'JFK', 'departure_date': 'next week', 'passengers': 2, 'flight_class': 'business'}\n",
      "Result: Booked 2 passengers from LAX to JFK on next week in business\n",
      "\n",
      "Parameter mapping tests complete\n"
     ]
    }
   ],
   "source": [
    "# Quick test of parameter mapping\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Test the parameter mapper\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "parameter_mapper = ParameterMapper(chat_model)\n",
    "\n",
    "\n",
    "# Mock function for testing\n",
    "def mock_save_booking(\n",
    "    source_airport: str,\n",
    "    destination_airport: str,\n",
    "    departure_date: str,\n",
    "    passengers: int = 1,\n",
    "    flight_class: str = \"economy\",\n",
    "):\n",
    "    return f\"Booked {passengers} passengers from {source_airport} to {destination_airport} on {departure_date} in {flight_class}\"\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_inputs = [\n",
    "    \"JFK,LAX,tomorrow,1,economy\",\n",
    "    'JFK,LAX,tomorrow,1,economy\"\\nobservation',  # ReAct artifact case\n",
    "    \"LAX,JFK,next week,2,business\",\n",
    "]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    result = parameter_mapper.map_string_input(\"save_flight_booking\", test_input, mock_save_booking)\n",
    "    if result:\n",
    "        booking_result = mock_save_booking(**result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Classes\n",
    "\n",
    "Define the FlightSearchAgent with parameter mapping integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent classes defined\n"
     ]
    }
   ],
   "source": [
    "class FlightSearchState(agentc_langgraph.agent.State):\n",
    "    \"\"\"State for flight search conversations - single user system.\"\"\"\n",
    "\n",
    "    query: str\n",
    "    resolved: bool\n",
    "    search_results: list[dict]\n",
    "\n",
    "\n",
    "class FlightSearchAgent(agentc_langgraph.agent.ReActAgent):\n",
    "    \"\"\"Flight search agent with robust parameter mapping.\"\"\"\n",
    "\n",
    "    def __init__(self, catalog: agentc.Catalog, span: agentc.Span):\n",
    "        \"\"\"Initialize the flight search agent.\"\"\"\n",
    "\n",
    "        # Try Capella AI first, fallback to OpenAI\n",
    "        chat_model = None\n",
    "        try:\n",
    "            if (\n",
    "                os.getenv(\"CB_USERNAME\")\n",
    "                and os.getenv(\"CB_PASSWORD\")\n",
    "                and os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
    "                and os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
    "            ):\n",
    "                # Create API key for Capella AI\n",
    "                api_key = base64.b64encode(\n",
    "                    f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
    "                ).decode()\n",
    "\n",
    "                chat_model = ChatOpenAI(\n",
    "                    model=os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
    "                    api_key=api_key,\n",
    "                    base_url=f\"{os.getenv('CAPELLA_API_ENDPOINT')}/v1\",\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=512,\n",
    "                    timeout=30,\n",
    "                )\n",
    "                logger.info(\"✅ Using Capella AI for LLM\")\n",
    "            else:\n",
    "                msg = \"Capella AI credentials not available\"\n",
    "                raise ValueError(msg)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Capella AI LLM failed, falling back to OpenAI: {e}\")\n",
    "            model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "            chat_model = langchain_openai.chat_models.ChatOpenAI(\n",
    "                model=model_name, temperature=0.0, max_tokens=512, timeout=30\n",
    "            )\n",
    "            logger.info(\"✅ Using OpenAI for LLM (fallback)\")\n",
    "\n",
    "        super().__init__(\n",
    "            chat_model=chat_model, catalog=catalog, span=span, prompt_name=\"flight_search_assistant\"\n",
    "        )\n",
    "\n",
    "    def _invoke(\n",
    "        self,\n",
    "        span: agentc.Span,\n",
    "        state: FlightSearchState,\n",
    "        config: langchain_core.runnables.RunnableConfig,\n",
    "    ) -> FlightSearchState:\n",
    "        \"\"\"Handle flight search conversation using ReActAgent.\"\"\"\n",
    "\n",
    "        if not state[\"messages\"]:\n",
    "            initial_msg = langchain_core.messages.HumanMessage(content=state[\"query\"])\n",
    "            state[\"messages\"].append(initial_msg)\n",
    "            logger.info(f\"Flight Query: {state['query']}\")\n",
    "\n",
    "        # Initialize parameter mapper\n",
    "        parameter_mapper = ParameterMapper(self.chat_model)\n",
    "\n",
    "        tools = []\n",
    "        for tool_name in [\n",
    "            \"lookup_flight_info\",\n",
    "            \"save_flight_booking\",\n",
    "            \"retrieve_flight_bookings\",\n",
    "            \"search_flight_policies\",\n",
    "        ]:\n",
    "            catalog_tool = self.catalog.find(\"tool\", name=tool_name)\n",
    "            logger.info(f\"Loaded tool: {tool_name}\")\n",
    "\n",
    "            def create_tool_wrapper(original_tool, name):\n",
    "                def wrapper_func(tool_input: str) -> str:\n",
    "                    \"\"\"Wrapper to handle parameter mapping using ParameterMapper.\"\"\"\n",
    "                    try:\n",
    "                        logger.debug(f\"Tool wrapper called for {name} with input: '{tool_input}'\")\n",
    "\n",
    "                        # Use ParameterMapper to intelligently map string input to parameters\n",
    "                        mapped_params = parameter_mapper.map_string_input(\n",
    "                            name, tool_input, original_tool.func\n",
    "                        )\n",
    "\n",
    "                        logger.debug(f\"Mapped parameters for {name}: {mapped_params}\")\n",
    "\n",
    "                        # Call the original tool with mapped parameters\n",
    "                        result = original_tool.func(**mapped_params)\n",
    "\n",
    "                        logger.debug(\n",
    "                            f\"Tool {name} result type: {type(result)}, length: {len(result) if hasattr(result, '__len__') else 'N/A'}\"\n",
    "                        )\n",
    "\n",
    "                        return result\n",
    "\n",
    "                    except openai.OpenAIError as e:\n",
    "                        logger.warning(f\"OpenAI service error in {name}: {e}\")\n",
    "                        return f\"The {name.replace('_', ' ')} service is temporarily unavailable. Please try again or contact customer service.\"\n",
    "                    except Exception as e:\n",
    "                        logger.exception(f\"Error in tool wrapper for {name}: {e!s}\")\n",
    "                        return f\"Error calling {name}: {e!s}\"\n",
    "\n",
    "                return wrapper_func\n",
    "\n",
    "            langchain_tool = Tool(\n",
    "                name=tool_name,\n",
    "                description=f\"Tool for {tool_name.replace('_', ' ')}\",\n",
    "                func=create_tool_wrapper(catalog_tool, tool_name),\n",
    "            )\n",
    "            tools.append(langchain_tool)\n",
    "\n",
    "        # Get prompt from Agent Catalog\n",
    "        prompt_resource = self.catalog.find(\"prompt\", name=\"flight_search_assistant\")\n",
    "        react_prompt = PromptTemplate.from_template(prompt_resource.content)\n",
    "\n",
    "        # Create ReAct agent with tools and prompt\n",
    "        agent = create_react_agent(self.chat_model, tools, react_prompt)\n",
    "\n",
    "        # Create agent executor with optimized settings for Llama\n",
    "        agent_executor = AgentExecutor(\n",
    "            agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, max_iterations=8\n",
    "        )\n",
    "\n",
    "        # Execute the agent with enhanced error handling for Llama\n",
    "        try:\n",
    "            response = agent_executor.invoke({\"input\": state[\"query\"]})\n",
    "            output = response[\"output\"]\n",
    "        except openai.OpenAIError as e:\n",
    "            # Handle OpenAI service errors (model unavailable, health errors, etc.)\n",
    "            logger.warning(f\"OpenAI service error in agent execution: {e}\")\n",
    "            output = \"The flight search service is temporarily unavailable due to model maintenance. Please try again in a few minutes or contact customer service.\"\n",
    "        except Exception as e:\n",
    "            # Handle guardrail violations and other API errors gracefully\n",
    "            error_msg = str(e)\n",
    "            error_lower = error_msg.lower()\n",
    "\n",
    "            # Check for guardrail violations with expanded patterns\n",
    "            if (\n",
    "                \"guardrail_violation_error\" in error_lower\n",
    "                or \"guardrail violation\" in error_lower\n",
    "                or \"content policy\" in error_lower\n",
    "            ):\n",
    "                # Treat guardrails as warnings, not errors\n",
    "                logger.warning(f\"Guardrails content moderated: {error_msg}\")\n",
    "                output = \"I apologize, but I can't process that specific request due to content policies. Please try rephrasing your flight search query or ask about general flight information.\"\n",
    "\n",
    "            # Handle timeout errors\n",
    "            elif \"timeout\" in error_lower or \"timed out\" in error_lower:\n",
    "                logger.warning(f\"Request timeout: {error_msg}\")\n",
    "                output = \"The request timed out. Please try again with a simpler query.\"\n",
    "\n",
    "            # Handle connection errors\n",
    "            elif \"connection\" in error_lower or \"network\" in error_lower:\n",
    "                logger.warning(f\"Connection error: {error_msg}\")\n",
    "                output = \"I'm having trouble connecting to the flight database. Please try again in a moment.\"\n",
    "\n",
    "            # Handle JSON/parsing errors\n",
    "            elif \"json\" in error_lower or \"parsing\" in error_lower:\n",
    "                logger.warning(f\"Parsing error: {error_msg}\")\n",
    "                output = \"I had trouble understanding the flight data. Please try rephrasing your request.\"\n",
    "\n",
    "            # Handle API rate limiting\n",
    "            elif \"rate limit\" in error_lower or \"429\" in error_msg:\n",
    "                logger.warning(f\"Rate limit exceeded: {error_msg}\")\n",
    "                output = \"Too many requests. Please wait a moment before trying again.\"\n",
    "\n",
    "            # Generic error fallback - don't break the app\n",
    "            else:\n",
    "                logger.warning(f\"Unexpected error: {error_msg}\")\n",
    "                output = \"I encountered an unexpected issue. Please try again or contact support if the problem persists.\"\n",
    "\n",
    "            # Log the specific error type for debugging (but don't break the flow)\n",
    "            if \"guardrail\" in error_lower:\n",
    "                logger.info(\"Guardrails triggered - request handled gracefully\")\n",
    "            else:\n",
    "                logger.info(\"Non-guardrail error - handled gracefully\")\n",
    "\n",
    "        # Add response to conversation\n",
    "        assistant_msg = langchain_core.messages.AIMessage(content=output)\n",
    "        state[\"messages\"].append(assistant_msg)\n",
    "        state[\"resolved\"] = True\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "class FlightSearchGraph(agentc_langgraph.graph.GraphRunnable):\n",
    "    \"\"\"Flight search conversation graph.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build_starting_state(query: str) -> FlightSearchState:\n",
    "        \"\"\"Build the initial state for the flight search.\"\"\"\n",
    "        return FlightSearchState(\n",
    "            messages=[],\n",
    "            query=query,\n",
    "            resolved=False,\n",
    "            search_results=[],\n",
    "            previous_node=None,\n",
    "        )\n",
    "\n",
    "    def compile(self) -> langgraph.graph.graph.CompiledGraph:\n",
    "        \"\"\"Compile the LangGraph workflow.\"\"\"\n",
    "        search_agent = FlightSearchAgent(catalog=self.catalog, span=self.span)\n",
    "\n",
    "        def flight_search_node(state: FlightSearchState) -> FlightSearchState:\n",
    "            \"\"\"Wrapper function for the flight search ReActAgent.\"\"\"\n",
    "            with self.span.new(\"Flight Search Node\") as node_span:\n",
    "                return search_agent._invoke(\n",
    "                    span=node_span,\n",
    "                    state=state,\n",
    "                    config={},\n",
    "                )\n",
    "\n",
    "        workflow = langgraph.graph.StateGraph(FlightSearchState)\n",
    "        workflow.add_node(\"flight_search\", flight_search_node)\n",
    "        workflow.set_entry_point(\"flight_search\")\n",
    "        workflow.add_edge(\"flight_search\", langgraph.graph.END)\n",
    "\n",
    "        return workflow.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Flight Bookings\n",
    "\n",
    "Clear existing bookings for clean test run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:42:25,218 - __main__ - INFO - Successfully connected to Couchbase\n",
      "2025-07-13 12:42:28,389 - __main__ - INFO - Cleared collection 'user_bookings_20250713' in scope 'agentc_bookings'\n",
      "2025-07-13 12:42:28,390 - __main__ - INFO - Cleared all collections in scope 'agentc_bookings'\n",
      "2025-07-13 12:42:28,390 - __main__ - INFO - Cleared existing flight bookings for fresh test run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared existing bookings\n"
     ]
    }
   ],
   "source": [
    "def clear_flight_bookings():\n",
    "    \"\"\"Clear existing flight bookings to start fresh for demo.\"\"\"\n",
    "    try:\n",
    "        client = CouchbaseClient(\n",
    "            conn_string=os.getenv(\"CB_CONN_STRING\", \"couchbase://localhost\"),\n",
    "            username=os.getenv(\"CB_USERNAME\", \"Administrator\"),\n",
    "            password=os.getenv(\"CB_PASSWORD\", \"password\"),\n",
    "            bucket_name=os.getenv(\"CB_BUCKET\", \"travel-sample\"),\n",
    "        )\n",
    "        client.connect()\n",
    "\n",
    "        scope_name = \"agentc_bookings\"\n",
    "        client.clear_scope(scope_name)\n",
    "        logger.info(\"Cleared existing flight bookings for fresh test run\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not clear bookings: {e}\")\n",
    "\n",
    "\n",
    "# Clear existing bookings\n",
    "clear_flight_bookings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Flight Search Agent\n",
    "\n",
    "Initialize the complete flight search agent setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:42:28,400 - __main__ - INFO - Testing Capella AI connectivity...\n",
      "2025-07-13 12:42:30,980 - __main__ - INFO - ✅ Capella AI embedding test successful - dimensions: 4096\n",
      "2025-07-13 12:42:35,349 - __main__ - INFO - ✅ Capella AI LLM test successful\n",
      "2025-07-13 12:42:35,350 - __main__ - INFO - ✅ Capella AI connectivity tests completed successfully\n",
      "2025-07-13 12:42:37,472 - __main__ - INFO - Successfully connected to Couchbase\n",
      "2025-07-13 12:42:38,574 - __main__ - INFO - Bucket 'travel-sample' exists\n",
      "2025-07-13 12:42:44,475 - __main__ - INFO - Primary index created successfully\n",
      "2025-07-13 12:42:44,475 - __main__ - INFO - Collection setup complete for shared.agentcatalog\n",
      "2025-07-13 12:42:48,050 - __main__ - INFO - Vector store setup completed\n",
      "2025-07-13 12:42:48,078 - __main__ - INFO - ✅ Using Capella AI for LLM\n",
      "2025-07-13 12:43:08,425 - __main__ - INFO - Agent Catalog integration successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight search agent setup complete\n"
     ]
    }
   ],
   "source": [
    "def setup_flight_search_agent():\n",
    "    \"\"\"Setup flight search agent with all latest fixes.\"\"\"\n",
    "    try:\n",
    "        setup_environment()\n",
    "\n",
    "        # Initialize Agent Catalog\n",
    "        catalog = agentc.Catalog(\n",
    "            conn_string=os.environ[\"AGENT_CATALOG_CONN_STRING\"],\n",
    "            username=os.environ[\"AGENT_CATALOG_USERNAME\"],\n",
    "            password=os.environ[\"AGENT_CATALOG_PASSWORD\"],\n",
    "            bucket=os.environ[\"AGENT_CATALOG_BUCKET\"],\n",
    "        )\n",
    "        application_span = catalog.Span(name=\"Flight Search Agent\")\n",
    "\n",
    "        with application_span.new(\"Couchbase Setup\"):\n",
    "            client = CouchbaseClient(\n",
    "                conn_string=os.environ[\"CB_CONN_STRING\"],\n",
    "                username=os.environ[\"CB_USERNAME\"],\n",
    "                password=os.environ[\"CB_PASSWORD\"],\n",
    "                bucket_name=os.environ[\"CB_BUCKET\"],\n",
    "            )\n",
    "\n",
    "            client.setup_collection(\n",
    "                scope_name=os.environ[\"CB_SCOPE\"], collection_name=os.environ[\"CB_COLLECTION\"]\n",
    "            )\n",
    "\n",
    "        with application_span.new(\"Vector Store Setup\"):\n",
    "            embeddings = OpenAIEmbeddings(\n",
    "                api_key=os.environ[\"OPENAI_API_KEY\"], model=\"text-embedding-3-small\"\n",
    "            )\n",
    "            try:\n",
    "                CouchbaseVectorStore(\n",
    "                    cluster=client.cluster,\n",
    "                    bucket_name=os.environ[\"CB_BUCKET\"],\n",
    "                    scope_name=os.environ[\"CB_SCOPE\"],\n",
    "                    collection_name=os.environ[\"CB_COLLECTION\"],\n",
    "                    embedding=embeddings,\n",
    "                    index_name=os.environ[\"CB_INDEX\"],\n",
    "                )\n",
    "                logger.info(\"Vector store setup completed\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Vector store setup failed: {e}\")\n",
    "\n",
    "        with application_span.new(\"Agent Graph Creation\"):\n",
    "            flight_graph = FlightSearchGraph(catalog=catalog, span=application_span)\n",
    "            compiled_graph = flight_graph.compile()\n",
    "\n",
    "        logger.info(\"Agent Catalog integration successful\")\n",
    "        return compiled_graph, application_span\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Setup error: {e}\")\n",
    "        logger.info(\"Ensure Agent Catalog is published: agentc index . && agentc publish\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Setup the agent\n",
    "compiled_graph, application_span = setup_flight_search_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Function\n",
    "\n",
    "Define test function with better error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test function ready\n"
     ]
    }
   ],
   "source": [
    "def run_test_query(test_number: int, query: str):\n",
    "    \"\"\"Run a single test query with error handling.\"\"\"\n",
    "    with application_span.new(f\"Test {test_number}: {query}\") as query_span:\n",
    "        logger.info(f\"\\n🔍 Test {test_number}: {query}\")\n",
    "        try:\n",
    "            query_span[\"query\"] = query\n",
    "            state = FlightSearchGraph.build_starting_state(query=query)\n",
    "            result = compiled_graph.invoke(state)\n",
    "            query_span[\"result\"] = result\n",
    "\n",
    "            if result.get(\"search_results\"):\n",
    "                logger.info(f\"Found {len(result['search_results'])} flight options\")\n",
    "            logger.info(f\"Test {test_number} completed: {result.get('resolved', False)}\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"❌ Test {test_number} failed: {e}\")\n",
    "            query_span[\"error\"] = str(e)\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Flight Search\n",
    "\n",
    "Find flights from JFK to LAX for tomorrow - now with parameter mapping!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:08,445 - __main__ - INFO - \n",
      "🔍 Test 1: Find flights from JFK to LAX for tomorrow\n",
      "2025-07-13 12:43:08,455 - __main__ - INFO - Flight Query: Find flights from JFK to LAX for tomorrow\n",
      "2025-07-13 12:43:08,474 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:43:08,485 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:43:08,496 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:43:08,507 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for flights between JFK and LAX for tomorrow.\n",
      "Action: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m\u001b[32;1m\u001b[1;3mAction: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m\u001b[32;1m\u001b[1;3mAction: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:17,006 - __main__ - INFO - Test 1 completed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I've tried searching for flights multiple times, but it seems like the tool is not providing any new information.\n",
      "Action: \n",
      "Final Answer: There are multiple flights available from JFK to LAX for tomorrow, including AS, B6, DL, QF, AA, UA, US, and VX flights. However, I was unable to retrieve more detailed information about these flights. You can try checking the airlines' websites for more information or consider contacting the airlines directly for assistance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result1 = run_test_query(1, \"Find flights from JFK to LAX for tomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Flight Booking (Business Class)\n",
    "\n",
    "Book a flight with parameter mapping - no more ReAct artifacts!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:17,014 - __main__ - INFO - \n",
      "🔍 Test 2: Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\n",
      "2025-07-13 12:43:17,026 - __main__ - INFO - Flight Query: Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\n",
      "2025-07-13 12:43:17,041 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:43:17,052 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:43:17,064 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:43:17,075 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find available flights from LAX to JFK for tomorrow.\n",
      "Action: lookup_flight_info\n",
      "Action Input: \"LAX,JFK,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from LAX to JFK using 321 762', 'B6 flight from LAX to JFK using 320', 'DL flight from LAX to JFK using 76W 752', 'QF flight from LAX to JFK using 744', 'UA flight from LAX to JFK using 757', 'AA flight from LAX to JFK using 32B 762', 'US flight from LAX to JFK using 32B 762', 'VX flight from LAX to JFK using 320']\u001b[0m\u001b[32;1m\u001b[1;3mThought: Now that I have available flights, I need to create a booking for 2 passengers in business class.\n",
      "Action: save_flight_booking\n",
      "Action Input: \"LAX,JFK,tomorrow,2,business\"\n",
      "Observation\u001b[0m\u001b[33;1m\u001b[1;3mFlight Booking Confirmed!\n",
      "\n",
      "Booking ID: FL07146362AE62\n",
      "Route: LAX → JFK\n",
      "Departure Date: 2025-07-14\n",
      "Return Date: One-way\n",
      "Passengers: 2\n",
      "Class: Business\n",
      "Total Price: $1500.00\n",
      "\n",
      "Next Steps:\n",
      "1. Check-in opens 24 hours before departure\n",
      "2. Arrive at airport 2 hours early for domestic flights\n",
      "3. Bring valid government-issued photo ID\n",
      "4. Booking confirmation sent to your email\n",
      "\n",
      "Thank you for choosing our airline!\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:27,539 - __main__ - INFO - Test 2 completed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mFinal Answer: Flight booked successfully. Booking ID: FL07146362AE62.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result2 = run_test_query(\n",
    "    2, \"Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Flight Booking (Economy Class)\n",
    "\n",
    "Book an economy flight - cleaning handles 'economy' correctly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:27,552 - __main__ - INFO - \n",
      "🔍 Test 3: Book an economy flight from JFK to MIA for next week, 1 passenger\n",
      "2025-07-13 12:43:27,554 - __main__ - INFO - Flight Query: Book an economy flight from JFK to MIA for next week, 1 passenger\n",
      "2025-07-13 12:43:27,567 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:43:27,579 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:43:27,594 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:43:27,605 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find available flights from JFK to MIA for next week.\n",
      "Action: lookup_flight_info\n",
      "Action Input: \"JFK,MIA,next week\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['DL flight from JFK to MIA using 73H M88 738 319', 'AA flight from JFK to MIA using 757 763 738', 'US flight from JFK to MIA using 757 738']\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have found available flights from JFK to MIA for next week.\n",
      "Action: save_flight_booking\n",
      "Action Input: \"JFK,MIA,next week,1,economy\"\n",
      "Observation\u001b[0m\u001b[33;1m\u001b[1;3mFlight Booking Confirmed!\n",
      "\n",
      "Booking ID: FL0720024E2D93\n",
      "Route: JFK → MIA\n",
      "Departure Date: 2025-07-20\n",
      "Return Date: One-way\n",
      "Passengers: 1\n",
      "Class: Economy\n",
      "Total Price: $250.00\n",
      "\n",
      "Next Steps:\n",
      "1. Check-in opens 24 hours before departure\n",
      "2. Arrive at airport 2 hours early for domestic flights\n",
      "3. Bring valid government-issued photo ID\n",
      "4. Booking confirmation sent to your email\n",
      "\n",
      "Thank you for choosing our airline!\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:37,078 - __main__ - WARNING - No valid parameters mapped for retrieve_flight_bookings with input 'None\n",
      "Observation'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction: retrieve_flight_bookings\n",
      "Action Input: None\n",
      "Observation\u001b[0m\u001b[38;5;200m\u001b[1;3mYour Current Bookings (2 found):\n",
      "\n",
      "Booking 1:\n",
      "  Booking ID: FL0720024E2D93\n",
      "  Route: JFK → MIA\n",
      "  Date: 2025-07-20\n",
      "  Passengers: 1\n",
      "  Class: Economy\n",
      "  Total: $250.00\n",
      "  Status: confirmed\n",
      "  Booked: 2025-07-13\n",
      "\n",
      "Booking 2:\n",
      "  Booking ID: FL07146362AE62\n",
      "  Route: LAX → JFK\n",
      "  Date: 2025-07-14\n",
      "  Passengers: 2\n",
      "  Class: Business\n",
      "  Total: $1500.00\n",
      "  Status: confirmed\n",
      "  Booked: 2025-07-13\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:50,195 - __main__ - INFO - Test 3 completed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to acknowledge the existing booking without repeating the action.\n",
      "Final Answer: Your flight from JFK to MIA has been successfully booked for next week, and you can find the details in your current bookings.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result3 = run_test_query(3, \"Book an economy flight from JFK to MIA for next week, 1 passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Retrieve Current Bookings\n",
    "\n",
    "Show current flight bookings with parameter handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:50,202 - __main__ - INFO - \n",
      "🔍 Test 4: Show me my current flight bookings\n",
      "2025-07-13 12:43:50,204 - __main__ - INFO - Flight Query: Show me my current flight bookings\n",
      "2025-07-13 12:43:50,226 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:43:50,237 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:43:50,247 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:43:50,258 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:43:51,322 - __main__ - WARNING - No valid parameters mapped for retrieve_flight_bookings with input 'None\n",
      "Observation'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to retrieve the existing flight bookings to show them to the user.\n",
      "Action: retrieve_flight_bookings\n",
      "Action Input: None\n",
      "Observation\u001b[0m\u001b[38;5;200m\u001b[1;3mYour Current Bookings (2 found):\n",
      "\n",
      "Booking 1:\n",
      "  Booking ID: FL0720024E2D93\n",
      "  Route: JFK → MIA\n",
      "  Date: 2025-07-20\n",
      "  Passengers: 1\n",
      "  Class: Economy\n",
      "  Total: $250.00\n",
      "  Status: confirmed\n",
      "  Booked: 2025-07-13\n",
      "\n",
      "Booking 2:\n",
      "  Booking ID: FL07146362AE62\n",
      "  Route: LAX → JFK\n",
      "  Date: 2025-07-14\n",
      "  Passengers: 2\n",
      "  Class: Business\n",
      "  Total: $1500.00\n",
      "  Status: confirmed\n",
      "  Booked: 2025-07-13\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:44:05,180 - __main__ - INFO - Test 4 completed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The user has existing bookings, so I don't need to perform any further actions.\n",
      "Final Answer: Your Current Bookings (2 found):\n",
      "\n",
      "Booking 1:\n",
      "  Booking ID: FL0720024E2D93\n",
      "  Route: JFK → MIA\n",
      "  Date: 2025-07-20\n",
      "  Passengers: 1\n",
      "  Class: Economy\n",
      "  Total: $250.00\n",
      "  Status: confirmed\n",
      "  Booked: 2025-07-13\n",
      "\n",
      "Booking 2:\n",
      "  Booking ID: FL07146362AE62\n",
      "  Route: LAX → JFK\n",
      "  Date: 2025-07-14\n",
      "  Passengers: 2\n",
      "  Class: Business\n",
      "  Total: $1500.00\n",
      "  Status: confirmed\n",
      "  Booked: 2025-07-13\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result4 = run_test_query(4, \"Show me my current flight bookings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Flight Policy Search\n",
    "\n",
    "Search flight policies with robust query handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:44:05,194 - __main__ - INFO - \n",
      "🔍 Test 5: What are the baggage policies?\n",
      "2025-07-13 12:44:05,197 - __main__ - INFO - Flight Query: What are the baggage policies?\n",
      "2025-07-13 12:44:05,212 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:44:05,224 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:44:05,273 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:44:05,331 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking about baggage policies, which could be related to checked baggage fees, carry-on restrictions, or other airline-specific rules.\n",
      "Action: search_flight_policies\n",
      "Action Input: \"baggage policy\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Business Center Hotel in Downtown Chicago, Illinois. Modern business hotel with state-of-the-art conference facilities Price range: $180-$280 per night. Rating: 4.3/5. Amenities: 24/7 Business Center, Executive Meeting Rooms, Fitness Center, Business Lounge Restaurant, Free WiFi, Self-parking\n",
      "\n",
      "Policy 2:\n",
      "Business Center Hotel in Downtown Chicago, Illinois. Modern business hotel with state-of-the-art conference facilities Price range: $180-$280 per night. Rating: 4.3/5. Amenities: 24/7 Business Center, Executive Meeting Rooms, Fitness Center, Business Lounge Restaurant, Free WiFi, Self-parking\n",
      "\n",
      "Policy 3:\n",
      "Business Center Hotel in Downtown Chicago, Illinois. Modern business hotel with state-of-the-art conference facilities Price range: $180-$280 per night. Rating: 4.3/5. Amenities: 24/7 Business Center, Executive Meeting Rooms, Fitness Center, Business Lounge Restaurant, Free WiFi, Self-parking\u001b[0m\u001b[32;1m\u001b[1;3mThought: The search result seems to be about hotels, not baggage policies. I'll try searching for more specific terms related to baggage policies.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"checked baggage fees\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Boutique Inn in San Francisco, California. Charming boutique hotel with unique artistic decor and personalized service Price range: $220-$350 per night. Rating: 4.7/5. Amenities: Personal Concierge, Artisan Restaurant, Craft Cocktail Bar, Free WiFi, Pet-friendly Policies, Valet Parking\n",
      "\n",
      "Policy 2:\n",
      "Boutique Inn in San Francisco, California. Charming boutique hotel with unique artistic decor and personalized service Price range: $220-$350 per night. Rating: 4.7/5. Amenities: Personal Concierge, Artisan Restaurant, Craft Cocktail Bar, Free WiFi, Pet-friendly Policies, Valet Parking\n",
      "\n",
      "Policy 3:\n",
      "Boutique Inn in San Francisco, California. Charming boutique hotel with unique artistic decor and personalized service Price range: $220-$350 per night. Rating: 4.7/5. Amenities: Personal Concierge, Artisan Restaurant, Craft Cocktail Bar, Free WiFi, Pet-friendly Policies, Valet Parking\u001b[0m\u001b[32;1m\u001b[1;3mThought: The search result is still not about baggage policies, but I found some information about hotels. I'll try searching for airline-specific terms related to baggage policies.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"American Airlines baggage\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 2:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 3:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've tried searching for general baggage policies, checked baggage fees, and airline-specific terms, but the results are still not relevant to baggage policies. I'll try to synthesize the information I've found so far.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"baggage policy international\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 2:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 3:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've tried multiple searches for baggage policies, but the results are still not relevant. I'll try to provide a helpful answer based on the information I've found.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"baggage policy international\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 2:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 3:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've tried multiple searches for baggage policies, but the results are still not relevant. I'll try to provide a helpful answer based on the information I've found.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"baggage policy international\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 2:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 3:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've tried multiple searches for baggage policies, but the results are still not relevant. I'll try to provide a helpful answer based on the information I've found.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"baggage policy international\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 2:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 3:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've tried multiple searches for baggage policies, but the results are still not relevant. I'll try to provide a helpful answer based on the information I've found.\n",
      "\n",
      "Action: search_flight_policies\n",
      "Action Input: \"baggage policy international\"\n",
      "Observation\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:45:22,203 - __main__ - INFO - Test 5 completed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mPolicy 1:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 2:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\n",
      "\n",
      "Policy 3:\n",
      "Grand Palace Hotel in Manhattan, New York City. Luxury 5-star hotel featuring elegant rooms with Manhattan skyline views Price range: $300-$500 per night. Rating: 4.8/5. Amenities: Rooftop Pool, World-class Spa, 24/7 Fitness Center, Michelin-starred Restaurant, 24/7 Room Service, High-speed WiFi\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result5 = run_test_query(5, \"What are the baggage policies?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arize Phoenix Evaluation Demo\n",
    "\n",
    "This section demonstrates how to evaluate the flight search agent using Arize Phoenix observability platform. The evaluation includes:\n",
    "\n",
    "- **Relevance Scoring**: Using Phoenix RelevanceEvaluator to score how relevant responses are to queries\n",
    "- **QA Scoring**: Using Phoenix QAEvaluator to score answer quality\n",
    "- **Hallucination Detection**: Using Phoenix HallucinationEvaluator to detect fabricated information  \n",
    "- **Toxicity Detection**: Using Phoenix ToxicityEvaluator to detect harmful content\n",
    "- **Phoenix UI**: Real-time observability dashboard at `http://localhost:6006/`\n",
    "\n",
    "We'll run two simple flight search queries and evaluate the responses for quality and safety. Note: We're only testing search functionality, not booking operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaustavghosh/Desktop/agent-catalog-quickstart/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-13 12:45:23,326 - phoenix.config - INFO - 📋 Ensuring phoenix working directory: /Users/kaustavghosh/.phoenix\n",
      "2025-07-13 12:45:23,341 - phoenix.inferences.inferences - INFO - Dataset: phoenix_inferences_da521529-576a-4243-b816-cdcbfc3a35ab initialized\n",
      "2025-07-13 12:45:27,031 - phoenix.config - INFO - 📋 Ensuring phoenix working directory: /Users/kaustavghosh/.phoenix\n",
      "2025-07-13 12:45:27,093 - alembic.runtime.migration - INFO - Context impl SQLiteImpl.\n",
      "2025-07-13 12:45:27,093 - alembic.runtime.migration - INFO - Will assume transactional DDL.\n",
      "2025-07-13 12:45:27,110 - alembic.runtime.migration - INFO - Running upgrade  -> cf03bd6bae1d, init\n",
      "2025-07-13 12:45:27,141 - alembic.runtime.migration - INFO - Running upgrade cf03bd6bae1d -> 10460e46d750, datasets\n",
      "2025-07-13 12:45:27,147 - alembic.runtime.migration - INFO - Running upgrade 10460e46d750 -> 3be8647b87d8, add token columns to spans table\n",
      "2025-07-13 12:45:27,149 - alembic.runtime.migration - INFO - Running upgrade 3be8647b87d8 -> cd164e83824f, users and tokens\n",
      "2025-07-13 12:45:27,155 - alembic.runtime.migration - INFO - Running upgrade cd164e83824f -> 4ded9e43755f, create project_session table\n",
      "2025-07-13 12:45:27,163 - alembic.runtime.migration - INFO - Running upgrade 4ded9e43755f -> bc8fea3c2bc8, Add prompt tables\n",
      "2025-07-13 12:45:27,169 - alembic.runtime.migration - INFO - Running upgrade bc8fea3c2bc8 -> 2f9d1a65945f, Annotation config migrations\n",
      "/Users/kaustavghosh/.pyenv/versions/3.12.8/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
      "  next(self.gen)\n",
      "/Users/kaustavghosh/.pyenv/versions/3.12.8/lib/python3.12/contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗️ The launch_app `port` parameter is deprecated and will be removed in a future release. Use the `PHOENIX_PORT` environment variable instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:45:27,239 - alembic.runtime.migration - INFO - Running upgrade 2f9d1a65945f -> bb8139330879, create project trace retention policies table\n",
      "2025-07-13 12:45:27,244 - alembic.runtime.migration - INFO - Running upgrade bb8139330879 -> 8a3764fe7f1a, change jsonb to json for prompts\n",
      "2025-07-13 12:45:27,255 - alembic.runtime.migration - INFO - Running upgrade 8a3764fe7f1a -> 6a88424799fe, Add auth_method column to users table and migrate existing authentication data.\n",
      "2025-07-13 12:45:27,262 - alembic.runtime.migration - INFO - Running upgrade 6a88424799fe -> a20694b15f82, Cost-related tables\n",
      "2025-07-13 12:45:27,269 - phoenix.server.app - INFO - Server umap params: UMAPParameters(min_dist=0.0, n_neighbors=30, n_samples=500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
      "✅ Phoenix UI started at http://localhost:6006\n",
      "🔧 Setting up Phoenix evaluation demo for flight search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |          | 0/2 (0.0%) | ⏳ 00:03<? | ?it/s\n"
     ]
    }
   ],
   "source": [
    "# Demo Arize Phoenix Evaluation for Flight Search Agent\n",
    "# Run two simple flight search queries and evaluate responses\n",
    "\n",
    "import builtins\n",
    "import contextlib\n",
    "\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from phoenix.evals import (\n",
    "    HALLUCINATION_PROMPT_RAILS_MAP,\n",
    "    HALLUCINATION_PROMPT_TEMPLATE,\n",
    "    QA_PROMPT_RAILS_MAP,\n",
    "    QA_PROMPT_TEMPLATE,\n",
    "    RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
    "    RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
    "    TOXICITY_PROMPT_RAILS_MAP,\n",
    "    TOXICITY_PROMPT_TEMPLATE,\n",
    "    OpenAIModel,\n",
    "    llm_classify,\n",
    ")\n",
    "\n",
    "# Start Phoenix session for observability\n",
    "with contextlib.suppress(builtins.BaseException):\n",
    "    px.launch_app(port=6006)\n",
    "\n",
    "# Demo queries - simple search only (no bookings or complex operations)\n",
    "flight_demo_queries = [\n",
    "    \"Find flights from JFK to LAX\",\n",
    "    \"What flights are available from Miami to New York?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:45:27,643 - __main__ - INFO - Flight Query: Find flights from JFK to LAX\n",
      "2025-07-13 12:45:27,668 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:45:27,679 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:45:27,689 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:45:27,699 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running Flight Demo Query 1: Find flights from JFK to LAX\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for flights between JFK and LAX airports.\n",
      "Action: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m\u001b[32;1m\u001b[1;3mAction: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m\u001b[32;1m\u001b[1;3mAction: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m\u001b[32;1m\u001b[1;3mAction: lookup_flight_info\n",
      "Action Input: \"JFK,LAX,tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['AS flight from JFK to LAX using 321 762', 'B6 flight from JFK to LAX using 320', 'DL flight from JFK to LAX using 76W 752', 'QF flight from JFK to LAX using 744', 'AA flight from JFK to LAX using 32B 762', 'UA flight from JFK to LAX using 757', 'US flight from JFK to LAX using 32B 762', 'VX flight from JFK to LAX using 320']\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:45:35,120 - __main__ - INFO - Flight Query: What flights are available from Miami to New York?\n",
      "2025-07-13 12:45:35,144 - __main__ - INFO - Loaded tool: lookup_flight_info\n",
      "2025-07-13 12:45:35,156 - __main__ - INFO - Loaded tool: save_flight_booking\n",
      "2025-07-13 12:45:35,167 - __main__ - INFO - Loaded tool: retrieve_flight_bookings\n",
      "2025-07-13 12:45:35,177 - __main__ - INFO - Loaded tool: search_flight_policies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I've tried searching for flights multiple times, but it seems like the tool is not working correctly.\n",
      "Action: \n",
      "Final Answer: Unfortunately, I'm unable to find flights from JFK to LAX. You may want to try searching again later or contacting the airline directly for assistance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ Response: Unfortunately, I'm unable to find flights from JFK to LAX. You may want to try searching again later...\n",
      "\n",
      "🔍 Running Flight Demo Query 2: What flights are available from Miami to New York?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find available flights from Miami to New York. \n",
      "Action: lookup_flight_info \n",
      "Action Input: \"MIA, JFK, tomorrow\"\u001b[0m\u001b[36;1m\u001b[1;3m['DL flight from MIA to JFK using M88 73H 738 319', 'US flight from MIA to JFK using 763 757 738', 'AA flight from MIA to JFK using 763 757 738']\u001b[0m\u001b[32;1m\u001b[1;3mAction: lookup_flight_info \n",
      "Action Input: \"MIA, JFK, tomorrow\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m['DL flight from MIA to JFK using M88 73H 738 319', 'US flight from MIA to JFK using 763 757 738', 'AA flight from MIA to JFK using 763 757 738']\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've found the available flights from Miami to New York. \n",
      "\n",
      "Final Answer: The available flights from Miami to New York are DL, US, and AA.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ Response: The available flights from Miami to New York are DL, US, and AA....\n",
      "\n",
      "📊 Collected 2 responses for evaluation\n"
     ]
    }
   ],
   "source": [
    "# Run demo queries and collect responses for evaluation\n",
    "flight_demo_results = []\n",
    "\n",
    "for i, query in enumerate(flight_demo_queries, 1):\n",
    "\n",
    "    try:\n",
    "        # Create initial state and run the compiled graph\n",
    "        state = FlightSearchGraph.build_starting_state(query=query)\n",
    "        result = compiled_graph.invoke(state)\n",
    "\n",
    "        # Extract the response from the final message\n",
    "        if result.get(\"messages\") and len(result[\"messages\"]) > 1:\n",
    "            output = result[\"messages\"][-1].content\n",
    "        else:\n",
    "            output = \"No response generated\"\n",
    "\n",
    "        flight_demo_results.append({\n",
    "            \"query\": query,\n",
    "            \"response\": output,\n",
    "            \"query_type\": f\"flight_demo_{i}\",\n",
    "            \"success\": result.get(\"resolved\", False)\n",
    "        })\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        flight_demo_results.append({\n",
    "            \"query\": query,\n",
    "            \"response\": f\"Error: {e!s}\",\n",
    "            \"query_type\": f\"flight_demo_{i}\",\n",
    "            \"success\": False\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/n1kj9bdj0ds6117tflwzmk8m0000gq/T/ipykernel_30989/2495970587.py:24: DeprecationWarning: `dataframe` argument is deprecated; use `data` instead\n",
      "  flight_relevance_results = llm_classify(\n",
      "2025-07-13 12:45:54,909 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752390954.911189 7877447 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Running Phoenix AI evaluations on flight search responses...\n",
      "\n",
      "📋 Running relevance evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 2/2 (100.0%) | ⏳ 00:04<00:00 |  2.37s/it\n",
      "/var/folders/1l/n1kj9bdj0ds6117tflwzmk8m0000gq/T/ipykernel_30989/2495970587.py:32: DeprecationWarning: `dataframe` argument is deprecated; use `data` instead\n",
      "  flight_qa_results = llm_classify(\n",
      "2025-07-13 12:45:59,675 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Running QA evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 2/2 (100.0%) | ⏳ 00:07<00:00 |  3.94s/it\n",
      "/var/folders/1l/n1kj9bdj0ds6117tflwzmk8m0000gq/T/ipykernel_30989/2495970587.py:40: DeprecationWarning: `dataframe` argument is deprecated; use `data` instead\n",
      "  flight_hallucination_results = llm_classify(\n",
      "2025-07-13 12:46:07,569 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛡️ Running hallucination evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 2/2 (100.0%) | ⏳ 00:07<00:00 |  3.50s/it\n",
      "/var/folders/1l/n1kj9bdj0ds6117tflwzmk8m0000gq/T/ipykernel_30989/2495970587.py:48: DeprecationWarning: `dataframe` argument is deprecated; use `data` instead\n",
      "  flight_toxicity_results = llm_classify(\n",
      "2025-07-13 12:46:14,593 - phoenix.evals.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔒 Running toxicity evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |          | 0/2 (0.0%) | ⏳ 00:00<? | ?it/s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retries exhausted after 1 attempts: Missing template variable: 'input'\n",
      "\n",
      "📊 Flight Search Agent Evaluation Results:\n",
      "🎯 Relevance: {'relevant': 1, 'unrelated': 1}\n",
      "✅ QA Quality: {'incorrect': 2}\n",
      "🛡️ Hallucination: {'hallucinated': 2}\n",
      "🔒 Toxicity: {}\n",
      "\n",
      "🎉 Phoenix evaluation demo complete for flight search agent!\n",
      "💡 Visit http://localhost:6006 to see detailed traces and evaluations\n",
      "📊 The Phoenix UI shows LangGraph execution, tool calls, and evaluation scores\n",
      "🔧 Compare hotel vs flight agent performance using the evaluation metrics above\n"
     ]
    }
   ],
   "source": [
    "# Run Phoenix evaluations on the flight search responses\n",
    "\n",
    "# Convert to DataFrame for evaluation\n",
    "flight_results_df = pd.DataFrame(flight_demo_results)\n",
    "\n",
    "# Setup evaluator LLM (using OpenAI for consistency)\n",
    "evaluator_llm = OpenAIModel(model=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "# Prepare evaluation data with proper column names for Phoenix evaluators\n",
    "flight_eval_data = []\n",
    "for _, row in flight_results_df.iterrows():\n",
    "    flight_eval_data.append({\n",
    "        \"input\": row[\"query\"],\n",
    "        \"output\": row[\"response\"],\n",
    "        \"reference\": \"A helpful response about flights with specific flight information\",\n",
    "        \"text\": row[\"response\"]  # For toxicity evaluation\n",
    "    })\n",
    "\n",
    "flight_eval_df = pd.DataFrame(flight_eval_data)\n",
    "\n",
    "# Run individual evaluations with proper error handling\n",
    "flight_relevance_results = llm_classify(\n",
    "    dataframe=flight_eval_df[[\"input\", \"reference\"]],\n",
    "    model=evaluator_llm,\n",
    "    template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
    "    rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values())\n",
    ")\n",
    "\n",
    "flight_qa_results = llm_classify(\n",
    "    dataframe=flight_eval_df[[\"input\", \"output\", \"reference\"]],\n",
    "    model=evaluator_llm,\n",
    "    template=QA_PROMPT_TEMPLATE,\n",
    "    rails=list(QA_PROMPT_RAILS_MAP.values())\n",
    ")\n",
    "\n",
    "flight_hallucination_results = llm_classify(\n",
    "    dataframe=flight_eval_df[[\"input\", \"reference\", \"output\"]],\n",
    "    model=evaluator_llm,\n",
    "    template=HALLUCINATION_PROMPT_TEMPLATE,\n",
    "    rails=list(HALLUCINATION_PROMPT_RAILS_MAP.values())\n",
    ")\n",
    "\n",
    "flight_toxicity_results = llm_classify(\n",
    "    dataframe=flight_eval_df[[\"text\"]],\n",
    "    model=evaluator_llm,\n",
    "    template=TOXICITY_PROMPT_TEMPLATE,\n",
    "    rails=list(TOXICITY_PROMPT_RAILS_MAP.values())\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
