{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Search Agent Tutorial\n",
    "\n",
    "This notebook demonstrates the Agent Catalog flight search agent with fixed parameter mapping and robust ReAct artifact cleaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import all necessary modules with parameter mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import getpass\n",
    "import inspect\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from typing import Any, Optional\n",
    "\n",
    "import agentc\n",
    "import agentc_langgraph.agent\n",
    "import agentc_langgraph.graph\n",
    "import dotenv\n",
    "import langchain_core.messages\n",
    "import langchain_core.runnables\n",
    "import langchain_openai.chat_models\n",
    "import langgraph.graph\n",
    "import openai\n",
    "import requests\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress verbose logging\n",
    "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"agentc_core\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "print(\"All imports completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Setup environment variables and initialization functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_capella_ai_config():\n",
    "    \"\"\"Setup Capella AI configuration - requires environment variables to be set.\"\"\"\n",
    "    # Verify required environment variables are set (no defaults)\n",
    "    required_capella_vars = [\n",
    "        \"CB_USERNAME\",\n",
    "        \"CB_PASSWORD\",\n",
    "        \"CAPELLA_API_ENDPOINT\",\n",
    "        \"CAPELLA_API_EMBEDDING_MODEL\",\n",
    "        \"CAPELLA_API_LLM_MODEL\",\n",
    "    ]\n",
    "    missing_vars = [var for var in required_capella_vars if not os.getenv(var)]\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Missing required Capella AI environment variables: {missing_vars}\")\n",
    "\n",
    "    return {\n",
    "        \"endpoint\": os.getenv(\"CAPELLA_API_ENDPOINT\"),\n",
    "        \"embedding_model\": os.getenv(\"CAPELLA_API_EMBEDDING_MODEL\"),\n",
    "        \"llm_model\": os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
    "        \"dimensions\": 4096,\n",
    "    }\n",
    "\n",
    "\n",
    "def test_capella_connectivity():\n",
    "    \"\"\"Test connectivity to Capella AI services.\"\"\"\n",
    "    try:\n",
    "        endpoint = os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
    "        if not endpoint:\n",
    "            logger.warning(\"CAPELLA_API_ENDPOINT not configured\")\n",
    "            return False\n",
    "\n",
    "        # Test basic HTTP connectivity\n",
    "        logger.info(\"Testing Capella AI connectivity...\")\n",
    "        response = requests.get(f\"{endpoint}/health\", timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            logger.warning(f\"Capella AI health check failed: {response.status_code}\")\n",
    "\n",
    "        # Test embedding model (requires API key)\n",
    "        if os.getenv(\"CB_USERNAME\") and os.getenv(\"CB_PASSWORD\"):\n",
    "            api_key = base64.b64encode(\n",
    "                f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
    "            ).decode()\n",
    "\n",
    "            headers = {\"Authorization\": f\"Basic {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "            # Test embedding\n",
    "            embedding_data = {\n",
    "                \"model\": os.getenv(\n",
    "                    \"CAPELLA_API_EMBEDDING_MODEL\", \"intfloat/e5-mistral-7b-instruct\"\n",
    "                ),\n",
    "                \"input\": \"test connectivity\",\n",
    "            }\n",
    "\n",
    "            embedding_response = requests.post(\n",
    "                f\"{endpoint}/v1/embeddings\", headers=headers, json=embedding_data, timeout=30\n",
    "            )\n",
    "\n",
    "            if embedding_response.status_code == 200:\n",
    "                embed_result = embedding_response.json()\n",
    "                embed_dims = len(embed_result[\"data\"][0][\"embedding\"])\n",
    "                logger.info(f\"✅ Capella AI embedding test successful - dimensions: {embed_dims}\")\n",
    "\n",
    "                if embed_dims != 4096:\n",
    "                    logger.warning(f\"Expected 4096 dimensions, got {embed_dims}\")\n",
    "                    return False\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"Capella AI embedding test failed: {embedding_response.status_code}\"\n",
    "                )\n",
    "                return False\n",
    "\n",
    "            # Test LLM\n",
    "            llm_data = {\n",
    "                \"model\": os.getenv(\"CAPELLA_API_LLM_MODEL\", \"meta-llama/Llama-3.1-8B-Instruct\"),\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                \"max_tokens\": 10,\n",
    "            }\n",
    "\n",
    "            llm_response = requests.post(\n",
    "                f\"{endpoint}/v1/chat/completions\", headers=headers, json=llm_data, timeout=30\n",
    "            )\n",
    "\n",
    "            if llm_response.status_code == 200:\n",
    "                logger.info(\"✅ Capella AI LLM test successful\")\n",
    "            else:\n",
    "                logger.warning(f\"Capella AI LLM test failed: {llm_response.status_code}\")\n",
    "                return False\n",
    "\n",
    "        logger.info(\"✅ Capella AI connectivity tests completed successfully\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Capella AI connectivity test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if os.environ.get(var) is None:\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}: \")\n",
    "\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup required environment variables with defaults.\"\"\"\n",
    "    # Setup Capella AI configuration first\n",
    "    setup_capella_ai_config()\n",
    "\n",
    "    # Required variables\n",
    "    required_vars = [\"OPENAI_API_KEY\", \"CB_CONN_STRING\", \"CB_USERNAME\", \"CB_PASSWORD\", \"CB_BUCKET\"]\n",
    "    for var in required_vars:\n",
    "        _set_if_undefined(var)\n",
    "\n",
    "    defaults = {\n",
    "        \"CB_CONN_STRING\": \"couchbase://localhost\",\n",
    "        \"CB_USERNAME\": \"Administrator\",\n",
    "        \"CB_PASSWORD\": \"password\",\n",
    "        \"CB_BUCKET\": \"vector-search-testing\",\n",
    "    }\n",
    "\n",
    "    for key, default_value in defaults.items():\n",
    "        if not os.environ.get(key):\n",
    "            os.environ[key] = input(f\"Enter {key} (default: {default_value}): \") or default_value\n",
    "\n",
    "    os.environ[\"INDEX_NAME\"] = os.getenv(\"INDEX_NAME\", \"vector_search_agentcatalog\")\n",
    "    os.environ[\"SCOPE_NAME\"] = os.getenv(\"SCOPE_NAME\", \"shared\")\n",
    "    os.environ[\"COLLECTION_NAME\"] = os.getenv(\"COLLECTION_NAME\", \"agentcatalog\")\n",
    "\n",
    "    # Test Capella AI connectivity\n",
    "    test_capella_connectivity()\n",
    "\n",
    "\n",
    "setup_environment()\n",
    "print(\"Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CouchbaseClient Class\n",
    "\n",
    "Define the CouchbaseClient for all database operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouchbaseClient:\n",
    "    \"\"\"Centralized Couchbase client for all database operations.\"\"\"\n",
    "\n",
    "    def __init__(self, conn_string: str, username: str, password: str, bucket_name: str):\n",
    "        \"\"\"Initialize Couchbase client with connection details.\"\"\"\n",
    "        self.conn_string = conn_string\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.bucket_name = bucket_name\n",
    "        self.cluster = None\n",
    "        self.bucket = None\n",
    "        self._collections = {}\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to Couchbase cluster.\"\"\"\n",
    "        try:\n",
    "            auth = PasswordAuthenticator(self.username, self.password)\n",
    "            options = ClusterOptions(auth)\n",
    "            # Use WAN profile for better timeout handling with remote clusters\n",
    "            options.apply_profile(\"wan_development\")\n",
    "            self.cluster = Cluster(self.conn_string, options)\n",
    "            self.cluster.wait_until_ready(timedelta(seconds=10))\n",
    "            logger.info(\"Successfully connected to Couchbase\")\n",
    "            return self.cluster\n",
    "        except Exception as e:\n",
    "            raise ConnectionError(f\"Failed to connect to Couchbase: {e!s}\")\n",
    "\n",
    "    def setup_collection(self, scope_name: str, collection_name: str):\n",
    "        \"\"\"Setup bucket, scope and collection all in one function.\"\"\"\n",
    "        try:\n",
    "            if not self.cluster:\n",
    "                self.connect()\n",
    "\n",
    "            if not self.bucket:\n",
    "                try:\n",
    "                    self.bucket = self.cluster.bucket(self.bucket_name)\n",
    "                    logger.info(f\"Bucket '{self.bucket_name}' exists\")\n",
    "                except Exception:\n",
    "                    logger.info(f\"Creating bucket '{self.bucket_name}'...\")\n",
    "                    bucket_settings = CreateBucketSettings(\n",
    "                        name=self.bucket_name,\n",
    "                        bucket_type=\"couchbase\",\n",
    "                        ram_quota_mb=1024,\n",
    "                        flush_enabled=True,\n",
    "                        num_replicas=0,\n",
    "                    )\n",
    "                    self.cluster.buckets().create_bucket(bucket_settings)\n",
    "                    time.sleep(5)\n",
    "                    self.bucket = self.cluster.bucket(self.bucket_name)\n",
    "                    logger.info(f\"Bucket '{self.bucket_name}' created successfully\")\n",
    "\n",
    "            bucket_manager = self.bucket.collections()\n",
    "            scopes = bucket_manager.get_all_scopes()\n",
    "            scope_exists = any(scope.name == scope_name for scope in scopes)\n",
    "\n",
    "            if not scope_exists and scope_name != \"_default\":\n",
    "                logger.info(f\"Creating scope '{scope_name}'...\")\n",
    "                bucket_manager.create_scope(scope_name)\n",
    "                logger.info(f\"Scope '{scope_name}' created successfully\")\n",
    "\n",
    "            collections = bucket_manager.get_all_scopes()\n",
    "            collection_exists = any(\n",
    "                scope.name == scope_name\n",
    "                and collection_name in [col.name for col in scope.collections]\n",
    "                for scope in collections\n",
    "            )\n",
    "\n",
    "            if not collection_exists:\n",
    "                logger.info(f\"Creating collection '{collection_name}'...\")\n",
    "                bucket_manager.create_collection(scope_name, collection_name)\n",
    "                logger.info(f\"Collection '{collection_name}' created successfully\")\n",
    "\n",
    "            collection = self.bucket.scope(scope_name).collection(collection_name)\n",
    "            time.sleep(3)\n",
    "\n",
    "            try:\n",
    "                self.cluster.query(\n",
    "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "                ).execute()\n",
    "                logger.info(\"Primary index created successfully\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error creating primary index: {e!s}\")\n",
    "\n",
    "            collection_key = f\"{scope_name}.{collection_name}\"\n",
    "            self._collections[collection_key] = collection\n",
    "\n",
    "            logger.info(f\"Collection setup complete for {scope_name}.{collection_name}\")\n",
    "            return collection\n",
    "\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error setting up collection: {e!s}\")\n",
    "\n",
    "    def get_collection(self, scope_name: str, collection_name: str):\n",
    "        \"\"\"Get a collection, creating it if it doesn't exist.\"\"\"\n",
    "        collection_key = f\"{scope_name}.{collection_name}\"\n",
    "        if collection_key not in self._collections:\n",
    "            self.setup_collection(scope_name, collection_name)\n",
    "        return self._collections[collection_key]\n",
    "\n",
    "    def clear_scope(self, scope_name: str):\n",
    "        \"\"\"Clear all collections in the specified scope.\"\"\"\n",
    "        try:\n",
    "            if not self.bucket:\n",
    "                if not self.cluster:\n",
    "                    self.connect()\n",
    "                self.bucket = self.cluster.bucket(self.bucket_name)\n",
    "\n",
    "            bucket_manager = self.bucket.collections()\n",
    "            scopes = bucket_manager.get_all_scopes()\n",
    "\n",
    "            target_scope = None\n",
    "            for scope in scopes:\n",
    "                if scope.name == scope_name:\n",
    "                    target_scope = scope\n",
    "                    break\n",
    "\n",
    "            if not target_scope:\n",
    "                logger.info(f\"Scope '{scope_name}' does not exist, nothing to clear\")\n",
    "                return\n",
    "\n",
    "            for collection in target_scope.collections:\n",
    "                try:\n",
    "                    delete_query = (\n",
    "                        f\"DELETE FROM `{self.bucket_name}`.`{scope_name}`.`{collection.name}`\"\n",
    "                    )\n",
    "                    self.cluster.query(delete_query).execute()\n",
    "                    logger.info(f\"Cleared collection '{collection.name}' in scope '{scope_name}'\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not clear collection '{collection.name}': {e}\")\n",
    "\n",
    "            logger.info(f\"Cleared all collections in scope '{scope_name}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not clear scope '{scope_name}': {e}\")\n",
    "\n",
    "    def setup_vector_search_index(self, index_definition: dict, scope_name: str):\n",
    "        \"\"\"Setup vector search index for the specified scope.\"\"\"\n",
    "        try:\n",
    "            if not self.bucket:\n",
    "                raise RuntimeError(\"Bucket not initialized. Call setup_collection first.\")\n",
    "\n",
    "            scope_index_manager = self.bucket.scope(scope_name).search_indexes()\n",
    "            existing_indexes = scope_index_manager.get_all_indexes()\n",
    "            index_name = index_definition[\"name\"]\n",
    "\n",
    "            if index_name not in [index.name for index in existing_indexes]:\n",
    "                logger.info(f\"Creating vector search index '{index_name}'...\")\n",
    "                search_index = SearchIndex.from_json(index_definition)\n",
    "                scope_index_manager.upsert_index(search_index)\n",
    "                logger.info(f\"Vector search index '{index_name}' created successfully\")\n",
    "            else:\n",
    "                logger.info(f\"Vector search index '{index_name}' already exists\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error setting up vector search index: {e!s}\")\n",
    "\n",
    "    def load_flight_data(self):\n",
    "        \"\"\"Load flight data from the enhanced flight_data.py file.\"\"\"\n",
    "        try:\n",
    "            # Import flight data\n",
    "            sys.path.append(os.path.join(os.path.dirname(__file__), \"data\"))\n",
    "            from flight_data import get_all_flight_data\n",
    "\n",
    "            flight_data = get_all_flight_data()\n",
    "\n",
    "            # Convert to text format for vector store\n",
    "            flight_texts = []\n",
    "            for item in flight_data:\n",
    "                text = f\"{item['title']} - {item['content']}\"\n",
    "                flight_texts.append(text)\n",
    "\n",
    "            return flight_texts\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading flight data: {e!s}\")\n",
    "\n",
    "    def setup_vector_store(\n",
    "        self, scope_name: str, collection_name: str, index_name: str, embeddings\n",
    "    ):\n",
    "        \"\"\"Setup vector store with flight data.\"\"\"\n",
    "        try:\n",
    "            if not self.cluster:\n",
    "                raise RuntimeError(\"Cluster not connected. Call connect first.\")\n",
    "\n",
    "            vector_store = CouchbaseVectorStore(\n",
    "                cluster=self.cluster,\n",
    "                bucket_name=self.bucket_name,\n",
    "                scope_name=scope_name,\n",
    "                collection_name=collection_name,\n",
    "                embedding=embeddings,\n",
    "                index_name=index_name,\n",
    "            )\n",
    "\n",
    "            # Load flight data - single attempt\n",
    "            try:\n",
    "                flight_data = self.load_flight_data()\n",
    "                vector_store.add_texts(texts=flight_data, batch_size=10)\n",
    "                logger.info(\"Flight data loaded into vector store successfully\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load flight data: {e}\")\n",
    "                logger.warning(\"Vector store created but data not loaded.\")\n",
    "\n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error setting up vector store: {e!s}\")\n",
    "\n",
    "\n",
    "print(\"CouchbaseClient defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Mapper\n",
    "\n",
    "Define the ParameterMapper class with ReAct artifact cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterMapper:\n",
    "    \"\"\"Intelligent parameter mapper using LLM with guardrail-safe prompts.\"\"\"\n",
    "\n",
    "    def __init__(self, chat_model: ChatOpenAI):\n",
    "        self.chat_model = chat_model\n",
    "\n",
    "        # Common parameter synonyms for flight tools\n",
    "        self.parameter_synonyms = {\n",
    "            \"source_airport\": [\"departure_airport\", \"origin\", \"from\", \"origin_airport\", \"start\"],\n",
    "            \"destination_airport\": [\"arrival_airport\", \"destination\", \"to\", \"dest\", \"end\"],\n",
    "            \"departure_date\": [\"date\", \"travel_date\", \"dep_date\", \"when\"],\n",
    "            \"return_date\": [\"return\", \"return_date\", \"back_date\"],\n",
    "            \"passengers\": [\"pax\", \"travelers\", \"people\", \"passenger_count\"],\n",
    "            \"flight_class\": [\"class\", \"cabin\", \"service_class\", \"ticket_class\"],\n",
    "        }\n",
    "\n",
    "    def get_function_parameters(self, func) -> set[str]:\n",
    "        \"\"\"Extract parameter names from function signature.\"\"\"\n",
    "        try:\n",
    "            sig = inspect.signature(func)\n",
    "            return set(sig.parameters.keys())\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Error getting function parameters\")\n",
    "            return set()\n",
    "\n",
    "    def map_parameters_smart(\n",
    "        self, tool_name: str, raw_args: dict[str, Any], func\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Smart parameter mapping using LLM to understand parameter intent.\n",
    "\n",
    "        Args:\n",
    "            tool_name: Name of the tool being called\n",
    "            raw_args: Raw arguments from LLM\n",
    "            func: Function object to get expected parameters\n",
    "\n",
    "        Returns:\n",
    "            Mapped parameters ready for function call\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get expected parameters from function signature\n",
    "            expected_params = self.get_function_parameters(func)\n",
    "\n",
    "            # If parameters already match, return as-is\n",
    "            if set(raw_args.keys()).issubset(expected_params):\n",
    "                return raw_args\n",
    "\n",
    "            # Use LLM to map parameters intelligently with guardrail-safe prompts\n",
    "            mapped_params = self._llm_parameter_mapping(tool_name, raw_args, expected_params)\n",
    "\n",
    "            # Add tool-specific defaults\n",
    "            mapped_params = self._add_tool_defaults(tool_name, mapped_params)\n",
    "\n",
    "            # Filter to only valid parameters\n",
    "            final_params = {k: v for k, v in mapped_params.items() if k in expected_params}\n",
    "\n",
    "            return final_params\n",
    "\n",
    "        except Exception:\n",
    "            logger.exception(\"Error in smart parameter mapping\")\n",
    "            # Fallback to synonym-based mapping\n",
    "            return self._fallback_synonym_mapping(raw_args, expected_params)\n",
    "\n",
    "    def _llm_parameter_mapping(\n",
    "        self, tool_name: str, raw_args: dict[str, Any], expected_params: set[str]\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Use LLM to map parameters with minimal, guardrail-safe prompts.\"\"\"\n",
    "\n",
    "        # Ultra-minimal prompt to avoid guardrail violations\n",
    "        system_prompt = f\"\"\"Map parameters to: {list(expected_params)}\n",
    "Output only valid JSON.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Input: {json.dumps(raw_args)}\n",
    "Tool: {tool_name}\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Primary LLM call with minimal prompt\n",
    "            mapped_params = self._safe_llm_call(system_prompt, user_prompt)\n",
    "            if mapped_params:\n",
    "                return mapped_params\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"LLM parameter mapping failed: {e}\")\n",
    "\n",
    "        # Fallback to synonym-based mapping\n",
    "        return self._fallback_synonym_mapping(raw_args, expected_params)\n",
    "\n",
    "    def _safe_llm_call(self, system_prompt: str, user_prompt: str) -> Optional[dict]:\n",
    "        \"\"\"Make safe LLM call with robust JSON parsing.\"\"\"\n",
    "        try:\n",
    "            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)]\n",
    "\n",
    "            response = self.chat_model.invoke(messages)\n",
    "            content = response.content.strip()\n",
    "\n",
    "            # Try multiple JSON parsing methods\n",
    "            return self._parse_json_response(content)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Safe LLM call failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _parse_json_response(self, content: str) -> Optional[dict]:\n",
    "        \"\"\"Parse JSON response with multiple fallback methods.\"\"\"\n",
    "\n",
    "        logger.debug(f\"Parsing JSON response: '{content[:200]}...' (length: {len(content)})\")\n",
    "\n",
    "        # Method 1: Direct JSON parsing\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.debug(f\"Direct JSON parsing failed: {e}\")\n",
    "            pass\n",
    "\n",
    "        # Method 2: Extract from code blocks\n",
    "        try:\n",
    "            if \"```json\" in content:\n",
    "                json_content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                return json.loads(json_content)\n",
    "            elif \"```\" in content:\n",
    "                json_content = content.split(\"```\")[1].strip()\n",
    "                return json.loads(json_content)\n",
    "        except (json.JSONDecodeError, IndexError):\n",
    "            pass\n",
    "\n",
    "        # Method 3: Find JSON-like patterns\n",
    "        try:\n",
    "            # Look for balanced {.*} patterns\n",
    "            json_pattern = r\"\\{[^{}]*\\}\"\n",
    "            matches = re.findall(json_pattern, content)\n",
    "            if matches:\n",
    "                return json.loads(matches[0])\n",
    "        except (json.JSONDecodeError, IndexError):\n",
    "            pass\n",
    "\n",
    "        # Method 3b: More complex JSON pattern with nested braces\n",
    "        try:\n",
    "            # Find JSON with proper brace matching\n",
    "            start = content.find(\"{\")\n",
    "            if start != -1:\n",
    "                brace_count = 0\n",
    "                for i, char in enumerate(content[start:], start):\n",
    "                    if char == \"{\":\n",
    "                        brace_count += 1\n",
    "                    elif char == \"}\":\n",
    "                        brace_count -= 1\n",
    "                        if brace_count == 0:\n",
    "                            json_content = content[start : i + 1]\n",
    "                            return json.loads(json_content)\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            pass\n",
    "\n",
    "        # Method 4: Handle truncated JSON (common at character 168)\n",
    "        try:\n",
    "            # If content appears truncated, try to find the last complete JSON object\n",
    "            if len(content) >= 160:  # Near the problematic character range\n",
    "                # Look for the last complete brace pair\n",
    "                last_close_brace = content.rfind(\"}\")\n",
    "                if last_close_brace > 0:\n",
    "                    # Find the matching opening brace\n",
    "                    brace_count = 0\n",
    "                    for i in range(last_close_brace, -1, -1):\n",
    "                        if content[i] == \"}\":\n",
    "                            brace_count += 1\n",
    "                        elif content[i] == \"{\":\n",
    "                            brace_count -= 1\n",
    "                            if brace_count == 0:\n",
    "                                truncated_json = content[i : last_close_brace + 1]\n",
    "                                logger.debug(f\"Trying truncated JSON: '{truncated_json}'\")\n",
    "                                return json.loads(truncated_json)\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            pass\n",
    "\n",
    "        # Method 5: Clean and retry\n",
    "        try:\n",
    "            # Remove extra whitespace and try again\n",
    "            cleaned = re.sub(r\"\\s+\", \" \", content.strip())\n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        # Method 6: Emergency fallback - try to construct basic JSON from visible patterns\n",
    "        try:\n",
    "            # Look for key-value pairs and construct basic JSON\n",
    "            if \"source_airport\" in content and \"destination_airport\" in content:\n",
    "                # Try to extract airport codes with regex\n",
    "                source_match = re.search(r'\"source_airport\"\\s*:\\s*\"([^\"]*)\"', content)\n",
    "                dest_match = re.search(r'\"destination_airport\"\\s*:\\s*\"([^\"]*)\"', content)\n",
    "\n",
    "                if source_match and dest_match:\n",
    "                    fallback_json = {\n",
    "                        \"source_airport\": source_match.group(1),\n",
    "                        \"destination_airport\": dest_match.group(1),\n",
    "                    }\n",
    "                    logger.debug(f\"Emergency fallback JSON: {fallback_json}\")\n",
    "                    return fallback_json\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        logger.warning(\n",
    "            f\"Failed to parse JSON response (length: {len(content)}): {content[:200]}...\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    def _fallback_synonym_mapping(\n",
    "        self, raw_args: dict[str, Any], expected_params: set[str]\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Fallback to synonym-based mapping if LLM fails.\"\"\"\n",
    "        mapped = {}\n",
    "\n",
    "        for expected_param in expected_params:\n",
    "            # Check if parameter exists directly\n",
    "            if expected_param in raw_args:\n",
    "                mapped[expected_param] = raw_args[expected_param]\n",
    "                continue\n",
    "\n",
    "            # Check synonyms\n",
    "            synonyms = self.parameter_synonyms.get(expected_param, [])\n",
    "            for synonym in synonyms:\n",
    "                if synonym in raw_args:\n",
    "                    mapped[expected_param] = raw_args[synonym]\n",
    "                    break\n",
    "\n",
    "        return mapped\n",
    "\n",
    "    def _add_tool_defaults(self, tool_name: str, params: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Add tool-specific defaults for single user system.\"\"\"\n",
    "\n",
    "        if tool_name == \"save_flight_booking\":\n",
    "            # Default departure date if missing\n",
    "            if \"departure_date\" not in params:\n",
    "                params[\"departure_date\"] = \"tomorrow\"\n",
    "\n",
    "            # Default passengers if missing\n",
    "            if \"passengers\" not in params:\n",
    "                params[\"passengers\"] = 1\n",
    "\n",
    "            # Default flight class if missing\n",
    "            if \"flight_class\" not in params:\n",
    "                params[\"flight_class\"] = \"economy\"\n",
    "\n",
    "        elif tool_name == \"retrieve_flight_bookings\":\n",
    "            # No customer_id needed for single user system\n",
    "            pass\n",
    "\n",
    "        return params\n",
    "\n",
    "    def extract_airports_from_text(self, text: str) -> dict[str, Optional[str]]:\n",
    "        \"\"\"Extract airport codes from text using guardrail-safe LLM calls.\"\"\"\n",
    "\n",
    "        # Ultra-minimal prompt for location code extraction\n",
    "        system_prompt = (\n",
    "            \"Extract location codes. Return JSON with source_airport and destination_airport.\"\n",
    "        )\n",
    "        user_prompt = f\"Text: {text}\"\n",
    "\n",
    "        try:\n",
    "            # Try LLM extraction with minimal prompt\n",
    "            result = self._safe_llm_call(system_prompt, user_prompt)\n",
    "            if result and isinstance(result, dict):\n",
    "                # Validate and clean the result\n",
    "                cleaned_result = {}\n",
    "                for key in [\"source_airport\", \"destination_airport\"]:\n",
    "                    value = result.get(key)\n",
    "                    if value and isinstance(value, str) and len(value) == 3:\n",
    "                        cleaned_result[key] = value.upper()\n",
    "                    else:\n",
    "                        cleaned_result[key] = None\n",
    "                return cleaned_result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"LLM airport extraction failed: {e}\")\n",
    "\n",
    "        # Fallback to pattern matching\n",
    "        return self._fallback_airport_extraction(text)\n",
    "\n",
    "    def _fallback_airport_extraction(self, text: str) -> dict[str, Optional[str]]:\n",
    "        \"\"\"Fallback airport extraction using regex patterns.\"\"\"\n",
    "        result = {\"source_airport\": None, \"destination_airport\": None}\n",
    "\n",
    "        # Find 3-letter codes\n",
    "        airport_codes = re.findall(r\"\\b[A-Z]{3}\\b\", text.upper())\n",
    "\n",
    "        if len(airport_codes) >= 2:\n",
    "            result[\"source_airport\"] = airport_codes[0]\n",
    "            result[\"destination_airport\"] = airport_codes[1]\n",
    "        elif len(airport_codes) == 1:\n",
    "            # Try to determine if it's source or destination\n",
    "            if any(word in text.lower() for word in [\"from\", \"origin\"]):\n",
    "                result[\"source_airport\"] = airport_codes[0]\n",
    "            elif any(word in text.lower() for word in [\"to\", \"destination\"]):\n",
    "                result[\"destination_airport\"] = airport_codes[0]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def map_positional_args(self, tool_name: str, args: tuple, func) -> dict[str, Any]:\n",
    "        \"\"\"Map positional arguments from ReAct agent to function parameters.\"\"\"\n",
    "        try:\n",
    "            expected_params = self.get_function_parameters(func)\n",
    "\n",
    "            # Map positional args to expected parameter names\n",
    "            mapped = {}\n",
    "\n",
    "            if tool_name == \"lookup_flight_info\":\n",
    "                # Expects source_airport, destination_airport\n",
    "                if len(args) >= 2:\n",
    "                    mapped[\"source_airport\"] = args[0]\n",
    "                    mapped[\"destination_airport\"] = args[1]\n",
    "                elif len(args) == 1:\n",
    "                    # Try to extract both from single string\n",
    "                    airports = self.extract_airports_from_text(args[0])\n",
    "                    mapped.update(airports)\n",
    "\n",
    "            elif tool_name == \"save_flight_booking\":\n",
    "                # Map based on position and add defaults\n",
    "                if len(args) >= 2:\n",
    "                    mapped[\"source_airport\"] = args[0]\n",
    "                    mapped[\"destination_airport\"] = args[1]\n",
    "                if len(args) >= 3:\n",
    "                    mapped[\"departure_date\"] = args[2]\n",
    "\n",
    "                # Add defaults for missing parameters\n",
    "                mapped = self._add_tool_defaults(tool_name, mapped)\n",
    "\n",
    "            elif tool_name == \"search_flight_policies\":\n",
    "                # Single query parameter\n",
    "                if len(args) >= 1:\n",
    "                    mapped[\"query\"] = \" \".join(args)\n",
    "\n",
    "            # Filter to only valid parameters\n",
    "            final_mapped = {k: v for k, v in mapped.items() if k in expected_params}\n",
    "            return final_mapped\n",
    "\n",
    "        except Exception:\n",
    "            logger.exception(\"Error mapping positional args for %s\", tool_name)\n",
    "            return {}\n",
    "\n",
    "    def map_string_input(self, tool_name: str, input_str: str, func) -> dict[str, Any]:\n",
    "        \"\"\"Map single string input to function parameters.\"\"\"\n",
    "        try:\n",
    "            expected_params = self.get_function_parameters(func)\n",
    "            mapped = {}\n",
    "\n",
    "            logger.debug(\n",
    "                f\"Parameter mapping for {tool_name}: input='{input_str}', expected={expected_params}\"\n",
    "            )\n",
    "\n",
    "            # Enhanced cleaning for ReAct parsing artifacts\n",
    "            clean_input = self._clean_react_artifacts(input_str)\n",
    "\n",
    "            # Debug logging for edge cases\n",
    "            if input_str != clean_input:\n",
    "                logger.debug(\n",
    "                    f\"Cleaned ReAct artifacts for {tool_name}: '{input_str}' -> '{clean_input}'\"\n",
    "                )\n",
    "\n",
    "            if tool_name == \"lookup_flight_info\":\n",
    "                # Handle comma-separated format: \"JFK,LAX,tomorrow\"\n",
    "                parts = [part.strip() for part in clean_input.split(\",\")]\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    # Direct airport codes\n",
    "                    mapped[\"source_airport\"] = parts[0].upper()\n",
    "                    mapped[\"destination_airport\"] = parts[1].upper()\n",
    "                else:\n",
    "                    # Try to extract airports from string\n",
    "                    airports = self.extract_airports_from_text(clean_input)\n",
    "                    mapped.update(airports)\n",
    "\n",
    "            elif tool_name == \"save_flight_booking\":\n",
    "                # Handle comma-separated format: \"SOURCE,DEST,DATE,PASSENGERS,CLASS\"\n",
    "                parts = [part.strip() for part in clean_input.split(\",\")]\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    mapped[\"source_airport\"] = parts[0].upper()\n",
    "                    mapped[\"destination_airport\"] = parts[1].upper()\n",
    "\n",
    "                    # Handle positional parameters\n",
    "                    if len(parts) >= 3:\n",
    "                        mapped[\"departure_date\"] = parts[2]\n",
    "                    if len(parts) >= 4:\n",
    "                        # Try to parse passengers as integer\n",
    "                        try:\n",
    "                            mapped[\"passengers\"] = int(parts[3])\n",
    "                        except ValueError:\n",
    "                            # If not integer, check if it contains a number\n",
    "                            numbers = re.findall(r\"\\d+\", parts[3])\n",
    "                            if numbers:\n",
    "                                mapped[\"passengers\"] = int(numbers[0])\n",
    "                    if len(parts) >= 5:\n",
    "                        # Enhanced cleaning for flight class with ReAct artifacts\n",
    "                        flight_class = self._clean_flight_class(parts[4])\n",
    "                        if flight_class:\n",
    "                            mapped[\"flight_class\"] = flight_class\n",
    "                else:\n",
    "                    # Try to extract flight info from text\n",
    "                    airports = self.extract_airports_from_text(clean_input)\n",
    "                    mapped.update(airports)\n",
    "\n",
    "                # Add defaults\n",
    "                mapped = self._add_tool_defaults(tool_name, mapped)\n",
    "\n",
    "            elif tool_name == \"search_flight_policies\":\n",
    "                # Use cleaned string as query\n",
    "                mapped[\"query\"] = clean_input\n",
    "\n",
    "            elif tool_name == \"retrieve_flight_bookings\":\n",
    "                # No parameters needed for single user system\n",
    "                pass\n",
    "\n",
    "            # Filter to only valid parameters\n",
    "            final_mapped = {\n",
    "                k: v for k, v in mapped.items() if k in expected_params and v is not None\n",
    "            }\n",
    "\n",
    "            logger.debug(f\"Parameter mapping result for {tool_name}: {final_mapped}\")\n",
    "\n",
    "            if not final_mapped:\n",
    "                logger.warning(\n",
    "                    f\"No valid parameters mapped for {tool_name} with input '{input_str}'\"\n",
    "                )\n",
    "\n",
    "            return final_mapped\n",
    "\n",
    "        except Exception:\n",
    "            logger.exception(\"Error mapping string input for %s\", tool_name)\n",
    "            return {}\n",
    "\n",
    "    def _clean_react_artifacts(self, input_str: str) -> str:\n",
    "        \"\"\"Clean ReAct parsing artifacts from input string.\"\"\"\n",
    "        if not input_str:\n",
    "            return \"\"\n",
    "\n",
    "        # Remove common ReAct artifacts\n",
    "        clean_str = input_str\n",
    "\n",
    "        # Enhanced cleaning for ReAct artifacts - handle multi-line patterns\n",
    "        # Remove trailing quotes and observation artifacts (case insensitive)\n",
    "        clean_str = re.sub(\n",
    "            r'[\"\\']?\\s*\\n?\\s*observation.*$', \"\", clean_str, flags=re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "\n",
    "        # Remove newlines followed by any text (common ReAct artifact)\n",
    "        clean_str = re.sub(r\"\\n.*$\", \"\", clean_str, flags=re.DOTALL)\n",
    "\n",
    "        # Remove leading/trailing quotes and whitespace\n",
    "        clean_str = clean_str.strip().strip(\"\\\"'\").strip()\n",
    "\n",
    "        # Handle specific ReAct patterns like \\\"None\\nObservation\\\"\n",
    "        if clean_str.lower().startswith(\"none\"):\n",
    "            # Extract just \\\"none\\\" if it starts with none followed by artifacts\n",
    "            clean_str = \"none\"\n",
    "\n",
    "        return clean_str\n",
    "\n",
    "    def _clean_flight_class(self, flight_class_str: str) -> str:\n",
    "        \"\"\"Clean flight class parameter with enhanced artifact removal.\"\"\"\n",
    "        if not flight_class_str:\n",
    "            return \"\"\n",
    "\n",
    "        # Start with basic cleaning\n",
    "        cleaned = flight_class_str.strip().lower()\n",
    "\n",
    "        # Remove quotes\n",
    "        cleaned = cleaned.strip(\"\\\"'\")\n",
    "\n",
    "        # Remove observation artifacts (case insensitive)\n",
    "        cleaned = re.sub(r'\\s*[\"\\']?\\s*observation.*$', \"\", cleaned, flags=re.IGNORECASE)\n",
    "\n",
    "        # Remove newlines and everything after\n",
    "        cleaned = re.sub(r\"\\n.*$\", \"\", cleaned)\n",
    "\n",
    "        # Remove any remaining special characters at the end\n",
    "        cleaned = re.sub(r\"[^a-zA-Z]+$\", \"\", cleaned)\n",
    "\n",
    "        # Final trim\n",
    "        cleaned = cleaned.strip()\n",
    "\n",
    "        # Validate against known flight classes\n",
    "        valid_classes = [\"economy\", \"business\", \"first\", \"premium\"]\n",
    "        if cleaned in valid_classes:\n",
    "            return cleaned\n",
    "\n",
    "        # If not exact match, try to find closest match\n",
    "        for valid_class in valid_classes:\n",
    "            if valid_class in cleaned:\n",
    "                return valid_class\n",
    "\n",
    "        return cleaned  # Return as-is if no match found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parameter Mapping\n",
    "\n",
    "Test the parameter mapping functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of parameter mapping\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Test the parameter mapper\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "parameter_mapper = ParameterMapper(chat_model)\n",
    "\n",
    "\n",
    "# Mock function for testing\n",
    "def mock_save_booking(\n",
    "    source_airport: str,\n",
    "    destination_airport: str,\n",
    "    departure_date: str,\n",
    "    passengers: int = 1,\n",
    "    flight_class: str = \"economy\",\n",
    "):\n",
    "    return f\"Booked {passengers} passengers from {source_airport} to {destination_airport} on {departure_date} in {flight_class}\"\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_inputs = [\n",
    "    \"JFK,LAX,tomorrow,1,economy\",\n",
    "    'JFK,LAX,tomorrow,1,economy\"\\nobservation',  # ReAct artifact case\n",
    "    \"LAX,JFK,next week,2,business\",\n",
    "]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    print(f\"\\nTesting: '{test_input}'\")\n",
    "    result = parameter_mapper.map_string_input(\"save_flight_booking\", test_input, mock_save_booking)\n",
    "    print(f\"Mapped parameters: {result}\")\n",
    "    if result:\n",
    "        booking_result = mock_save_booking(**result)\n",
    "        print(f\"Result: {booking_result}\")\n",
    "\n",
    "print(\"\\nParameter mapping tests complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Classes\n",
    "\n",
    "Define the FlightSearchAgent with parameter mapping integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightSearchState(agentc_langgraph.agent.State):\n",
    "    \"\"\"State for flight search conversations - single user system.\"\"\"\n",
    "\n",
    "    query: str\n",
    "    resolved: bool\n",
    "    search_results: list[dict]\n",
    "\n",
    "\n",
    "class FlightSearchAgent(agentc_langgraph.agent.ReActAgent):\n",
    "    \"\"\"Flight search agent with robust parameter mapping.\"\"\"\n",
    "\n",
    "    def __init__(self, catalog: agentc.Catalog, span: agentc.Span):\n",
    "        \"\"\"Initialize the flight search agent.\"\"\"\n",
    "\n",
    "        # Try Capella AI first, fallback to OpenAI\n",
    "        chat_model = None\n",
    "        try:\n",
    "            if (\n",
    "                os.getenv(\"CB_USERNAME\")\n",
    "                and os.getenv(\"CB_PASSWORD\")\n",
    "                and os.getenv(\"CAPELLA_API_ENDPOINT\")\n",
    "                and os.getenv(\"CAPELLA_API_LLM_MODEL\")\n",
    "            ):\n",
    "                # Create API key for Capella AI\n",
    "                api_key = base64.b64encode(\n",
    "                    f\"{os.getenv('CB_USERNAME')}:{os.getenv('CB_PASSWORD')}\".encode()\n",
    "                ).decode()\n",
    "\n",
    "                chat_model = ChatOpenAI(\n",
    "                    model=os.getenv(\"CAPELLA_API_LLM_MODEL\"),\n",
    "                    api_key=api_key,\n",
    "                    base_url=f\"{os.getenv('CAPELLA_API_ENDPOINT')}/v1\",\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=512,\n",
    "                    timeout=30,\n",
    "                )\n",
    "                logger.info(\"✅ Using Capella AI for LLM\")\n",
    "            else:\n",
    "                raise ValueError(\"Capella AI credentials not available\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Capella AI LLM failed, falling back to OpenAI: {e}\")\n",
    "            model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "            chat_model = langchain_openai.chat_models.ChatOpenAI(\n",
    "                model=model_name, temperature=0.0, max_tokens=512, timeout=30\n",
    "            )\n",
    "            logger.info(\"✅ Using OpenAI for LLM (fallback)\")\n",
    "\n",
    "        super().__init__(\n",
    "            chat_model=chat_model, catalog=catalog, span=span, prompt_name=\"flight_search_assistant\"\n",
    "        )\n",
    "\n",
    "    def _invoke(\n",
    "        self,\n",
    "        span: agentc.Span,\n",
    "        state: FlightSearchState,\n",
    "        config: langchain_core.runnables.RunnableConfig,\n",
    "    ) -> FlightSearchState:\n",
    "        \"\"\"Handle flight search conversation using ReActAgent.\"\"\"\n",
    "\n",
    "        if not state[\"messages\"]:\n",
    "            initial_msg = langchain_core.messages.HumanMessage(content=state[\"query\"])\n",
    "            state[\"messages\"].append(initial_msg)\n",
    "            logger.info(f\"Flight Query: {state['query']}\")\n",
    "\n",
    "        # Initialize parameter mapper\n",
    "        parameter_mapper = ParameterMapper(self.chat_model)\n",
    "\n",
    "        tools = []\n",
    "        for tool_name in [\n",
    "            \"lookup_flight_info\",\n",
    "            \"save_flight_booking\",\n",
    "            \"retrieve_flight_bookings\",\n",
    "            \"search_flight_policies\",\n",
    "        ]:\n",
    "            catalog_tool = self.catalog.find(\"tool\", name=tool_name)\n",
    "            logger.info(f\"Loaded tool: {tool_name}\")\n",
    "\n",
    "            def create_tool_wrapper(original_tool, name):\n",
    "                def wrapper_func(tool_input: str) -> str:\n",
    "                    \"\"\"Wrapper to handle parameter mapping using ParameterMapper.\"\"\"\n",
    "                    try:\n",
    "                        logger.debug(f\"Tool wrapper called for {name} with input: '{tool_input}'\")\n",
    "\n",
    "                        # Use ParameterMapper to intelligently map string input to parameters\n",
    "                        mapped_params = parameter_mapper.map_string_input(\n",
    "                            name, tool_input, original_tool.func\n",
    "                        )\n",
    "\n",
    "                        logger.debug(f\"Mapped parameters for {name}: {mapped_params}\")\n",
    "\n",
    "                        # Call the original tool with mapped parameters\n",
    "                        result = original_tool.func(**mapped_params)\n",
    "\n",
    "                        logger.debug(\n",
    "                            f\"Tool {name} result type: {type(result)}, length: {len(result) if hasattr(result, '__len__') else 'N/A'}\"\n",
    "                        )\n",
    "\n",
    "                        return result\n",
    "\n",
    "                    except openai.OpenAIError as e:\n",
    "                        logger.warning(f\"OpenAI service error in {name}: {e}\")\n",
    "                        return f\"The {name.replace('_', ' ')} service is temporarily unavailable. Please try again or contact customer service.\"\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error in tool wrapper for {name}: {e!s}\")\n",
    "                        return f\"Error calling {name}: {e!s}\"\n",
    "\n",
    "                return wrapper_func\n",
    "\n",
    "            langchain_tool = Tool(\n",
    "                name=tool_name,\n",
    "                description=f\"Tool for {tool_name.replace('_', ' ')}\",\n",
    "                func=create_tool_wrapper(catalog_tool, tool_name),\n",
    "            )\n",
    "            tools.append(langchain_tool)\n",
    "\n",
    "        # Get prompt from Agent Catalog\n",
    "        prompt_resource = self.catalog.find(\"prompt\", name=\"flight_search_assistant\")\n",
    "        react_prompt = PromptTemplate.from_template(prompt_resource.content)\n",
    "\n",
    "        # Create ReAct agent with tools and prompt\n",
    "        agent = create_react_agent(self.chat_model, tools, react_prompt)\n",
    "\n",
    "        # Create agent executor with optimized settings for Llama\n",
    "        agent_executor = AgentExecutor(\n",
    "            agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, max_iterations=8\n",
    "        )\n",
    "\n",
    "        # Execute the agent with enhanced error handling for Llama\n",
    "        try:\n",
    "            response = agent_executor.invoke({\"input\": state[\"query\"]})\n",
    "            output = response[\"output\"]\n",
    "        except openai.OpenAIError as e:\n",
    "            # Handle OpenAI service errors (model unavailable, health errors, etc.)\n",
    "            logger.warning(f\"OpenAI service error in agent execution: {e}\")\n",
    "            output = \"The flight search service is temporarily unavailable due to model maintenance. Please try again in a few minutes or contact customer service.\"\n",
    "        except Exception as e:\n",
    "            # Handle guardrail violations and other API errors gracefully\n",
    "            error_msg = str(e)\n",
    "            error_lower = error_msg.lower()\n",
    "\n",
    "            # Check for guardrail violations with expanded patterns\n",
    "            if (\n",
    "                \"guardrail_violation_error\" in error_lower\n",
    "                or \"guardrail violation\" in error_lower\n",
    "                or \"content policy\" in error_lower\n",
    "            ):\n",
    "                # Treat guardrails as warnings, not errors\n",
    "                logger.warning(f\"Guardrails content moderated: {error_msg}\")\n",
    "                output = \"I apologize, but I can't process that specific request due to content policies. Please try rephrasing your flight search query or ask about general flight information.\"\n",
    "\n",
    "            # Handle timeout errors\n",
    "            elif \"timeout\" in error_lower or \"timed out\" in error_lower:\n",
    "                logger.warning(f\"Request timeout: {error_msg}\")\n",
    "                output = \"The request timed out. Please try again with a simpler query.\"\n",
    "\n",
    "            # Handle connection errors\n",
    "            elif \"connection\" in error_lower or \"network\" in error_lower:\n",
    "                logger.warning(f\"Connection error: {error_msg}\")\n",
    "                output = \"I'm having trouble connecting to the flight database. Please try again in a moment.\"\n",
    "\n",
    "            # Handle JSON/parsing errors\n",
    "            elif \"json\" in error_lower or \"parsing\" in error_lower:\n",
    "                logger.warning(f\"Parsing error: {error_msg}\")\n",
    "                output = \"I had trouble understanding the flight data. Please try rephrasing your request.\"\n",
    "\n",
    "            # Handle API rate limiting\n",
    "            elif \"rate limit\" in error_lower or \"429\" in error_msg:\n",
    "                logger.warning(f\"Rate limit exceeded: {error_msg}\")\n",
    "                output = \"Too many requests. Please wait a moment before trying again.\"\n",
    "\n",
    "            # Generic error fallback - don't break the app\n",
    "            else:\n",
    "                logger.warning(f\"Unexpected error: {error_msg}\")\n",
    "                output = \"I encountered an unexpected issue. Please try again or contact support if the problem persists.\"\n",
    "\n",
    "            # Log the specific error type for debugging (but don't break the flow)\n",
    "            if \"guardrail\" in error_lower:\n",
    "                logger.info(\"Guardrails triggered - request handled gracefully\")\n",
    "            else:\n",
    "                logger.info(\"Non-guardrail error - handled gracefully\")\n",
    "\n",
    "        # Add response to conversation\n",
    "        assistant_msg = langchain_core.messages.AIMessage(content=output)\n",
    "        state[\"messages\"].append(assistant_msg)\n",
    "        state[\"resolved\"] = True\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "class FlightSearchGraph(agentc_langgraph.graph.GraphRunnable):\n",
    "    \"\"\"Flight search conversation graph.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build_starting_state(query: str) -> FlightSearchState:\n",
    "        \"\"\"Build the initial state for the flight search.\"\"\"\n",
    "        return FlightSearchState(\n",
    "            messages=[],\n",
    "            query=query,\n",
    "            resolved=False,\n",
    "            search_results=[],\n",
    "            previous_node=None,\n",
    "        )\n",
    "\n",
    "    def compile(self) -> langgraph.graph.graph.CompiledGraph:\n",
    "        \"\"\"Compile the LangGraph workflow.\"\"\"\n",
    "        search_agent = FlightSearchAgent(catalog=self.catalog, span=self.span)\n",
    "\n",
    "        def flight_search_node(state: FlightSearchState) -> FlightSearchState:\n",
    "            \"\"\"Wrapper function for the flight search ReActAgent.\"\"\"\n",
    "            with self.span.new(\"Flight Search Node\") as node_span:\n",
    "                return search_agent._invoke(\n",
    "                    span=node_span,\n",
    "                    state=state,\n",
    "                    config={},\n",
    "                )\n",
    "\n",
    "        workflow = langgraph.graph.StateGraph(FlightSearchState)\n",
    "        workflow.add_node(\"flight_search\", flight_search_node)\n",
    "        workflow.set_entry_point(\"flight_search\")\n",
    "        workflow.add_edge(\"flight_search\", langgraph.graph.END)\n",
    "\n",
    "        return workflow.compile()\n",
    "\n",
    "\n",
    "print(\"Agent classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Flight Bookings\n",
    "\n",
    "Clear existing bookings for clean test run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_flight_bookings():\n",
    "    \"\"\"Clear existing flight bookings to start fresh for demo.\"\"\"\n",
    "    try:\n",
    "        client = CouchbaseClient(\n",
    "            conn_string=os.getenv(\"CB_CONN_STRING\", \"couchbase://localhost\"),\n",
    "            username=os.getenv(\"CB_USERNAME\", \"Administrator\"),\n",
    "            password=os.getenv(\"CB_PASSWORD\", \"password\"),\n",
    "            bucket_name=os.getenv(\"CB_BUCKET\", \"vector-search-testing\"),\n",
    "        )\n",
    "        client.connect()\n",
    "\n",
    "        scope_name = \"agentc_bookings\"\n",
    "        client.clear_scope(scope_name)\n",
    "        logger.info(\"Cleared existing flight bookings for fresh test run\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not clear bookings: {e}\")\n",
    "\n",
    "\n",
    "# Clear existing bookings\n",
    "clear_flight_bookings()\n",
    "print(\"Cleared existing bookings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Flight Search Agent\n",
    "\n",
    "Initialize the complete flight search agent setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_flight_search_agent():\n",
    "    \"\"\"Setup flight search agent with all latest fixes.\"\"\"\n",
    "    try:\n",
    "        setup_environment()\n",
    "\n",
    "        # Initialize Agent Catalog\n",
    "        catalog = agentc.Catalog(\n",
    "            conn_string=os.environ[\"AGENT_CATALOG_CONN_STRING\"],\n",
    "            username=os.environ[\"AGENT_CATALOG_USERNAME\"],\n",
    "            password=os.environ[\"AGENT_CATALOG_PASSWORD\"],\n",
    "            bucket=os.environ[\"AGENT_CATALOG_BUCKET\"],\n",
    "        )\n",
    "        application_span = catalog.Span(name=\"Flight Search Agent\")\n",
    "\n",
    "        with application_span.new(\"Couchbase Setup\"):\n",
    "            client = CouchbaseClient(\n",
    "                conn_string=os.environ[\"CB_CONN_STRING\"],\n",
    "                username=os.environ[\"CB_USERNAME\"],\n",
    "                password=os.environ[\"CB_PASSWORD\"],\n",
    "                bucket_name=os.environ[\"CB_BUCKET\"],\n",
    "            )\n",
    "\n",
    "            client.setup_collection(\n",
    "                scope_name=os.environ[\"SCOPE_NAME\"], collection_name=os.environ[\"COLLECTION_NAME\"]\n",
    "            )\n",
    "\n",
    "        with application_span.new(\"Vector Store Setup\"):\n",
    "            embeddings = OpenAIEmbeddings(\n",
    "                api_key=os.environ[\"OPENAI_API_KEY\"], model=\"text-embedding-3-small\"\n",
    "            )\n",
    "            try:\n",
    "                vector_store = CouchbaseVectorStore(\n",
    "                    cluster=client.cluster,\n",
    "                    bucket_name=os.environ[\"CB_BUCKET\"],\n",
    "                    scope_name=os.environ[\"SCOPE_NAME\"],\n",
    "                    collection_name=os.environ[\"COLLECTION_NAME\"],\n",
    "                    embedding=embeddings,\n",
    "                    index_name=os.environ[\"INDEX_NAME\"],\n",
    "                )\n",
    "                logger.info(\"Vector store setup completed\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Vector store setup failed: {e}\")\n",
    "\n",
    "        with application_span.new(\"Agent Graph Creation\"):\n",
    "            flight_graph = FlightSearchGraph(catalog=catalog, span=application_span)\n",
    "            compiled_graph = flight_graph.compile()\n",
    "\n",
    "        logger.info(\"Agent Catalog integration successful\")\n",
    "        return compiled_graph, application_span\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Setup error: {e}\")\n",
    "        logger.info(\"Ensure Agent Catalog is published: agentc index . && agentc publish\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Setup the agent\n",
    "compiled_graph, application_span = setup_flight_search_agent()\n",
    "print(\"Flight search agent setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Function\n",
    "\n",
    "Define test function with better error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_query(test_number: int, query: str):\n",
    "    \"\"\"Run a single test query with error handling.\"\"\"\n",
    "    with application_span.new(f\"Test {test_number}: {query}\") as query_span:\n",
    "        logger.info(f\"\\n🔍 Test {test_number}: {query}\")\n",
    "        try:\n",
    "            query_span[\"query\"] = query\n",
    "            state = FlightSearchGraph.build_starting_state(query=query)\n",
    "            result = compiled_graph.invoke(state)\n",
    "            query_span[\"result\"] = result\n",
    "\n",
    "            if result.get(\"search_results\"):\n",
    "                logger.info(f\"Found {len(result['search_results'])} flight options\")\n",
    "            logger.info(f\"Test {test_number} completed: {result.get('resolved', False)}\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"❌ Test {test_number} failed: {e}\")\n",
    "            query_span[\"error\"] = str(e)\n",
    "            return None\n",
    "\n",
    "\n",
    "print(\"Test function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Flight Search\n",
    "\n",
    "Find flights from JFK to LAX for tomorrow - now with parameter mapping!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = run_test_query(1, \"Find flights from JFK to LAX for tomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Flight Booking (Business Class)\n",
    "\n",
    "Book a flight with parameter mapping - no more ReAct artifacts!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = run_test_query(\n",
    "    2, \"Book a flight from LAX to JFK for tomorrow, 2 passengers, business class\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Flight Booking (Economy Class)\n",
    "\n",
    "Book an economy flight - cleaning handles 'economy' correctly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = run_test_query(3, \"Book an economy flight from JFK to MIA for next week, 1 passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Retrieve Current Bookings\n",
    "\n",
    "Show current flight bookings with parameter handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = run_test_query(4, \"Show me my current flight bookings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Flight Policy Search\n",
    "\n",
    "Search flight policies with robust query handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = run_test_query(5, \"What are the baggage policies?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arize AI Integration Demo\n",
    "\n",
    "Demonstrate Phoenix observability and LLM-as-a-judge evaluation with Arize AI platform integration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Phoenix Observability\n",
    "\n",
    "Initialize Phoenix for observability and tracing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Phoenix observability\n",
    "try:\n",
    "    import phoenix as px\n",
    "    from phoenix.trace import using_project\n",
    "    from phoenix.trace.langchain import LangChainInstrumentor\n",
    "    from phoenix.trace.openai import OpenAIInstrumentor\n",
    "    from phoenix.evals import (\n",
    "        QA_PROMPT_RAILS_MAP,\n",
    "        QA_PROMPT_TEMPLATE,\n",
    "        OpenAIModel,\n",
    "        llm_classify,\n",
    "    )\n",
    "\n",
    "    PHOENIX_AVAILABLE = True\n",
    "    print(\"✅ Phoenix imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Phoenix not available: {e}\")\n",
    "    PHOENIX_AVAILABLE = False\n",
    "\n",
    "# Arize AI Configuration\n",
    "SPACE_ID = os.getenv(\"ARIZE_SPACE_ID\", \"your-space-id\")\n",
    "API_KEY = os.getenv(\"ARIZE_API_KEY\", \"your-api-key\")\n",
    "PROJECT_NAME = \"flight-search-agent-evaluation\"\n",
    "\n",
    "print(f\"Arize Space ID: {SPACE_ID}\")\n",
    "print(f\"Arize Project: {PROJECT_NAME}\")\n",
    "print(f\"Phoenix Available: {PHOENIX_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Phoenix Session\n",
    "\n",
    "Start Phoenix session with proper instrumentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PHOENIX_AVAILABLE:\n",
    "    # Start Phoenix session\n",
    "    session = px.launch_app()\n",
    "\n",
    "    # Instrument LangChain and OpenAI\n",
    "    LangChainInstrumentor().instrument()\n",
    "    OpenAIInstrumentor().instrument()\n",
    "\n",
    "    # Set project context\n",
    "    tracer = using_project(PROJECT_NAME)\n",
    "\n",
    "    print(f\"🚀 Phoenix session started\")\n",
    "    print(f\"📊 Phoenix UI available at: http://localhost:6006/\")\n",
    "    print(f\"📝 Project: {PROJECT_NAME}\")\n",
    "else:\n",
    "    print(\"⚠️ Phoenix not available - skipping observability setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Evaluation Dataset\n",
    "\n",
    "Define test queries for flight search agent evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation queries\n",
    "evaluation_queries = [\n",
    "    {\n",
    "        \"query\": \"Find flights from New York to Los Angeles tomorrow\",\n",
    "        \"query_type\": \"flight_search\",\n",
    "        \"expected_actions\": [\"lookup_flight_info\"],\n",
    "        \"expected_keywords\": [\"flights\", \"JFK\", \"LAX\", \"tomorrow\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Book a business class flight from LAX to JFK for 2 passengers\",\n",
    "        \"query_type\": \"flight_booking\",\n",
    "        \"expected_actions\": [\"save_flight_booking\"],\n",
    "        \"expected_keywords\": [\"booking\", \"business\", \"LAX\", \"JFK\", \"2 passengers\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Show me my current flight reservations\",\n",
    "        \"query_type\": \"booking_retrieval\",\n",
    "        \"expected_actions\": [\"retrieve_flight_bookings\"],\n",
    "        \"expected_keywords\": [\"bookings\", \"reservations\", \"current\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the baggage policies for domestic flights?\",\n",
    "        \"query_type\": \"policy_search\",\n",
    "        \"expected_actions\": [\"search_flight_policies\"],\n",
    "        \"expected_keywords\": [\"baggage\", \"policy\", \"domestic\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Book an economy flight from Miami to Boston next week\",\n",
    "        \"query_type\": \"flight_booking\",\n",
    "        \"expected_actions\": [\"save_flight_booking\"],\n",
    "        \"expected_keywords\": [\"economy\", \"Miami\", \"Boston\", \"next week\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Find the cheapest flights from Chicago to Seattle\",\n",
    "        \"query_type\": \"flight_search\",\n",
    "        \"expected_actions\": [\"lookup_flight_info\"],\n",
    "        \"expected_keywords\": [\"cheapest\", \"Chicago\", \"Seattle\", \"flights\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"📋 Created {len(evaluation_queries)} evaluation queries\")\n",
    "for i, query in enumerate(evaluation_queries, 1):\n",
    "    print(f\"  {i}. {query['query_type']}: {query['query']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Agent Evaluation\n",
    "\n",
    "Execute the flight search agent on evaluation queries with Phoenix tracing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Run evaluation with Phoenix tracing\n",
    "evaluation_results = []\n",
    "\n",
    "for i, test_case in enumerate(evaluation_queries, 1):\n",
    "    print(f\"\\n🔍 Running evaluation {i}/{len(evaluation_queries)}: {test_case['query']}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Create state and run agent\n",
    "        state = FlightSearchGraph.build_starting_state(query=test_case[\"query\"])\n",
    "\n",
    "        # Execute with Phoenix tracing\n",
    "        if PHOENIX_AVAILABLE:\n",
    "            with tracer:\n",
    "                result = compiled_graph.invoke(state)\n",
    "        else:\n",
    "            result = compiled_graph.invoke(state)\n",
    "\n",
    "        end_time = time.time()\n",
    "        response_time = end_time - start_time\n",
    "\n",
    "        # Extract response\n",
    "        response = \"\"\n",
    "        if result.get(\"messages\"):\n",
    "            for msg in result[\"messages\"]:\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    response += msg.content + \" \"\n",
    "\n",
    "        # Calculate basic quality score\n",
    "        quality_score = 0\n",
    "        expected_keywords = test_case.get(\"expected_keywords\", [])\n",
    "\n",
    "        for keyword in expected_keywords:\n",
    "            if keyword.lower() in response.lower():\n",
    "                quality_score += 1\n",
    "\n",
    "        # Normalize score (0-10)\n",
    "        max_score = len(expected_keywords) if expected_keywords else 1\n",
    "        normalized_score = (quality_score / max_score) * 10\n",
    "\n",
    "        # Store result\n",
    "        evaluation_results.append(\n",
    "            {\n",
    "                \"query\": test_case[\"query\"],\n",
    "                \"query_type\": test_case[\"query_type\"],\n",
    "                \"response\": response.strip(),\n",
    "                \"response_time\": response_time,\n",
    "                \"quality_score\": normalized_score,\n",
    "                \"success\": result.get(\"resolved\", False),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"  ✅ Success: {result.get('resolved', False)}\")\n",
    "        print(f\"  ⏱️  Response time: {response_time:.2f}s\")\n",
    "        print(f\"  📊 Quality score: {normalized_score:.1f}/10\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        evaluation_results.append(\n",
    "            {\n",
    "                \"query\": test_case[\"query\"],\n",
    "                \"query_type\": test_case[\"query_type\"],\n",
    "                \"response\": f\"Error: {str(e)}\",\n",
    "                \"response_time\": time.time() - start_time,\n",
    "                \"quality_score\": 0,\n",
    "                \"success\": False,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "print(f\"\\n📊 Evaluation completed:\")\n",
    "print(f\"  Total queries: {len(evaluation_results)}\")\n",
    "print(f\"  Successful: {results_df['success'].sum()}\")\n",
    "print(f\"  Average response time: {results_df['response_time'].mean():.2f}s\")\n",
    "print(f\"  Average quality score: {results_df['quality_score'].mean():.1f}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-as-a-Judge Evaluation\n",
    "\n",
    "Use Phoenix evaluators for advanced LLM-based evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PHOENIX_AVAILABLE:\n",
    "    print(\"🧠 Running LLM-as-a-Judge evaluation...\")\n",
    "\n",
    "    # Setup OpenAI model for evaluation\n",
    "    eval_model = OpenAIModel(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    # Prepare evaluation data\n",
    "    eval_data = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        eval_data.append(\n",
    "            {\n",
    "                \"input\": row[\"query\"],\n",
    "                \"output\": row[\"response\"],\n",
    "                \"reference\": f\"A helpful response about {row['query_type'].replace('_', ' ')}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    eval_df = pd.DataFrame(eval_data)\n",
    "\n",
    "    # Run correctness evaluation\n",
    "    try:\n",
    "        correctness_classifications = llm_classify(\n",
    "            dataframe=eval_df,\n",
    "            template=QA_PROMPT_TEMPLATE,\n",
    "            model=eval_model,\n",
    "            rails=list(QA_PROMPT_RAILS_MAP.values()),\n",
    "            provide_explanation=True,\n",
    "        )\n",
    "\n",
    "        # Add LLM evaluation results to main DataFrame\n",
    "        results_df[\"llm_correctness\"] = correctness_classifications[\"label\"]\n",
    "        results_df[\"llm_explanation\"] = correctness_classifications[\"explanation\"]\n",
    "\n",
    "        # Calculate LLM evaluation metrics\n",
    "        correct_responses = (correctness_classifications[\"label\"] == \"correct\").sum()\n",
    "        total_responses = len(correctness_classifications)\n",
    "        llm_accuracy = correct_responses / total_responses if total_responses > 0 else 0\n",
    "\n",
    "        print(f\"\\n🎯 LLM-as-a-Judge Results:\")\n",
    "        print(f\"  Correct responses: {correct_responses}/{total_responses}\")\n",
    "        print(f\"  LLM accuracy: {llm_accuracy:.1%}\")\n",
    "\n",
    "        # Show sample evaluations\n",
    "        print(f\"\\n📝 Sample LLM Evaluations:\")\n",
    "        for i, row in results_df.head(3).iterrows():\n",
    "            print(f\"  Query: {row['query'][:50]}...\")\n",
    "            print(f\"  LLM Judgment: {row['llm_correctness']}\")\n",
    "            print(f\"  Explanation: {row['llm_explanation'][:100]}...\")\n",
    "            print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ LLM evaluation failed: {e}\")\n",
    "        print(\"Continuing with basic evaluation metrics...\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Phoenix not available - skipping LLM-as-a-Judge evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Results and Phoenix UI\n",
    "\n",
    "Export evaluation results and show Phoenix observability dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"flight_agent_evaluation_{timestamp}.csv\"\n",
    "results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"📁 Results exported to: {csv_filename}\")\n",
    "print(f\"\\n📊 Final Evaluation Summary:\")\n",
    "print(f\"  Total queries: {len(results_df)}\")\n",
    "print(f\"  Success rate: {results_df['success'].mean():.1%}\")\n",
    "print(f\"  Average response time: {results_df['response_time'].mean():.2f}s\")\n",
    "print(f\"  Average quality score: {results_df['quality_score'].mean():.1f}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results Summary\n",
    "\n",
    "Display the evaluation results in a clean format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "print(\"📋 Evaluation Results Summary:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"\\n{i + 1}. {row['query_type'].replace('_', ' ').title()}\")\n",
    "    print(f\"   Query: {row['query']}\")\n",
    "    print(f\"   Success: {'✅' if row['success'] else '❌'}\")\n",
    "    print(f\"   Quality Score: {row['quality_score']:.1f}/10\")\n",
    "    print(f\"   Response Time: {row['response_time']:.2f}s\")\n",
    "\n",
    "    if \"llm_correctness\" in row:\n",
    "        print(f\"   LLM Judgment: {row['llm_correctness']}\")\n",
    "\n",
    "    # Show truncated response\n",
    "    response_preview = (\n",
    "        row[\"response\"][:100] + \"...\" if len(row[\"response\"]) > 100 else row[\"response\"]\n",
    "    )\n",
    "    print(f\"   Response: {response_preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Overall Success Rate: {results_df['success'].mean():.1%}\")\n",
    "print(f\"Average Quality Score: {results_df['quality_score'].mean():.1f}/10\")\n",
    "print(f\"Average Response Time: {results_df['response_time'].mean():.2f}s\")\n",
    "\n",
    "if PHOENIX_AVAILABLE and \"llm_correctness\" in results_df.columns:\n",
    "    correct_count = (results_df[\"llm_correctness\"] == \"correct\").sum()\n",
    "    total_count = len(results_df)\n",
    "    print(\n",
    "        f\"LLM-as-a-Judge Accuracy: {correct_count}/{total_count} ({correct_count / total_count:.1%})\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
